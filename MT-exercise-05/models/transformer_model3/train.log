2023-05-30 20:46:51,299 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers -                           cfg.name : transformer_model3
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers -                cfg.joeynmt_version : 2.0.0
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers -                     cfg.data.train : data/train
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers -                       cfg.data.dev : data/dev
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers -                      cfg.data.test : data/test
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers -              cfg.data.dataset_type : plain
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers -                  cfg.data.src.lang : nl
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers -                 cfg.data.src.level : bpe
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers -             cfg.data.src.lowercase : False
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers -       cfg.data.src.max_sent_length : 100
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers -              cfg.data.src.voc_file : data/bpe_vocab_6000.txt
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers -        cfg.data.src.tokenizer_type : subword-nmt
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.num_merges : 6000
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers -   cfg.data.src.tokenizer_cfg.codes : data/codes_file.6000
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.pretokenizer : none
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers -                  cfg.data.trg.lang : de
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers -                 cfg.data.trg.level : bpe
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers -             cfg.data.trg.lowercase : False
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers -       cfg.data.trg.max_sent_length : 100
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers -              cfg.data.trg.voc_file : data/bpe_vocab_6000.txt
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers -        cfg.data.trg.tokenizer_type : subword-nmt
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.num_merges : 6000
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers -   cfg.data.trg.tokenizer_cfg.codes : data/codes_file.6000
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.pretokenizer : none
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers -              cfg.testing.beam_size : 5
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers -                  cfg.testing.alpha : 1.0
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers -           cfg.training.random_seed : 42
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers -             cfg.training.optimizer : adam
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers -         cfg.training.normalization : tokens
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers -         cfg.training.learning_rate : 0.0003
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers -            cfg.training.batch_size : 2048
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers -            cfg.training.batch_type : token
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers -       cfg.training.eval_batch_size : 1024
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers -       cfg.training.eval_batch_type : token
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers -            cfg.training.scheduling : plateau
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers -              cfg.training.patience : 8
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers -          cfg.training.weight_decay : 0.0
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers -       cfg.training.decrease_factor : 0.7
2023-05-30 20:46:51,300 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers -                cfg.training.epochs : 10
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers -       cfg.training.validation_freq : 500
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers -          cfg.training.logging_freq : 100
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers -           cfg.training.eval_metric : bleu
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers -             cfg.training.model_dir : models/transformer_model3
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers -             cfg.training.overwrite : False
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers -               cfg.training.shuffle : True
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers -              cfg.training.use_cuda : False
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers -     cfg.training.max_output_length : 100
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers -     cfg.training.print_valid_sents : [0, 1, 2, 3, 4]
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers -       cfg.training.label_smoothing : 0.3
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers -              cfg.model.initializer : xavier_uniform
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers -         cfg.model.bias_initializer : zeros
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers -                cfg.model.init_gain : 1.0
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers -        cfg.model.embed_initializer : xavier_uniform
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers -          cfg.model.embed_init_gain : 1.0
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers -          cfg.model.tied_embeddings : True
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers -             cfg.model.tied_softmax : True
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers -             cfg.model.encoder.type : transformer
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers -       cfg.model.encoder.num_layers : 4
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers -        cfg.model.encoder.num_heads : 2
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers -      cfg.model.encoder.hidden_size : 256
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers -          cfg.model.encoder.ff_size : 512
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers -          cfg.model.encoder.dropout : 0
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers -             cfg.model.decoder.type : transformer
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers -       cfg.model.decoder.num_layers : 1
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers -        cfg.model.decoder.num_heads : 2
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers -      cfg.model.decoder.hidden_size : 256
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers -          cfg.model.decoder.ff_size : 512
2023-05-30 20:46:51,301 - INFO - joeynmt.helpers -          cfg.model.decoder.dropout : 0
2023-05-30 20:46:51,302 - INFO - joeynmt.data - Building tokenizer...
2023-05-30 20:46:51,311 - INFO - joeynmt.tokenizers - nl tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2023-05-30 20:46:51,311 - INFO - joeynmt.tokenizers - de tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2023-05-30 20:46:51,311 - INFO - joeynmt.data - Loading train set...
2023-05-30 20:46:51,404 - INFO - joeynmt.data - Building vocabulary...
2023-05-30 20:46:51,717 - INFO - joeynmt.data - Loading dev set...
2023-05-30 20:46:51,720 - INFO - joeynmt.data - Loading test set...
2023-05-30 20:46:51,722 - INFO - joeynmt.data - Data loaded.
2023-05-30 20:46:51,722 - INFO - joeynmt.data - Train dataset: PlaintextDataset(split=train, len=100000, src_lang=nl, trg_lang=de, has_trg=True, random_subset=-1)
2023-05-30 20:46:51,722 - INFO - joeynmt.data - Valid dataset: PlaintextDataset(split=dev, len=1001, src_lang=nl, trg_lang=de, has_trg=True, random_subset=-1)
2023-05-30 20:46:51,722 - INFO - joeynmt.data -  Test dataset: PlaintextDataset(split=test, len=1779, src_lang=nl, trg_lang=de, has_trg=True, random_subset=-1)
2023-05-30 20:46:51,722 - INFO - joeynmt.data - First training example:
	[SRC] Al Gor@@ e over het af@@ wen@@ den van de klimaat@@ cris@@ is
	[TRG] Al Gor@@ e: Die Ab@@ wen@@ dung der Klima@@ kat@@ ast@@ rop@@ he
2023-05-30 20:46:51,722 - INFO - joeynmt.data - First 10 Src tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) de (5) die (6) in (7) en (8) een (9) het
2023-05-30 20:46:51,722 - INFO - joeynmt.data - First 10 Trg tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) de (5) die (6) in (7) en (8) een (9) het
2023-05-30 20:46:51,722 - INFO - joeynmt.data - Number of unique Src tokens (vocab_size): 6258
2023-05-30 20:46:51,722 - INFO - joeynmt.data - Number of unique Trg tokens (vocab_size): 6258
2023-05-30 20:46:51,724 - INFO - joeynmt.model - Building an encoder-decoder model...
2023-05-30 20:46:51,775 - INFO - joeynmt.model - Enc-dec model built.
2023-05-30 20:46:51,776 - INFO - joeynmt.model - Total params: 4501248
2023-05-30 20:46:51,777 - DEBUG - joeynmt.model - Trainable parameters: ['decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'src_embed.lut.weight']
2023-05-30 20:46:51,777 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=6258),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=6258),
	loss_function=XentLoss(criterion=KLDivLoss(), smoothing=0.3))
2023-05-30 20:46:51,777 - INFO - joeynmt.builders - Adam(lr=0.0003, weight_decay=0.0, betas=(0.9, 0.999))
2023-05-30 20:46:51,777 - INFO - joeynmt.builders - ReduceLROnPlateau(mode=min, verbose=False, threshold_mode=abs, eps=0.0, factor=0.7, patience=8)
2023-05-30 20:46:51,777 - INFO - joeynmt.training - Train stats:
	device: cpu
	n_gpu: 0
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 2048
	effective batch size (w. parallel & accumulation): 2048
2023-05-30 20:46:51,777 - INFO - joeynmt.training - EPOCH 1
2023-05-30 20:47:09,725 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     4.604233, Batch Acc: 0.041949, Tokens per Sec:     3957, Lr: 0.000300
2023-05-30 20:47:28,063 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     4.559906, Batch Acc: 0.054339, Tokens per Sec:     3976, Lr: 0.000300
2023-05-30 20:47:46,930 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     4.421869, Batch Acc: 0.060354, Tokens per Sec:     3870, Lr: 0.000300
2023-05-30 20:48:06,533 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     4.389872, Batch Acc: 0.063253, Tokens per Sec:     3652, Lr: 0.000300
2023-05-30 20:48:24,023 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     4.203370, Batch Acc: 0.067991, Tokens per Sec:     4116, Lr: 0.000300
2023-05-30 20:48:24,023 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 20:48:24,023 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 20:49:46,495 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.26, ppl:  70.67, acc:   0.06, generation: 82.4532[sec], evaluation: 0.0000[sec]
2023-05-30 20:49:46,496 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 20:49:46,592 - INFO - joeynmt.training - Example #0
2023-05-30 20:49:46,592 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 20:49:46,592 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 20:49:46,592 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die']
2023-05-30 20:49:46,593 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 20:49:46,593 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 20:49:46,593 - INFO - joeynmt.training - 	Hypothesis: Und ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die
2023-05-30 20:49:46,593 - INFO - joeynmt.training - Example #1
2023-05-30 20:49:46,593 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 20:49:46,593 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 20:49:46,593 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich']
2023-05-30 20:49:46,593 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 20:49:46,593 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 20:49:46,593 - INFO - joeynmt.training - 	Hypothesis: Und ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich
2023-05-30 20:49:46,593 - INFO - joeynmt.training - Example #2
2023-05-30 20:49:46,593 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 20:49:46,593 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 20:49:46,593 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich']
2023-05-30 20:49:46,593 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 20:49:46,593 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 20:49:46,593 - INFO - joeynmt.training - 	Hypothesis: Und ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich
2023-05-30 20:49:46,593 - INFO - joeynmt.training - Example #3
2023-05-30 20:49:46,593 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 20:49:46,593 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 20:49:46,593 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'die', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der']
2023-05-30 20:49:46,594 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 20:49:46,594 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 20:49:46,594 - INFO - joeynmt.training - 	Hypothesis: Und ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich die der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der
2023-05-30 20:49:46,594 - INFO - joeynmt.training - Example #4
2023-05-30 20:49:46,594 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 20:49:46,594 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 20:49:46,594 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich']
2023-05-30 20:49:46,594 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 20:49:46,594 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 20:49:46,594 - INFO - joeynmt.training - 	Hypothesis: Und ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich
2023-05-30 20:50:06,237 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     4.132295, Batch Acc: 0.072949, Tokens per Sec:     3668, Lr: 0.000300
2023-05-30 20:50:25,919 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     4.058621, Batch Acc: 0.077733, Tokens per Sec:     3739, Lr: 0.000300
2023-05-30 20:50:44,428 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:     4.100940, Batch Acc: 0.083650, Tokens per Sec:     3868, Lr: 0.000300
2023-05-30 20:51:02,822 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:     4.095300, Batch Acc: 0.086401, Tokens per Sec:     3884, Lr: 0.000300
2023-05-30 20:51:22,791 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     3.957574, Batch Acc: 0.093934, Tokens per Sec:     3559, Lr: 0.000300
2023-05-30 20:51:22,791 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 20:51:22,791 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 20:52:49,308 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.03, ppl:  56.34, acc:   0.09, generation: 86.5025[sec], evaluation: 0.0000[sec]
2023-05-30 20:52:49,308 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 20:52:49,402 - INFO - joeynmt.training - Example #0
2023-05-30 20:52:49,403 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 20:52:49,403 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 20:52:49,403 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'ist', 'die', 'die', 'Sch@@', 'ü@@', 'te', 'der', 'Sch@@', 'ü@@', 'te', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'Sch@@', 'ä@@', 'te', 'der', 'Sch@@', 'ü@@', 'te', 'der', 'Sch@@', 'ä@@', 'te', 'der', 'Sch@@', 'ä@@', 'te', 'der', 'Sch@@', 'ä@@', 'te', 'der', 'Sch@@', 'ü@@', 'te', 'der', 'Sch@@', 'ü@@', 'te', 'der', 'Sch@@', 'ü@@', 'te', 'der', 'Sch@@', 'ä@@', 't', 'zu', 'der', 'Sch@@', 'ä@@', 't', 'zu', 'der', 'Sch@@', 'ä@@', 't', 'zu', 'zu', 'zu', 'zu', 'der', 'Sch@@', 'ä@@', 't', 'zu', 'der', 'Sch@@', 'ä@@', 't', 'zu', 'zu', 'der']
2023-05-30 20:52:49,403 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 20:52:49,403 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 20:52:49,403 - INFO - joeynmt.training - 	Hypothesis: Und ich ist die die Schüte der Schüte die die die die die die die die die die die die Schäte der Schüte der Schäte der Schäte der Schäte der Schüte der Schüte der Schüte der Schät zu der Schät zu der Schät zu zu zu zu der Schät zu der Schät zu zu der
2023-05-30 20:52:49,403 - INFO - joeynmt.training - Example #1
2023-05-30 20:52:49,403 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 20:52:49,403 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 20:52:49,403 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'wir', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu']
2023-05-30 20:52:49,403 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 20:52:49,403 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 20:52:49,403 - INFO - joeynmt.training - 	Hypothesis: Und wir nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu zu
2023-05-30 20:52:49,403 - INFO - joeynmt.training - Example #2
2023-05-30 20:52:49,403 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 20:52:49,403 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 20:52:49,403 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'die', 'die', 'die', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der']
2023-05-30 20:52:49,404 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 20:52:49,404 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 20:52:49,404 - INFO - joeynmt.training - 	Hypothesis: Das ist die die die der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der
2023-05-30 20:52:49,404 - INFO - joeynmt.training - Example #3
2023-05-30 20:52:49,404 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 20:52:49,404 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 20:52:49,404 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'die', 'die', 'der', 'Sch@@', 'ä@@', 't', 'und', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'der', 'Sch@@', 'ä@@', 't', '</s>']
2023-05-30 20:52:49,404 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 20:52:49,404 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 20:52:49,404 - INFO - joeynmt.training - 	Hypothesis: Das ist die die der Schät und die die die die die die die die der Schät
2023-05-30 20:52:49,404 - INFO - joeynmt.training - Example #4
2023-05-30 20:52:49,404 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 20:52:49,404 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 20:52:49,404 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'ist', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich']
2023-05-30 20:52:49,404 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 20:52:49,404 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 20:52:49,404 - INFO - joeynmt.training - 	Hypothesis: Und ich ist ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich
2023-05-30 20:53:09,645 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:     4.072000, Batch Acc: 0.095537, Tokens per Sec:     3499, Lr: 0.000300
2023-05-30 20:53:28,914 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:     3.958262, Batch Acc: 0.100322, Tokens per Sec:     3726, Lr: 0.000300
2023-05-30 20:53:48,464 - INFO - joeynmt.training - Epoch   1, Step:     1300, Batch Loss:     3.877798, Batch Acc: 0.102575, Tokens per Sec:     3725, Lr: 0.000300
2023-05-30 20:54:07,518 - INFO - joeynmt.training - Epoch   1, Step:     1400, Batch Loss:     4.005716, Batch Acc: 0.109395, Tokens per Sec:     3782, Lr: 0.000300
2023-05-30 20:54:27,366 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:     3.887220, Batch Acc: 0.113341, Tokens per Sec:     3582, Lr: 0.000300
2023-05-30 20:54:27,368 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 20:54:27,368 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 20:55:55,162 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.89, ppl:  48.98, acc:   0.11, generation: 87.7840[sec], evaluation: 0.0000[sec]
2023-05-30 20:55:55,163 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 20:55:55,258 - INFO - joeynmt.training - Example #0
2023-05-30 20:55:55,258 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 20:55:55,258 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 20:55:55,258 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'ich', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'Welt', 'zu', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der']
2023-05-30 20:55:55,259 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 20:55:55,259 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 20:55:55,259 - INFO - joeynmt.training - 	Hypothesis: Und ich habe ich die die die die die die die die die die Welt zu der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der
2023-05-30 20:55:55,259 - INFO - joeynmt.training - Example #1
2023-05-30 20:55:55,259 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 20:55:55,259 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 20:55:55,259 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'es', 'ist', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'zu', 'sein.', '</s>']
2023-05-30 20:55:55,259 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 20:55:55,259 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 20:55:55,259 - INFO - joeynmt.training - 	Hypothesis: Aber es ist nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht zu sein.
2023-05-30 20:55:55,259 - INFO - joeynmt.training - Example #2
2023-05-30 20:55:55,259 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 20:55:55,259 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 20:55:55,259 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'T@@', 'ä@@', 's@@', '-@@', 'T@@', 'ä@@', 's@@', '-@@', 'T@@', 'ä@@', 'e', 'in', 'der', 'T@@', 'ä@@', 's@@', '-@@', 'T@@', 'ä@@', 's@@', '-@@', 'T@@', 'ä@@', 's@@', '-@@', 'T@@', 'ä@@', 's@@', '-@@', 'T@@', 'ä@@', '.', '</s>']
2023-05-30 20:55:55,259 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 20:55:55,259 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 20:55:55,259 - INFO - joeynmt.training - 	Hypothesis: Die Täs-Täs-Täe in der Täs-Täs-Täs-Täs-Tä.
2023-05-30 20:55:55,259 - INFO - joeynmt.training - Example #3
2023-05-30 20:55:55,259 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 20:55:55,259 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 20:55:55,259 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'die', 'T@@', 'ä@@', 's', 'und', 'die', 'und', 'die', 'und', 'die', 'und', 'die', 'und', 'die', 'und', 'die', 'T@@', 'ä@@', '.', '</s>']
2023-05-30 20:55:55,259 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 20:55:55,259 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 20:55:55,259 - INFO - joeynmt.training - 	Hypothesis: Es ist die Täs und die und die und die und die und die und die Tä.
2023-05-30 20:55:55,260 - INFO - joeynmt.training - Example #4
2023-05-30 20:55:55,260 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 20:55:55,260 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 20:55:55,260 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'ist', 'ein', 'paar', 'der', 'Welt', 'in', 'der', 'Welt', 'in', 'der', 'Welt', 'in', 'der', 'Welt', 'in', 'der', 'Welt', 'in', 'der', 'Welt', 'in', 'der', 'Welt', 'in', 'der', 'Welt', 'zu', '.', '</s>']
2023-05-30 20:55:55,260 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 20:55:55,260 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 20:55:55,260 - INFO - joeynmt.training - 	Hypothesis: Die ist ein paar der Welt in der Welt in der Welt in der Welt in der Welt in der Welt in der Welt in der Welt zu .
2023-05-30 20:56:13,919 - INFO - joeynmt.training - Epoch   1, Step:     1600, Batch Loss:     3.863101, Batch Acc: 0.119019, Tokens per Sec:     3839, Lr: 0.000300
2023-05-30 20:56:33,472 - INFO - joeynmt.training - Epoch   1, Step:     1700, Batch Loss:     3.750609, Batch Acc: 0.123878, Tokens per Sec:     3743, Lr: 0.000300
2023-05-30 20:56:53,256 - INFO - joeynmt.training - Epoch   1, Step:     1800, Batch Loss:     3.629519, Batch Acc: 0.124479, Tokens per Sec:     3588, Lr: 0.000300
2023-05-30 20:57:12,357 - INFO - joeynmt.training - Epoch   1, Step:     1900, Batch Loss:     3.706898, Batch Acc: 0.129070, Tokens per Sec:     3730, Lr: 0.000300
2023-05-30 20:57:30,527 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:     3.770092, Batch Acc: 0.134066, Tokens per Sec:     4029, Lr: 0.000300
2023-05-30 20:57:30,527 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 20:57:30,527 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 20:58:59,805 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.72, ppl:  41.38, acc:   0.12, generation: 89.2688[sec], evaluation: 0.0000[sec]
2023-05-30 20:58:59,805 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 20:58:59,905 - INFO - joeynmt.training - Example #0
2023-05-30 20:58:59,906 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 20:58:59,906 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 20:58:59,906 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'ich', 'diese', 'Jahre', 'in', 'der', 'Jahre', 'in', 'der', 'Welt', 'zu', 'zu', 'den', 'Welt', 'zu', 'zu', 'zu', 'zu', 'zu', 'den', 'Jahre', 'in', 'der', 'Jahre', 'in', 'der', 'Jahre', 'in', 'der', 'Jahre', 'des', 'Jahre', 'in', 'der', 'Jahre', 'in', 'der', 'letzten', 'Jahren', 'in', 'der', 'Welt', 'in', 'der', 'Welt', 'in', 'der', 'Welt', 'in', 'der', 'Welt', 'in', 'der', 'Welt', 'in', 'der', 'Welt', 'in', 'der', 'Welt', 'in', 'der', 'Welt', 'in', 'der', 'Welt', 'in', 'der', 'letzten', 'Jahre', 'in', 'der', 'Welt', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu', 'zu']
2023-05-30 20:58:59,906 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 20:58:59,906 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 20:58:59,906 - INFO - joeynmt.training - 	Hypothesis: Und ich habe ich diese Jahre in der Jahre in der Welt zu zu den Welt zu zu zu zu zu den Jahre in der Jahre in der Jahre in der Jahre des Jahre in der Jahre in der letzten Jahren in der Welt in der Welt in der Welt in der Welt in der Welt in der Welt in der Welt in der Welt in der Welt in der letzten Jahre in der Welt zu zu zu zu zu zu zu zu zu zu
2023-05-30 20:58:59,906 - INFO - joeynmt.training - Example #1
2023-05-30 20:58:59,906 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 20:58:59,906 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 20:58:59,906 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'die', 'Welt', 'ist', 'die', 'Welt', 'der', 'Welt', 'ist', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'der', 'Welt', 'zu', 'der', 'Welt', 'zu', 'ist.', '</s>']
2023-05-30 20:58:59,906 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 20:58:59,906 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 20:58:59,906 - INFO - joeynmt.training - 	Hypothesis: Aber das ist die Welt ist die Welt der Welt ist nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht der Welt zu der Welt zu ist.
2023-05-30 20:58:59,906 - INFO - joeynmt.training - Example #2
2023-05-30 20:58:59,907 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 20:58:59,907 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 20:58:59,907 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'erste', 'erste', 'erste', 'erste', 'erste', 'erste', 'erste', 'ist', 'die', 'Sch@@', 'un@@', 'den', 'Sch@@', 'un@@', 'st@@', 'ä@@', 'm@@', '-@@', 'F@@', 'ä@@', '-@@', 'F@@', 'un@@', 's.', '</s>']
2023-05-30 20:58:59,907 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 20:58:59,907 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 20:58:59,907 - INFO - joeynmt.training - 	Hypothesis: Die erste erste erste erste erste erste erste ist die Schunden Schunstäm-Fä-Funs.
2023-05-30 20:58:59,907 - INFO - joeynmt.training - Example #3
2023-05-30 20:58:59,907 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 20:58:59,907 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 20:58:59,907 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'die', 'Sch@@', 'ei@@', 's@@', 'ischen', 'und', 'in', 'der', 'Sch@@', 'ei@@', 's@@', 'ischen', 'und', 'die', 'Sch@@', 'ei@@', 's@@', 'en.', '</s>']
2023-05-30 20:58:59,907 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 20:58:59,907 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 20:58:59,907 - INFO - joeynmt.training - 	Hypothesis: Es ist die Scheisischen und in der Scheisischen und die Scheisen.
2023-05-30 20:58:59,907 - INFO - joeynmt.training - Example #4
2023-05-30 20:58:59,907 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 20:58:59,907 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 20:58:59,907 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'erste', 'erste', 'erste', 'erste', 'erste', 'erste', 'ist', 'ein', 'paar', 'Jahren', 'ist', 'die', 'Welt', 'in', 'der', 'Welt', 'in', 'der', 'Welt', 'in', 'der', 'Welt', 'ist.', '</s>']
2023-05-30 20:58:59,907 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 20:58:59,907 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 20:58:59,907 - INFO - joeynmt.training - 	Hypothesis: Und die erste erste erste erste erste erste ist ein paar Jahren ist die Welt in der Welt in der Welt in der Welt ist.
2023-05-30 20:59:19,176 - INFO - joeynmt.training - Epoch   1, Step:     2100, Batch Loss:     3.631647, Batch Acc: 0.137587, Tokens per Sec:     3725, Lr: 0.000300
2023-05-30 20:59:39,064 - INFO - joeynmt.training - Epoch   1, Step:     2200, Batch Loss:     3.700787, Batch Acc: 0.143673, Tokens per Sec:     3568, Lr: 0.000300
2023-05-30 20:59:58,189 - INFO - joeynmt.training - Epoch   1, Step:     2300, Batch Loss:     3.568852, Batch Acc: 0.147025, Tokens per Sec:     3806, Lr: 0.000300
2023-05-30 21:00:17,677 - INFO - joeynmt.training - Epoch   1, Step:     2400, Batch Loss:     3.371417, Batch Acc: 0.150745, Tokens per Sec:     3529, Lr: 0.000300
2023-05-30 21:00:37,728 - INFO - joeynmt.training - Epoch   1, Step:     2500, Batch Loss:     3.388409, Batch Acc: 0.160583, Tokens per Sec:     3628, Lr: 0.000300
2023-05-30 21:00:37,728 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 21:00:37,728 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 21:02:01,480 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.54, ppl:  34.45, acc:   0.15, generation: 83.7429[sec], evaluation: 0.0000[sec]
2023-05-30 21:02:01,482 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 21:02:01,581 - INFO - joeynmt.training - Example #0
2023-05-30 21:02:01,581 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 21:02:01,581 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 21:02:01,581 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'diese', 'zwei', 'Jahren', 'über', 'diese', 'zwei', 'Jahren', 'zu', 'sehen,', 'dass', 'die', 'letzten', 'Jahren', 'um', 'die', 'letzten', 'Jahren', 'in', 'der', 'letzten', 'Jahren', 'in', 'der', 'letzten', 'Jahren', 'in', 'der', 'letzten', 'Jahren', 'in', 'der', 'letzten', 'Jahr', 'der', 'letzten', 'letzten', 'Jahren', 'von', 'der', 'letzten', 'Jahr', 'von', 'der', 'letzten', 'Jahr', 'von', 'der', 'letzten', 'Jahren', 'in', 'der', 'letzten', 'Jahren', 'in', 'der', 'letzten', 'Jahren', 'in', 'der', 'letzten', 'Jahren', 'in', 'der', 'letzten', 'Jahren', 'in', 'der', 'letzten', 'Jahren', 'in', 'der', 'letzten', 'Jahren', 'in', 'der', 'letzten', 'Jahren', 'über', 'den', 'letzten', 'Jahren', 'in', 'der']
2023-05-30 21:02:01,581 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 21:02:01,581 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 21:02:01,581 - INFO - joeynmt.training - 	Hypothesis: Ich habe diese zwei Jahren über diese zwei Jahren zu sehen, dass die letzten Jahren um die letzten Jahren in der letzten Jahren in der letzten Jahren in der letzten Jahren in der letzten Jahr der letzten letzten Jahren von der letzten Jahr von der letzten Jahr von der letzten Jahren in der letzten Jahren in der letzten Jahren in der letzten Jahren in der letzten Jahren in der letzten Jahren in der letzten Jahren in der letzten Jahren über den letzten Jahren in der
2023-05-30 21:02:01,582 - INFO - joeynmt.training - Example #1
2023-05-30 21:02:01,582 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 21:02:01,582 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 21:02:01,582 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'das', 'das', 'das', 'erste', 'erste', 'erste', 'Leben', 'ist', 'das', 'nicht', 'die', 'Welt', 'zu', 'tun', 'zu', 'zu', 'zu', 'zu', 'tun', 'zu', 'zu', 'tun', 'zu', 'tun', 'zu', 'tun', 'zu', 'tun', 'zu', 'tun', 'zu', 'tun', 'zu', 'tun', 'zu', 'tun', 'können.', '</s>']
2023-05-30 21:02:01,582 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 21:02:01,582 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 21:02:01,582 - INFO - joeynmt.training - 	Hypothesis: Aber das ist das das das erste erste erste Leben ist das nicht die Welt zu tun zu zu zu zu tun zu zu tun zu tun zu tun zu tun zu tun zu tun zu tun zu tun können.
2023-05-30 21:02:01,582 - INFO - joeynmt.training - Example #2
2023-05-30 21:02:01,582 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 21:02:01,582 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 21:02:01,582 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'erste', 'erste', 'erste', 'erste', 'erste', 'erste', 'erste', 'ist', 'das', 'erste', 'erste', 'erste', 'erste', 'erste', 'erste', 'Leben', 'zu', 'ver@@', 'st@@', 'ü@@', 'gt', 'zu', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'antwor@@', 't.', '</s>']
2023-05-30 21:02:01,582 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 21:02:01,582 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 21:02:01,582 - INFO - joeynmt.training - 	Hypothesis: Die erste erste erste erste erste erste erste ist das erste erste erste erste erste erste Leben zu verstügt zu verververververantwort.
2023-05-30 21:02:01,582 - INFO - joeynmt.training - Example #3
2023-05-30 21:02:01,582 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 21:02:01,582 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 21:02:01,582 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'gibt', 'in', 'der', 'Sch@@', 'ei@@', 'g@@', 't@@', 't@@', 't@@', 'ü@@', 'gen', 'in', 'der', 'T@@', 'an@@', 's.', '</s>']
2023-05-30 21:02:01,582 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 21:02:01,582 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 21:02:01,583 - INFO - joeynmt.training - 	Hypothesis: Es gibt in der Scheigtttügen in der Tans.
2023-05-30 21:02:01,583 - INFO - joeynmt.training - Example #4
2023-05-30 21:02:01,583 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 21:02:01,583 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 21:02:01,583 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'erste', 'erste', 'erste', 'erste', 'erste', 'erste', 'erste', 'ist', 'eine', 'Art', 'der', 'Welt', 'der', 'Welt', 'der', 'Welt', 'der', 'Welt', 'in', 'der', 'Welt', 'in', 'der', 'Welt', 'in', 'der', 'Welt', 'in', 'der', 'Welt', 'ist.', '</s>']
2023-05-30 21:02:01,583 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 21:02:01,583 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 21:02:01,583 - INFO - joeynmt.training - 	Hypothesis: Die erste erste erste erste erste erste erste ist eine Art der Welt der Welt der Welt der Welt in der Welt in der Welt in der Welt in der Welt ist.
2023-05-30 21:02:20,841 - INFO - joeynmt.training - Epoch   1, Step:     2600, Batch Loss:     3.603421, Batch Acc: 0.168873, Tokens per Sec:     3856, Lr: 0.000300
2023-05-30 21:02:38,461 - INFO - joeynmt.training - Epoch   1, Step:     2700, Batch Loss:     3.314482, Batch Acc: 0.173965, Tokens per Sec:     4132, Lr: 0.000300
2023-05-30 21:02:56,465 - INFO - joeynmt.training - Epoch   1, Step:     2800, Batch Loss:     3.281456, Batch Acc: 0.179346, Tokens per Sec:     4132, Lr: 0.000300
2023-05-30 21:03:13,840 - INFO - joeynmt.training - Epoch   1, Step:     2900, Batch Loss:     3.379576, Batch Acc: 0.186643, Tokens per Sec:     4149, Lr: 0.000300
2023-05-30 21:03:31,353 - INFO - joeynmt.training - Epoch   1, Step:     3000, Batch Loss:     3.351151, Batch Acc: 0.197549, Tokens per Sec:     4115, Lr: 0.000300
2023-05-30 21:03:31,354 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 21:03:31,354 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 21:04:54,187 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.35, ppl:  28.55, acc:   0.19, generation: 82.8245[sec], evaluation: 0.0000[sec]
2023-05-30 21:04:54,188 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 21:04:54,279 - INFO - joeynmt.helpers - delete models/transformer_model3/500.ckpt
2023-05-30 21:04:54,279 - INFO - joeynmt.training - Example #0
2023-05-30 21:04:54,279 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 21:04:54,279 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 21:04:54,279 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Meine', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Jahren', 'zu', 'sehen,', 'dass', 'die', 'die', 'Geschichte', 'der', 'der', 'der', 'der', 'letzten', 'Jahren', 'der', 'der', 'letzten', 'Jahren', 'der', 'der', 'der', 'letzten', 'Jahren', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'K@@', 'amp@@', 'f', 'der', 'der', 'der', 'der', 'K@@', 'un@@', 'un@@', 'un@@', 'un@@', 's.', '</s>']
2023-05-30 21:04:54,279 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 21:04:54,279 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 21:04:54,279 - INFO - joeynmt.training - 	Hypothesis: Meine Jahr habe ich diese zwei Jahren zu sehen, dass die die Geschichte der der der der letzten Jahren der der letzten Jahren der der der letzten Jahren der der der der der der der der der der der der der Kampf der der der der Kununununs.
2023-05-30 21:04:54,279 - INFO - joeynmt.training - Example #1
2023-05-30 21:04:54,279 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 21:04:54,279 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 21:04:54,279 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'das', 'das', 'das', 'ist', 'das', 'das', 'das', 'das', 'Problem', 'der', 'der', 'W@@', 'ett@@', 'ung', 'der', 'W@@', 'ü@@', 'cht@@', 'ung', 'der', 'W@@', 'ü@@', 'cht@@', 'ung', 'der', 'W@@', 'ett@@', 'ung', 'der', 'W@@', 'ett@@', 'ung.', '</s>']
2023-05-30 21:04:54,280 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 21:04:54,280 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 21:04:54,280 - INFO - joeynmt.training - 	Hypothesis: Aber das ist das das das ist das das das das Problem der der Wettung der Wüchtung der Wüchtung der Wettung der Wettung.
2023-05-30 21:04:54,280 - INFO - joeynmt.training - Example #2
2023-05-30 21:04:54,280 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 21:04:54,280 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 21:04:54,280 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'erste', 'ist', 'die', 'B@@', 'all@@', '-@@', 'E@@', '-@@', 'E@@', 'y@@', 'y@@', '-@@', 'P@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'it@@', 'en.', '</s>']
2023-05-30 21:04:54,280 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 21:04:54,280 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 21:04:54,280 - INFO - joeynmt.training - 	Hypothesis: Die erste ist die Ball-E-Eyy-Pitititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititen.
2023-05-30 21:04:54,280 - INFO - joeynmt.training - Example #3
2023-05-30 21:04:54,280 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 21:04:54,280 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 21:04:54,280 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'S@@', 'and@@', 'z@@', 'z@@', 'z@@', 'z@@', 'z@@', 'z@@', 'ischen', 'und', 'in', 'der', 'S@@', 'and@@', 'z@@', 'z@@', 'z@@', 'z@@', 'z@@', 'z@@', 'z@@', 'ischen', 'und', 'die', 'S@@', 'ig@@', 'ig@@', 'ig@@', 'ig@@', 'ig@@', 'ig@@', 'ig@@', 'ig@@', 'ig@@', 't.', '</s>']
2023-05-30 21:04:54,280 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 21:04:54,280 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 21:04:54,280 - INFO - joeynmt.training - 	Hypothesis: Es ist in der Sandzzzzzzischen und in der Sandzzzzzzzischen und die Sigigigigigigigigigt.
2023-05-30 21:04:54,280 - INFO - joeynmt.training - Example #4
2023-05-30 21:04:54,280 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 21:04:54,280 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 21:04:54,280 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'erste', 'ist', 'die', 'ich', 'die', 'Geschichte', 'der', 'der', 'der', 'der', 'der', 'Geschichte', 'der', 'der', 'der', 'letzten', '2@@', '7', 'Jahre', 'der', 'letzten', 'letzten', 'Jahren', '</s>']
2023-05-30 21:04:54,281 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 21:04:54,281 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 21:04:54,281 - INFO - joeynmt.training - 	Hypothesis: Die erste ist die ich die Geschichte der der der der der Geschichte der der der letzten 27 Jahre der letzten letzten Jahren
2023-05-30 21:05:13,577 - INFO - joeynmt.training - Epoch   1, Step:     3100, Batch Loss:     3.244377, Batch Acc: 0.201278, Tokens per Sec:     3761, Lr: 0.000300
2023-05-30 21:05:32,896 - INFO - joeynmt.training - Epoch   1, Step:     3200, Batch Loss:     3.243600, Batch Acc: 0.207851, Tokens per Sec:     3781, Lr: 0.000300
2023-05-30 21:05:51,627 - INFO - joeynmt.training - Epoch   1, Step:     3300, Batch Loss:     3.179797, Batch Acc: 0.212311, Tokens per Sec:     3776, Lr: 0.000300
2023-05-30 21:06:10,766 - INFO - joeynmt.training - Epoch   1, Step:     3400, Batch Loss:     3.153517, Batch Acc: 0.213526, Tokens per Sec:     3788, Lr: 0.000300
2023-05-30 21:06:30,167 - INFO - joeynmt.training - Epoch   1, Step:     3500, Batch Loss:     3.041384, Batch Acc: 0.220032, Tokens per Sec:     3705, Lr: 0.000300
2023-05-30 21:06:30,168 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 21:06:30,168 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 21:07:56,818 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.19, ppl:  24.32, acc:   0.21, generation: 86.6407[sec], evaluation: 0.0000[sec]
2023-05-30 21:07:56,819 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 21:07:56,911 - INFO - joeynmt.helpers - delete models/transformer_model3/1000.ckpt
2023-05-30 21:07:56,915 - INFO - joeynmt.training - Example #0
2023-05-30 21:07:56,915 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 21:07:56,915 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 21:07:56,915 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'dann', 'habe', 'ich', 'zwei', 'Jahren', 'haben', 'diese', 'zwei', 'Dollar', 'zu', 'sehen,', 'dass', 'die', 'die', 'K@@', 'af@@', 'f@@', 'f@@', 'f@@', 'f@@', 'ik@@', 'ik@@', 'ik@@', 'ik@@', 'ik@@', 'ik@@', 'ik@@', 'ik@@', 'ik@@', 'ik@@', 'ik@@', 'ik@@', 'ik@@', 'ation', 'von', 'der', 'letzten', 'Jahren', 'in', 'der', 'Er@@', 'd@@', 'ungs@@', 'ungs@@', '-@@', 'H@@', 'ell@@', ',', 'die', 'die', 'die', 'Er@@', 'de.', '</s>']
2023-05-30 21:07:56,916 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 21:07:56,916 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 21:07:56,916 - INFO - joeynmt.training - 	Hypothesis: Und dann habe ich zwei Jahren haben diese zwei Dollar zu sehen, dass die die Kafffffikikikikikikikikikikikikikation von der letzten Jahren in der Erdungsungs-Hell, die die die Erde.
2023-05-30 21:07:56,916 - INFO - joeynmt.training - Example #1
2023-05-30 21:07:56,916 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 21:07:56,916 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 21:07:56,916 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'die', 'Er@@', 'klär@@', 'ung', 'der', 'Er@@', 'klär@@', 'ung', 'des', 'Teil', 'der', 'Er@@', 'klär@@', 'ung', 'des', 'des', 'des', 'des', 'des', 'des', 'des', 'des', 'des', 'Ver@@', 'sion', 'des', 'des', 'Ver@@', 'sion', 'des', 'des', 'Sch@@', 'lag@@', 's', 'zu', 'sehen.', '</s>']
2023-05-30 21:07:56,916 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 21:07:56,916 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 21:07:56,916 - INFO - joeynmt.training - 	Hypothesis: Aber das ist die Erklärung der Erklärung des Teil der Erklärung des des des des des des des des des Version des des Version des des Schlags zu sehen.
2023-05-30 21:07:56,916 - INFO - joeynmt.training - Example #2
2023-05-30 21:07:56,916 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 21:07:56,916 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 21:07:56,916 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'erste', 'ist', 'die', 'B@@', 'äume', 'auf', 'der', 'B@@', 'äume', 'ist', 'der', 'Er@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'ün@@', 'd@@', 'lichen', 'Ver@@', 'sion', 'von', 'uns', 'die', 'Er@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'ün@@', 'd@@', 'lichen', 'ist.', '</s>']
2023-05-30 21:07:56,916 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 21:07:56,916 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 21:07:56,916 - INFO - joeynmt.training - 	Hypothesis: Die erste ist die Bäume auf der Bäume ist der Erdddddddündlichen Version von uns die Erddddddündlichen ist.
2023-05-30 21:07:56,916 - INFO - joeynmt.training - Example #3
2023-05-30 21:07:56,916 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 21:07:56,916 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 21:07:56,916 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'wird', 'in', 'der', 'K@@', 'af@@', 'f@@', 'f@@', 'ä@@', 'ff@@', 'lich', 'in', 'der', 'K@@', 'af@@', 'f@@', 'er.', '</s>']
2023-05-30 21:07:56,917 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 21:07:56,917 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 21:07:56,917 - INFO - joeynmt.training - 	Hypothesis: Es wird in der Kafffäfflich in der Kaffer.
2023-05-30 21:07:56,917 - INFO - joeynmt.training - Example #4
2023-05-30 21:07:56,917 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 21:07:56,917 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 21:07:56,917 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'erste', 'erste', 'hier', 'ist', 'ein', 'der', 'der', 'Er@@', 'd@@', 'ungs@@', 'ge@@', 'ge@@', 'tr@@', 'eten', 'ist', 'die', 'Er@@', 'klär@@', 'ung', 'der', 'Welt', 'ist.', '</s>']
2023-05-30 21:07:56,917 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 21:07:56,917 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 21:07:56,917 - INFO - joeynmt.training - 	Hypothesis: Und die erste erste hier ist ein der der Erdungsgegetreten ist die Erklärung der Welt ist.
2023-05-30 21:08:04,419 - INFO - joeynmt.training - Epoch   1: total training loss 13377.39
2023-05-30 21:08:04,419 - INFO - joeynmt.training - EPOCH 2
2023-05-30 21:08:15,345 - INFO - joeynmt.training - Epoch   2, Step:     3600, Batch Loss:     2.994110, Batch Acc: 0.236268, Tokens per Sec:     4069, Lr: 0.000300
2023-05-30 21:08:34,228 - INFO - joeynmt.training - Epoch   2, Step:     3700, Batch Loss:     3.026306, Batch Acc: 0.234724, Tokens per Sec:     3776, Lr: 0.000300
2023-05-30 21:08:52,935 - INFO - joeynmt.training - Epoch   2, Step:     3800, Batch Loss:     3.073104, Batch Acc: 0.242736, Tokens per Sec:     3884, Lr: 0.000300
2023-05-30 21:09:11,784 - INFO - joeynmt.training - Epoch   2, Step:     3900, Batch Loss:     2.846866, Batch Acc: 0.245007, Tokens per Sec:     3939, Lr: 0.000300
2023-05-30 21:09:29,673 - INFO - joeynmt.training - Epoch   2, Step:     4000, Batch Loss:     3.004935, Batch Acc: 0.250880, Tokens per Sec:     4048, Lr: 0.000300
2023-05-30 21:09:29,673 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 21:09:29,673 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 21:10:51,038 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.07, ppl:  21.59, acc:   0.23, generation: 81.3562[sec], evaluation: 0.0000[sec]
2023-05-30 21:10:51,039 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 21:10:51,132 - INFO - joeynmt.helpers - delete models/transformer_model3/1500.ckpt
2023-05-30 21:10:51,136 - INFO - joeynmt.training - Example #0
2023-05-30 21:10:51,136 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 21:10:51,136 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 21:10:51,136 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor', 'einigen', 'Jahren', 'habe', 'ich', 'zwei', 'Wochen', 'zwei', 'zwei', 'Stunden', 'Stunden', 'zu', 'sehen,', 'dass', 'die', 'die', 'drei', 'Millionen', 'Jahre', 'Jahre', 'Jahre', 'in', 'der', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'Jahr@@', ',', 'der', 'der', 'der', 'der', 'letzten', 'zwei', 'Millionen', 'von', 'der', 'der', 'letzten', 'Jahr@@', '.', '</s>']
2023-05-30 21:10:51,136 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 21:10:51,136 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 21:10:51,136 - INFO - joeynmt.training - 	Hypothesis: Vor einigen Jahren habe ich zwei Wochen zwei zwei Stunden Stunden zu sehen, dass die die drei Millionen Jahre Jahre Jahre in der letzten letzten letzten letzten letzten letzten Jahr, der der der der letzten zwei Millionen von der der letzten Jahr.
2023-05-30 21:10:51,136 - INFO - joeynmt.training - Example #1
2023-05-30 21:10:51,136 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 21:10:51,136 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 21:10:51,136 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'die', 'W@@', 'ieder@@', 'auf@@', 'grund', 'der', 'Teil', 'des', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'W@@', 'ieder@@', 'grund', 'der', 'E@@', 'E@@', 'E@@', 'E@@', 'E@@', 'E@@', 'E@@', 'E@@', 'E@@', 'E@@', 'E@@', 'E@@', 'E@@', 'E@@', 'E@@', 'E@@', 'E@@', 'E@@', 'E@@', 'E@@', 'E@@', 'E@@', 'E@@', 'E@@', 'E@@', 'E@@', 'E@@', 'E@@', 'E@@', 'rei@@', 'st.', '</s>']
2023-05-30 21:10:51,136 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 21:10:51,136 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 21:10:51,136 - INFO - joeynmt.training - 	Hypothesis: Aber das ist die Wiederaufgrund der Teil des Problem ist, weil es nicht die Wiedergrund der EEEEEEEEEEEEEEEEEEEEEEEEEEEEEreist.
2023-05-30 21:10:51,136 - INFO - joeynmt.training - Example #2
2023-05-30 21:10:51,136 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 21:10:51,136 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 21:10:51,136 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'F@@', 'ein@@', 'halb', 'der', 'ersten', 'ersten', 'T@@', 'ag,', 'ist', 'in', 'der', 'T@@', 'ele@@', 'genheit', 'der', 'Er@@', 'wachsen@@', 'en', 'von', 'uns', 'von', 'uns', 'in', 'der', 'Meer@@', 'es@@', 'es@@', 'es@@', 'es@@', 'ischen', 'Re@@', 'sult@@', 'y@@', '-@@', 'N@@', 'icht@@', 'icht@@', 'icht@@', 's@@', 's@@', 's@@', 's@@', 'ü@@', 'cken', '</s>']
2023-05-30 21:10:51,137 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 21:10:51,137 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 21:10:51,137 - INFO - joeynmt.training - 	Hypothesis: Die Feinhalb der ersten ersten Tag, ist in der Telegenheit der Erwachsenen von uns von uns in der Meeresesesesischen Resulty-Nichtichtichtssssücken
2023-05-30 21:10:51,137 - INFO - joeynmt.training - Example #3
2023-05-30 21:10:51,137 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 21:10:51,137 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 21:10:51,137 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'K@@', 'lei@@', 'der', 'und', 'in', 'der', 'K@@', 'amp@@', 'f', 'der', 'H@@', 'äus@@', 'er.', '</s>']
2023-05-30 21:10:51,137 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 21:10:51,137 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 21:10:51,137 - INFO - joeynmt.training - 	Hypothesis: Es ist in der Kleider und in der Kampf der Häuser.
2023-05-30 21:10:51,137 - INFO - joeynmt.training - Example #4
2023-05-30 21:10:51,137 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 21:10:51,137 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 21:10:51,137 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'erste', 'Mal', 'die', 'ich', 'Ihnen', 'hier', 'sehen', 'ist', 'ein', 'Sch@@', 'wier@@', 'igkei@@', 't,', 'was', 'die', 'letzten', '2@@', '5', 'Jahren', 'ist', 'das', 'letzten', '2@@', '2@@', '%', 'ist.', '</s>']
2023-05-30 21:10:51,137 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 21:10:51,137 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 21:10:51,137 - INFO - joeynmt.training - 	Hypothesis: Die erste Mal die ich Ihnen hier sehen ist ein Schwierigkeit, was die letzten 25 Jahren ist das letzten 22% ist.
2023-05-30 21:11:11,094 - INFO - joeynmt.training - Epoch   2, Step:     4100, Batch Loss:     2.935196, Batch Acc: 0.249752, Tokens per Sec:     3569, Lr: 0.000300
2023-05-30 21:11:29,820 - INFO - joeynmt.training - Epoch   2, Step:     4200, Batch Loss:     2.806153, Batch Acc: 0.256842, Tokens per Sec:     3922, Lr: 0.000300
2023-05-30 21:11:48,901 - INFO - joeynmt.training - Epoch   2, Step:     4300, Batch Loss:     2.844475, Batch Acc: 0.263199, Tokens per Sec:     3798, Lr: 0.000300
2023-05-30 21:12:07,180 - INFO - joeynmt.training - Epoch   2, Step:     4400, Batch Loss:     2.944295, Batch Acc: 0.269179, Tokens per Sec:     3827, Lr: 0.000300
2023-05-30 21:12:25,667 - INFO - joeynmt.training - Epoch   2, Step:     4500, Batch Loss:     3.104881, Batch Acc: 0.273643, Tokens per Sec:     3902, Lr: 0.000300
2023-05-30 21:12:25,667 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 21:12:25,667 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 21:13:47,775 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.97, ppl:  19.49, acc:   0.25, generation: 82.1003[sec], evaluation: 0.0000[sec]
2023-05-30 21:13:47,776 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 21:13:47,865 - INFO - joeynmt.helpers - delete models/transformer_model3/2000.ckpt
2023-05-30 21:13:47,868 - INFO - joeynmt.training - Example #0
2023-05-30 21:13:47,868 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 21:13:47,868 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 21:13:47,868 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'ich', 'habe', 'diese', 'zwei', 'Jahre', 'später', 'habe', 'ich', 'zwei', 'Jahren', 'die', 'die', 'D@@', 'rit@@', 'tel', 'der', 'der', 'der', 'letzten', 'drei', 'Millionen', 'Jahren', 'die', 'letzten', 'drei', 'Millionen', 'Jahren', 'die', 'die', 'die', 'drei', 'Millionen', 'Jahren', 'der', 'der', 'V@@', 'at@@', 'at@@', 'at@@', 'ur', 'der', 'S@@', 'S@@', ',', 'mit', 'der', 'S@@', 'ig@@', 'ig@@', 'ig@@', 'ar@@', ',', '</s>']
2023-05-30 21:13:47,868 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 21:13:47,868 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 21:13:47,868 - INFO - joeynmt.training - 	Hypothesis: Aber ich habe diese zwei Jahre später habe ich zwei Jahren die die Drittel der der der letzten drei Millionen Jahren die letzten drei Millionen Jahren die die die drei Millionen Jahren der der Vatatatur der SS, mit der Sigigigar,
2023-05-30 21:13:47,868 - INFO - joeynmt.training - Example #1
2023-05-30 21:13:47,869 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 21:13:47,869 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 21:13:47,869 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'die', 'die', 'Ver@@', 'sion', 'des', 'E@@', 'is', 'des', 'E@@', 'is', 'nicht', 'die', 'die', 'nicht', 'die', 'die', 'die', 'nicht', 'die', 'die', 'D@@', 'rit@@', 'tel', 'des', 'E@@', 'is', 'des', 'E@@', 'is', 'des', 'E@@', 'is', 'des', 'E@@', 'is', 'des', 'E@@', 'is', 'zu', 'sehen.', '</s>']
2023-05-30 21:13:47,869 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 21:13:47,869 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 21:13:47,869 - INFO - joeynmt.training - 	Hypothesis: Aber das ist die die Version des Eis des Eis nicht die die nicht die die die nicht die die Drittel des Eis des Eis des Eis des Eis des Eis zu sehen.
2023-05-30 21:13:47,869 - INFO - joeynmt.training - Example #2
2023-05-30 21:13:47,869 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 21:13:47,869 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 21:13:47,869 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'F@@', 'isch@@', 'er@@', 'ei@@', 'ch@@', 's@@', 'eines', 'der', 'Nor@@', 'd@@', 'd@@', '-@@', 'F@@', 'isch@@', 'er@@', 's,', 'das', 'ist', 'ein', 'Ver@@', 'sion', 'der', 'Kon@@', 'text', 'der', 'I@@', 'mm@@', 'y@@', 'y@@', '-@@', 'F@@', 'isch@@', 'er@@', 'er@@', 'ei@@', 'ch@@', '-@@', 'F@@', 'äll@@', 'e', 'er@@', 'er@@', 'ei@@', 'ch@@', 'lo@@', 'se', 'zu', 'er@@', 'halten.', '</s>']
2023-05-30 21:13:47,869 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 21:13:47,869 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 21:13:47,869 - INFO - joeynmt.training - 	Hypothesis: Die Fischereichseines der Nordd-Fischers, das ist ein Version der Kontext der Immyy-Fischerereich-Fälle erereichlose zu erhalten.
2023-05-30 21:13:47,869 - INFO - joeynmt.training - Example #3
2023-05-30 21:13:47,869 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 21:13:47,869 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 21:13:47,869 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'aus', 'der', 'K@@', 'ern@@', 'e', 'in', 'der', 'S@@', 'ig@@', 'n@@', 'al', 'in', 'der', 'S@@', 'eh@@', 'n@@', 'n@@', 'is.', '</s>']
2023-05-30 21:13:47,869 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 21:13:47,869 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 21:13:47,869 - INFO - joeynmt.training - 	Hypothesis: Es ist aus der Kerne in der Signal in der Sehnnis.
2023-05-30 21:13:47,869 - INFO - joeynmt.training - Example #4
2023-05-30 21:13:47,870 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 21:13:47,870 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 21:13:47,870 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'nächste', 'nächste', 'Mal', 'die', 'ich', 'Ihnen', 'sehen,', 'ist', 'eine', 'Ver@@', 'sion', 'der', 'letzten', '25', 'Jahren', 'ist', 'der', 'letzten', '25', 'Jahren', 'ist', 'das', 'im', 'letzten', 'letzten', '25', 'Jahren', 'ist.', '</s>']
2023-05-30 21:13:47,870 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 21:13:47,870 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 21:13:47,870 - INFO - joeynmt.training - 	Hypothesis: Die nächste nächste nächste Mal die ich Ihnen sehen, ist eine Version der letzten 25 Jahren ist der letzten 25 Jahren ist das im letzten letzten 25 Jahren ist.
2023-05-30 21:14:06,610 - INFO - joeynmt.training - Epoch   2, Step:     4600, Batch Loss:     2.738904, Batch Acc: 0.276569, Tokens per Sec:     3718, Lr: 0.000300
2023-05-30 21:14:24,240 - INFO - joeynmt.training - Epoch   2, Step:     4700, Batch Loss:     2.771536, Batch Acc: 0.280948, Tokens per Sec:     4080, Lr: 0.000300
2023-05-30 21:14:42,158 - INFO - joeynmt.training - Epoch   2, Step:     4800, Batch Loss:     2.851394, Batch Acc: 0.288182, Tokens per Sec:     4045, Lr: 0.000300
2023-05-30 21:15:00,666 - INFO - joeynmt.training - Epoch   2, Step:     4900, Batch Loss:     2.848741, Batch Acc: 0.296873, Tokens per Sec:     3894, Lr: 0.000300
2023-05-30 21:15:19,613 - INFO - joeynmt.training - Epoch   2, Step:     5000, Batch Loss:     2.853742, Batch Acc: 0.297911, Tokens per Sec:     3849, Lr: 0.000300
2023-05-30 21:15:19,613 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 21:15:19,613 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 21:16:41,795 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.85, ppl:  17.33, acc:   0.27, generation: 82.1735[sec], evaluation: 0.0000[sec]
2023-05-30 21:16:41,797 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 21:16:41,888 - INFO - joeynmt.helpers - delete models/transformer_model3/2500.ckpt
2023-05-30 21:16:41,888 - INFO - joeynmt.training - Example #0
2023-05-30 21:16:41,888 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 21:16:41,889 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 21:16:41,889 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'diese', 'zwei', 'Di@@', 'mensi@@', 'on', 'hier', 'zwei', 'Di@@', 'mensi@@', 'on', 'zu', 'zeigen,', 'dass', 'die', 'P@@', 'han@@', 'g', 'der', 'letzten', 'drei', 'Millionen', 'Jahren', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', 'in', 'der', 'V@@', 'at@@', 'at@@', 'at@@', 'at@@', 'ur', 'von', 'V@@', 'at@@', 'at@@', 'at@@', 'ten', 'von', 'V@@', 'ier@@', 'tel', 'der', 'V@@', 'at@@', 'at@@', 'men', 'von', 'V@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'ischen', 'Jahren', 'in', 'der', 'V@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'men', 'von', 'der', 'USA', 'in', 'der', 'USA', 'in', 'der']
2023-05-30 21:16:41,889 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 21:16:41,889 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 21:16:41,889 - INFO - joeynmt.training - 	Hypothesis: Ich habe diese zwei Dimension hier zwei Dimension zu zeigen, dass die Phang der letzten drei Millionen Jahren in den letzten drei Millionen Jahren in den letzten drei Millionen Jahren in der Vatatatatur von Vatatatten von Viertel der Vatatmen von Vatatatatatischen Jahren in der Vatatatatatmen von der USA in der USA in der
2023-05-30 21:16:41,889 - INFO - joeynmt.training - Example #1
2023-05-30 21:16:41,889 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 21:16:41,889 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 21:16:41,889 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'die', 'Be@@', 'gin@@', 'n', 'der', 'Be@@', 'gin@@', 'n', 'des', 'Proble@@', 'ms', 'zu', 'sehen,', 'weil', 'es', 'nicht', 'die', 'der', 'der', 'Re@@', 'alität', 'des', 'E@@', 'is', 'zu', 'sehen.', '</s>']
2023-05-30 21:16:41,889 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 21:16:41,889 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 21:16:41,889 - INFO - joeynmt.training - 	Hypothesis: Aber das ist die Beginn der Beginn des Problems zu sehen, weil es nicht die der der Realität des Eis zu sehen.
2023-05-30 21:16:41,889 - INFO - joeynmt.training - Example #2
2023-05-30 21:16:41,889 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 21:16:41,889 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 21:16:41,889 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'Sch@@', 'w@@', 'ör@@', 'der@@', 'auf', 'der', 'Nor@@', 'd@@', 'br@@', 'ing@@', 't,', 'ist', 'ein', 'bisschen', 'wie', 'es', 'S@@', 'icht', 'des', 'I@@', 'll@@', 's', 'der', 'I@@', 'mm@@', 'mm@@', 'mm@@', 'mm@@', 'mm@@', 'mm@@', 'mm@@', 'er', 'zu', 'unserem', 'O@@', 'ff@@', 'en.', '</s>']
2023-05-30 21:16:41,889 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 21:16:41,889 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 21:16:41,889 - INFO - joeynmt.training - 	Hypothesis: Die Schwörderauf der Nordbringt, ist ein bisschen wie es Sicht des Ills der Immmmmmmmmmmmmmer zu unserem Offen.
2023-05-30 21:16:41,889 - INFO - joeynmt.training - Example #3
2023-05-30 21:16:41,890 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 21:16:41,890 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 21:16:41,890 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'gibt', 'aus', 'der', 'K@@', 'unden', 'und', 'und', 'K@@', 'im@@', 'ation', 'in', 'der', 'K@@', 'ilometer', 'in', 'der', 'S@@', 'omm@@', 'er', 'in', 'der', 'K@@', 'ilometer', 'in', 'der', 'K@@', 'ilometer', 'im', 'S@@', 'omm@@', 'er', 'in', 'der', 'K@@', 'ilometer', 'in', 'der', 'K@@', 'ilometer', 'in', 'der', 'K@@', 'ilometer', 'in', 'der', 'K@@', 'unden', 'in', 'der', 'K@@', 'ilometer', 'im', 'S@@', 'omm@@', 'er', 'in', 'der', 'K@@', 'ilometer', 'in', 'der', 'K@@', 'unden', 'in', 'der', 'K@@', 'ir@@', 'ir@@', 'm.', '</s>']
2023-05-30 21:16:41,890 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 21:16:41,890 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 21:16:41,890 - INFO - joeynmt.training - 	Hypothesis: Es gibt aus der Kunden und und Kimation in der Kilometer in der Sommer in der Kilometer in der Kilometer im Sommer in der Kilometer in der Kilometer in der Kilometer in der Kunden in der Kilometer im Sommer in der Kilometer in der Kunden in der Kirirm.
2023-05-30 21:16:41,890 - INFO - joeynmt.training - Example #4
2023-05-30 21:16:41,890 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 21:16:41,890 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 21:16:41,890 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Di@@', 'a', 'die', 'ich', 'Ihnen', 'sehen,', 'ist', 'ein', 'Ver@@', 'sion', 'der', 'Ver@@', 'sion', 'der', 'letzten', '25', 'Jahren', 'ist', 'das', 'im', 'letzten', '25', 'Jahren', 'ist', 'das', 'im', 'Jahr', 'ist.', '</s>']
2023-05-30 21:16:41,890 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 21:16:41,890 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 21:16:41,890 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia die ich Ihnen sehen, ist ein Version der Version der letzten 25 Jahren ist das im letzten 25 Jahren ist das im Jahr ist.
2023-05-30 21:17:00,654 - INFO - joeynmt.training - Epoch   2, Step:     5100, Batch Loss:     2.709252, Batch Acc: 0.305939, Tokens per Sec:     3709, Lr: 0.000300
2023-05-30 21:17:19,292 - INFO - joeynmt.training - Epoch   2, Step:     5200, Batch Loss:     2.688175, Batch Acc: 0.313542, Tokens per Sec:     3999, Lr: 0.000300
2023-05-30 21:17:38,289 - INFO - joeynmt.training - Epoch   2, Step:     5300, Batch Loss:     2.647299, Batch Acc: 0.316591, Tokens per Sec:     3866, Lr: 0.000300
2023-05-30 21:17:58,040 - INFO - joeynmt.training - Epoch   2, Step:     5400, Batch Loss:     2.424358, Batch Acc: 0.320729, Tokens per Sec:     3705, Lr: 0.000300
2023-05-30 21:18:16,289 - INFO - joeynmt.training - Epoch   2, Step:     5500, Batch Loss:     2.552649, Batch Acc: 0.327250, Tokens per Sec:     3946, Lr: 0.000300
2023-05-30 21:18:16,289 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 21:18:16,289 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 21:19:33,932 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.76, ppl:  15.72, acc:   0.30, generation: 77.6358[sec], evaluation: 0.0000[sec]
2023-05-30 21:19:33,934 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 21:19:34,026 - INFO - joeynmt.helpers - delete models/transformer_model3/3000.ckpt
2023-05-30 21:19:34,029 - INFO - joeynmt.training - Example #0
2023-05-30 21:19:34,029 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 21:19:34,029 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 21:19:34,029 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'ich', 'habe', 'diese', 'zwei', 'Di@@', 'mensi@@', 'onen', 'zu', 'zeigen,', 'dass', 'die', 'P@@', 'ha@@', 'se', 'zu', 'zeigen,', 'dass', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'Jahre', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahre', 'Jahre', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahre', 'Jahre', 'in', 'den', 'V@@', 'ier@@', 'tel', 'von', '7@@', '0@@', 'ern', 'war.', '</s>']
2023-05-30 21:19:34,030 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 21:19:34,030 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 21:19:34,030 - INFO - joeynmt.training - 	Hypothesis: Aber ich habe diese zwei Dimensionen zu zeigen, dass die Phase zu zeigen, dass die die letzten drei Millionen Jahre Jahre in den letzten drei Millionen Jahre Jahre in den letzten drei Millionen Jahre Jahre in den Viertel von 70ern war.
2023-05-30 21:19:34,030 - INFO - joeynmt.training - Example #1
2023-05-30 21:19:34,030 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 21:19:34,030 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 21:19:34,030 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'das', 'Be@@', 'gin@@', 'n', 'der', 'Be@@', 'gin@@', 'n', 'des', 'E@@', 'is', 'nicht', 'die', 'die', 'Be@@', 'wei@@', 's', 'des', 'E@@', 'is', 'zu', 'sehen.', '</s>']
2023-05-30 21:19:34,030 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 21:19:34,030 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 21:19:34,030 - INFO - joeynmt.training - 	Hypothesis: Aber das ist das Beginn der Beginn des Eis nicht die die Beweis des Eis zu sehen.
2023-05-30 21:19:34,030 - INFO - joeynmt.training - Example #2
2023-05-30 21:19:34,030 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 21:19:34,030 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 21:19:34,030 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'Nor@@', 'd@@', 'd@@', 'd@@', 'ul@@', 'l', 'ist', 'in', 'einer', 'einer', 'Art', 'von', 'uns', 'in', 'einer', 'einer', 'Art', 'von', 'uns', 'in', 'einem', 'glob@@', 'alen', 'Ver@@', 'ständ@@', 'nis', 'des', 'Klima@@', 'wandel@@', 's.', '</s>']
2023-05-30 21:19:34,030 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 21:19:34,030 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 21:19:34,030 - INFO - joeynmt.training - 	Hypothesis: Die Nordddull ist in einer einer Art von uns in einer einer Art von uns in einem globalen Verständnis des Klimawandels.
2023-05-30 21:19:34,030 - INFO - joeynmt.training - Example #3
2023-05-30 21:19:34,030 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 21:19:34,030 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 21:19:34,030 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'aus', 'der', 'Win@@', 'ter', 'und', 'K@@', 'im@@', 'ation', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'Win@@', 'ter', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', '</s>']
2023-05-30 21:19:34,031 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 21:19:34,031 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 21:19:34,031 - INFO - joeynmt.training - 	Hypothesis: Es ist aus der Winter und Kimation in den Sommer in den Sommer in den Sommer in den Sommer in den Sommer in den Winter in den Sommer und
2023-05-30 21:19:34,031 - INFO - joeynmt.training - Example #4
2023-05-30 21:19:34,031 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 21:19:34,031 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 21:19:34,031 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Di@@', 'a', 'der', 'ich', 'Ihnen', 'sehen', 'ist', 'ein', 'ver@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'inder@@', 'n', 'ist.', '</s>']
2023-05-30 21:19:34,031 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 21:19:34,031 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 21:19:34,031 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia der ich Ihnen sehen ist ein verhhhhhhhhhhindern ist.
2023-05-30 21:19:52,338 - INFO - joeynmt.training - Epoch   2, Step:     5600, Batch Loss:     2.548943, Batch Acc: 0.335229, Tokens per Sec:     3966, Lr: 0.000300
2023-05-30 21:20:11,379 - INFO - joeynmt.training - Epoch   2, Step:     5700, Batch Loss:     2.659695, Batch Acc: 0.328538, Tokens per Sec:     3742, Lr: 0.000300
2023-05-30 21:20:29,972 - INFO - joeynmt.training - Epoch   2, Step:     5800, Batch Loss:     2.691826, Batch Acc: 0.336847, Tokens per Sec:     3919, Lr: 0.000300
2023-05-30 21:20:49,426 - INFO - joeynmt.training - Epoch   2, Step:     5900, Batch Loss:     2.450928, Batch Acc: 0.338950, Tokens per Sec:     3698, Lr: 0.000300
2023-05-30 21:21:08,471 - INFO - joeynmt.training - Epoch   2, Step:     6000, Batch Loss:     2.701430, Batch Acc: 0.342799, Tokens per Sec:     3807, Lr: 0.000300
2023-05-30 21:21:08,472 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 21:21:08,472 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 21:22:34,185 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.67, ppl:  14.49, acc:   0.31, generation: 85.7054[sec], evaluation: 0.0000[sec]
2023-05-30 21:22:34,187 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 21:22:34,282 - INFO - joeynmt.helpers - delete models/transformer_model3/3500.ckpt
2023-05-30 21:22:34,282 - INFO - joeynmt.training - Example #0
2023-05-30 21:22:34,282 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 21:22:34,282 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 21:22:34,282 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'diese', 'zwei', 'Di@@', 'a@@', 'a@@', 'a', 'sehen', 'um', 'zu', 'zeigen,', 'dass', 'die', 'P@@', 'ool@@', 's@@', 'ap@@', 'ap@@', 'az@@', 'ität', 'sehen', 'können,', 'dass', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'von', 'Jahren', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'von', 'der', 'V@@', 'S@@', ',', 'mit', '40', 'Prozent', 'von', '40', 'Prozent', 'von', '40', 'Prozent', 'von', '40', 'Prozent', 'von', 'der', 'V@@', 'V@@', 'ier@@', 'tel', 'der', 'V@@', 'ier@@', 'tel', 'der', 'V@@', 'V@@', 'V@@', 'ier@@', 'tel', 'von', 'den', 'V@@', 'ier@@', 'tel', 'Millionen', 'Jahre', 'lang', 'lang', 'lang', 'hatte.', '</s>']
2023-05-30 21:22:34,282 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 21:22:34,282 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 21:22:34,282 - INFO - joeynmt.training - 	Hypothesis: Ich habe diese zwei Diaaa sehen um zu zeigen, dass die Poolsapapazität sehen können, dass die die letzten drei Millionen Jahre von Jahren die letzten drei Millionen Jahre von der VS, mit 40 Prozent von 40 Prozent von 40 Prozent von 40 Prozent von der VViertel der Viertel der VVViertel von den Viertel Millionen Jahre lang lang lang hatte.
2023-05-30 21:22:34,282 - INFO - joeynmt.training - Example #1
2023-05-30 21:22:34,282 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 21:22:34,282 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 21:22:34,282 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Be@@', 'gin@@', 'n', 'der', 'Be@@', 'gin@@', 'n', 'des', 'E@@', 'is', 'der', 'E@@', 'is', 'nicht', 'die', 'G@@', 'lob@@', 'al', 'des', 'E@@', 'is', 'des', 'E@@', 'is', 'des', 'E@@', 'is', 'zu', 'sehen.', '</s>']
2023-05-30 21:22:34,283 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 21:22:34,283 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 21:22:34,283 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Beginn der Beginn des Eis der Eis nicht die Global des Eis des Eis des Eis zu sehen.
2023-05-30 21:22:34,283 - INFO - joeynmt.training - Example #2
2023-05-30 21:22:34,283 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 21:22:34,283 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 21:22:34,283 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'hr@@', 'e', 'auf', 'der', 'Nor@@', 'd@@', 'p@@', 'reis', 'ist', 'in', 'der', 'Nor@@', 'd@@', 'po@@', 'l', 'des', 'E@@', 'rei@@', 's', 'der', 'uns', 'in', 'der', 'glob@@', 'alen', 'I@@', 'mm@@', 'mm@@', 'mm@@', 'ig@@', 'nor@@', 'ieren', '</s>']
2023-05-30 21:22:34,283 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 21:22:34,283 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 21:22:34,283 - INFO - joeynmt.training - 	Hypothesis: Die Ehre auf der Nordpreis ist in der Nordpol des Ereis der uns in der globalen Immmmmmignorieren
2023-05-30 21:22:34,283 - INFO - joeynmt.training - Example #3
2023-05-30 21:22:34,283 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 21:22:34,283 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 21:22:34,283 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'ist', 'aus', 'dem', 'Win@@', 'ter', 'und', 'K@@', 'ris@@', 'e', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'no@@', 'chmal', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'im@@', 'it@@', 't.', '</s>']
2023-05-30 21:22:34,283 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 21:22:34,283 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 21:22:34,283 - INFO - joeynmt.training - 	Hypothesis: Das ist aus dem Winter und Krise in den Sommer und Knochmal in den Sommer und Krimitt.
2023-05-30 21:22:34,283 - INFO - joeynmt.training - Example #4
2023-05-30 21:22:34,283 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 21:22:34,283 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 21:22:34,283 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'nächste', 'Di@@', 'a', 'er@@', 'hö@@', 'her@@', 'e', 'ist', 'ein', 'ver@@', 'trau@@', 't', 'der', 'letzten', '25', 'Jahre', 'ist.', '</s>']
2023-05-30 21:22:34,284 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 21:22:34,284 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 21:22:34,284 - INFO - joeynmt.training - 	Hypothesis: Und die nächste Dia erhöhere ist ein vertraut der letzten 25 Jahre ist.
2023-05-30 21:22:53,673 - INFO - joeynmt.training - Epoch   2, Step:     6100, Batch Loss:     2.504736, Batch Acc: 0.341989, Tokens per Sec:     3567, Lr: 0.000300
2023-05-30 21:23:12,501 - INFO - joeynmt.training - Epoch   2, Step:     6200, Batch Loss:     2.419661, Batch Acc: 0.352342, Tokens per Sec:     3785, Lr: 0.000300
2023-05-30 21:23:31,289 - INFO - joeynmt.training - Epoch   2, Step:     6300, Batch Loss:     2.473823, Batch Acc: 0.356683, Tokens per Sec:     3868, Lr: 0.000300
2023-05-30 21:23:50,294 - INFO - joeynmt.training - Epoch   2, Step:     6400, Batch Loss:     2.580245, Batch Acc: 0.355163, Tokens per Sec:     3802, Lr: 0.000300
2023-05-30 21:24:09,163 - INFO - joeynmt.training - Epoch   2, Step:     6500, Batch Loss:     2.495683, Batch Acc: 0.355693, Tokens per Sec:     3748, Lr: 0.000300
2023-05-30 21:24:09,164 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 21:24:09,164 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 21:25:26,167 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.63, ppl:  13.87, acc:   0.33, generation: 76.9951[sec], evaluation: 0.0000[sec]
2023-05-30 21:25:26,168 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 21:25:26,262 - INFO - joeynmt.helpers - delete models/transformer_model3/4000.ckpt
2023-05-30 21:25:26,266 - INFO - joeynmt.training - Example #0
2023-05-30 21:25:26,267 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 21:25:26,267 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 21:25:26,267 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'diese', 'zwei', 'Di@@', 'ag@@', 'ram@@', 'm', 'aus', 'dem', 'P@@', 'y@@', 'y@@', 'y@@', 'e', 'zu', 'zeigen,', 'dass', 'die', 'P@@', 'ool@@', 'er', 'der', 'Größe', 'eines', 'der', 'Größe', 'eines', 'Jahr@@', 'es', 'etwa', 'etwa', 'die', 'Größe', 'eines', 'der', 'Größe', 'eines', 'der', 'Größe', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'war.', '</s>']
2023-05-30 21:25:26,267 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 21:25:26,267 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 21:25:26,267 - INFO - joeynmt.training - 	Hypothesis: Ich habe diese zwei Diagramm aus dem Pyyye zu zeigen, dass die Pooler der Größe eines der Größe eines Jahres etwa etwa die Größe eines der Größe eines der Größe der VS, mit 40% der VS, mit 40% war.
2023-05-30 21:25:26,267 - INFO - joeynmt.training - Example #1
2023-05-30 21:25:26,267 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 21:25:26,267 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 21:25:26,267 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Be@@', 'gin@@', 'n', 'der', 'An@@', 'gst', 'des', 'Spe@@', 'zi@@', 'p@@', 'p@@', 'ä@@', 'm@@', 'ischen', 'Proble@@', 'm,', 'weil', 'es', 'nicht', 'die', 'G@@', 'ele@@', 'genheit', 'zu', 'sehen.', '</s>']
2023-05-30 21:25:26,267 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 21:25:26,267 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 21:25:26,267 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Beginn der Angst des Spezippämischen Problem, weil es nicht die Gelegenheit zu sehen.
2023-05-30 21:25:26,267 - INFO - joeynmt.training - Example #2
2023-05-30 21:25:26,267 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 21:25:26,267 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 21:25:26,267 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'hr@@', 'e', 'auf', 'die', 'Nor@@', 'd@@', 'p@@', 'el', 'ist', 'in', 'gew@@', 'is@@', 'se', 'Weise', 'das', 'ist', 'ein', 'bisschen', 'bisschen', 'der', 'glob@@', 'alen', 'Klima@@', 'wandel@@', '.', '</s>']
2023-05-30 21:25:26,267 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 21:25:26,267 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 21:25:26,267 - INFO - joeynmt.training - 	Hypothesis: Die Ehre auf die Nordpel ist in gewisse Weise das ist ein bisschen bisschen der globalen Klimawandel.
2023-05-30 21:25:26,267 - INFO - joeynmt.training - Example #3
2023-05-30 21:25:26,268 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 21:25:26,268 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 21:25:26,268 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'aus', 'der', 'Win@@', 'ter', 'und', 'K@@', 'im@@', 'ation', 'in', 'der', 'S@@', 'omm@@', 'er', 'in', 'der', 'S@@', 'omm@@', 'er', 'in', 'der', 'S@@', 'omm@@', 'er', 'und', '</s>']
2023-05-30 21:25:26,268 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 21:25:26,268 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 21:25:26,268 - INFO - joeynmt.training - 	Hypothesis: Es ist aus der Winter und Kimation in der Sommer in der Sommer in der Sommer und
2023-05-30 21:25:26,268 - INFO - joeynmt.training - Example #4
2023-05-30 21:25:26,268 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 21:25:26,268 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 21:25:26,268 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Di@@', 'a', 'die', 'ich', 'Ihnen', 'sehen', 'ist', 'ein', 'Ver@@', 'sion', 'der', 'letzten', '25', 'Jahren', 'ist', 'ein', 'wenig', 'der', 'letzten', '25', 'Jahren', 'ist.', '</s>']
2023-05-30 21:25:26,268 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 21:25:26,268 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 21:25:26,268 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia die ich Ihnen sehen ist ein Version der letzten 25 Jahren ist ein wenig der letzten 25 Jahren ist.
2023-05-30 21:25:44,687 - INFO - joeynmt.training - Epoch   2, Step:     6600, Batch Loss:     2.538947, Batch Acc: 0.361279, Tokens per Sec:     3881, Lr: 0.000300
2023-05-30 21:26:04,185 - INFO - joeynmt.training - Epoch   2, Step:     6700, Batch Loss:     2.497288, Batch Acc: 0.364620, Tokens per Sec:     3726, Lr: 0.000300
2023-05-30 21:26:23,054 - INFO - joeynmt.training - Epoch   2, Step:     6800, Batch Loss:     2.458374, Batch Acc: 0.361349, Tokens per Sec:     3888, Lr: 0.000300
2023-05-30 21:26:42,520 - INFO - joeynmt.training - Epoch   2, Step:     6900, Batch Loss:     2.577051, Batch Acc: 0.367006, Tokens per Sec:     3643, Lr: 0.000300
2023-05-30 21:27:01,589 - INFO - joeynmt.training - Epoch   2, Step:     7000, Batch Loss:     2.539098, Batch Acc: 0.369128, Tokens per Sec:     3845, Lr: 0.000300
2023-05-30 21:27:01,589 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 21:27:01,589 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 21:28:15,821 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.56, ppl:  12.95, acc:   0.34, generation: 74.2252[sec], evaluation: 0.0000[sec]
2023-05-30 21:28:15,824 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 21:28:15,920 - INFO - joeynmt.helpers - delete models/transformer_model3/4500.ckpt
2023-05-30 21:28:15,921 - INFO - joeynmt.training - Example #0
2023-05-30 21:28:15,922 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 21:28:15,922 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 21:28:15,922 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'diese', 'beiden', 'Di@@', 'mensi@@', 'on', 'sehen,', 'dass', 'die', 'P@@', 'ool@@', 's@@', 'ap@@', ',', 'die', 'die', 'P@@', 'ool@@', 's@@', 'ap@@', ',', 'die', 'die', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', 'die', 'Größe', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'F@@', 'r@@', 'r@@', 'aten', 'des', 'V@@', 'ier@@', 'tes', 'ge@@', 'geben', 'war.', '</s>']
2023-05-30 21:28:15,922 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 21:28:15,922 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 21:28:15,922 - INFO - joeynmt.training - 	Hypothesis: Ich habe diese beiden Dimension sehen, dass die Poolsap, die die Poolsap, die die den letzten drei Millionen Jahren die Größe der VS, mit 40% der VS, mit 40% der Frraten des Viertes gegeben war.
2023-05-30 21:28:15,922 - INFO - joeynmt.training - Example #1
2023-05-30 21:28:15,922 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 21:28:15,922 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 21:28:15,922 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'die', 'Be@@', 'gin@@', 'n', 'dieser', 'spezi@@', 'f@@', 'ischen', 'Problem', 'der', 'E@@', 'is', 'nicht', 'die', 'Z@@', 'enti@@', 'meter', 'des', 'E@@', 'is', 'zu', 'sehen.', '</s>']
2023-05-30 21:28:15,922 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 21:28:15,922 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 21:28:15,922 - INFO - joeynmt.training - 	Hypothesis: Aber das ist die Beginn dieser spezifischen Problem der Eis nicht die Zentimeter des Eis zu sehen.
2023-05-30 21:28:15,922 - INFO - joeynmt.training - Example #2
2023-05-30 21:28:15,922 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 21:28:15,922 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 21:28:15,922 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'hr@@', 'e', 'auf', 'den', 'Nor@@', 'd@@', 'p@@', 'reis', 'ist', 'in', 'gew@@', 'gew@@', 'issen', 'und', 'das', 'ist', 'ein', 'Gefühl', 'der', 'G@@', 'lob@@', 'al', 'zu', 'ver@@', 'mittel@@', 'n.', '</s>']
2023-05-30 21:28:15,922 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 21:28:15,922 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 21:28:15,922 - INFO - joeynmt.training - 	Hypothesis: Die Ehre auf den Nordpreis ist in gewgewissen und das ist ein Gefühl der Global zu vermitteln.
2023-05-30 21:28:15,922 - INFO - joeynmt.training - Example #3
2023-05-30 21:28:15,923 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 21:28:15,923 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 21:28:15,923 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'geht', 'aus', 'den', 'Win@@', 'ter', 'und', 'K@@', 'im@@', 'm', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'im@@', 'im@@', 'm', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', '</s>']
2023-05-30 21:28:15,923 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 21:28:15,923 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 21:28:15,923 - INFO - joeynmt.training - 	Hypothesis: Es geht aus den Winter und Kimm in den Sommer und Kimimm in den Sommer und
2023-05-30 21:28:15,923 - INFO - joeynmt.training - Example #4
2023-05-30 21:28:15,923 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 21:28:15,923 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 21:28:15,923 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'nächste', 'Di@@', 'a', 'er@@', 'hö@@', 'ht', 'sich', 'ein', 'Ver@@', 'sion', 'der', 'letzten', '25', 'Jahre', 'der', 'letzten', '25', 'Jahre', 'ist.', '</s>']
2023-05-30 21:28:15,923 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 21:28:15,923 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 21:28:15,923 - INFO - joeynmt.training - 	Hypothesis: Und die nächste Dia erhöht sich ein Version der letzten 25 Jahre der letzten 25 Jahre ist.
2023-05-30 21:28:30,456 - INFO - joeynmt.training - Epoch   2: total training loss 9562.82
2023-05-30 21:28:30,456 - INFO - joeynmt.training - EPOCH 3
2023-05-30 21:28:35,374 - INFO - joeynmt.training - Epoch   3, Step:     7100, Batch Loss:     2.318435, Batch Acc: 0.383086, Tokens per Sec:     3631, Lr: 0.000300
2023-05-30 21:28:53,762 - INFO - joeynmt.training - Epoch   3, Step:     7200, Batch Loss:     2.246572, Batch Acc: 0.392647, Tokens per Sec:     3966, Lr: 0.000300
2023-05-30 21:29:12,248 - INFO - joeynmt.training - Epoch   3, Step:     7300, Batch Loss:     2.293293, Batch Acc: 0.390415, Tokens per Sec:     3784, Lr: 0.000300
2023-05-30 21:29:32,098 - INFO - joeynmt.training - Epoch   3, Step:     7400, Batch Loss:     2.319224, Batch Acc: 0.394343, Tokens per Sec:     3655, Lr: 0.000300
2023-05-30 21:29:50,246 - INFO - joeynmt.training - Epoch   3, Step:     7500, Batch Loss:     2.300650, Batch Acc: 0.389756, Tokens per Sec:     3938, Lr: 0.000300
2023-05-30 21:29:50,247 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 21:29:50,247 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 21:30:59,513 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.54, ppl:  12.64, acc:   0.35, generation: 69.2584[sec], evaluation: 0.0000[sec]
2023-05-30 21:30:59,516 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 21:30:59,609 - INFO - joeynmt.helpers - delete models/transformer_model3/5000.ckpt
2023-05-30 21:30:59,612 - INFO - joeynmt.training - Example #0
2023-05-30 21:30:59,612 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 21:30:59,612 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 21:30:59,612 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'diese', 'zwei', 'Di@@', 'as', 'sehen', 'Sie,', 'um', 'zu', 'zeigen,', 'dass', 'die', 'P@@', 'ool@@', 'e', 'der', 'P@@', 'ool@@', 'e', 'der', 'P@@', 'ool@@', 's@@', 'ap@@', ',', 'die', 'letzten', 'drei', 'Millionen', 'Jahren', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', 'von', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', '%', 'ver@@', 'r@@', 'r@@', 'r@@', 'ück@@', 'te.', '</s>']
2023-05-30 21:30:59,612 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 21:30:59,612 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 21:30:59,612 - INFO - joeynmt.training - 	Hypothesis: Ich habe diese zwei Dias sehen Sie, um zu zeigen, dass die Poole der Poole der Poolsap, die letzten drei Millionen Jahren in den letzten drei Millionen Jahren von der VS, mit 40% % verrrrückte.
2023-05-30 21:30:59,612 - INFO - joeynmt.training - Example #1
2023-05-30 21:30:59,613 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 21:30:59,613 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 21:30:59,613 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Unter@@', 'hal@@', 'tung', 'des', 'E@@', 'is', 'des', 'E@@', 'is', 'des', 'E@@', 'is', 'des', 'E@@', 'is', 'des', 'E@@', 'is', 'des', 'E@@', 'is', 'des', 'E@@', 'is', 'sehen.', '</s>']
2023-05-30 21:30:59,613 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 21:30:59,613 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 21:30:59,613 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Unterhaltung des Eis des Eis des Eis des Eis des Eis des Eis des Eis sehen.
2023-05-30 21:30:59,613 - INFO - joeynmt.training - Example #2
2023-05-30 21:30:59,613 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 21:30:59,613 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 21:30:59,613 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'Eis@@', 'en@@', 'k@@', 'reis', 'auf', 'der', 'Nor@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'er', 'Weise', 'das', 'ist', 'ein', 'Her@@', 'z', 'des', 'glob@@', 'alen', 'Klima@@', 'wandel@@', 's.', '</s>']
2023-05-30 21:30:59,613 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 21:30:59,613 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 21:30:59,613 - INFO - joeynmt.training - 	Hypothesis: Die Eisenkreis auf der Nordpol ist in gewisser Weise das ist ein Herz des globalen Klimawandels.
2023-05-30 21:30:59,613 - INFO - joeynmt.training - Example #3
2023-05-30 21:30:59,613 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 21:30:59,613 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 21:30:59,613 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'geht', 'aus', 'der', 'Win@@', 'ter', 'und', 'kr@@', 'im@@', 't', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'der', 'S@@', 'omm@@', 'er', 'aus.', '</s>']
2023-05-30 21:30:59,613 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 21:30:59,613 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 21:30:59,613 - INFO - joeynmt.training - 	Hypothesis: Es geht aus der Winter und krimt in den Sommer in den Sommer in den Sommer in der Sommer aus.
2023-05-30 21:30:59,613 - INFO - joeynmt.training - Example #4
2023-05-30 21:30:59,614 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 21:30:59,614 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 21:30:59,614 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Di@@', 'a', 'die', 'ich', 'Ihnen', 'sehen', 'ist', 'ein', 'Ver@@', 'sion', 'der', 'letzten', '25', 'Jahren', 'ist', 'das', 'letzte', '25', 'Jahre', 'ist.', '</s>']
2023-05-30 21:30:59,614 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 21:30:59,614 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 21:30:59,614 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia die ich Ihnen sehen ist ein Version der letzten 25 Jahren ist das letzte 25 Jahre ist.
2023-05-30 21:31:18,494 - INFO - joeynmt.training - Epoch   3, Step:     7600, Batch Loss:     2.388106, Batch Acc: 0.390932, Tokens per Sec:     3816, Lr: 0.000300
2023-05-30 21:31:37,252 - INFO - joeynmt.training - Epoch   3, Step:     7700, Batch Loss:     2.362743, Batch Acc: 0.393611, Tokens per Sec:     3870, Lr: 0.000300
2023-05-30 21:31:56,061 - INFO - joeynmt.training - Epoch   3, Step:     7800, Batch Loss:     2.288994, Batch Acc: 0.390908, Tokens per Sec:     3869, Lr: 0.000300
2023-05-30 21:32:15,202 - INFO - joeynmt.training - Epoch   3, Step:     7900, Batch Loss:     2.360062, Batch Acc: 0.391124, Tokens per Sec:     3786, Lr: 0.000300
2023-05-30 21:32:34,303 - INFO - joeynmt.training - Epoch   3, Step:     8000, Batch Loss:     2.384332, Batch Acc: 0.394411, Tokens per Sec:     3863, Lr: 0.000300
2023-05-30 21:32:34,303 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 21:32:34,303 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 21:33:42,787 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.52, ppl:  12.46, acc:   0.35, generation: 68.4765[sec], evaluation: 0.0000[sec]
2023-05-30 21:33:42,787 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 21:33:42,878 - INFO - joeynmt.helpers - delete models/transformer_model3/5500.ckpt
2023-05-30 21:33:42,881 - INFO - joeynmt.training - Example #0
2023-05-30 21:33:42,881 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 21:33:42,881 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 21:33:42,881 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'diese', 'zwei', 'Di@@', 'as', 'zeigen,', 'dass', 'die', 'P@@', 'ool@@', 'e', 'zeigen,', 'dass', 'die', 'P@@', 'ool@@', 'e', 'der', 'P@@', 'ool@@', 'e', 'der', 'P@@', 'ool@@', 'e', 'des', 'V@@', 'S@@', ',', 'der', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', 'in', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', '%', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', '%', '%', '%', '%', 'der', 'S@@', ',', '</s>']
2023-05-30 21:33:42,881 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 21:33:42,881 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 21:33:42,881 - INFO - joeynmt.training - 	Hypothesis: Ich habe diese zwei Dias zeigen, dass die Poole zeigen, dass die Poole der Poole der Poole des VS, der den letzten drei Millionen Jahren in der VS, mit 40% % der VS, mit 40% der VS, mit 40% % % % % der S,
2023-05-30 21:33:42,881 - INFO - joeynmt.training - Example #1
2023-05-30 21:33:42,881 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 21:33:42,881 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 21:33:42,881 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Be@@', 'gin@@', 'n', 'der', 'Au@@', 'ss@@', 'age', 'dieses', 'Problem', 'der', 'Di@@', 'mensi@@', 'on', 'des', 'E@@', 'is', 'nicht', 'die', 'Di@@', 'mensi@@', 'on', 'des', 'E@@', 'is', 'zu', 'sehen.', '</s>']
2023-05-30 21:33:42,881 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 21:33:42,881 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 21:33:42,881 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Beginn der Aussage dieses Problem der Dimension des Eis nicht die Dimension des Eis zu sehen.
2023-05-30 21:33:42,881 - INFO - joeynmt.training - Example #2
2023-05-30 21:33:42,881 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 21:33:42,881 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 21:33:42,881 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is', 'auf', 'dem', 'Nor@@', 'd@@', 'p@@', 'reis', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'Sin@@', 'ne,', 'das', 'ist', 'das', 'wunder@@', 'bar@@', 'er', 'L@@', 'og@@', 'ik.', '</s>']
2023-05-30 21:33:42,882 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 21:33:42,882 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 21:33:42,882 - INFO - joeynmt.training - 	Hypothesis: Die Eis auf dem Nordpreis ist in gewissem Sinne, das ist das wunderbarer Logik.
2023-05-30 21:33:42,882 - INFO - joeynmt.training - Example #3
2023-05-30 21:33:42,882 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 21:33:42,882 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 21:33:42,882 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'geht', 'aus', 'dem', 'Win@@', 'ter', 'und', 'kr@@', 'ä@@', 'fte', 'in', 'der', 'S@@', 'omm@@', 'er', 'in', 'der', 'S@@', 'omm@@', 'er', 'und', '</s>']
2023-05-30 21:33:42,882 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 21:33:42,882 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 21:33:42,882 - INFO - joeynmt.training - 	Hypothesis: Es geht aus dem Winter und kräfte in der Sommer in der Sommer und
2023-05-30 21:33:42,882 - INFO - joeynmt.training - Example #4
2023-05-30 21:33:42,882 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 21:33:42,882 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 21:33:42,882 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'nächsten', 'Di@@', 'a', 'der', 'ich', 'Ihnen', 'zeigen', 'ist', 'eine', 'Ver@@', 'sion', 'der', 'letzten', '25', 'Jahren', 'passiert', 'ist.', '</s>']
2023-05-30 21:33:42,882 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 21:33:42,882 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 21:33:42,882 - INFO - joeynmt.training - 	Hypothesis: Und die nächsten Dia der ich Ihnen zeigen ist eine Version der letzten 25 Jahren passiert ist.
2023-05-30 21:34:01,757 - INFO - joeynmt.training - Epoch   3, Step:     8100, Batch Loss:     2.454726, Batch Acc: 0.394093, Tokens per Sec:     3827, Lr: 0.000300
2023-05-30 21:34:21,395 - INFO - joeynmt.training - Epoch   3, Step:     8200, Batch Loss:     2.361928, Batch Acc: 0.396926, Tokens per Sec:     3737, Lr: 0.000300
2023-05-30 21:34:39,566 - INFO - joeynmt.training - Epoch   3, Step:     8300, Batch Loss:     2.432852, Batch Acc: 0.394585, Tokens per Sec:     3957, Lr: 0.000300
2023-05-30 21:34:58,332 - INFO - joeynmt.training - Epoch   3, Step:     8400, Batch Loss:     2.239913, Batch Acc: 0.400917, Tokens per Sec:     3904, Lr: 0.000300
2023-05-30 21:35:16,737 - INFO - joeynmt.training - Epoch   3, Step:     8500, Batch Loss:     2.340797, Batch Acc: 0.395162, Tokens per Sec:     3884, Lr: 0.000300
2023-05-30 21:35:16,737 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 21:35:16,737 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 21:36:36,782 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.48, ppl:  11.99, acc:   0.36, generation: 80.0378[sec], evaluation: 0.0000[sec]
2023-05-30 21:36:36,783 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 21:36:36,880 - INFO - joeynmt.helpers - delete models/transformer_model3/6000.ckpt
2023-05-30 21:36:36,880 - INFO - joeynmt.training - Example #0
2023-05-30 21:36:36,880 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 21:36:36,880 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 21:36:36,880 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'war', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'zeigt', 'zwei', 'Di@@', 'as', 'zu', 'zeigen,', 'dass', 'die', 'P@@', 'ool@@', 'e', 'der', 'P@@', 'ool@@', 'e', 'der', 'letzten', 'drei', 'Millionen', 'Jahre', 'vor', 'drei', 'Millionen', 'Jahre', 'Jahre', 'in', 'der', 'F@@', 'ach@@', 'tel', 'der', 'F@@', 'ach@@', 'tel', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'von', '40@@', '%', 'von', 'der', 'F@@', 'ro@@', 'm@@', 'pen', 'war.', '</s>']
2023-05-30 21:36:36,880 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 21:36:36,880 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 21:36:36,880 - INFO - joeynmt.training - 	Hypothesis: Das war ich diese zwei Dias zeigt zwei Dias zu zeigen, dass die Poole der Poole der letzten drei Millionen Jahre vor drei Millionen Jahre Jahre in der Fachtel der Fachtel der VS, mit 40% von 40% von der Frompen war.
2023-05-30 21:36:36,880 - INFO - joeynmt.training - Example #1
2023-05-30 21:36:36,881 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 21:36:36,881 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 21:36:36,881 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Be@@', 'gin@@', 'n', 'dieses', 'Problem', 'der', 'E@@', 'is', 'dieses', 'Bild', 'von', 'E@@', 'is', 'nicht', 'die', 'Di@@', 'mensi@@', 'on', 'des', 'E@@', 'is', 'zu', 'sehen.', '</s>']
2023-05-30 21:36:36,881 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 21:36:36,881 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 21:36:36,881 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Beginn dieses Problem der Eis dieses Bild von Eis nicht die Dimension des Eis zu sehen.
2023-05-30 21:36:36,881 - INFO - joeynmt.training - Example #2
2023-05-30 21:36:36,881 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 21:36:36,881 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 21:36:36,881 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'Eis@@', 'b@@', 'au', 'auf', 'dem', 'Nor@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'einem', 'gew@@', 'iss@@', 'em', 'Her@@', 'z', 'von', 'uns', 'G@@', 'lob@@', 'al', 'Klima@@', 'wandel@@', '.', '</s>']
2023-05-30 21:36:36,881 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 21:36:36,881 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 21:36:36,881 - INFO - joeynmt.training - 	Hypothesis: Der Eisbau auf dem Nordpol ist in einem gewissem Herz von uns Global Klimawandel.
2023-05-30 21:36:36,881 - INFO - joeynmt.training - Example #3
2023-05-30 21:36:36,881 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 21:36:36,881 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 21:36:36,881 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'aus', 'dem', 'Win@@', 'ter', 'und', 'kr@@', 'im@@', 'ft', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', '</s>']
2023-05-30 21:36:36,881 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 21:36:36,881 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 21:36:36,881 - INFO - joeynmt.training - 	Hypothesis: Es ist aus dem Winter und krimft in den Sommer in den Sommer
2023-05-30 21:36:36,881 - INFO - joeynmt.training - Example #4
2023-05-30 21:36:36,882 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 21:36:36,882 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 21:36:36,882 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Di@@', 'a', 'die', 'ich', 'Ihnen', 'zeigen', 'ist', 'ein', 'Ver@@', 'sion', 'der', 'letzten', '25', 'Jahre', 'passier@@', 'te.', '</s>']
2023-05-30 21:36:36,882 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 21:36:36,882 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 21:36:36,882 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia die ich Ihnen zeigen ist ein Version der letzten 25 Jahre passierte.
2023-05-30 21:36:55,421 - INFO - joeynmt.training - Epoch   3, Step:     8600, Batch Loss:     2.387133, Batch Acc: 0.400045, Tokens per Sec:     3855, Lr: 0.000300
2023-05-30 21:37:14,310 - INFO - joeynmt.training - Epoch   3, Step:     8700, Batch Loss:     2.173157, Batch Acc: 0.407298, Tokens per Sec:     3828, Lr: 0.000300
2023-05-30 21:37:33,434 - INFO - joeynmt.training - Epoch   3, Step:     8800, Batch Loss:     2.366160, Batch Acc: 0.398505, Tokens per Sec:     3825, Lr: 0.000300
2023-05-30 21:37:51,573 - INFO - joeynmt.training - Epoch   3, Step:     8900, Batch Loss:     2.313341, Batch Acc: 0.403227, Tokens per Sec:     3966, Lr: 0.000300
2023-05-30 21:38:10,333 - INFO - joeynmt.training - Epoch   3, Step:     9000, Batch Loss:     2.321781, Batch Acc: 0.399281, Tokens per Sec:     3780, Lr: 0.000300
2023-05-30 21:38:10,333 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 21:38:10,333 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 21:39:15,015 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.46, ppl:  11.76, acc:   0.36, generation: 64.6751[sec], evaluation: 0.0000[sec]
2023-05-30 21:39:15,016 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 21:39:15,106 - INFO - joeynmt.helpers - delete models/transformer_model3/6500.ckpt
2023-05-30 21:39:15,106 - INFO - joeynmt.training - Example #0
2023-05-30 21:39:15,106 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 21:39:15,106 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 21:39:15,106 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'diese', 'beiden', 'Di@@', 'as', 'von', 'zwei', 'Di@@', 'as', 'zeigen,', 'dass', 'die', 'P@@', 'ool@@', 'e', 'der', 'P@@', 'ool@@', 'e', 'der', 'letzten', 'drei', 'Millionen', 'Jahren', 'die', 'letzten', 'drei', 'Millionen', 'Jahren', 'der', 'USA', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'U@@', '-@@', 'M@@', 'um@@', 'pen', 'war.', '</s>']
2023-05-30 21:39:15,106 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 21:39:15,106 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 21:39:15,106 - INFO - joeynmt.training - 	Hypothesis: Ich habe diese beiden Dias von zwei Dias zeigen, dass die Poole der Poole der letzten drei Millionen Jahren die letzten drei Millionen Jahren der USA der VS, mit 40% der VS, mit 40% der VS, mit 40% der U-Mumpen war.
2023-05-30 21:39:15,106 - INFO - joeynmt.training - Example #1
2023-05-30 21:39:15,106 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 21:39:15,106 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 21:39:15,106 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Be@@', 'gin@@', 'n', 'dieser', 'Frage', 'ist,', 'weil', 'es', 'nicht', 'die', 'Di@@', 're@@', 'kt', 'des', 'E@@', 'is', 'zu', 'sehen.', '</s>']
2023-05-30 21:39:15,107 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 21:39:15,107 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 21:39:15,107 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Beginn dieser Frage ist, weil es nicht die Direkt des Eis zu sehen.
2023-05-30 21:39:15,107 - INFO - joeynmt.training - Example #2
2023-05-30 21:39:15,107 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 21:39:15,107 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 21:39:15,107 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'Eis@@', 'k@@', 'ün@@', 'f@@', 'ter', 'auf', 'der', 'Nor@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'er', 'Weise', 'das', 'ist', 'das', 'G@@', 'lob@@', 'al', 'Klima@@', 'wan@@', 'z', 'des', 'glob@@', 'alen', 'Klima@@', 'wandel@@', 's.', '</s>']
2023-05-30 21:39:15,107 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 21:39:15,107 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 21:39:15,107 - INFO - joeynmt.training - 	Hypothesis: Die Eiskünfter auf der Nordpol ist in gewisser Weise das ist das Global Klimawanz des globalen Klimawandels.
2023-05-30 21:39:15,107 - INFO - joeynmt.training - Example #3
2023-05-30 21:39:15,107 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 21:39:15,107 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 21:39:15,107 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'aus', 'der', 'Win@@', 'ter', 'und', 'K@@', 'im@@', 'ation', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'der', 'S@@', 'omm@@', 'er', '</s>']
2023-05-30 21:39:15,107 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 21:39:15,107 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 21:39:15,107 - INFO - joeynmt.training - 	Hypothesis: Es ist aus der Winter und Kimation in den Sommer in den Sommer in den Sommer in den Sommer in der Sommer
2023-05-30 21:39:15,107 - INFO - joeynmt.training - Example #4
2023-05-30 21:39:15,107 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 21:39:15,107 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 21:39:15,107 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Di@@', 'a', 'die', 'ich', 'zeigen,', 'ist', 'eine', 'ver@@', 'schnell@@', 'te', 'Ver@@', 'sion', 'der', 'letzten', '25', 'Jahren', 'passiert', 'ist.', '</s>']
2023-05-30 21:39:15,108 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 21:39:15,108 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 21:39:15,108 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia die ich zeigen, ist eine verschnellte Version der letzten 25 Jahren passiert ist.
2023-05-30 21:39:33,793 - INFO - joeynmt.training - Epoch   3, Step:     9100, Batch Loss:     2.248828, Batch Acc: 0.398335, Tokens per Sec:     3846, Lr: 0.000300
2023-05-30 21:39:52,278 - INFO - joeynmt.training - Epoch   3, Step:     9200, Batch Loss:     2.273961, Batch Acc: 0.405561, Tokens per Sec:     3975, Lr: 0.000300
2023-05-30 21:40:10,322 - INFO - joeynmt.training - Epoch   3, Step:     9300, Batch Loss:     2.335399, Batch Acc: 0.402529, Tokens per Sec:     3971, Lr: 0.000300
2023-05-30 21:40:28,724 - INFO - joeynmt.training - Epoch   3, Step:     9400, Batch Loss:     2.352081, Batch Acc: 0.406471, Tokens per Sec:     4066, Lr: 0.000300
2023-05-30 21:40:47,125 - INFO - joeynmt.training - Epoch   3, Step:     9500, Batch Loss:     2.229865, Batch Acc: 0.403011, Tokens per Sec:     3826, Lr: 0.000300
2023-05-30 21:40:47,125 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 21:40:47,125 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 21:41:50,848 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.44, ppl:  11.45, acc:   0.37, generation: 63.7152[sec], evaluation: 0.0000[sec]
2023-05-30 21:41:50,849 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 21:41:50,941 - INFO - joeynmt.helpers - delete models/transformer_model3/7000.ckpt
2023-05-30 21:41:50,941 - INFO - joeynmt.training - Example #0
2023-05-30 21:41:50,942 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 21:41:50,942 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 21:41:50,942 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Im', 'Jahr', 'zei@@', 'gte', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'sehen,', 'dass', 'die', 'P@@', 'ool@@', 's@@', 'ap@@', ',', 'dass', 'die', 'P@@', 'ool@@', 's@@', 'ap@@', ',', 'der', 'den', 'letzten', 'drei', 'Millionen', 'Jahre', 'in', 'der', 'U@@', '-@@', 'N@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', 'Prozent', 'der', 'U@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'U@@', 'S@@', ',', 'mit', '40@@', '%', 'war.', '</s>']
2023-05-30 21:41:50,942 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 21:41:50,942 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 21:41:50,942 - INFO - joeynmt.training - 	Hypothesis: Im Jahr zeigte ich diese zwei Dias sehen, dass die Poolsap, dass die Poolsap, der den letzten drei Millionen Jahre in der U-N-------Prozent der US, mit 40% der US, mit 40% war.
2023-05-30 21:41:50,942 - INFO - joeynmt.training - Example #1
2023-05-30 21:41:50,942 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 21:41:50,942 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 21:41:50,942 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'das', 'Ver@@', 'ständ@@', 'nis', 'dieses', 'spezi@@', 'f@@', 'ischen', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'Z@@', 'iv@@', 'ilis@@', 'ation', 'des', 'E@@', 'is', 'zu', 'sehen.', '</s>']
2023-05-30 21:41:50,942 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 21:41:50,942 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 21:41:50,942 - INFO - joeynmt.training - 	Hypothesis: Aber das ist das Verständnis dieses spezifischen Problem ist, weil es nicht die Zivilisation des Eis zu sehen.
2023-05-30 21:41:50,942 - INFO - joeynmt.training - Example #2
2023-05-30 21:41:50,942 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 21:41:50,942 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 21:41:50,942 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'Eis@@', 'en@@', 'k@@', 'ap@@', 'f', 'auf', 'der', 'Nor@@', 'd@@', 'p@@', 'f', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'wandel@@', 's', 'uns', 'glob@@', 'al', 'Klima@@', 'wandel@@', '.', '</s>']
2023-05-30 21:41:50,942 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 21:41:50,943 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 21:41:50,943 - INFO - joeynmt.training - 	Hypothesis: Der Eisenkapf auf der Nordpf Herz unseres globalen Klimawandels uns global Klimawandel.
2023-05-30 21:41:50,943 - INFO - joeynmt.training - Example #3
2023-05-30 21:41:50,943 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 21:41:50,943 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 21:41:50,943 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'aus', 'dem', 'Win@@', 'ter', 'und', 'K@@', 'im@@', 'e', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', '</s>']
2023-05-30 21:41:50,943 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 21:41:50,943 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 21:41:50,943 - INFO - joeynmt.training - 	Hypothesis: Es ist aus dem Winter und Kime in den Sommer in den Sommer in den Sommer in den Sommer in den Sommer in den Sommer in den Sommer in den Sommer in den Sommer in den Sommer
2023-05-30 21:41:50,943 - INFO - joeynmt.training - Example #4
2023-05-30 21:41:50,943 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 21:41:50,943 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 21:41:50,943 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Di@@', 'a', 'die', 'ich', 'Ihnen', 'zeigen', 'ist', 'ein', 'ver@@', 'schnell@@', 'er', 'Ver@@', 'sion', 'der', 'letzten', '25', 'Jahren', 'passier@@', 'te.', '</s>']
2023-05-30 21:41:50,943 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 21:41:50,943 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 21:41:50,943 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia die ich Ihnen zeigen ist ein verschneller Version der letzten 25 Jahren passierte.
2023-05-30 21:42:09,339 - INFO - joeynmt.training - Epoch   3, Step:     9600, Batch Loss:     2.226822, Batch Acc: 0.407103, Tokens per Sec:     3921, Lr: 0.000300
2023-05-30 21:42:28,063 - INFO - joeynmt.training - Epoch   3, Step:     9700, Batch Loss:     2.333647, Batch Acc: 0.406118, Tokens per Sec:     3899, Lr: 0.000300
2023-05-30 21:42:47,333 - INFO - joeynmt.training - Epoch   3, Step:     9800, Batch Loss:     2.221987, Batch Acc: 0.406863, Tokens per Sec:     3646, Lr: 0.000300
2023-05-30 21:43:05,904 - INFO - joeynmt.training - Epoch   3, Step:     9900, Batch Loss:     2.349480, Batch Acc: 0.404520, Tokens per Sec:     3920, Lr: 0.000300
2023-05-30 21:43:24,656 - INFO - joeynmt.training - Epoch   3, Step:    10000, Batch Loss:     2.077108, Batch Acc: 0.402370, Tokens per Sec:     3826, Lr: 0.000300
2023-05-30 21:43:24,656 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 21:43:24,656 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 21:44:24,782 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.42, ppl:  11.22, acc:   0.37, generation: 60.1183[sec], evaluation: 0.0000[sec]
2023-05-30 21:44:24,782 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 21:44:24,875 - INFO - joeynmt.helpers - delete models/transformer_model3/7500.ckpt
2023-05-30 21:44:24,876 - INFO - joeynmt.training - Example #0
2023-05-30 21:44:24,876 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 21:44:24,876 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 21:44:24,876 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'diese', 'zwei', 'Di@@', 'as', 'zeigen,', 'dass', 'die', 'zwei', 'Di@@', 'as', 'sehen,', 'dass', 'die', 'P@@', 'ool@@', 'e', 'der', 'P@@', 'ool@@', 's@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'Jahre', 'lang', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'U@@', 'hr', 'war.', '</s>']
2023-05-30 21:44:24,876 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 21:44:24,876 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 21:44:24,876 - INFO - joeynmt.training - 	Hypothesis: Ich habe diese zwei Dias zeigen, dass die zwei Dias sehen, dass die Poole der Poolsap, die die letzten drei Millionen Jahre Jahre lang der VS, mit 40% der VS, mit 40% der VS, mit 40% der Uhr war.
2023-05-30 21:44:24,876 - INFO - joeynmt.training - Example #1
2023-05-30 21:44:24,876 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 21:44:24,876 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 21:44:24,876 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'die', 'Be@@', 'gin@@', 'n', 'dieser', 'spezi@@', 'f@@', 'ischen', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'Z@@', 'iv@@', 'ilis@@', 'ation', 'des', 'E@@', 'is', 'zu', 'sehen.', '</s>']
2023-05-30 21:44:24,876 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 21:44:24,876 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 21:44:24,876 - INFO - joeynmt.training - 	Hypothesis: Aber das ist die Beginn dieser spezifischen Problem ist, weil es nicht die Zivilisation des Eis zu sehen.
2023-05-30 21:44:24,876 - INFO - joeynmt.training - Example #2
2023-05-30 21:44:24,876 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 21:44:24,876 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 21:44:24,877 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'Eis@@', 'sch@@', 'lä@@', 'ge', 'auf', 'der', 'Nor@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'er', 'Weise', 'das', 'wirklich', 'kl@@', 'u@@', 'g', 'Her@@', 'z', 'unseres', 'G@@', 'lob@@', 'alen', 'Klima@@', 'wandel@@', 's.', '</s>']
2023-05-30 21:44:24,877 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 21:44:24,877 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 21:44:24,877 - INFO - joeynmt.training - 	Hypothesis: Der Eisschläge auf der Nordpol ist in gewisser Weise das wirklich klug Herz unseres Globalen Klimawandels.
2023-05-30 21:44:24,877 - INFO - joeynmt.training - Example #3
2023-05-30 21:44:24,877 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 21:44:24,877 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 21:44:24,877 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'aus', 'der', 'Win@@', 'ter', 'und', 'K@@', 'r@@', 'imin@@', 'alität', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', '</s>']
2023-05-30 21:44:24,877 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 21:44:24,877 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 21:44:24,877 - INFO - joeynmt.training - 	Hypothesis: Es ist aus der Winter und Kriminalität in den Sommer in den Sommer in den Sommer in den Sommer in den Sommer in den Sommer
2023-05-30 21:44:24,877 - INFO - joeynmt.training - Example #4
2023-05-30 21:44:24,877 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 21:44:24,877 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 21:44:24,877 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Fol@@', 'ie', 'die', 'ich', 'Ihnen', 'zeigen,', 'ist', 'ein', 'Gesch@@', 'windig@@', 'keit', 'der', 'letzten', '25', 'Jahren', 'ist', 'ein', 'Gesch@@', 'windig@@', 'keit', 'der', 'letzten', '25', 'Jahren', 'gesch@@', 'windig@@', 'keit', 'der', 'letzten', '25', 'Jahren', 'gesch@@', 'windig@@', 'keit', 'ist.', '</s>']
2023-05-30 21:44:24,877 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 21:44:24,877 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 21:44:24,877 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie die ich Ihnen zeigen, ist ein Geschwindigkeit der letzten 25 Jahren ist ein Geschwindigkeit der letzten 25 Jahren geschwindigkeit der letzten 25 Jahren geschwindigkeit ist.
2023-05-30 21:44:44,735 - INFO - joeynmt.training - Epoch   3, Step:    10100, Batch Loss:     2.269657, Batch Acc: 0.408658, Tokens per Sec:     3582, Lr: 0.000300
2023-05-30 21:45:04,176 - INFO - joeynmt.training - Epoch   3, Step:    10200, Batch Loss:     2.463464, Batch Acc: 0.408473, Tokens per Sec:     3632, Lr: 0.000300
2023-05-30 21:45:23,899 - INFO - joeynmt.training - Epoch   3, Step:    10300, Batch Loss:     2.294144, Batch Acc: 0.407328, Tokens per Sec:     3746, Lr: 0.000300
2023-05-30 21:45:42,536 - INFO - joeynmt.training - Epoch   3, Step:    10400, Batch Loss:     2.147767, Batch Acc: 0.412820, Tokens per Sec:     3860, Lr: 0.000300
2023-05-30 21:46:01,100 - INFO - joeynmt.training - Epoch   3, Step:    10500, Batch Loss:     2.202115, Batch Acc: 0.409632, Tokens per Sec:     3962, Lr: 0.000300
2023-05-30 21:46:01,100 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 21:46:01,101 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 21:47:06,149 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.40, ppl:  10.98, acc:   0.37, generation: 65.0408[sec], evaluation: 0.0000[sec]
2023-05-30 21:47:06,150 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 21:47:06,244 - INFO - joeynmt.helpers - delete models/transformer_model3/8000.ckpt
2023-05-30 21:47:06,244 - INFO - joeynmt.training - Example #0
2023-05-30 21:47:06,244 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 21:47:06,244 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 21:47:06,244 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'diese', 'zwei', 'Di@@', 'as', 'ge@@', 'zeigt', 'habe,', 'um', 'zu', 'zeigen,', 'dass', 'die', 'P@@', 'ool@@', 'e', 'von', 'den', 'letzten', 'drei', 'Millionen', 'Jahre', 'vor', 'etwa', 'drei', 'Millionen', 'Jahre', 'vor', 'etwa', 'drei', 'Millionen', 'Jahre', 'vor', 'etwa', 'den', 'Größe', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'war.', '</s>']
2023-05-30 21:47:06,244 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 21:47:06,244 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 21:47:06,244 - INFO - joeynmt.training - 	Hypothesis: Ich habe diese zwei Dias gezeigt habe, um zu zeigen, dass die Poole von den letzten drei Millionen Jahre vor etwa drei Millionen Jahre vor etwa drei Millionen Jahre vor etwa den Größe der VS, mit 40% der VS, mit 40% der VS, mit 40% war.
2023-05-30 21:47:06,244 - INFO - joeynmt.training - Example #1
2023-05-30 21:47:06,245 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 21:47:06,245 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 21:47:06,245 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'die', 'Be@@', 'gin@@', 'n', 'dieses', 'spezi@@', 'f@@', 'ischen', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'Di@@', 're@@', 'kt', 'des', 'E@@', 'is', 'zu', 'zeigen.', '</s>']
2023-05-30 21:47:06,245 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 21:47:06,245 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 21:47:06,245 - INFO - joeynmt.training - 	Hypothesis: Aber das ist die Beginn dieses spezifischen Problem ist, weil es nicht die Direkt des Eis zu zeigen.
2023-05-30 21:47:06,245 - INFO - joeynmt.training - Example #2
2023-05-30 21:47:06,245 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 21:47:06,245 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 21:47:06,245 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'Eis@@', 'sch@@', 'ä@@', 'ss@@', 'liche', 'E@@', 'hr@@', 'e', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'des', 'G@@', 'lob@@', 'alen', 'Klima@@', 'sch@@', 'ir@@', 'm@@', 'alen', 'Klima@@', 'er@@', 'ei@@', 's.', '</s>']
2023-05-30 21:47:06,245 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 21:47:06,245 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 21:47:06,245 - INFO - joeynmt.training - 	Hypothesis: Der Eisschässliche Ehre ist in gewissem Sinne des Globalen Klimaschirmalen Klimaereis.
2023-05-30 21:47:06,245 - INFO - joeynmt.training - Example #3
2023-05-30 21:47:06,245 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 21:47:06,245 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 21:47:06,245 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'Win@@', 'ter', 'und', 'K@@', 'ris@@', 'e', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', '</s>']
2023-05-30 21:47:06,245 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 21:47:06,245 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 21:47:06,245 - INFO - joeynmt.training - 	Hypothesis: Es ist in der Winter und Krise in den Sommer in den Sommer in den Sommer in den Sommer
2023-05-30 21:47:06,245 - INFO - joeynmt.training - Example #4
2023-05-30 21:47:06,246 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 21:47:06,246 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 21:47:06,246 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Di@@', 'a', 'die', 'ich', 'Ihnen', 'hier', 'ist', 'eine', 'Gesch@@', 'windig@@', 'keit', 'der', 'letzten', '25', 'Jahren', 'passiert', 'ist.', '</s>']
2023-05-30 21:47:06,246 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 21:47:06,246 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 21:47:06,246 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia die ich Ihnen hier ist eine Geschwindigkeit der letzten 25 Jahren passiert ist.
2023-05-30 21:47:25,351 - INFO - joeynmt.training - Epoch   3, Step:    10600, Batch Loss:     2.192099, Batch Acc: 0.411654, Tokens per Sec:     3780, Lr: 0.000300
2023-05-30 21:47:26,228 - INFO - joeynmt.training - Epoch   3: total training loss 8089.54
2023-05-30 21:47:26,228 - INFO - joeynmt.training - EPOCH 4
2023-05-30 21:47:43,832 - INFO - joeynmt.training - Epoch   4, Step:    10700, Batch Loss:     2.154677, Batch Acc: 0.434553, Tokens per Sec:     3885, Lr: 0.000300
2023-05-30 21:48:02,651 - INFO - joeynmt.training - Epoch   4, Step:    10800, Batch Loss:     2.142629, Batch Acc: 0.439465, Tokens per Sec:     3837, Lr: 0.000300
2023-05-30 21:48:26,126 - INFO - joeynmt.training - Epoch   4, Step:    10900, Batch Loss:     1.929105, Batch Acc: 0.436721, Tokens per Sec:     3213, Lr: 0.000300
2023-05-30 21:48:44,737 - INFO - joeynmt.training - Epoch   4, Step:    11000, Batch Loss:     2.299257, Batch Acc: 0.435649, Tokens per Sec:     3922, Lr: 0.000300
2023-05-30 21:48:44,737 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 21:48:44,738 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 21:49:50,238 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.40, ppl:  10.99, acc:   0.38, generation: 65.4926[sec], evaluation: 0.0000[sec]
2023-05-30 21:49:50,330 - INFO - joeynmt.helpers - delete models/transformer_model3/8500.ckpt
2023-05-30 21:49:50,332 - INFO - joeynmt.training - Example #0
2023-05-30 21:49:50,332 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 21:49:50,332 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 21:49:50,332 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'diese', 'beiden', 'Di@@', 'as', 'zeigen,', 'dass', 'ich', 'diese', 'beiden', 'Di@@', 'a@@', 'g', 'aus', 'dem', 'P@@', 'ool@@', 'sk@@', 'ap@@', ',', 'der', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', 'in', 'etwa', 'etwa', 'die', 'Größe', 'der', 'Größe', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'be@@', 'kam@@', '.', '</s>']
2023-05-30 21:49:50,332 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 21:49:50,332 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 21:49:50,332 - INFO - joeynmt.training - 	Hypothesis: Ich habe diese beiden Dias zeigen, dass ich diese beiden Diag aus dem Poolskap, der den letzten drei Millionen Jahren in etwa etwa die Größe der Größe der VS, mit 40% der VS, mit 40% der VS, mit 40% der VS, mit 40% bekam.
2023-05-30 21:49:50,332 - INFO - joeynmt.training - Example #1
2023-05-30 21:49:50,332 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 21:49:50,332 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 21:49:50,332 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'die', 'Be@@', 'gin@@', 'n', 'dieser', 'spezi@@', 'elle', 'Problem', 'weil', 'es', 'nicht', 'die', 'Di@@', 'mensi@@', 'on', 'des', 'E@@', 'is', 'zei@@', 'g@@', 'te.', '</s>']
2023-05-30 21:49:50,332 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 21:49:50,333 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 21:49:50,333 - INFO - joeynmt.training - 	Hypothesis: Aber das ist die Beginn dieser spezielle Problem weil es nicht die Dimension des Eis zeigte.
2023-05-30 21:49:50,333 - INFO - joeynmt.training - Example #2
2023-05-30 21:49:50,333 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 21:49:50,333 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 21:49:50,333 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'E@@', 'hr@@', 'e', 'auf', 'dem', 'Nor@@', 'd@@', 'pol@@', ',', 'ist', 'in', 'gew@@', 'iss@@', 'er', 'Weise', 'das', 'kl@@', 'app@@', 'el@@', 't', 'Her@@', 'z', 'des', 'Klima@@', 'wandel@@', 's', 'zu', 'er@@', 'hö@@', 'h@@', 's@@', 'es', 'ist.', '</s>']
2023-05-30 21:49:50,333 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 21:49:50,333 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 21:49:50,333 - INFO - joeynmt.training - 	Hypothesis: Der Ehre auf dem Nordpol, ist in gewisser Weise das klappelt Herz des Klimawandels zu erhöhses ist.
2023-05-30 21:49:50,333 - INFO - joeynmt.training - Example #3
2023-05-30 21:49:50,333 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 21:49:50,333 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 21:49:50,333 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'wird', 'in', 'den', 'Win@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'Win@@', 'ter', 'und', 'K@@', 'ris@@', 'e.', '</s>']
2023-05-30 21:49:50,333 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 21:49:50,333 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 21:49:50,333 - INFO - joeynmt.training - 	Hypothesis: Es wird in den Winter und Krimpt in den Sommer in den Sommer in den Sommer in den Sommer in den Winter und Krise.
2023-05-30 21:49:50,333 - INFO - joeynmt.training - Example #4
2023-05-30 21:49:50,333 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 21:49:50,333 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 21:49:50,333 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'nächste', 'Di@@', 'a', 'die', 'ich', 'zeigen,', 'ist', 'eine', 'Gesch@@', 'windig@@', 'kei@@', 'te', 'der', 'Ver@@', 'sion', 'der', 'letzten', '25', 'Jahren', 'passiert', 'ist.', '</s>']
2023-05-30 21:49:50,333 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 21:49:50,333 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 21:49:50,333 - INFO - joeynmt.training - 	Hypothesis: Der nächste Dia die ich zeigen, ist eine Geschwindigkeite der Version der letzten 25 Jahren passiert ist.
2023-05-30 21:50:09,563 - INFO - joeynmt.training - Epoch   4, Step:    11100, Batch Loss:     2.089293, Batch Acc: 0.434095, Tokens per Sec:     3732, Lr: 0.000300
2023-05-30 21:50:28,643 - INFO - joeynmt.training - Epoch   4, Step:    11200, Batch Loss:     1.919365, Batch Acc: 0.430912, Tokens per Sec:     3762, Lr: 0.000300
2023-05-30 21:50:47,369 - INFO - joeynmt.training - Epoch   4, Step:    11300, Batch Loss:     2.388867, Batch Acc: 0.429882, Tokens per Sec:     3823, Lr: 0.000300
2023-05-30 21:51:06,197 - INFO - joeynmt.training - Epoch   4, Step:    11400, Batch Loss:     2.013929, Batch Acc: 0.426063, Tokens per Sec:     3857, Lr: 0.000300
2023-05-30 21:51:25,185 - INFO - joeynmt.training - Epoch   4, Step:    11500, Batch Loss:     2.242099, Batch Acc: 0.427802, Tokens per Sec:     3784, Lr: 0.000300
2023-05-30 21:51:25,186 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 21:51:25,186 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 21:52:40,643 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.38, ppl:  10.83, acc:   0.38, generation: 75.4499[sec], evaluation: 0.0000[sec]
2023-05-30 21:52:40,644 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 21:52:40,735 - INFO - joeynmt.helpers - delete models/transformer_model3/9000.ckpt
2023-05-30 21:52:40,736 - INFO - joeynmt.training - Example #0
2023-05-30 21:52:40,736 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 21:52:40,736 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 21:52:40,736 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'sehen,', 'um', 'zu', 'zeigen,', 'dass', 'die', 'P@@', 'ool@@', 'sk@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'in', 'etwa', 'etwa', 'der', 'Größe', 'von', 'der', 'Größe', 'des', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'Größe', 'des', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'F@@', 'ro@@', 'm@@', 'pen', 'war.', '</s>']
2023-05-30 21:52:40,736 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 21:52:40,736 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 21:52:40,736 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Dias sehen, um zu zeigen, dass die Poolskap, die die letzten drei Millionen Jahre in etwa etwa der Größe von der Größe des VS, mit 40% der Größe des VS, mit 40% der Frompen war.
2023-05-30 21:52:40,736 - INFO - joeynmt.training - Example #1
2023-05-30 21:52:40,736 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 21:52:40,736 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 21:52:40,736 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'die', 'Be@@', 'gin@@', 'n', 'dieses', 'spezi@@', 'f@@', 'ischen', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'Di@@', 'ät', 'des', 'E@@', 'is', 'zeigt', 'die', 'Z@@', 'eh@@', 'n@@', 'is.', '</s>']
2023-05-30 21:52:40,736 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 21:52:40,736 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 21:52:40,736 - INFO - joeynmt.training - 	Hypothesis: Aber das ist die Beginn dieses spezifischen Problem ist, weil es nicht die Diät des Eis zeigt die Zehnis.
2023-05-30 21:52:40,736 - INFO - joeynmt.training - Example #2
2023-05-30 21:52:40,736 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 21:52:40,736 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 21:52:40,736 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'Eis@@', 'sch@@', 'rit@@', 'ten@@', 'en', 'in', 'der', 'Nor@@', 'd@@', 'pol@@', 'is', 'in', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'des', 'Her@@', 'z', 'des', 'Klima@@', 'wandel@@', 's.', '</s>']
2023-05-30 21:52:40,737 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 21:52:40,737 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 21:52:40,737 - INFO - joeynmt.training - 	Hypothesis: Und die Eisschrittenen in der Nordpolis in gewissem Sinne des Herz des Klimawandels.
2023-05-30 21:52:40,737 - INFO - joeynmt.training - Example #3
2023-05-30 21:52:40,737 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 21:52:40,737 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 21:52:40,737 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'Win@@', 'ter', 'und', 'kr@@', 'im@@', 't', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'zu', 'sein.', '</s>']
2023-05-30 21:52:40,737 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 21:52:40,737 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 21:52:40,737 - INFO - joeynmt.training - 	Hypothesis: Es ist in der Winter und krimt in den Sommer in den Sommer in den Sommer in den Sommer zu sein.
2023-05-30 21:52:40,737 - INFO - joeynmt.training - Example #4
2023-05-30 21:52:40,737 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 21:52:40,737 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 21:52:40,737 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'nächste', 'Di@@', 'a', 'die', 'ich', 'zeigen', 'ist', 'eine', 'ver@@', 'trau@@', 't', 'Ver@@', 'sion', 'von', 'dem,', 'was', 'die', 'letzten', '25', 'Jahre', 'passiert', 'ist.', '</s>']
2023-05-30 21:52:40,737 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 21:52:40,737 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 21:52:40,737 - INFO - joeynmt.training - 	Hypothesis: Und die nächste Dia die ich zeigen ist eine vertraut Version von dem, was die letzten 25 Jahre passiert ist.
2023-05-30 21:52:59,682 - INFO - joeynmt.training - Epoch   4, Step:    11600, Batch Loss:     2.287796, Batch Acc: 0.431600, Tokens per Sec:     3711, Lr: 0.000300
2023-05-30 21:53:18,557 - INFO - joeynmt.training - Epoch   4, Step:    11700, Batch Loss:     2.308569, Batch Acc: 0.434082, Tokens per Sec:     3853, Lr: 0.000300
2023-05-30 21:53:37,564 - INFO - joeynmt.training - Epoch   4, Step:    11800, Batch Loss:     2.132766, Batch Acc: 0.430964, Tokens per Sec:     3779, Lr: 0.000300
2023-05-30 21:53:55,686 - INFO - joeynmt.training - Epoch   4, Step:    11900, Batch Loss:     2.323864, Batch Acc: 0.430310, Tokens per Sec:     4005, Lr: 0.000300
2023-05-30 21:54:14,485 - INFO - joeynmt.training - Epoch   4, Step:    12000, Batch Loss:     2.093915, Batch Acc: 0.428836, Tokens per Sec:     3739, Lr: 0.000300
2023-05-30 21:54:14,485 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 21:54:14,485 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 21:55:23,548 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.38, ppl:  10.77, acc:   0.38, generation: 69.0552[sec], evaluation: 0.0000[sec]
2023-05-30 21:55:23,548 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 21:55:23,639 - INFO - joeynmt.helpers - delete models/transformer_model3/9500.ckpt
2023-05-30 21:55:23,639 - INFO - joeynmt.training - Example #0
2023-05-30 21:55:23,639 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 21:55:23,639 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 21:55:23,639 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'diese', 'zwei', 'Di@@', 'as', 'sehen', 'Sie', 'diese', 'zwei', 'Di@@', 'as', 'sehen', 'um', 'zu', 'zeigen,', 'dass', 'die', 'P@@', 'ool@@', 'e', 'der', 'P@@', 'ool@@', 'e', 'der', 'letzten', 'drei', 'Millionen', 'Jahren', 'in', 'der', 'Größe', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'S@@', ',', 'mit', '40@@', '%', 'des', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'des', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'Größe', 'des', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'P@@']
2023-05-30 21:55:23,639 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 21:55:23,639 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 21:55:23,639 - INFO - joeynmt.training - 	Hypothesis: Ich habe diese zwei Dias sehen Sie diese zwei Dias sehen um zu zeigen, dass die Poole der Poole der letzten drei Millionen Jahren in der Größe der VS, mit 40% der VS, mit 40% der VS, mit 40% der S, mit 40% des VS, mit 40% des VS, mit 40% der Größe des VS, mit 40% der P
2023-05-30 21:55:23,639 - INFO - joeynmt.training - Example #1
2023-05-30 21:55:23,640 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 21:55:23,640 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 21:55:23,640 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'unter@@', 'sch@@', 'ätz@@', 't', 'es', 'tatsächlich', 'die', 'ern@@', 'st', 'dieses', 'spezi@@', 'f@@', 'ischen', 'Problem', 'weil', 'es', 'nicht', 'die', 'Z@@', 'au@@', 'ber@@', 't.', '</s>']
2023-05-30 21:55:23,640 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 21:55:23,640 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 21:55:23,640 - INFO - joeynmt.training - 	Hypothesis: Aber das unterschätzt es tatsächlich die ernst dieses spezifischen Problem weil es nicht die Zaubert.
2023-05-30 21:55:23,640 - INFO - joeynmt.training - Example #2
2023-05-30 21:55:23,640 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 21:55:23,640 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 21:55:23,640 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'Eis@@', 'en', 'auf', 'den', 'Nor@@', 'd@@', 'p@@', 'ool', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'Sinn', 'zu', 'unserem', 'glob@@', 'alen', 'Klima@@', 'wandel@@', '.', '</s>']
2023-05-30 21:55:23,640 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 21:55:23,640 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 21:55:23,640 - INFO - joeynmt.training - 	Hypothesis: Die Eisen auf den Nordpool ist in gewissem Sinn zu unserem globalen Klimawandel.
2023-05-30 21:55:23,640 - INFO - joeynmt.training - Example #3
2023-05-30 21:55:23,640 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 21:55:23,640 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 21:55:23,640 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'Win@@', 'ter', 'und', 'K@@', 'lei@@', 'd', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'ün@@', 'sch@@', 'en.', '</s>']
2023-05-30 21:55:23,640 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 21:55:23,640 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 21:55:23,640 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Kleid in den Sommer und Künschen.
2023-05-30 21:55:23,640 - INFO - joeynmt.training - Example #4
2023-05-30 21:55:23,640 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 21:55:23,640 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 21:55:23,640 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Di@@', 'a', 'die', 'ich', 'Ihnen', 'zeigen', 'ist', 'eine', 'Gesch@@', 'windig@@', 'keit', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert.', '</s>']
2023-05-30 21:55:23,641 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 21:55:23,641 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 21:55:23,641 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia die ich Ihnen zeigen ist eine Geschwindigkeit von dem, was in den letzten 25 Jahren passiert.
2023-05-30 21:55:42,788 - INFO - joeynmt.training - Epoch   4, Step:    12100, Batch Loss:     2.042929, Batch Acc: 0.434101, Tokens per Sec:     3644, Lr: 0.000300
2023-05-30 21:56:01,103 - INFO - joeynmt.training - Epoch   4, Step:    12200, Batch Loss:     2.283618, Batch Acc: 0.434079, Tokens per Sec:     3887, Lr: 0.000300
2023-05-30 21:56:20,603 - INFO - joeynmt.training - Epoch   4, Step:    12300, Batch Loss:     2.152642, Batch Acc: 0.429836, Tokens per Sec:     3823, Lr: 0.000300
2023-05-30 21:56:39,030 - INFO - joeynmt.training - Epoch   4, Step:    12400, Batch Loss:     2.188391, Batch Acc: 0.434677, Tokens per Sec:     3811, Lr: 0.000300
2023-05-30 21:56:57,429 - INFO - joeynmt.training - Epoch   4, Step:    12500, Batch Loss:     2.012777, Batch Acc: 0.431269, Tokens per Sec:     3886, Lr: 0.000300
2023-05-30 21:56:57,430 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 21:56:57,430 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 21:58:06,692 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.36, ppl:  10.60, acc:   0.38, generation: 69.2553[sec], evaluation: 0.0000[sec]
2023-05-30 21:58:06,694 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 21:58:06,783 - INFO - joeynmt.helpers - delete models/transformer_model3/10000.ckpt
2023-05-30 21:58:06,783 - INFO - joeynmt.training - Example #0
2023-05-30 21:58:06,783 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 21:58:06,783 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 21:58:06,783 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'diese', 'zwei', 'Di@@', 'as', 'von', 'zwei', 'Di@@', 'as', 'von', 'Ihnen', 'zu', 'zeigen,', 'dass', 'die', 'P@@', 'ool@@', 's@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'vor', 'etwa', 'etwa', 'etwa', 'etwa', 'der', 'Größe', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'U@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'U@@', '.@@', 'S@@', '.@@', 'S.', '</s>']
2023-05-30 21:58:06,784 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 21:58:06,784 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 21:58:06,784 - INFO - joeynmt.training - 	Hypothesis: Ich habe diese zwei Dias von zwei Dias von Ihnen zu zeigen, dass die Poolsap, die die letzten drei Millionen Jahre vor etwa etwa etwa etwa der Größe der VS, mit 40% der US, mit 40% der U.S.S.
2023-05-30 21:58:06,784 - INFO - joeynmt.training - Example #1
2023-05-30 21:58:06,784 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 21:58:06,784 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 21:58:06,784 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'das', 'Be@@', 'sch@@', 'ätz@@', 'ung', 'dieses', 'spezi@@', 'f@@', 'ischen', 'Problem', 'weil', 'es', 'nicht', 'die', 'Di@@', 're@@', 'kt@@', 'es', 'des', 'E@@', 'is', 'zu', 'sehen.', '</s>']
2023-05-30 21:58:06,784 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 21:58:06,784 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 21:58:06,784 - INFO - joeynmt.training - 	Hypothesis: Aber das ist das Beschätzung dieses spezifischen Problem weil es nicht die Direktes des Eis zu sehen.
2023-05-30 21:58:06,784 - INFO - joeynmt.training - Example #2
2023-05-30 21:58:06,784 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 21:58:06,784 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 21:58:06,784 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'der', 'Eis@@', 'sch@@', 'ä@@', 'm@@', 'me', 'in', 'gew@@', 'iss@@', 'er', 'Weise', 'das', 'ist', 'das', 'das', 'wirklich', 'p@@', 'aar@@', 'ende', 'Her@@', 'z', 'unseres', 'Klima@@', 'wandel@@', 's', 'zu', 'unserem', 'glob@@', 'alen', 'Klima@@', 'wandel@@', '.', '</s>']
2023-05-30 21:58:06,784 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 21:58:06,784 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 21:58:06,784 - INFO - joeynmt.training - 	Hypothesis: Und der Eisschämme in gewisser Weise das ist das das wirklich paarende Herz unseres Klimawandels zu unserem globalen Klimawandel.
2023-05-30 21:58:06,784 - INFO - joeynmt.training - Example #3
2023-05-30 21:58:06,784 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 21:58:06,784 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 21:58:06,784 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'Win@@', 'ter', 'und', 'K@@', 'ä@@', 'mpf@@', 'en,', '</s>']
2023-05-30 21:58:06,785 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 21:58:06,785 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 21:58:06,785 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Kämpfen,
2023-05-30 21:58:06,785 - INFO - joeynmt.training - Example #4
2023-05-30 21:58:06,785 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 21:58:06,785 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 21:58:06,785 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'nächste', 'Di@@', 'a,', 'die', 'ich', 'Ihnen', 'zeigen', 'ist', 'eine', 'Gesch@@', 'windig@@', 'keit', 'von', 'dem,', 'was', 'die', 'letzten', '25', 'Jahren', 'passiert', 'ist.', '</s>']
2023-05-30 21:58:06,785 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 21:58:06,785 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 21:58:06,785 - INFO - joeynmt.training - 	Hypothesis: Und die nächste Dia, die ich Ihnen zeigen ist eine Geschwindigkeit von dem, was die letzten 25 Jahren passiert ist.
2023-05-30 21:58:25,671 - INFO - joeynmt.training - Epoch   4, Step:    12600, Batch Loss:     2.156240, Batch Acc: 0.425916, Tokens per Sec:     3867, Lr: 0.000300
2023-05-30 21:58:45,270 - INFO - joeynmt.training - Epoch   4, Step:    12700, Batch Loss:     2.344094, Batch Acc: 0.432254, Tokens per Sec:     3719, Lr: 0.000300
2023-05-30 21:59:05,053 - INFO - joeynmt.training - Epoch   4, Step:    12800, Batch Loss:     2.130021, Batch Acc: 0.434908, Tokens per Sec:     3656, Lr: 0.000300
2023-05-30 21:59:23,967 - INFO - joeynmt.training - Epoch   4, Step:    12900, Batch Loss:     2.127622, Batch Acc: 0.438584, Tokens per Sec:     3915, Lr: 0.000300
2023-05-30 21:59:42,776 - INFO - joeynmt.training - Epoch   4, Step:    13000, Batch Loss:     2.147446, Batch Acc: 0.435033, Tokens per Sec:     3811, Lr: 0.000300
2023-05-30 21:59:42,777 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 21:59:42,777 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 22:00:52,911 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.36, ppl:  10.57, acc:   0.39, generation: 70.1270[sec], evaluation: 0.0000[sec]
2023-05-30 22:00:52,912 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 22:00:53,004 - INFO - joeynmt.helpers - delete models/transformer_model3/11000.ckpt
2023-05-30 22:00:53,005 - INFO - joeynmt.training - Example #0
2023-05-30 22:00:53,005 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 22:00:53,005 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 22:00:53,005 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'zeigen,', 'dass', 'die', 'P@@', 'ool@@', 'e', 'von', '40', 'Prozent', 'der', 'Größe', 'des', 'letzten', 'drei', 'Millionen', 'Jahre', 'lang', 'von', 'Jahren', 'die', 'Größe', 'des', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'des', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'des', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'des', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'des', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'des', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'des', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'Größe', 'des', 'V@@', 'S@@']
2023-05-30 22:00:53,005 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 22:00:53,006 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 22:00:53,006 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Dias zeigen, dass die Poole von 40 Prozent der Größe des letzten drei Millionen Jahre lang von Jahren die Größe des VS, mit 40% des VS, mit 40% des VS, mit 40% des VS, mit 40% des VS, mit 40% des VS, mit 40% des VS, mit 40% der Größe des VS
2023-05-30 22:00:53,006 - INFO - joeynmt.training - Example #1
2023-05-30 22:00:53,006 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 22:00:53,006 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 22:00:53,006 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Be@@', 'gr@@', 'iff', 'des', 'E@@', 'is', 'des', 'E@@', 'is', 'nicht', 'die', 'D@@', 'ef@@', 'in@@', 'in@@', 's@@', 'besonder@@', 'e', 'des', 'E@@', 'is', 'zei@@', 'gt.', '</s>']
2023-05-30 22:00:53,006 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 22:00:53,006 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 22:00:53,006 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Begriff des Eis des Eis nicht die Defininsbesondere des Eis zeigt.
2023-05-30 22:00:53,006 - INFO - joeynmt.training - Example #2
2023-05-30 22:00:53,006 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 22:00:53,006 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 22:00:53,006 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'Eis@@', 'sch@@', 'mei@@', 'fe', 'auf', 'dem', 'Nor@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'Sinn', 'unseres', 'glob@@', 'alen', 'Klima@@', 'wandel@@', 's', 'zu', 'unserem', 'glob@@', 'alen', 'Klima@@', 'wandel@@', '.', '</s>']
2023-05-30 22:00:53,006 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 22:00:53,006 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 22:00:53,006 - INFO - joeynmt.training - 	Hypothesis: Die Eisschmeife auf dem Nordpol ist in gewissem Sinn unseres globalen Klimawandels zu unserem globalen Klimawandel.
2023-05-30 22:00:53,006 - INFO - joeynmt.training - Example #3
2023-05-30 22:00:53,006 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 22:00:53,006 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 22:00:53,006 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'aus', 'dem', 'Win@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'im', 'S@@', 'omm@@', 'er', 'und', 'sch@@', 'lä@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '</s>']
2023-05-30 22:00:53,006 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 22:00:53,006 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 22:00:53,007 - INFO - joeynmt.training - 	Hypothesis: Es ist aus dem Winter und Krimft im Sommer und schläft im Sommer
2023-05-30 22:00:53,007 - INFO - joeynmt.training - Example #4
2023-05-30 22:00:53,007 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 22:00:53,007 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 22:00:53,007 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Fol@@', 'ie', 'die', 'ich', 'Ihnen', 'zeigen', 'ist', 'eine', 'Gesch@@', 'windig@@', 'kei@@', 't,', 'was', 'die', 'letzten', '25', 'Jahren', 'passiert', 'ist.', '</s>']
2023-05-30 22:00:53,007 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 22:00:53,007 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 22:00:53,007 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie die ich Ihnen zeigen ist eine Geschwindigkeit, was die letzten 25 Jahren passiert ist.
2023-05-30 22:01:12,534 - INFO - joeynmt.training - Epoch   4, Step:    13100, Batch Loss:     2.058146, Batch Acc: 0.434948, Tokens per Sec:     3724, Lr: 0.000300
2023-05-30 22:01:32,621 - INFO - joeynmt.training - Epoch   4, Step:    13200, Batch Loss:     2.304434, Batch Acc: 0.435198, Tokens per Sec:     3624, Lr: 0.000300
2023-05-30 22:01:51,491 - INFO - joeynmt.training - Epoch   4, Step:    13300, Batch Loss:     2.158888, Batch Acc: 0.435914, Tokens per Sec:     3840, Lr: 0.000300
2023-05-30 22:02:10,306 - INFO - joeynmt.training - Epoch   4, Step:    13400, Batch Loss:     2.255147, Batch Acc: 0.431747, Tokens per Sec:     3697, Lr: 0.000300
2023-05-30 22:02:28,890 - INFO - joeynmt.training - Epoch   4, Step:    13500, Batch Loss:     2.251696, Batch Acc: 0.435973, Tokens per Sec:     3851, Lr: 0.000300
2023-05-30 22:02:28,891 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 22:02:28,891 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 22:03:41,720 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.34, ppl:  10.42, acc:   0.39, generation: 72.8220[sec], evaluation: 0.0000[sec]
2023-05-30 22:03:41,720 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 22:03:41,813 - INFO - joeynmt.helpers - delete models/transformer_model3/10500.ckpt
2023-05-30 22:03:41,813 - INFO - joeynmt.training - Example #0
2023-05-30 22:03:41,813 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 22:03:41,813 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 22:03:41,814 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Di@@', 'as', 'zu', 'zeigen,', 'dass', 'die', 'P@@', 'ool@@', 'e', 'der', 'P@@', 'ool@@', 'e', 'der', 'P@@', 'ool@@', 'e', 'der', 'P@@', 'ool@@', 'e', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'Größe', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'Größe', 'der', 'US@@', '-@@', 'A@@', 'hn@@', 'ung', 'war.', '</s>']
2023-05-30 22:03:41,814 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 22:03:41,814 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 22:03:41,814 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese beiden Dias zu zeigen, dass die Poole der Poole der Poole der Poole der VS, mit 40% der Größe der VS, mit 40% der VS, mit 40% der VS, mit 40% der Größe der US-Ahnung war.
2023-05-30 22:03:41,814 - INFO - joeynmt.training - Example #1
2023-05-30 22:03:41,814 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 22:03:41,814 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 22:03:41,814 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'unter@@', 'sch@@', 'ätz@@', 't', 'sich', 'die', 'ern@@', 'st', 'dieses', 'Problem', 'zu', 'sein,', 'weil', 'es', 'nicht', 'die', 'Di@@', 're@@', 'se', 'des', 'E@@', 'is', 'zu', 'sehen.', '</s>']
2023-05-30 22:03:41,814 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 22:03:41,814 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 22:03:41,814 - INFO - joeynmt.training - 	Hypothesis: Aber das unterschätzt sich die ernst dieses Problem zu sein, weil es nicht die Direse des Eis zu sehen.
2023-05-30 22:03:41,814 - INFO - joeynmt.training - Example #2
2023-05-30 22:03:41,814 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 22:03:41,814 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 22:03:41,814 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'Eis@@', 'en@@', 'ke', 'auf', 'dem', 'Nor@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'Sinn', 'unseres', 'glob@@', 'alen', 'Klima@@', 'wandel@@', 's', 'zu', 'unserem', 'glob@@', 'alen', 'Klima@@', '.', '</s>']
2023-05-30 22:03:41,814 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 22:03:41,814 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 22:03:41,814 - INFO - joeynmt.training - 	Hypothesis: Die Eisenke auf dem Nordpol ist in gewissem Sinn unseres globalen Klimawandels zu unserem globalen Klima.
2023-05-30 22:03:41,814 - INFO - joeynmt.training - Example #3
2023-05-30 22:03:41,814 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 22:03:41,814 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 22:03:41,815 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'aus', 'dem', 'Win@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'im', 'S@@', 'omm@@', 'er', 'S@@', 'omm@@', 'er', 'im', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'im@@', 'en.', '</s>']
2023-05-30 22:03:41,815 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 22:03:41,815 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 22:03:41,815 - INFO - joeynmt.training - 	Hypothesis: Es ist aus dem Winter und Krimft im Sommer Sommer im Sommer und Krimen.
2023-05-30 22:03:41,815 - INFO - joeynmt.training - Example #4
2023-05-30 22:03:41,815 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 22:03:41,815 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 22:03:41,815 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Di@@', 'a,', 'die', 'ich', 'Ihnen', 'zeigen', 'ist', 'eine', 'Ver@@', 'sion', 'der', 'Ver@@', 'sion', 'von', '25', 'Jahren', 'gesch@@', 'ehen', 'ist.', '</s>']
2023-05-30 22:03:41,815 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 22:03:41,815 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 22:03:41,815 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia, die ich Ihnen zeigen ist eine Version der Version von 25 Jahren geschehen ist.
2023-05-30 22:04:00,993 - INFO - joeynmt.training - Epoch   4, Step:    13600, Batch Loss:     2.114740, Batch Acc: 0.435052, Tokens per Sec:     3747, Lr: 0.000300
2023-05-30 22:04:20,336 - INFO - joeynmt.training - Epoch   4, Step:    13700, Batch Loss:     2.144757, Batch Acc: 0.437326, Tokens per Sec:     3892, Lr: 0.000300
2023-05-30 22:04:39,784 - INFO - joeynmt.training - Epoch   4, Step:    13800, Batch Loss:     2.071682, Batch Acc: 0.434013, Tokens per Sec:     3785, Lr: 0.000300
2023-05-30 22:04:59,615 - INFO - joeynmt.training - Epoch   4, Step:    13900, Batch Loss:     2.097852, Batch Acc: 0.438945, Tokens per Sec:     3702, Lr: 0.000300
2023-05-30 22:05:18,358 - INFO - joeynmt.training - Epoch   4, Step:    14000, Batch Loss:     2.233219, Batch Acc: 0.432521, Tokens per Sec:     3827, Lr: 0.000300
2023-05-30 22:05:18,358 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 22:05:18,358 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 22:06:20,965 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.33, ppl:  10.28, acc:   0.39, generation: 62.5998[sec], evaluation: 0.0000[sec]
2023-05-30 22:06:20,965 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 22:06:21,062 - INFO - joeynmt.helpers - delete models/transformer_model3/11500.ckpt
2023-05-30 22:06:21,063 - INFO - joeynmt.training - Example #0
2023-05-30 22:06:21,063 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 22:06:21,063 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 22:06:21,063 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Di@@', 'as', 'zu', 'zeigen,', 'dass', 'die', 'P@@', 'ool@@', 'e', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahre', 'lang', 'der', 'Größe', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'er@@', 'fahr@@', 'en.', '</s>']
2023-05-30 22:06:21,063 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 22:06:21,063 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 22:06:21,063 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese beiden Dias zu zeigen, dass die Poole in den letzten drei Millionen Jahren in den letzten drei Millionen Jahre lang der Größe der VS, mit 40% der VS, mit 40% der VS, mit 40% der VS, mit 40% erfahren.
2023-05-30 22:06:21,063 - INFO - joeynmt.training - Example #1
2023-05-30 22:06:21,063 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 22:06:21,063 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 22:06:21,063 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Be@@', 'sit@@', 'z', 'des', 'E@@', 'is', 'des', 'E@@', 'is', 'des', 'E@@', 'is', 'des', 'E@@', 'is', 'zu', 'sehen.', '</s>']
2023-05-30 22:06:21,064 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 22:06:21,064 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 22:06:21,064 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Besitz des Eis des Eis des Eis des Eis zu sehen.
2023-05-30 22:06:21,064 - INFO - joeynmt.training - Example #2
2023-05-30 22:06:21,064 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 22:06:21,064 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 22:06:21,064 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'Eis@@', 'en', 'der', 'Nor@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'Sinn', 'des', 'Klima@@', 'wandel@@', 's', 'und', 'das', 'ist', 'ein', 'glob@@', 'ales', 'Kl@@', 'im@@', 'a', 'zu', 'sein.', '</s>']
2023-05-30 22:06:21,064 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 22:06:21,064 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 22:06:21,064 - INFO - joeynmt.training - 	Hypothesis: Der Eisen der Nordpol ist in gewissem Sinn des Klimawandels und das ist ein globales Klima zu sein.
2023-05-30 22:06:21,064 - INFO - joeynmt.training - Example #3
2023-05-30 22:06:21,064 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 22:06:21,064 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 22:06:21,064 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'Win@@', 'ter', 'und', 'K@@', 'kr@@', 'im@@', 't', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'um@@', 'p@@', 'f', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'Win@@', 'ter', 'und', '</s>']
2023-05-30 22:06:21,064 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 22:06:21,064 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 22:06:21,064 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Kkrimt in den Sommer und Kumpf in den Sommer in den Winter und
2023-05-30 22:06:21,064 - INFO - joeynmt.training - Example #4
2023-05-30 22:06:21,064 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 22:06:21,064 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 22:06:21,064 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'nächste', 'Di@@', 'a', 'zeigt', 'eine', 'Gesch@@', 'windig@@', 'keit', 'von', 'dem', 'ich', 'Ihnen', 'zeigen', 'ist', 'eine', 'Gesch@@', 'windig@@', 'keit', 'von', '25', 'Jahren', 'gesch@@', 'ehen', 'ist.', '</s>']
2023-05-30 22:06:21,064 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 22:06:21,065 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 22:06:21,065 - INFO - joeynmt.training - 	Hypothesis: Und die nächste Dia zeigt eine Geschwindigkeit von dem ich Ihnen zeigen ist eine Geschwindigkeit von 25 Jahren geschehen ist.
2023-05-30 22:06:40,109 - INFO - joeynmt.training - Epoch   4, Step:    14100, Batch Loss:     2.098037, Batch Acc: 0.439386, Tokens per Sec:     3836, Lr: 0.000300
2023-05-30 22:06:46,083 - INFO - joeynmt.training - Epoch   4: total training loss 7525.96
2023-05-30 22:06:46,084 - INFO - joeynmt.training - EPOCH 5
2023-05-30 22:06:58,377 - INFO - joeynmt.training - Epoch   5, Step:    14200, Batch Loss:     1.971309, Batch Acc: 0.455568, Tokens per Sec:     3774, Lr: 0.000300
2023-05-30 22:07:17,731 - INFO - joeynmt.training - Epoch   5, Step:    14300, Batch Loss:     2.070553, Batch Acc: 0.462822, Tokens per Sec:     3677, Lr: 0.000300
2023-05-30 22:07:36,658 - INFO - joeynmt.training - Epoch   5, Step:    14400, Batch Loss:     1.954813, Batch Acc: 0.460143, Tokens per Sec:     3800, Lr: 0.000300
2023-05-30 22:07:55,997 - INFO - joeynmt.training - Epoch   5, Step:    14500, Batch Loss:     2.002349, Batch Acc: 0.460060, Tokens per Sec:     3841, Lr: 0.000300
2023-05-30 22:07:55,997 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 22:07:55,997 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 22:08:59,602 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.33, ppl:  10.27, acc:   0.39, generation: 63.5976[sec], evaluation: 0.0000[sec]
2023-05-30 22:08:59,603 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 22:08:59,693 - INFO - joeynmt.helpers - delete models/transformer_model3/12000.ckpt
2023-05-30 22:08:59,694 - INFO - joeynmt.training - Example #0
2023-05-30 22:08:59,694 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 22:08:59,694 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 22:08:59,694 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Im', 'letzten', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Di@@', 'as', 'sehen,', 'um', 'zu', 'zeigen,', 'dass', 'die', 'Pol@@', 'iz@@', 'iz@@', 'iz@@', 'iz@@', 'ieren', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'lang', 'der', 'Größe', 'des', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'Größe', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'ge@@', 'fr@@', 'ro@@', 'h@@', 'pen', 'war.', '</s>']
2023-05-30 22:08:59,694 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 22:08:59,694 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 22:08:59,694 - INFO - joeynmt.training - 	Hypothesis: Im letzten Jahr habe ich diese beiden Dias sehen, um zu zeigen, dass die Polizizizizieren die letzten drei Millionen Jahre lang der Größe des VS, mit 40% der Größe der VS, mit 40% der VS, mit 40% gefrrohpen war.
2023-05-30 22:08:59,694 - INFO - joeynmt.training - Example #1
2023-05-30 22:08:59,694 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 22:08:59,694 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 22:08:59,694 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Be@@', 'ste', 'dieses', 'spezi@@', 'f@@', 'ische', 'Problem', 'weil', 'es', 'nicht', 'die', 'Di@@', 'te', 'des', 'E@@', 'is', 'zu', 'sehen.', '</s>']
2023-05-30 22:08:59,695 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 22:08:59,695 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 22:08:59,695 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Beste dieses spezifische Problem weil es nicht die Dite des Eis zu sehen.
2023-05-30 22:08:59,695 - INFO - joeynmt.training - Example #2
2023-05-30 22:08:59,695 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 22:08:59,695 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 22:08:59,695 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'Eis@@', 'en@@', 'ba@@', 'hn', 'auf', 'dem', 'Nor@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'Sinn', 'unseres', 'glob@@', 'alen', 'Klima@@', 'wandel@@', 's', 'unseres', 'glob@@', 'alen', 'Klima@@', 'wandel@@', '.', '</s>']
2023-05-30 22:08:59,695 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 22:08:59,695 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 22:08:59,695 - INFO - joeynmt.training - 	Hypothesis: Die Eisenbahn auf dem Nordpol ist in gewissem Sinn unseres globalen Klimawandels unseres globalen Klimawandel.
2023-05-30 22:08:59,695 - INFO - joeynmt.training - Example #3
2023-05-30 22:08:59,695 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 22:08:59,695 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 22:08:59,695 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'Win@@', 'ter', 'und', 'kr@@', 'im@@', 't', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', '</s>']
2023-05-30 22:08:59,695 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 22:08:59,695 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 22:08:59,695 - INFO - joeynmt.training - 	Hypothesis: Es ist in der Winter und krimt in den Sommer in den Sommer in den Sommer in den Sommer in den Sommer in den Sommer in den Sommer
2023-05-30 22:08:59,695 - INFO - joeynmt.training - Example #4
2023-05-30 22:08:59,695 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 22:08:59,695 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 22:08:59,695 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Fol@@', 'ie', 'zeigt,', 'ist', 'eine', 'ver@@', 'schnell@@', 'te', 'Ver@@', 'sion', 'von', 'dem,', 'was', 'die', 'letzten', '25', 'Jahre', 'passiert', 'ist.', '</s>']
2023-05-30 22:08:59,696 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 22:08:59,696 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 22:08:59,696 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie zeigt, ist eine verschnellte Version von dem, was die letzten 25 Jahre passiert ist.
2023-05-30 22:09:19,360 - INFO - joeynmt.training - Epoch   5, Step:    14600, Batch Loss:     2.167585, Batch Acc: 0.462390, Tokens per Sec:     3641, Lr: 0.000300
2023-05-30 22:09:38,711 - INFO - joeynmt.training - Epoch   5, Step:    14700, Batch Loss:     2.046039, Batch Acc: 0.458744, Tokens per Sec:     3707, Lr: 0.000300
2023-05-30 22:09:57,524 - INFO - joeynmt.training - Epoch   5, Step:    14800, Batch Loss:     2.240306, Batch Acc: 0.456120, Tokens per Sec:     3804, Lr: 0.000300
2023-05-30 22:10:16,258 - INFO - joeynmt.training - Epoch   5, Step:    14900, Batch Loss:     1.804624, Batch Acc: 0.458025, Tokens per Sec:     3933, Lr: 0.000300
2023-05-30 22:10:35,693 - INFO - joeynmt.training - Epoch   5, Step:    15000, Batch Loss:     2.179182, Batch Acc: 0.454467, Tokens per Sec:     3797, Lr: 0.000300
2023-05-30 22:10:35,694 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 22:10:35,694 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 22:11:41,054 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.33, ppl:  10.26, acc:   0.39, generation: 65.3534[sec], evaluation: 0.0000[sec]
2023-05-30 22:11:41,055 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 22:11:41,142 - INFO - joeynmt.helpers - delete models/transformer_model3/12500.ckpt
2023-05-30 22:11:41,143 - INFO - joeynmt.training - Example #0
2023-05-30 22:11:41,143 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 22:11:41,143 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 22:11:41,143 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'zeigen,', 'dass', 'die', 'Pol@@', 'i@@', 'zei@@', 'zei@@', 'ge,', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahren', 'in', 'der', 'Größe', 'der', 'Größe', 'der', 'Größe', 'der', 'Größe', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'Größe', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'Größe', 'der', 'F@@', 'est@@', 'ung', 'war.', '</s>']
2023-05-30 22:11:41,144 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 22:11:41,144 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 22:11:41,144 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Dias zeigen, dass die Polizeizeige, die die letzten drei Millionen Jahren in der Größe der Größe der Größe der Größe der VS, mit 40% der Größe der VS, mit 40% der Größe der Festung war.
2023-05-30 22:11:41,144 - INFO - joeynmt.training - Example #1
2023-05-30 22:11:41,144 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 22:11:41,144 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 22:11:41,144 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Be@@', 'sch@@', 'ätz@@', 'ung', 'dieses', 'spezi@@', 'f@@', 'ischen', 'Problem', 'weil', 'es', 'nicht', 'die', 'Di@@', 're@@', 'kt', 'des', 'E@@', 'is', 'zu', 'sehen.', '</s>']
2023-05-30 22:11:41,144 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 22:11:41,144 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 22:11:41,144 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Beschätzung dieses spezifischen Problem weil es nicht die Direkt des Eis zu sehen.
2023-05-30 22:11:41,144 - INFO - joeynmt.training - Example #2
2023-05-30 22:11:41,144 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 22:11:41,144 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 22:11:41,144 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'Eis@@', 'en@@', 'k@@', 'ehr', 'auf', 'dem', 'Nor@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'is@@', 'se', 'Weise', 'das', 'bedeut@@', 'end', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'wandel@@', '.', '</s>']
2023-05-30 22:11:41,144 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 22:11:41,144 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 22:11:41,144 - INFO - joeynmt.training - 	Hypothesis: Der Eisenkehr auf dem Nordpol ist in gewisse Weise das bedeutend Herz unseres globalen Klimawandel.
2023-05-30 22:11:41,144 - INFO - joeynmt.training - Example #3
2023-05-30 22:11:41,144 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 22:11:41,144 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 22:11:41,144 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'aus', 'dem', 'Win@@', 'ter', 'und', 'kr@@', 'is@@', 'e', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'kr@@', 'im@@', 't', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'kr@@', 'is@@', 'e.', '</s>']
2023-05-30 22:11:41,145 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 22:11:41,145 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 22:11:41,145 - INFO - joeynmt.training - 	Hypothesis: Es ist aus dem Winter und krise in den Sommer und krimt in den Sommer in den Sommer und krise.
2023-05-30 22:11:41,145 - INFO - joeynmt.training - Example #4
2023-05-30 22:11:41,145 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 22:11:41,145 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 22:11:41,145 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Fol@@', 'ie', 'die', 'ich', 'Ihnen', 'zeigen', 'ist', 'eine', 'Ver@@', 'sion', 'der', 'Ver@@', 'sion', 'von', 'dem', 'letzten', '25', 'Jahren', 'passiert.', '</s>']
2023-05-30 22:11:41,145 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 22:11:41,145 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 22:11:41,145 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie die ich Ihnen zeigen ist eine Version der Version von dem letzten 25 Jahren passiert.
2023-05-30 22:12:00,521 - INFO - joeynmt.training - Epoch   5, Step:    15100, Batch Loss:     1.995004, Batch Acc: 0.460170, Tokens per Sec:     3705, Lr: 0.000300
2023-05-30 22:12:19,374 - INFO - joeynmt.training - Epoch   5, Step:    15200, Batch Loss:     2.048111, Batch Acc: 0.454558, Tokens per Sec:     3877, Lr: 0.000300
2023-05-30 22:12:38,272 - INFO - joeynmt.training - Epoch   5, Step:    15300, Batch Loss:     2.065286, Batch Acc: 0.454239, Tokens per Sec:     3808, Lr: 0.000300
2023-05-30 22:12:57,974 - INFO - joeynmt.training - Epoch   5, Step:    15400, Batch Loss:     2.085601, Batch Acc: 0.449573, Tokens per Sec:     3685, Lr: 0.000300
2023-05-30 22:13:18,462 - INFO - joeynmt.training - Epoch   5, Step:    15500, Batch Loss:     1.916363, Batch Acc: 0.450962, Tokens per Sec:     3593, Lr: 0.000300
2023-05-30 22:13:18,462 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 22:13:18,462 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 22:14:36,422 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.32, ppl:  10.22, acc:   0.40, generation: 77.9520[sec], evaluation: 0.0000[sec]
2023-05-30 22:14:36,422 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 22:14:36,512 - INFO - joeynmt.helpers - delete models/transformer_model3/13000.ckpt
2023-05-30 22:14:36,513 - INFO - joeynmt.training - Example #0
2023-05-30 22:14:36,513 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 22:14:36,513 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 22:14:36,513 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'zeigen,', 'dass', 'die', 'Pol@@', 'i@@', 'zei', 'zeigen,', 'dass', 'die', 'Pol@@', 'i@@', 'zei', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', 'in', 'der', 'Größe', 'des', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'von', '40@@', '%', '%', 'ge@@', 'wohn@@', 't', 'war.', '</s>']
2023-05-30 22:14:36,513 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 22:14:36,513 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 22:14:36,513 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Dias zeigen, dass die Polizei zeigen, dass die Polizei in den letzten drei Millionen Jahren in der Größe des VS, mit 40% der VS, mit 40% von 40% % gewohnt war.
2023-05-30 22:14:36,513 - INFO - joeynmt.training - Example #1
2023-05-30 22:14:36,513 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 22:14:36,513 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 22:14:36,513 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'ein', 'wenig', 'dieses', 'spezi@@', 'f@@', 'ischen', 'Problem', 'weil', 'es', 'nicht', 'die', 'Di@@', 're@@', 'kt', 'des', 'E@@', 'is', 'zu', 'sehen.', '</s>']
2023-05-30 22:14:36,513 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 22:14:36,513 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 22:14:36,513 - INFO - joeynmt.training - 	Hypothesis: Aber das ist ein wenig dieses spezifischen Problem weil es nicht die Direkt des Eis zu sehen.
2023-05-30 22:14:36,513 - INFO - joeynmt.training - Example #2
2023-05-30 22:14:36,513 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 22:14:36,513 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 22:14:36,513 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'Eis@@', 'k@@', 'reis', 'auf', 'der', 'Nor@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'Sinn', 'unseres', 'glob@@', 'alen', 'Klima@@', 'wandel@@', 's', 'uns', 'glob@@', 'al', 'Klima@@', 'wandel@@', '.', '</s>']
2023-05-30 22:14:36,514 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 22:14:36,514 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 22:14:36,514 - INFO - joeynmt.training - 	Hypothesis: Die Eiskreis auf der Nordpol ist in gewissem Sinn unseres globalen Klimawandels uns global Klimawandel.
2023-05-30 22:14:36,514 - INFO - joeynmt.training - Example #3
2023-05-30 22:14:36,514 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 22:14:36,514 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 22:14:36,514 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'Win@@', 'ter', 'und', 'K@@', 'im@@', 'p@@', 't', 'im', 'S@@', 'omm@@', 'er', 'im', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', '</s>']
2023-05-30 22:14:36,514 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 22:14:36,514 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 22:14:36,514 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Kimpt im Sommer im Sommer in den Sommer in den Sommer
2023-05-30 22:14:36,514 - INFO - joeynmt.training - Example #4
2023-05-30 22:14:36,514 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 22:14:36,514 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 22:14:36,514 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Di@@', 'a', 'die', 'ich', 'Ihnen', 'zeigen', 'ist', 'eine', 'Gesch@@', 'windig@@', 'keit', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passier@@', 'te.', '</s>']
2023-05-30 22:14:36,514 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 22:14:36,514 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 22:14:36,514 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia die ich Ihnen zeigen ist eine Geschwindigkeit von dem, was in den letzten 25 Jahren passierte.
2023-05-30 22:14:55,817 - INFO - joeynmt.training - Epoch   5, Step:    15600, Batch Loss:     2.165983, Batch Acc: 0.450420, Tokens per Sec:     3728, Lr: 0.000300
2023-05-30 22:15:15,456 - INFO - joeynmt.training - Epoch   5, Step:    15700, Batch Loss:     1.997474, Batch Acc: 0.461403, Tokens per Sec:     3697, Lr: 0.000300
2023-05-30 22:15:34,773 - INFO - joeynmt.training - Epoch   5, Step:    15800, Batch Loss:     1.926130, Batch Acc: 0.460328, Tokens per Sec:     3799, Lr: 0.000300
2023-05-30 22:15:53,505 - INFO - joeynmt.training - Epoch   5, Step:    15900, Batch Loss:     1.966483, Batch Acc: 0.450273, Tokens per Sec:     3907, Lr: 0.000300
2023-05-30 22:16:12,691 - INFO - joeynmt.training - Epoch   5, Step:    16000, Batch Loss:     2.041595, Batch Acc: 0.449134, Tokens per Sec:     3664, Lr: 0.000300
2023-05-30 22:16:12,692 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 22:16:12,692 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 22:17:24,256 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.32, ppl:  10.13, acc:   0.40, generation: 71.5566[sec], evaluation: 0.0000[sec]
2023-05-30 22:17:24,256 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 22:17:24,348 - INFO - joeynmt.helpers - delete models/transformer_model3/13500.ckpt
2023-05-30 22:17:24,349 - INFO - joeynmt.training - Example #0
2023-05-30 22:17:24,349 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 22:17:24,349 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 22:17:24,349 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Di@@', 'as', 'ge@@', 'zeigt,', 'dass', 'die', 'P@@', 'ool@@', 'e', 'der', 'P@@', 'ool@@', 'e', 'der', 'P@@', 'ool@@', 'e', 'der', 'P@@', 'ool@@', 'e', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'des', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'U@@', 'S@@', ',', 'mit', '40@@', '%', 'er@@', 'hö@@', 'h@@', 'st', 'war.', '</s>']
2023-05-30 22:17:24,349 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 22:17:24,349 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 22:17:24,349 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese beiden Dias gezeigt, dass die Poole der Poole der Poole der Poole der VS, mit 40% des VS, mit 40% der US, mit 40% erhöhst war.
2023-05-30 22:17:24,349 - INFO - joeynmt.training - Example #1
2023-05-30 22:17:24,349 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 22:17:24,349 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 22:17:24,350 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'die', 'Be@@', 'sch@@', 'ätz@@', 'ung', 'des', 'E@@', 'ss@@', 'ens', 'dieses', 'spezi@@', 'f@@', 'ischen', 'Problem', 'weil', 'es', 'nicht', 'die', 'Di@@', 'mensi@@', 'on', 'des', 'E@@', 'is', 'zu', 'sehen.', '</s>']
2023-05-30 22:17:24,350 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 22:17:24,350 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 22:17:24,350 - INFO - joeynmt.training - 	Hypothesis: Aber das ist die Beschätzung des Essens dieses spezifischen Problem weil es nicht die Dimension des Eis zu sehen.
2023-05-30 22:17:24,350 - INFO - joeynmt.training - Example #2
2023-05-30 22:17:24,350 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 22:17:24,350 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 22:17:24,350 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'Eis@@', 'sch@@', 'lä@@', 'ge', 'auf', 'dem', 'Nor@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'Sinn', 'unseres', 'glob@@', 'alen', 'Klima@@', 'wandel@@', 's', 'zu', 'unserem', 'glob@@', 'alen', 'Klima@@', 'er@@', 's@@', 'aus@@', 'sch@@', 'lä@@', 's@@', 'st.', '</s>']
2023-05-30 22:17:24,350 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 22:17:24,350 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 22:17:24,350 - INFO - joeynmt.training - 	Hypothesis: Der Eisschläge auf dem Nordpol ist in gewissem Sinn unseres globalen Klimawandels zu unserem globalen Klimaersausschlässt.
2023-05-30 22:17:24,350 - INFO - joeynmt.training - Example #3
2023-05-30 22:17:24,350 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 22:17:24,350 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 22:17:24,350 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'Win@@', 'ter', 'und', 'K@@', 'kr@@', 'im@@', 't', 'im', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'lu@@', 'ft', 'im', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', '</s>']
2023-05-30 22:17:24,350 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 22:17:24,350 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 22:17:24,350 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Kkrimt im Sommer und Kluft im Sommer in den Sommer
2023-05-30 22:17:24,350 - INFO - joeynmt.training - Example #4
2023-05-30 22:17:24,350 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 22:17:24,350 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 22:17:24,350 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'nächste', 'Fol@@', 'ie', 'zeigen', 'ist', 'eine', 'ver@@', 'schnell@@', 'te', 'Ver@@', 'sion', 'von', 'dem,', 'was', 'die', 'letzten', '25', 'Jahren', 'passiert.', '</s>']
2023-05-30 22:17:24,351 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 22:17:24,351 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 22:17:24,351 - INFO - joeynmt.training - 	Hypothesis: Und die nächste Folie zeigen ist eine verschnellte Version von dem, was die letzten 25 Jahren passiert.
2023-05-30 22:17:43,332 - INFO - joeynmt.training - Epoch   5, Step:    16100, Batch Loss:     1.940413, Batch Acc: 0.454068, Tokens per Sec:     3746, Lr: 0.000300
2023-05-30 22:18:02,872 - INFO - joeynmt.training - Epoch   5, Step:    16200, Batch Loss:     2.141022, Batch Acc: 0.459412, Tokens per Sec:     3690, Lr: 0.000300
2023-05-30 22:18:22,352 - INFO - joeynmt.training - Epoch   5, Step:    16300, Batch Loss:     2.007225, Batch Acc: 0.451399, Tokens per Sec:     3785, Lr: 0.000300
2023-05-30 22:18:41,188 - INFO - joeynmt.training - Epoch   5, Step:    16400, Batch Loss:     1.971725, Batch Acc: 0.451819, Tokens per Sec:     3772, Lr: 0.000300
2023-05-30 22:19:01,196 - INFO - joeynmt.training - Epoch   5, Step:    16500, Batch Loss:     2.091855, Batch Acc: 0.451077, Tokens per Sec:     3538, Lr: 0.000300
2023-05-30 22:19:01,196 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 22:19:01,196 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 22:20:14,778 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.31, ppl:  10.07, acc:   0.40, generation: 73.5747[sec], evaluation: 0.0000[sec]
2023-05-30 22:20:14,779 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 22:20:14,870 - INFO - joeynmt.helpers - delete models/transformer_model3/14000.ckpt
2023-05-30 22:20:14,871 - INFO - joeynmt.training - Example #0
2023-05-30 22:20:14,871 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 22:20:14,871 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 22:20:14,871 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Di@@', 'as', 'zeigen,', 'dass', 'die', 'Pol@@', 'ar@@', 'z@@', '.@@', ',', 'die', 'die', 'P@@', 'ool@@', 'e', 'drei', 'Millionen', 'Jahren', 'in', 'der', 'Größe', 'des', 'V@@', 'S@@', ',', 'die', 'die', 'Größe', 'des', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'ge@@', 'fa@@', 'ss@@', 'ung', 'der', 'U@@', '-@@', 'Prozent', 'des', 'F@@', 'ro@@', 'm@@', 'ens', 'war.', '</s>']
2023-05-30 22:20:14,871 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 22:20:14,871 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 22:20:14,871 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese beiden Dias zeigen, dass die Polarz., die die Poole drei Millionen Jahren in der Größe des VS, die die Größe des VS, mit 40% gefassung der U-Prozent des Fromens war.
2023-05-30 22:20:14,871 - INFO - joeynmt.training - Example #1
2023-05-30 22:20:14,871 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 22:20:14,871 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 22:20:14,871 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Be@@', 'gr@@', 'iff', 'des', 'E@@', 'is', 'der', 'spezi@@', 'f@@', 'ischen', 'Proble@@', 'me,', 'denn', 'es', 'ist', 'nicht', 'die', 'Di@@', 'mensi@@', 'on', 'des', 'E@@', 'is', 'zu', 'zeigen.', '</s>']
2023-05-30 22:20:14,872 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 22:20:14,872 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 22:20:14,872 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Begriff des Eis der spezifischen Probleme, denn es ist nicht die Dimension des Eis zu zeigen.
2023-05-30 22:20:14,872 - INFO - joeynmt.training - Example #2
2023-05-30 22:20:14,872 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 22:20:14,872 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 22:20:14,872 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is', 'auf', 'der', 'Nor@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'Sinn', 'unseres', 'glob@@', 'alen', 'Klima@@', 'wandel@@', 's', 'des', 'Her@@', 'zen', 'unserer', 'glob@@', 'alen', 'Kl@@', 'im@@', 'a', 'zu', 'machen.', '</s>']
2023-05-30 22:20:14,872 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 22:20:14,872 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 22:20:14,872 - INFO - joeynmt.training - 	Hypothesis: Die Eis auf der Nordpol ist in gewissem Sinn unseres globalen Klimawandels des Herzen unserer globalen Klima zu machen.
2023-05-30 22:20:14,872 - INFO - joeynmt.training - Example #3
2023-05-30 22:20:14,872 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 22:20:14,872 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 22:20:14,872 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'im', 'Win@@', 'kel@@', ',', 'und', 'im', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'im', 'S@@', 'omm@@', 'er', '</s>']
2023-05-30 22:20:14,872 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 22:20:14,872 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 22:20:14,872 - INFO - joeynmt.training - 	Hypothesis: Es ist im Winkel, und im Sommer in den Sommer im Sommer
2023-05-30 22:20:14,872 - INFO - joeynmt.training - Example #4
2023-05-30 22:20:14,872 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 22:20:14,872 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 22:20:14,872 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'der', 'nächste', 'Di@@', 'a', 'die', 'ich', 'Ihnen', 'zeigen', 'ist', 'eine', 'Gesch@@', 'windig@@', 'keit', 'von', 'dem,', 'was', 'die', 'letzten', '25', 'Jahren', 'passiert', 'ist.', '</s>']
2023-05-30 22:20:14,873 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 22:20:14,873 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 22:20:14,873 - INFO - joeynmt.training - 	Hypothesis: Und der nächste Dia die ich Ihnen zeigen ist eine Geschwindigkeit von dem, was die letzten 25 Jahren passiert ist.
2023-05-30 22:20:34,579 - INFO - joeynmt.training - Epoch   5, Step:    16600, Batch Loss:     2.103563, Batch Acc: 0.455813, Tokens per Sec:     3727, Lr: 0.000300
2023-05-30 22:20:53,908 - INFO - joeynmt.training - Epoch   5, Step:    16700, Batch Loss:     2.174295, Batch Acc: 0.452002, Tokens per Sec:     3745, Lr: 0.000300
2023-05-30 22:21:13,216 - INFO - joeynmt.training - Epoch   5, Step:    16800, Batch Loss:     2.096313, Batch Acc: 0.449377, Tokens per Sec:     3759, Lr: 0.000300
2023-05-30 22:21:32,249 - INFO - joeynmt.training - Epoch   5, Step:    16900, Batch Loss:     1.931015, Batch Acc: 0.452927, Tokens per Sec:     3759, Lr: 0.000300
2023-05-30 22:21:51,822 - INFO - joeynmt.training - Epoch   5, Step:    17000, Batch Loss:     2.000572, Batch Acc: 0.451981, Tokens per Sec:     3680, Lr: 0.000300
2023-05-30 22:21:51,822 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 22:21:51,822 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 22:23:03,787 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.29, ppl:   9.89, acc:   0.40, generation: 71.9575[sec], evaluation: 0.0000[sec]
2023-05-30 22:23:03,788 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 22:23:03,880 - INFO - joeynmt.helpers - delete models/transformer_model3/14500.ckpt
2023-05-30 22:23:03,881 - INFO - joeynmt.training - Example #0
2023-05-30 22:23:03,881 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 22:23:03,881 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 22:23:03,881 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Di@@', 'as', 'zu', 'zeigen,', 'dass', 'die', 'Pol@@', 'i@@', 'zei@@', 'ten', 'drei', 'Millionen', 'Jahren', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', 'in', 'etwa', 'die', 'Größe', 'des', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'ge@@', 'fa@@', 'ssen', 'hatte,', 'mit', '40@@', '%', 'ver@@', 'ab@@', 'l@@', 'ück@@', 'ten', 'F@@', 'est@@', 'ru@@', 'm@@', 'pen', 'war.', '</s>']
2023-05-30 22:23:03,881 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 22:23:03,881 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 22:23:03,881 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese beiden Dias zu zeigen, dass die Polizeiten drei Millionen Jahren in den letzten drei Millionen Jahren in etwa die Größe des VS, mit 40% gefassen hatte, mit 40% verablückten Festrumpen war.
2023-05-30 22:23:03,881 - INFO - joeynmt.training - Example #1
2023-05-30 22:23:03,881 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 22:23:03,881 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 22:23:03,881 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'eigentlich', 'die', 'Be@@', 'sch@@', 'ätz@@', 'ung', 'dieses', 'spezi@@', 'f@@', 'ischen', 'Proble@@', 'm,', 'weil', 'es', 'nicht', 'die', 'Di@@', 'a@@', 'g', 'des', 'E@@', 'is', 'zu', 'zeigen.', '</s>']
2023-05-30 22:23:03,881 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 22:23:03,881 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 22:23:03,882 - INFO - joeynmt.training - 	Hypothesis: Aber das ist eigentlich die Beschätzung dieses spezifischen Problem, weil es nicht die Diag des Eis zu zeigen.
2023-05-30 22:23:03,882 - INFO - joeynmt.training - Example #2
2023-05-30 22:23:03,882 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 22:23:03,882 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 22:23:03,882 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'Eis@@', 'sch@@', 'lag', 'auf', 'dem', 'Nor@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'Sinn', 'unseres', 'glob@@', 'alen', 'Klima@@', 'wandel@@', '.', '</s>']
2023-05-30 22:23:03,882 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 22:23:03,882 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 22:23:03,882 - INFO - joeynmt.training - 	Hypothesis: Der Eisschlag auf dem Nordpol ist in gewissem Sinn unseres globalen Klimawandel.
2023-05-30 22:23:03,882 - INFO - joeynmt.training - Example #3
2023-05-30 22:23:03,882 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 22:23:03,882 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 22:23:03,882 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'Win@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'p@@', 'iert', 'im', 'S@@', 'omm@@', 'er', 'im', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', '</s>']
2023-05-30 22:23:03,882 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 22:23:03,882 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 22:23:03,882 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Krimpiert im Sommer im Sommer in den Sommer in den Sommer
2023-05-30 22:23:03,882 - INFO - joeynmt.training - Example #4
2023-05-30 22:23:03,882 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 22:23:03,882 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 22:23:03,882 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Fol@@', 'ie', 'die', 'ich', 'Ihnen', 'zeigen', 'ist', 'eine', 'Ver@@', 'sion', 'von', 'dem', 'Ver@@', 'sion', 'von', 'dem,', 'was', 'die', 'letzten', '25', 'Jahren', 'passier@@', 'te.', '</s>']
2023-05-30 22:23:03,882 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 22:23:03,882 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 22:23:03,882 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie die ich Ihnen zeigen ist eine Version von dem Version von dem, was die letzten 25 Jahren passierte.
2023-05-30 22:23:23,204 - INFO - joeynmt.training - Epoch   5, Step:    17100, Batch Loss:     2.021680, Batch Acc: 0.452626, Tokens per Sec:     3720, Lr: 0.000300
2023-05-30 22:23:42,604 - INFO - joeynmt.training - Epoch   5, Step:    17200, Batch Loss:     2.029910, Batch Acc: 0.448740, Tokens per Sec:     3743, Lr: 0.000300
2023-05-30 22:24:01,488 - INFO - joeynmt.training - Epoch   5, Step:    17300, Batch Loss:     1.889547, Batch Acc: 0.454069, Tokens per Sec:     3720, Lr: 0.000300
2023-05-30 22:24:21,178 - INFO - joeynmt.training - Epoch   5, Step:    17400, Batch Loss:     2.034617, Batch Acc: 0.454823, Tokens per Sec:     3710, Lr: 0.000300
2023-05-30 22:24:41,103 - INFO - joeynmt.training - Epoch   5, Step:    17500, Batch Loss:     2.140839, Batch Acc: 0.450528, Tokens per Sec:     3584, Lr: 0.000300
2023-05-30 22:24:41,104 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 22:24:41,104 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 22:26:00,867 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.29, ppl:   9.86, acc:   0.40, generation: 79.7556[sec], evaluation: 0.0000[sec]
2023-05-30 22:26:00,868 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 22:26:00,960 - INFO - joeynmt.helpers - delete models/transformer_model3/15000.ckpt
2023-05-30 22:26:00,961 - INFO - joeynmt.training - Example #0
2023-05-30 22:26:00,961 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 22:26:00,961 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 22:26:00,961 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 't,', 'ich', 'habe', 'diese', 'zwei', 'Di@@', 'as', 'sehen', 'um', 'zu', 'zeigen,', 'dass', 'die', 'Pol@@', 'i@@', 'zei@@', 'zei@@', 'ge,', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'etwa', 'die', 'Größe', 'des', 'V@@', 'S@@', ',', 'der', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'auf', 'der', 'Größe', 'des', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'ge@@', 'tr@@', 'eten', 'war.', '</s>']
2023-05-30 22:26:00,962 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 22:26:00,962 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 22:26:00,962 - INFO - joeynmt.training - 	Hypothesis: Letzt, ich habe diese zwei Dias sehen um zu zeigen, dass die Polizeizeige, die die letzten drei Millionen Jahre etwa die Größe des VS, der die letzten drei Millionen Jahre auf der Größe des VS, mit 40% getreten war.
2023-05-30 22:26:00,962 - INFO - joeynmt.training - Example #1
2023-05-30 22:26:00,962 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 22:26:00,962 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 22:26:00,962 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Be@@', 'sch@@', 'ätz@@', 'ung', 'dieses', 'spezi@@', 'f@@', 'ischen', 'Proble@@', 'm,', 'weil', 'es', 'nicht', 'die', 'Di@@', 're@@', 'kt', 'des', 'E@@', 'is', 'zei@@', 'g@@', 't.', '</s>']
2023-05-30 22:26:00,962 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 22:26:00,962 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 22:26:00,962 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Beschätzung dieses spezifischen Problem, weil es nicht die Direkt des Eis zeigt.
2023-05-30 22:26:00,962 - INFO - joeynmt.training - Example #2
2023-05-30 22:26:00,962 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 22:26:00,962 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 22:26:00,962 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'E@@', 'is', 'ist', 'der', 'Nor@@', 'd@@', 'po@@', 'l', 'in', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'des', 'Kl@@', 'ar@@', 's', 'des', 'Klima@@', 'wandel@@', 's', 'des', 'Klima@@', 'wandel@@', 's', 'des', 'Klima@@', 'wandel@@', 's', 'zu', 'er@@', 'schaffen.', '</s>']
2023-05-30 22:26:00,962 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 22:26:00,962 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 22:26:00,962 - INFO - joeynmt.training - 	Hypothesis: Der Eis ist der Nordpol in gewissem Sinne des Klars des Klimawandels des Klimawandels des Klimawandels zu erschaffen.
2023-05-30 22:26:00,962 - INFO - joeynmt.training - Example #3
2023-05-30 22:26:00,962 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 22:26:00,962 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 22:26:00,962 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'Win@@', 'ter', 'und', 'kr@@', 'im@@', 'p@@', 't', 'im', 'S@@', 'omm@@', 'er', 'im', 'Som@@', 'mer@@', '.', '</s>']
2023-05-30 22:26:00,963 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 22:26:00,963 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 22:26:00,963 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und krimpt im Sommer im Sommer.
2023-05-30 22:26:00,963 - INFO - joeynmt.training - Example #4
2023-05-30 22:26:00,963 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 22:26:00,963 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 22:26:00,963 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Fol@@', 'ie', 'ist', 'eine', 'besch@@', 'le@@', 'un@@', 'ig@@', 'te', 'Ver@@', 'sion', 'von', 'dem,', 'was', 'die', 'letzten', '25', 'Jahre', 'passiert', 'ist.', '</s>']
2023-05-30 22:26:00,963 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 22:26:00,963 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 22:26:00,963 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie ist eine beschleunigte Version von dem, was die letzten 25 Jahre passiert ist.
2023-05-30 22:26:20,848 - INFO - joeynmt.training - Epoch   5, Step:    17600, Batch Loss:     1.856268, Batch Acc: 0.454014, Tokens per Sec:     3585, Lr: 0.000300
2023-05-30 22:26:33,257 - INFO - joeynmt.training - Epoch   5: total training loss 7189.49
2023-05-30 22:26:33,257 - INFO - joeynmt.training - EPOCH 6
2023-05-30 22:26:40,487 - INFO - joeynmt.training - Epoch   6, Step:    17700, Batch Loss:     1.997033, Batch Acc: 0.480969, Tokens per Sec:     3681, Lr: 0.000300
2023-05-30 22:26:59,393 - INFO - joeynmt.training - Epoch   6, Step:    17800, Batch Loss:     1.936026, Batch Acc: 0.478456, Tokens per Sec:     3754, Lr: 0.000300
2023-05-30 22:27:18,673 - INFO - joeynmt.training - Epoch   6, Step:    17900, Batch Loss:     1.819836, Batch Acc: 0.479230, Tokens per Sec:     3711, Lr: 0.000300
2023-05-30 22:27:37,993 - INFO - joeynmt.training - Epoch   6, Step:    18000, Batch Loss:     1.850367, Batch Acc: 0.477001, Tokens per Sec:     3626, Lr: 0.000300
2023-05-30 22:27:37,993 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 22:27:37,993 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 22:28:47,018 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.29, ppl:   9.88, acc:   0.40, generation: 69.0170[sec], evaluation: 0.0000[sec]
2023-05-30 22:28:47,112 - INFO - joeynmt.helpers - delete models/transformer_model3/15500.ckpt
2023-05-30 22:28:47,113 - INFO - joeynmt.training - Example #0
2023-05-30 22:28:47,113 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 22:28:47,114 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 22:28:47,114 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'zu', 'zeigen,', 'dass', 'die', 'Pol@@', 'ar@@', 'ien', 'in', 'der', 'letzten', 'drei', 'Millionen', 'Jahre', 'in', 'der', 'letzten', 'drei', 'Millionen', 'Jahre', 'in', 'der', 'Größe', 'des', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'von', 'der', 'U@@', '-@@', 'Prozent', 'von', 'der', 'U@@', 'S@@', ',', 'mit', '40@@', '%', 'ge@@', 'he@@', 'h@@', 'ut@@', 'ro@@', 'm@@', 'pen', 'war.', '</s>']
2023-05-30 22:28:47,114 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 22:28:47,114 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 22:28:47,114 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Dias zu zeigen, dass die Polarien in der letzten drei Millionen Jahre in der letzten drei Millionen Jahre in der Größe des VS, mit 40% von der U-Prozent von der US, mit 40% gehehutrompen war.
2023-05-30 22:28:47,114 - INFO - joeynmt.training - Example #1
2023-05-30 22:28:47,114 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 22:28:47,114 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 22:28:47,114 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Be@@', 'sch@@', 'ätz@@', 'ung', 'dieses', 'spezi@@', 'f@@', 'ischen', 'Proble@@', 'm,', 'weil', 'es', 'nicht', 'die', 'Di@@', 'mensi@@', 'on', 'zeigt', 'sich', 'das', 'E@@', 'is', 'zei@@', 'gt.', '</s>']
2023-05-30 22:28:47,114 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 22:28:47,114 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 22:28:47,114 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Beschätzung dieses spezifischen Problem, weil es nicht die Dimension zeigt sich das Eis zeigt.
2023-05-30 22:28:47,114 - INFO - joeynmt.training - Example #2
2023-05-30 22:28:47,114 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 22:28:47,114 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 22:28:47,114 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'Eis@@', 'sch@@', 'ap', 'auf', 'dem', 'Nor@@', 'd@@', 'pol@@', ',', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'des', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'wan@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'wandel@@', 's.', '</s>']
2023-05-30 22:28:47,114 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 22:28:47,114 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 22:28:47,114 - INFO - joeynmt.training - 	Hypothesis: Der Eisschap auf dem Nordpol, ist in gewissem Sinne des Herz unseres globalen Klimawanz unseres globalen Klimawandels.
2023-05-30 22:28:47,114 - INFO - joeynmt.training - Example #3
2023-05-30 22:28:47,114 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 22:28:47,115 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 22:28:47,115 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'im', 'Win@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'p@@', 't', 'im', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'im@@', 'p@@', 't.', '</s>']
2023-05-30 22:28:47,115 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 22:28:47,115 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 22:28:47,115 - INFO - joeynmt.training - 	Hypothesis: Es ist im Winter und Krimpt im Sommer in den Sommer und Krimpt.
2023-05-30 22:28:47,115 - INFO - joeynmt.training - Example #4
2023-05-30 22:28:47,115 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 22:28:47,115 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 22:28:47,115 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Di@@', 'a,', 'die', 'ich', 'Ihnen', 'zeigt', 'ist', 'eine', 'besch@@', 'le@@', 'un@@', 'ig@@', 'te', 'Ver@@', 'sion', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.', '</s>']
2023-05-30 22:28:47,115 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 22:28:47,115 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 22:28:47,115 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia, die ich Ihnen zeigt ist eine beschleunigte Version von dem, was in den letzten 25 Jahren passiert ist.
2023-05-30 22:29:06,805 - INFO - joeynmt.training - Epoch   6, Step:    18100, Batch Loss:     1.921090, Batch Acc: 0.473262, Tokens per Sec:     3720, Lr: 0.000300
2023-05-30 22:29:25,838 - INFO - joeynmt.training - Epoch   6, Step:    18200, Batch Loss:     2.070435, Batch Acc: 0.480618, Tokens per Sec:     3780, Lr: 0.000300
2023-05-30 22:29:46,204 - INFO - joeynmt.training - Epoch   6, Step:    18300, Batch Loss:     1.936271, Batch Acc: 0.473528, Tokens per Sec:     3485, Lr: 0.000300
2023-05-30 22:30:05,981 - INFO - joeynmt.training - Epoch   6, Step:    18400, Batch Loss:     1.726818, Batch Acc: 0.476059, Tokens per Sec:     3660, Lr: 0.000300
2023-05-30 22:30:25,190 - INFO - joeynmt.training - Epoch   6, Step:    18500, Batch Loss:     1.972829, Batch Acc: 0.470901, Tokens per Sec:     3590, Lr: 0.000300
2023-05-30 22:30:25,190 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 22:30:25,190 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 22:31:42,206 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.30, ppl:   9.95, acc:   0.40, generation: 77.0095[sec], evaluation: 0.0000[sec]
2023-05-30 22:31:42,307 - INFO - joeynmt.helpers - delete models/transformer_model3/16000.ckpt
2023-05-30 22:31:42,307 - INFO - joeynmt.training - Example #0
2023-05-30 22:31:42,307 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 22:31:42,308 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 22:31:42,308 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'zu', 'zeigen,', 'dass', 'die', 'Pol@@', 'i@@', 'zei@@', 'sk@@', 'ap@@', ',', 'die', 'die', 'P@@', 'ool@@', 'ei@@', 'sk@@', 'ap@@', ',', 'der', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'in', 'der', 'Größe', 'des', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'ge@@', 'tr@@', 'eten', 'war.', '</s>']
2023-05-30 22:31:42,308 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 22:31:42,308 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 22:31:42,308 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Dias zu zeigen, dass die Polizeiskap, die die Pooleiskap, der die letzten drei Millionen Jahre in der Größe des VS, mit 40% getreten war.
2023-05-30 22:31:42,308 - INFO - joeynmt.training - Example #1
2023-05-30 22:31:42,308 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 22:31:42,308 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 22:31:42,308 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'tatsächlich', 'der', 'Be@@', 'sch@@', 'ätz@@', 'ung', 'dieses', 'spezi@@', 'elle', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'E@@', 'is', 'zu', 'sehen.', '</s>']
2023-05-30 22:31:42,308 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 22:31:42,308 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 22:31:42,308 - INFO - joeynmt.training - 	Hypothesis: Aber das ist tatsächlich der Beschätzung dieses spezielle Problem ist, weil es nicht die Dicke des Eis zu sehen.
2023-05-30 22:31:42,308 - INFO - joeynmt.training - Example #2
2023-05-30 22:31:42,308 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 22:31:42,308 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 22:31:42,308 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'Eis@@', 'sch@@', 'elle', 'E@@', 'is', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'das', 'das', 'das', 'stimm@@', 't', 'für', 'unser', 'Her@@', 'z', 'unseres', 'G@@', 'lob@@', 'al', 'Klima@@', 'wandel@@', '.', '</s>']
2023-05-30 22:31:42,308 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 22:31:42,308 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 22:31:42,308 - INFO - joeynmt.training - 	Hypothesis: Die Eisschelle Eis ist in gewissem Sinne ist das das das stimmt für unser Herz unseres Global Klimawandel.
2023-05-30 22:31:42,308 - INFO - joeynmt.training - Example #3
2023-05-30 22:31:42,308 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 22:31:42,309 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 22:31:42,309 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'Win@@', 'ter', 'und', 'kr@@', 'im@@', 'p@@', 't', 'im', 'S@@', 'omm@@', 'er', 'und', 'kr@@', 'im@@', 'p@@', 't.', '</s>']
2023-05-30 22:31:42,309 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 22:31:42,309 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 22:31:42,309 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und krimpt im Sommer und krimpt.
2023-05-30 22:31:42,309 - INFO - joeynmt.training - Example #4
2023-05-30 22:31:42,309 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 22:31:42,309 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 22:31:42,309 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Fol@@', 'ie', 'zeigt,', 'dass', 'ich', 'Ihnen', 'eine', 'ver@@', 'sion', 'sion', 'sion', 'sion', 'sion', 'sion', 'Ver@@', 'sion', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.', '</s>']
2023-05-30 22:31:42,309 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 22:31:42,309 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 22:31:42,309 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie zeigt, dass ich Ihnen eine version sion sion sion sion sion Version von dem, was in den letzten 25 Jahren passiert ist.
2023-05-30 22:32:01,347 - INFO - joeynmt.training - Epoch   6, Step:    18600, Batch Loss:     1.940535, Batch Acc: 0.469181, Tokens per Sec:     3774, Lr: 0.000300
2023-05-30 22:32:20,360 - INFO - joeynmt.training - Epoch   6, Step:    18700, Batch Loss:     1.771058, Batch Acc: 0.476618, Tokens per Sec:     3777, Lr: 0.000300
2023-05-30 22:32:39,535 - INFO - joeynmt.training - Epoch   6, Step:    18800, Batch Loss:     1.963081, Batch Acc: 0.474206, Tokens per Sec:     3821, Lr: 0.000300
2023-05-30 22:32:59,017 - INFO - joeynmt.training - Epoch   6, Step:    18900, Batch Loss:     2.070302, Batch Acc: 0.470770, Tokens per Sec:     3721, Lr: 0.000300
2023-05-30 22:33:18,889 - INFO - joeynmt.training - Epoch   6, Step:    19000, Batch Loss:     1.961291, Batch Acc: 0.468580, Tokens per Sec:     3522, Lr: 0.000300
2023-05-30 22:33:18,889 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 22:33:18,889 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 22:34:28,184 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.29, ppl:   9.91, acc:   0.40, generation: 69.2878[sec], evaluation: 0.0000[sec]
2023-05-30 22:34:28,276 - INFO - joeynmt.helpers - delete models/transformer_model3/16500.ckpt
2023-05-30 22:34:28,277 - INFO - joeynmt.training - Example #0
2023-05-30 22:34:28,277 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 22:34:28,277 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 22:34:28,277 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'zeigen,', 'dass', 'die', 'Pol@@', 'iz@@', 'op@@', 'hr@@', 'en,', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'in', 'etwa', 'etwa', 'drei', 'Millionen', 'Jahre', 'auf', 'der', 'Größe', 'des', 'F@@', 'est@@', 'es', 'auf', 'den', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'auf', 'den', 'letzten', 'drei', 'Prozent', 'auf', 'auf', 'den', 'letzten', 'drei', 'Prozent', 'auf', 'auf', 'auf', 'der', 'Größe', 'des', 'F@@', 'est@@', 'es', 'war.', '</s>']
2023-05-30 22:34:28,278 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 22:34:28,278 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 22:34:28,278 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Dias zeigen, dass die Polizophren, die die letzten drei Millionen Jahre in etwa etwa drei Millionen Jahre auf der Größe des Festes auf den VS, mit 40% auf den letzten drei Prozent auf auf den letzten drei Prozent auf auf auf der Größe des Festes war.
2023-05-30 22:34:28,278 - INFO - joeynmt.training - Example #1
2023-05-30 22:34:28,278 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 22:34:28,278 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 22:34:28,278 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'eigentlich', 'der', 'Be@@', 'sch@@', 'ätz@@', 'ung', 'dieses', 'spezi@@', 'f@@', 'ische', 'Problem', 'weil', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'E@@', 'is', 'zu', 'sehen.', '</s>']
2023-05-30 22:34:28,278 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 22:34:28,278 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 22:34:28,278 - INFO - joeynmt.training - 	Hypothesis: Aber das ist eigentlich der Beschätzung dieses spezifische Problem weil es nicht die Dicke des Eis zu sehen.
2023-05-30 22:34:28,278 - INFO - joeynmt.training - Example #2
2023-05-30 22:34:28,278 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 22:34:28,278 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 22:34:28,278 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'Eis@@', 'en@@', 'ba@@', 'hn@@', 'ten', 'der', 'Nor@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'er', 'Weise', 'das', 'wirklich', 'kl@@', 'ingt', 'Her@@', 'z', 'der', 'G@@', 'lob@@', 'al@@', 'klim@@', 'a', 'zu', 'sein.', '</s>']
2023-05-30 22:34:28,278 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 22:34:28,278 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 22:34:28,278 - INFO - joeynmt.training - 	Hypothesis: Die Eisenbahnten der Nordpol ist in gewisser Weise das wirklich klingt Herz der Globalklima zu sein.
2023-05-30 22:34:28,278 - INFO - joeynmt.training - Example #3
2023-05-30 22:34:28,278 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 22:34:28,278 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 22:34:28,278 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'Win@@', 'ter', 'und', 'kr@@', 'im@@', 't', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'zu', 'sein.', '</s>']
2023-05-30 22:34:28,279 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 22:34:28,279 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 22:34:28,279 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und krimt in den Sommer in den Sommer in den Sommer zu sein.
2023-05-30 22:34:28,279 - INFO - joeynmt.training - Example #4
2023-05-30 22:34:28,279 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 22:34:28,279 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 22:34:28,279 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Fol@@', 'ie', 'ist', 'eine', 'Gesch@@', 'windig@@', 'keit', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.', '</s>']
2023-05-30 22:34:28,279 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 22:34:28,279 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 22:34:28,279 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie ist eine Geschwindigkeit von dem, was in den letzten 25 Jahren passiert ist.
2023-05-30 22:34:47,184 - INFO - joeynmt.training - Epoch   6, Step:    19100, Batch Loss:     1.942124, Batch Acc: 0.475854, Tokens per Sec:     3781, Lr: 0.000300
2023-05-30 22:35:06,340 - INFO - joeynmt.training - Epoch   6, Step:    19200, Batch Loss:     2.147460, Batch Acc: 0.469308, Tokens per Sec:     3555, Lr: 0.000300
2023-05-30 22:35:25,220 - INFO - joeynmt.training - Epoch   6, Step:    19300, Batch Loss:     1.967940, Batch Acc: 0.469787, Tokens per Sec:     3783, Lr: 0.000300
2023-05-30 22:35:44,775 - INFO - joeynmt.training - Epoch   6, Step:    19400, Batch Loss:     2.014444, Batch Acc: 0.468739, Tokens per Sec:     3851, Lr: 0.000300
2023-05-30 22:36:05,168 - INFO - joeynmt.training - Epoch   6, Step:    19500, Batch Loss:     1.995789, Batch Acc: 0.471915, Tokens per Sec:     3490, Lr: 0.000300
2023-05-30 22:36:05,168 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 22:36:05,168 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 22:37:16,643 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.28, ppl:   9.81, acc:   0.41, generation: 71.4676[sec], evaluation: 0.0000[sec]
2023-05-30 22:37:16,644 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 22:37:16,734 - INFO - joeynmt.helpers - delete models/transformer_model3/18500.ckpt
2023-05-30 22:37:16,735 - INFO - joeynmt.training - Example #0
2023-05-30 22:37:16,735 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 22:37:16,735 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 22:37:16,735 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'zeigen,', 'dass', 'die', 'Pol@@', 'ar@@', 'ar@@', 'ar@@', 'tig', 'der', 'P@@', 'ool@@', 'Eis@@', 'sch@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'etwa', 'etwa', 'die', 'Größe', 'des', 'F@@', 'est@@', 'es', 'zu', 'be@@', 'ge@@', 'g@@', 'ut@@', 'tet', 'hatte.', '</s>']
2023-05-30 22:37:16,735 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 22:37:16,735 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 22:37:16,735 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Dias zeigen, dass die Polararartig der PoolEisschap, die die letzten drei Millionen Jahre etwa etwa die Größe des Festes zu begeguttet hatte.
2023-05-30 22:37:16,735 - INFO - joeynmt.training - Example #1
2023-05-30 22:37:16,735 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 22:37:16,735 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 22:37:16,735 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'tatsächlich', 'die', 'Be@@', 'sch@@', 'äft@@', 'ig@@', 'ung', 'dieses', 'spezi@@', 'f@@', 'ische', 'Proble@@', 'm,', 'weil', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'E@@', 'is', 'zeigt', 'es', 'nicht', 'die', 'Di@@', 're@@', 'kt@@', 'es', 'sehen.', '</s>']
2023-05-30 22:37:16,735 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 22:37:16,735 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 22:37:16,735 - INFO - joeynmt.training - 	Hypothesis: Aber das ist tatsächlich die Beschäftigung dieses spezifische Problem, weil es nicht die Dicke des Eis zeigt es nicht die Direktes sehen.
2023-05-30 22:37:16,735 - INFO - joeynmt.training - Example #2
2023-05-30 22:37:16,736 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 22:37:16,736 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 22:37:16,736 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'Eis@@', 'en@@', 'ba@@', 'hn', 'ist', 'in', 'der', 'Nor@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'des', 'Klima@@', 'wandel@@', 's', 'unserer', 'Klima@@', 'wandel@@', 's', 'von', 'uns', 'glob@@', 'al', 'Klima@@', 'wandel@@', '.', '</s>']
2023-05-30 22:37:16,736 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 22:37:16,736 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 22:37:16,736 - INFO - joeynmt.training - 	Hypothesis: Die Eisenbahn ist in der Nordpol ist in gewissem Sinne des Klimawandels unserer Klimawandels von uns global Klimawandel.
2023-05-30 22:37:16,736 - INFO - joeynmt.training - Example #3
2023-05-30 22:37:16,736 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 22:37:16,736 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 22:37:16,736 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'Win@@', 'ter', 'und', 'kr@@', 'im@@', 't', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'im@@', 'iert', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'kr@@', 'im@@', 't', '</s>']
2023-05-30 22:37:16,736 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 22:37:16,736 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 22:37:16,736 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und krimt in den Sommer und Krimiert in den Sommer in den Sommer und krimt
2023-05-30 22:37:16,736 - INFO - joeynmt.training - Example #4
2023-05-30 22:37:16,736 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 22:37:16,736 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 22:37:16,736 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Fol@@', 'ie', 'zeigt', 'ist', 'eine', 'Gesch@@', 'windig@@', 'keit', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahre', 'passiert.', '</s>']
2023-05-30 22:37:16,736 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 22:37:16,736 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 22:37:16,736 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie zeigt ist eine Geschwindigkeit von dem, was in den letzten 25 Jahre passiert.
2023-05-30 22:37:35,995 - INFO - joeynmt.training - Epoch   6, Step:    19600, Batch Loss:     2.049115, Batch Acc: 0.470301, Tokens per Sec:     3763, Lr: 0.000300
2023-05-30 22:37:55,203 - INFO - joeynmt.training - Epoch   6, Step:    19700, Batch Loss:     2.005162, Batch Acc: 0.470718, Tokens per Sec:     3803, Lr: 0.000300
2023-05-30 22:38:13,542 - INFO - joeynmt.training - Epoch   6, Step:    19800, Batch Loss:     1.973313, Batch Acc: 0.466036, Tokens per Sec:     3903, Lr: 0.000300
2023-05-30 22:38:32,850 - INFO - joeynmt.training - Epoch   6, Step:    19900, Batch Loss:     1.910032, Batch Acc: 0.468608, Tokens per Sec:     3862, Lr: 0.000300
2023-05-30 22:38:51,546 - INFO - joeynmt.training - Epoch   6, Step:    20000, Batch Loss:     1.842828, Batch Acc: 0.470948, Tokens per Sec:     3834, Lr: 0.000300
2023-05-30 22:38:51,547 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 22:38:51,547 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 22:40:02,100 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.28, ppl:   9.76, acc:   0.40, generation: 70.5454[sec], evaluation: 0.0000[sec]
2023-05-30 22:40:02,101 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 22:40:02,192 - INFO - joeynmt.helpers - delete models/transformer_model3/19000.ckpt
2023-05-30 22:40:02,196 - INFO - joeynmt.training - Example #0
2023-05-30 22:40:02,196 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 22:40:02,196 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 22:40:02,196 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'a@@', 'h@@', 'ne@@', 's,', 'um', 'zu', 'zeigen,', 'dass', 'die', 'Pol@@', 'iz@@', 'isten', 'der', 'letzten', 'drei', 'Millionen', 'Jahre', 'lang', 'der', 'F@@', 'est@@', 'ung', 'der', 'Vereinigten', 'Staaten', 'von', 'den', 'Vereinigten', 'Staaten', 'des', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'ge@@', 'sto@@', 'ß@@', 'en.', '</s>']
2023-05-30 22:40:02,197 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 22:40:02,197 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 22:40:02,197 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Diahnes, um zu zeigen, dass die Polizisten der letzten drei Millionen Jahre lang der Festung der Vereinigten Staaten von den Vereinigten Staaten des VS, mit 40% gestoßen.
2023-05-30 22:40:02,197 - INFO - joeynmt.training - Example #1
2023-05-30 22:40:02,197 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 22:40:02,197 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 22:40:02,197 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Be@@', 'sch@@', 'ätz@@', 'ung', 'dieses', 'spezi@@', 'f@@', 'ische', 'Problem', 'weil', 'es', 'nicht', 'die', 'Di@@', 'ag@@', 'ram@@', 'm', 'des', 'E@@', 'is', 'zeigt', 'die', 'E@@', 'is', 'zei@@', 'gt.', '</s>']
2023-05-30 22:40:02,197 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 22:40:02,197 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 22:40:02,197 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Beschätzung dieses spezifische Problem weil es nicht die Diagramm des Eis zeigt die Eis zeigt.
2023-05-30 22:40:02,197 - INFO - joeynmt.training - Example #2
2023-05-30 22:40:02,197 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 22:40:02,197 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 22:40:02,197 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'Eis@@', 'sch@@', 'lä@@', 'ge', 'auf', 'dem', 'Nor@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'er', 'Weise', 'das', 'richtig', 'richtig', 'ist,', 'dass', 'Her@@', 'z', 'unseres', 'Klima@@', 'wandel@@', 's', 'des', 'Klima@@', 'wandel@@', 's.', '</s>']
2023-05-30 22:40:02,197 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 22:40:02,197 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 22:40:02,197 - INFO - joeynmt.training - 	Hypothesis: Die Eisschläge auf dem Nordpol ist in gewisser Weise das richtig richtig ist, dass Herz unseres Klimawandels des Klimawandels.
2023-05-30 22:40:02,197 - INFO - joeynmt.training - Example #3
2023-05-30 22:40:02,197 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 22:40:02,197 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 22:40:02,197 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'Win@@', 'ter', 'und', 'kr@@', 'im@@', 'pf@@', 't.', '</s>']
2023-05-30 22:40:02,198 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 22:40:02,198 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 22:40:02,198 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und krimpft.
2023-05-30 22:40:02,198 - INFO - joeynmt.training - Example #4
2023-05-30 22:40:02,198 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 22:40:02,198 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 22:40:02,198 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Fol@@', 'ie', 'zeigt,', 'die', 'ich', 'Ihnen', 'zeigen', 'habe,', 'ist', 'eine', 'besch@@', 'le@@', 'un@@', 'ig@@', 'te', 'Ver@@', 'sion', 'von', 'dem,', 'was', 'die', 'letzten', '25', 'Jahre', 'passiert.', '</s>']
2023-05-30 22:40:02,198 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 22:40:02,198 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 22:40:02,198 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie zeigt, die ich Ihnen zeigen habe, ist eine beschleunigte Version von dem, was die letzten 25 Jahre passiert.
2023-05-30 22:40:21,264 - INFO - joeynmt.training - Epoch   6, Step:    20100, Batch Loss:     1.839385, Batch Acc: 0.467547, Tokens per Sec:     3792, Lr: 0.000300
2023-05-30 22:40:40,757 - INFO - joeynmt.training - Epoch   6, Step:    20200, Batch Loss:     1.889479, Batch Acc: 0.469336, Tokens per Sec:     3776, Lr: 0.000300
2023-05-30 22:40:59,964 - INFO - joeynmt.training - Epoch   6, Step:    20300, Batch Loss:     2.091233, Batch Acc: 0.465101, Tokens per Sec:     3757, Lr: 0.000300
2023-05-30 22:41:19,719 - INFO - joeynmt.training - Epoch   6, Step:    20400, Batch Loss:     1.958328, Batch Acc: 0.468356, Tokens per Sec:     3579, Lr: 0.000300
2023-05-30 22:41:38,841 - INFO - joeynmt.training - Epoch   6, Step:    20500, Batch Loss:     2.205489, Batch Acc: 0.469304, Tokens per Sec:     3743, Lr: 0.000300
2023-05-30 22:41:38,841 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 22:41:38,841 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 22:42:46,657 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.27, ppl:   9.67, acc:   0.41, generation: 67.8080[sec], evaluation: 0.0000[sec]
2023-05-30 22:42:46,657 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 22:42:46,747 - INFO - joeynmt.helpers - delete models/transformer_model3/17000.ckpt
2023-05-30 22:42:46,747 - INFO - joeynmt.training - Example #0
2023-05-30 22:42:46,747 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 22:42:46,747 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 22:42:46,747 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'ge@@', 'zeigt,', 'dass', 'die', 'P@@', 'ool@@', 'Eis@@', 'sch@@', 'lä@@', 'ge', 'der', 'P@@', 'ool@@', 'Eis@@', 'sk@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'in', 'der', 'Lage', 'der', 'F@@', 'est@@', 'ung', 'der', 'U@@', 'S@@', ',', 'mit', '40@@', '%', 'ge@@', 'tr@@', 'eten', 'ge@@', 'zo@@', 'gen.', '</s>']
2023-05-30 22:42:46,747 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 22:42:46,747 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 22:42:46,747 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Dias gezeigt, dass die PoolEisschläge der PoolEisskap, die die letzten drei Millionen Jahre in der Lage der Festung der US, mit 40% getreten gezogen.
2023-05-30 22:42:46,747 - INFO - joeynmt.training - Example #1
2023-05-30 22:42:46,747 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 22:42:46,748 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 22:42:46,748 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'unter@@', 'sch@@', 'ätz@@', 't', 'das', 'Be@@', 'ste', 'dieses', 'spezi@@', 'f@@', 'ische', 'Problem', 'weil', 'es', 'nicht', 'die', 'Di@@', 're@@', 'kt', 'des', 'E@@', 'is', 'zeigt', 'wird,', '</s>']
2023-05-30 22:42:46,748 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 22:42:46,748 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 22:42:46,748 - INFO - joeynmt.training - 	Hypothesis: Aber das unterschätzt das Beste dieses spezifische Problem weil es nicht die Direkt des Eis zeigt wird,
2023-05-30 22:42:46,748 - INFO - joeynmt.training - Example #2
2023-05-30 22:42:46,748 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 22:42:46,748 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 22:42:46,748 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'Eis@@', 'sch@@', 'lä@@', 'ge', 'auf', 'der', 'Nor@@', 'd@@', 'po@@', 'l', 'gew@@', 'is@@', 'se', 'Weise', 'das', 'kl@@', 'ar', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'wandel@@', 's', 'des', 'Klima@@', 'wandel@@', 's', 'zu', 'sein.', '</s>']
2023-05-30 22:42:46,748 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 22:42:46,748 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 22:42:46,748 - INFO - joeynmt.training - 	Hypothesis: Der Eisschläge auf der Nordpol gewisse Weise das klar Herz unseres globalen Klimawandels des Klimawandels zu sein.
2023-05-30 22:42:46,748 - INFO - joeynmt.training - Example #3
2023-05-30 22:42:46,748 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 22:42:46,748 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 22:42:46,748 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'im', 'S@@', 'omm@@', 'er', 'und', 'kr@@', 'im@@', 't', 'im', 'S@@', 'omm@@', 'er', 'K@@', 'lu@@', 'm@@', 's.', '</s>']
2023-05-30 22:42:46,748 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 22:42:46,748 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 22:42:46,748 - INFO - joeynmt.training - 	Hypothesis: Es ist im Sommer und krimt im Sommer Klums.
2023-05-30 22:42:46,748 - INFO - joeynmt.training - Example #4
2023-05-30 22:42:46,748 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 22:42:46,748 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 22:42:46,748 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Fol@@', 'ie', 'zeigt,', 'die', 'ich', 'Ihnen', 'zeigen', 'ist', 'eine', 'besch@@', 'le@@', 'un@@', 'ig@@', 'te', 'Ver@@', 'sion', 'von', 'dem,', 'was', 'die', 'letzten', '25', 'Jahre', 'passiert.', '</s>']
2023-05-30 22:42:46,749 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 22:42:46,749 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 22:42:46,749 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie zeigt, die ich Ihnen zeigen ist eine beschleunigte Version von dem, was die letzten 25 Jahre passiert.
2023-05-30 22:43:06,218 - INFO - joeynmt.training - Epoch   6, Step:    20600, Batch Loss:     2.028742, Batch Acc: 0.466212, Tokens per Sec:     3669, Lr: 0.000300
2023-05-30 22:43:24,948 - INFO - joeynmt.training - Epoch   6, Step:    20700, Batch Loss:     2.005574, Batch Acc: 0.467176, Tokens per Sec:     3775, Lr: 0.000300
2023-05-30 22:43:43,811 - INFO - joeynmt.training - Epoch   6, Step:    20800, Batch Loss:     2.022052, Batch Acc: 0.466134, Tokens per Sec:     3834, Lr: 0.000300
2023-05-30 22:44:02,510 - INFO - joeynmt.training - Epoch   6, Step:    20900, Batch Loss:     2.067578, Batch Acc: 0.460206, Tokens per Sec:     3868, Lr: 0.000300
2023-05-30 22:44:22,021 - INFO - joeynmt.training - Epoch   6, Step:    21000, Batch Loss:     1.860399, Batch Acc: 0.471233, Tokens per Sec:     3678, Lr: 0.000300
2023-05-30 22:44:22,022 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 22:44:22,022 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 22:45:26,828 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.26, ppl:   9.62, acc:   0.41, generation: 64.7995[sec], evaluation: 0.0000[sec]
2023-05-30 22:45:26,829 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 22:45:26,921 - INFO - joeynmt.helpers - delete models/transformer_model3/18000.ckpt
2023-05-30 22:45:26,922 - INFO - joeynmt.training - Example #0
2023-05-30 22:45:26,922 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 22:45:26,922 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 22:45:26,922 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Fol@@', 'ien', 'zeigen,', 'dass', 'die', 'Pol@@', 'ar@@', 'z@@', '.@@', 'Eis@@', 'sch@@', 'lä@@', 'ge', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'etwa', 'die', 'Größe', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'der', 'Größe', 'des', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'ge@@', 'fr@@', 'ro@@', 'ch@@', 'ern', 'war.', '</s>']
2023-05-30 22:45:26,922 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 22:45:26,922 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 22:45:26,922 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Folien zeigen, dass die Polarz.Eisschläge die letzten drei Millionen Jahre etwa die Größe der VS, mit 40% der Größe des VS, mit 40% gefrrochern war.
2023-05-30 22:45:26,922 - INFO - joeynmt.training - Example #1
2023-05-30 22:45:26,922 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 22:45:26,922 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 22:45:26,922 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Be@@', 'gr@@', 'iff', 'dieses', 'spezi@@', 'f@@', 'ische', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'Di@@', 'mensi@@', 'on', 'des', 'E@@', 'is', 'zei@@', 'g@@', 'ten.', '</s>']
2023-05-30 22:45:26,922 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 22:45:26,922 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 22:45:26,922 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Begriff dieses spezifische Problem ist, weil es nicht die Dimension des Eis zeigten.
2023-05-30 22:45:26,922 - INFO - joeynmt.training - Example #2
2023-05-30 22:45:26,922 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 22:45:26,922 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 22:45:26,922 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'Eis@@', 'en', 'der', 'Eis@@', 'en@@', 'ba@@', 'hn@@', 't', 'in', 'einem', 'gew@@', 'issen', 'Sinn', 'unseres', 'glob@@', 'alen', 'Klima@@', 's', 'des', 'Klima@@', 'wandel@@', 's', 'des', 'Klima@@', 'wandel@@', 's', 'zu', 'unserem', 'glob@@', 'alen', 'Klima@@', 'wandel@@', 's.', '</s>']
2023-05-30 22:45:26,923 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 22:45:26,923 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 22:45:26,923 - INFO - joeynmt.training - 	Hypothesis: Die Eisen der Eisenbahnt in einem gewissen Sinn unseres globalen Klimas des Klimawandels des Klimawandels zu unserem globalen Klimawandels.
2023-05-30 22:45:26,923 - INFO - joeynmt.training - Example #3
2023-05-30 22:45:26,923 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 22:45:26,923 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 22:45:26,923 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'geht', 'also', 'aus', 'dem', 'Win@@', 'ter', 'und', 'kr@@', 'im@@', 't', 'im', 'S@@', 'omm@@', 'er', 'und', 'kr@@', 'im@@', 't', 'sich', 'im', 'S@@', 'omm@@', 'er', 'und', '</s>']
2023-05-30 22:45:26,923 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 22:45:26,923 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 22:45:26,923 - INFO - joeynmt.training - 	Hypothesis: Es geht also aus dem Winter und krimt im Sommer und krimt sich im Sommer und
2023-05-30 22:45:26,923 - INFO - joeynmt.training - Example #4
2023-05-30 22:45:26,923 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 22:45:26,923 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 22:45:26,923 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Fol@@', 'ie', 'die', 'ich', 'Ihnen', 'zeigen', 'ist', 'eine', 'besch@@', 'le@@', 'un@@', 'ig@@', 'te', 'Ver@@', 'sion', 'von', 'dem,', 'was', 'die', 'letzten', '25', 'Jahre', 'passiert.', '</s>']
2023-05-30 22:45:26,923 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 22:45:26,923 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 22:45:26,923 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie die ich Ihnen zeigen ist eine beschleunigte Version von dem, was die letzten 25 Jahre passiert.
2023-05-30 22:45:46,128 - INFO - joeynmt.training - Epoch   6, Step:    21100, Batch Loss:     2.095058, Batch Acc: 0.465402, Tokens per Sec:     3706, Lr: 0.000300
2023-05-30 22:46:05,764 - INFO - joeynmt.training - Epoch   6, Step:    21200, Batch Loss:     2.043687, Batch Acc: 0.465651, Tokens per Sec:     3686, Lr: 0.000300
2023-05-30 22:46:08,496 - INFO - joeynmt.training - Epoch   6: total training loss 6978.38
2023-05-30 22:46:08,498 - INFO - joeynmt.training - EPOCH 7
2023-05-30 22:46:24,873 - INFO - joeynmt.training - Epoch   7, Step:    21300, Batch Loss:     1.680407, Batch Acc: 0.504519, Tokens per Sec:     3831, Lr: 0.000300
2023-05-30 22:46:42,853 - INFO - joeynmt.training - Epoch   7, Step:    21400, Batch Loss:     1.947410, Batch Acc: 0.498796, Tokens per Sec:     3974, Lr: 0.000300
2023-05-30 22:47:01,557 - INFO - joeynmt.training - Epoch   7, Step:    21500, Batch Loss:     1.930264, Batch Acc: 0.495390, Tokens per Sec:     3747, Lr: 0.000300
2023-05-30 22:47:01,558 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 22:47:01,558 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 22:47:58,914 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.27, ppl:   9.66, acc:   0.41, generation: 57.3487[sec], evaluation: 0.0000[sec]
2023-05-30 22:47:59,008 - INFO - joeynmt.helpers - delete models/transformer_model3/17500.ckpt
2023-05-30 22:47:59,012 - INFO - joeynmt.training - Example #0
2023-05-30 22:47:59,012 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 22:47:59,012 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 22:47:59,012 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'ge@@', 'zeigt,', 'dass', 'die', 'Pol@@', 'ar@@', 'z@@', 'y@@', 'ei@@', 'sk@@', 'ap@@', 'ut@@', 'e,', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahre', 'in', 'etwa', 'etwa', 'drei', 'Millionen', 'Jahre', 'in', 'der', 'Größe', 'des', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'ge@@', 'wohn@@', 't.', '</s>']
2023-05-30 22:47:59,013 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 22:47:59,013 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 22:47:59,013 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Dias gezeigt, dass die Polarzyeiskapute, die in den letzten drei Millionen Jahre in etwa etwa drei Millionen Jahre in der Größe des VS, mit 40% gewohnt.
2023-05-30 22:47:59,013 - INFO - joeynmt.training - Example #1
2023-05-30 22:47:59,013 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 22:47:59,013 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 22:47:59,013 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Be@@', 'gr@@', 'iff', 'dieses', 'spezi@@', 'f@@', 'ischen', 'Proble@@', 'm,', 'weil', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'E@@', 'is', 'zu', 'zeigen.', '</s>']
2023-05-30 22:47:59,013 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 22:47:59,013 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 22:47:59,013 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Begriff dieses spezifischen Problem, weil es nicht die Dicke des Eis zu zeigen.
2023-05-30 22:47:59,013 - INFO - joeynmt.training - Example #2
2023-05-30 22:47:59,013 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 22:47:59,013 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 22:47:59,013 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'E@@', 'is', 'in', 'der', 'Nor@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'Klima@@', 'wandel@@', '.', '</s>']
2023-05-30 22:47:59,013 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 22:47:59,013 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 22:47:59,013 - INFO - joeynmt.training - 	Hypothesis: Der Eis in der Nordpol ist in gewissem Sinne ist in gewissem Klimawandel.
2023-05-30 22:47:59,013 - INFO - joeynmt.training - Example #3
2023-05-30 22:47:59,013 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 22:47:59,013 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 22:47:59,013 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'al@@', 'tet', 'im', 'S@@', 'omm@@', 'er', 'und', 'sch@@', 'lä@@', 'ft', 'im', 'S@@', 'omm@@', 'er', 'und', 'sch@@', 'lä@@', 'gt', 'im', 'S@@', 'omm@@', 'er', 'und', '</s>']
2023-05-30 22:47:59,014 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 22:47:59,014 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 22:47:59,014 - INFO - joeynmt.training - 	Hypothesis: Es ist im Winter und schaltet im Sommer und schläft im Sommer und schlägt im Sommer und
2023-05-30 22:47:59,014 - INFO - joeynmt.training - Example #4
2023-05-30 22:47:59,014 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 22:47:59,014 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 22:47:59,014 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'in', 'der', 'nächsten', '25', 'Jahren', 'zeige', 'ich', 'eine', 'Gesch@@', 'windig@@', 'kei@@', 't,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.', '</s>']
2023-05-30 22:47:59,014 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 22:47:59,014 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 22:47:59,014 - INFO - joeynmt.training - 	Hypothesis: Und in der nächsten 25 Jahren zeige ich eine Geschwindigkeit, was in den letzten 25 Jahren passiert ist.
2023-05-30 22:48:18,119 - INFO - joeynmt.training - Epoch   7, Step:    21600, Batch Loss:     1.804308, Batch Acc: 0.498847, Tokens per Sec:     3726, Lr: 0.000300
2023-05-30 22:48:36,662 - INFO - joeynmt.training - Epoch   7, Step:    21700, Batch Loss:     1.791837, Batch Acc: 0.493596, Tokens per Sec:     3954, Lr: 0.000300
2023-05-30 22:48:55,826 - INFO - joeynmt.training - Epoch   7, Step:    21800, Batch Loss:     1.751077, Batch Acc: 0.490546, Tokens per Sec:     3764, Lr: 0.000300
2023-05-30 22:49:14,762 - INFO - joeynmt.training - Epoch   7, Step:    21900, Batch Loss:     2.108874, Batch Acc: 0.485796, Tokens per Sec:     3895, Lr: 0.000300
2023-05-30 22:49:33,574 - INFO - joeynmt.training - Epoch   7, Step:    22000, Batch Loss:     1.929206, Batch Acc: 0.483726, Tokens per Sec:     3831, Lr: 0.000300
2023-05-30 22:49:33,574 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 22:49:33,574 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 22:50:37,598 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.27, ppl:   9.66, acc:   0.41, generation: 64.0162[sec], evaluation: 0.0000[sec]
2023-05-30 22:50:37,691 - INFO - joeynmt.helpers - delete models/transformer_model3/19500.ckpt
2023-05-30 22:50:37,691 - INFO - joeynmt.training - Example #0
2023-05-30 22:50:37,691 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 22:50:37,691 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 22:50:37,691 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'ge@@', 'zeigt', 'habe,', 'dass', 'die', 'Pol@@', 'y@@', 'bo@@', '-@@', 'Eis@@', 'k@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahren', 'auf', 'der', 'Größe', 'der', 'U@@', '-@@', 'U@@', '-@@', '-@@', 'Di@@', 'a@@', 'h@@', 'h@@', 'ne@@', 'te', 'in', 'den', 'USA', '</s>']
2023-05-30 22:50:37,691 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 22:50:37,691 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 22:50:37,691 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Dias gezeigt habe, dass die Polybo-Eiskap, die die letzten drei Millionen Jahren auf der Größe der U-U--Diahhnete in den USA
2023-05-30 22:50:37,691 - INFO - joeynmt.training - Example #1
2023-05-30 22:50:37,691 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 22:50:37,692 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 22:50:37,692 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'die', 'Be@@', 'sonder@@', 'ung', 'der', 'Be@@', 'gin@@', 'n', 'dieser', 'spezi@@', 'ellen', 'Proble@@', 'me,', 'weil', 'es', 'nicht', 'die', 'Di@@', 'mensi@@', 'onen', 'des', 'E@@', 'is', 'zei@@', 'gt.', '</s>']
2023-05-30 22:50:37,692 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 22:50:37,692 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 22:50:37,692 - INFO - joeynmt.training - 	Hypothesis: Aber das ist die Besonderung der Beginn dieser speziellen Probleme, weil es nicht die Dimensionen des Eis zeigt.
2023-05-30 22:50:37,692 - INFO - joeynmt.training - Example #2
2023-05-30 22:50:37,692 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 22:50:37,692 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 22:50:37,692 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'Eis@@', 'sch@@', 'ap', 'auf', 'der', 'Nor@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'des', 'Kl@@', 'är@@', 's', 'und', 'Klima@@', 'wandel@@', 's', 'zu', 'unseren', 'glob@@', 'alen', 'Klima@@', 'sch@@', 'utz@@', 'en.', '</s>']
2023-05-30 22:50:37,692 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 22:50:37,692 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 22:50:37,692 - INFO - joeynmt.training - 	Hypothesis: Die Eisschap auf der Nordpol ist in gewissem Sinne des Klärs und Klimawandels zu unseren globalen Klimaschutzen.
2023-05-30 22:50:37,692 - INFO - joeynmt.training - Example #3
2023-05-30 22:50:37,692 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 22:50:37,692 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 22:50:37,692 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'kr@@', 'im@@', 'pf@@', 't', 'im', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', '</s>']
2023-05-30 22:50:37,692 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 22:50:37,692 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 22:50:37,692 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Sommer und krimpft im Sommer und Kommer in den Sommer und Kommer in den Sommer und
2023-05-30 22:50:37,692 - INFO - joeynmt.training - Example #4
2023-05-30 22:50:37,692 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 22:50:37,692 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 22:50:37,692 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Di@@', 'a,', 'die', 'ich', 'Ihnen', 'zeigen', 'ist', 'eine', 'Gesch@@', 'windig@@', 'keit', 'von', 'den', 'letzten', '25', 'Jahren', 'passiert.', '</s>']
2023-05-30 22:50:37,693 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 22:50:37,693 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 22:50:37,693 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia, die ich Ihnen zeigen ist eine Geschwindigkeit von den letzten 25 Jahren passiert.
2023-05-30 22:50:56,788 - INFO - joeynmt.training - Epoch   7, Step:    22100, Batch Loss:     1.918460, Batch Acc: 0.489204, Tokens per Sec:     3825, Lr: 0.000300
2023-05-30 22:51:15,905 - INFO - joeynmt.training - Epoch   7, Step:    22200, Batch Loss:     1.906015, Batch Acc: 0.488660, Tokens per Sec:     3794, Lr: 0.000300
2023-05-30 22:51:34,952 - INFO - joeynmt.training - Epoch   7, Step:    22300, Batch Loss:     1.780474, Batch Acc: 0.485346, Tokens per Sec:     3749, Lr: 0.000300
2023-05-30 22:51:53,854 - INFO - joeynmt.training - Epoch   7, Step:    22400, Batch Loss:     1.885498, Batch Acc: 0.479537, Tokens per Sec:     3772, Lr: 0.000300
2023-05-30 22:52:13,000 - INFO - joeynmt.training - Epoch   7, Step:    22500, Batch Loss:     1.898682, Batch Acc: 0.481009, Tokens per Sec:     3769, Lr: 0.000300
2023-05-30 22:52:13,001 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 22:52:13,001 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 22:53:10,177 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.26, ppl:   9.62, acc:   0.41, generation: 57.1688[sec], evaluation: 0.0000[sec]
2023-05-30 22:53:10,275 - INFO - joeynmt.helpers - delete models/transformer_model3/20000.ckpt
2023-05-30 22:53:10,275 - INFO - joeynmt.training - Example #0
2023-05-30 22:53:10,275 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 22:53:10,275 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 22:53:10,275 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Di@@', 'as', 'zu', 'zeigen,', 'dass', 'die', 'Pol@@', 'l@@', 'im@@', 'pl@@', 'e', 'Eis@@', 'sch@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'in', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'ge@@', 'fa@@', 'hl@@', 't', 'hatte.', '</s>']
2023-05-30 22:53:10,275 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 22:53:10,275 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 22:53:10,275 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese beiden Dias zu zeigen, dass die Pollimple Eisschap, die die letzten drei Millionen Jahre in der VS, mit 40% gefahlt hatte.
2023-05-30 22:53:10,275 - INFO - joeynmt.training - Example #1
2023-05-30 22:53:10,276 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 22:53:10,276 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 22:53:10,276 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'tatsächlich', 'der', 'Be@@', 'gr@@', 'iff', 'dieses', 'spezi@@', 'f@@', 'ische', 'Problem', 'da@@', 'mit,', 'weil', 'es', 'nicht', 'die', 'Di@@', 'mensi@@', 'on', 'des', 'E@@', 'is', 'zei@@', 'gt.', '</s>']
2023-05-30 22:53:10,276 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 22:53:10,276 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 22:53:10,276 - INFO - joeynmt.training - 	Hypothesis: Aber das ist tatsächlich der Begriff dieses spezifische Problem damit, weil es nicht die Dimension des Eis zeigt.
2023-05-30 22:53:10,276 - INFO - joeynmt.training - Example #2
2023-05-30 22:53:10,276 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 22:53:10,276 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 22:53:10,276 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'Eis@@', 'sch@@', 'me@@', 'fe', 'auf', 'den', 'Nor@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'des', 'Klima@@', 'wandel@@', 's', 'des', 'Klima@@', 'wandel@@', 's', 'des', 'Klima@@', 'wandel@@', 's', 'zu', 'be@@', 'fin@@', 'det.', '</s>']
2023-05-30 22:53:10,276 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 22:53:10,276 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 22:53:10,276 - INFO - joeynmt.training - 	Hypothesis: Der Eisschmefe auf den Nordpol ist in gewissem Sinne des Klimawandels des Klimawandels des Klimawandels zu befindet.
2023-05-30 22:53:10,276 - INFO - joeynmt.training - Example #3
2023-05-30 22:53:10,276 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 22:53:10,276 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 22:53:10,276 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'geht', 'in', 'den', 'Win@@', 'ter', 'und', 'K@@', 'omm@@', 'er', 'im', 'Som@@', 'mer@@', '.', '</s>']
2023-05-30 22:53:10,276 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 22:53:10,276 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 22:53:10,276 - INFO - joeynmt.training - 	Hypothesis: Es geht in den Winter und Kommer im Sommer.
2023-05-30 22:53:10,276 - INFO - joeynmt.training - Example #4
2023-05-30 22:53:10,277 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 22:53:10,277 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 22:53:10,277 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'nächste', 'Fol@@', 'ie', 'zeigen,', 'die', 'ich', 'Ihnen', 'zeigen', 'ist', 'eine', 'Gesch@@', 'windig@@', 'keit', 'von', 'den', 'letzten', '25', 'Jahre', 'passier@@', 'te.', '</s>']
2023-05-30 22:53:10,277 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 22:53:10,277 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 22:53:10,277 - INFO - joeynmt.training - 	Hypothesis: Und die nächste Folie zeigen, die ich Ihnen zeigen ist eine Geschwindigkeit von den letzten 25 Jahre passierte.
2023-05-30 22:53:30,009 - INFO - joeynmt.training - Epoch   7, Step:    22600, Batch Loss:     1.852522, Batch Acc: 0.480583, Tokens per Sec:     3568, Lr: 0.000300
2023-05-30 22:53:49,563 - INFO - joeynmt.training - Epoch   7, Step:    22700, Batch Loss:     1.929398, Batch Acc: 0.481755, Tokens per Sec:     3672, Lr: 0.000300
2023-05-30 22:54:09,015 - INFO - joeynmt.training - Epoch   7, Step:    22800, Batch Loss:     1.876033, Batch Acc: 0.478468, Tokens per Sec:     3556, Lr: 0.000300
2023-05-30 22:54:28,149 - INFO - joeynmt.training - Epoch   7, Step:    22900, Batch Loss:     2.068890, Batch Acc: 0.477202, Tokens per Sec:     3766, Lr: 0.000300
2023-05-30 22:54:47,124 - INFO - joeynmt.training - Epoch   7, Step:    23000, Batch Loss:     2.084563, Batch Acc: 0.478727, Tokens per Sec:     3903, Lr: 0.000300
2023-05-30 22:54:47,124 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 22:54:47,125 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 22:55:51,570 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.26, ppl:   9.58, acc:   0.41, generation: 64.4385[sec], evaluation: 0.0000[sec]
2023-05-30 22:55:51,574 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 22:55:51,670 - INFO - joeynmt.helpers - delete models/transformer_model3/20500.ckpt
2023-05-30 22:55:51,671 - INFO - joeynmt.training - Example #0
2023-05-30 22:55:51,671 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 22:55:51,671 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 22:55:51,671 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'zeigen,', 'dass', 'die', 'Pol@@', 'i@@', 'zei@@', 'sk@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'in', 'etwa', 'die', 'Größe', 'des', 'US@@', 'A,', 'die', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahre', 'ge@@', 'hab@@', 't', 'hatte.', '</s>']
2023-05-30 22:55:51,671 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 22:55:51,671 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 22:55:51,671 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Dias zeigen, dass die Polizeiskap, die die letzten drei Millionen Jahre in etwa die Größe des USA, die die in den letzten drei Millionen Jahre gehabt hatte.
2023-05-30 22:55:51,671 - INFO - joeynmt.training - Example #1
2023-05-30 22:55:51,671 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 22:55:51,671 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 22:55:51,671 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Be@@', 'sch@@', 'ätz@@', 'ung', 'dieses', 'spezi@@', 'f@@', 'ische', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'Di@@', 're@@', 'kt', 'des', 'E@@', 'is', 'zu', 'sehen.', '</s>']
2023-05-30 22:55:51,671 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 22:55:51,671 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 22:55:51,671 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Beschätzung dieses spezifische Problem ist, weil es nicht die Direkt des Eis zu sehen.
2023-05-30 22:55:51,671 - INFO - joeynmt.training - Example #2
2023-05-30 22:55:51,672 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 22:55:51,672 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 22:55:51,672 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'Eis@@', 'sch@@', 'ap', 'auf', 'dem', 'Nor@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'er', 'Weise', 'das', 'wirklich', 'bedeut@@', 'end', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Kl@@', 'im@@', 'a', 'zu', 'machen.', '</s>']
2023-05-30 22:55:51,672 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 22:55:51,672 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 22:55:51,672 - INFO - joeynmt.training - 	Hypothesis: Die Eisschap auf dem Nordpol ist in gewisser Weise das wirklich bedeutend Herz unseres globalen Klima zu machen.
2023-05-30 22:55:51,672 - INFO - joeynmt.training - Example #3
2023-05-30 22:55:51,672 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 22:55:51,672 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 22:55:51,672 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'wird', 'in', 'den', 'Win@@', 'ter', 'und', 'kr@@', 'im@@', 'p@@', 't', 'im', 'S@@', 'omm@@', 'er', 'K@@', 'omm@@', 'er', 'im', 'S@@', 'omm@@', 'er', '</s>']
2023-05-30 22:55:51,672 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 22:55:51,672 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 22:55:51,672 - INFO - joeynmt.training - 	Hypothesis: Es wird in den Winter und krimpt im Sommer Kommer im Sommer
2023-05-30 22:55:51,672 - INFO - joeynmt.training - Example #4
2023-05-30 22:55:51,672 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 22:55:51,672 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 22:55:51,672 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Fol@@', 'ie', 'ist', 'die', 'ich', 'Ihnen', 'zeigen', 'ist', 'eine', 'Gesch@@', 'windig@@', 'keit', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.', '</s>']
2023-05-30 22:55:51,672 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 22:55:51,672 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 22:55:51,672 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie ist die ich Ihnen zeigen ist eine Geschwindigkeit von dem, was in den letzten 25 Jahren passiert ist.
2023-05-30 22:56:10,562 - INFO - joeynmt.training - Epoch   7, Step:    23100, Batch Loss:     1.803622, Batch Acc: 0.480486, Tokens per Sec:     3754, Lr: 0.000300
2023-05-30 22:56:30,208 - INFO - joeynmt.training - Epoch   7, Step:    23200, Batch Loss:     1.846554, Batch Acc: 0.477205, Tokens per Sec:     3640, Lr: 0.000300
2023-05-30 22:56:49,117 - INFO - joeynmt.training - Epoch   7, Step:    23300, Batch Loss:     1.781177, Batch Acc: 0.482880, Tokens per Sec:     3831, Lr: 0.000300
2023-05-30 22:57:07,635 - INFO - joeynmt.training - Epoch   7, Step:    23400, Batch Loss:     1.855956, Batch Acc: 0.476625, Tokens per Sec:     3887, Lr: 0.000300
2023-05-30 22:57:26,204 - INFO - joeynmt.training - Epoch   7, Step:    23500, Batch Loss:     2.082795, Batch Acc: 0.478330, Tokens per Sec:     3884, Lr: 0.000300
2023-05-30 22:57:26,204 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 22:57:26,204 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 22:58:24,890 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.26, ppl:   9.54, acc:   0.41, generation: 58.6787[sec], evaluation: 0.0000[sec]
2023-05-30 22:58:24,892 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 22:58:24,979 - INFO - joeynmt.helpers - delete models/transformer_model3/21500.ckpt
2023-05-30 22:58:24,980 - INFO - joeynmt.training - Example #0
2023-05-30 22:58:24,980 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 22:58:24,980 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 22:58:24,980 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Di@@', 'as', 'ge@@', 'zeigt,', 'dass', 'der', 'Pol@@', 'iz@@', 'ist', 'die', 'P@@', 'ool@@', 'Eis@@', 'sk@@', 'ap@@', ',', 'der', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'in', 'der', 'Größe', 'der', 'V@@', 'S@@', ',', 'mit', '40@@', '%', 'ge@@', 'ei@@', 'g@@', 'net', 'hat,', 'mit', '40@@', '%', 'ge@@', 'wohn@@', 't', 'war.', '</s>']
2023-05-30 22:58:24,981 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 22:58:24,981 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 22:58:24,981 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese beiden Dias gezeigt, dass der Polizist die PoolEisskap, der die letzten drei Millionen Jahre in der Größe der VS, mit 40% geeignet hat, mit 40% gewohnt war.
2023-05-30 22:58:24,981 - INFO - joeynmt.training - Example #1
2023-05-30 22:58:24,981 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 22:58:24,981 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 22:58:24,981 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'tatsächlich', 'der', 'Be@@', 'gr@@', 'iff', 'dieses', 'spezi@@', 'f@@', 'ischen', 'Problem', 'weil', 'es', 'nicht', 'die', 'Di@@', 're@@', 'kt', 'des', 'E@@', 'is', 'zu', 'sehen.', '</s>']
2023-05-30 22:58:24,981 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 22:58:24,981 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 22:58:24,981 - INFO - joeynmt.training - 	Hypothesis: Aber das ist tatsächlich der Begriff dieses spezifischen Problem weil es nicht die Direkt des Eis zu sehen.
2023-05-30 22:58:24,981 - INFO - joeynmt.training - Example #2
2023-05-30 22:58:24,981 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 22:58:24,981 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 22:58:24,981 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'Eis@@', 'sch@@', 'ap', 'am', 'Nor@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'das', 'das', 'wirklich', 'wirklich', 'das', 'Kl@@', 'im@@', 'im@@', 'a', 'zu', 'er@@', 'fahr@@', 'en.', '</s>']
2023-05-30 22:58:24,981 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 22:58:24,981 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 22:58:24,981 - INFO - joeynmt.training - 	Hypothesis: Der Eisschap am Nordpol ist in gewissem Sinne ist das das wirklich wirklich das Klimima zu erfahren.
2023-05-30 22:58:24,981 - INFO - joeynmt.training - Example #3
2023-05-30 22:58:24,981 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 22:58:24,981 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 22:58:24,981 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'Win@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 't', 'im', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'sch@@', 'al@@', 'z@@', 't.', '</s>']
2023-05-30 22:58:24,982 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 22:58:24,982 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 22:58:24,982 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Krimt im Sommer in den Sommer in den Sommer in den Sommer und schalzt.
2023-05-30 22:58:24,982 - INFO - joeynmt.training - Example #4
2023-05-30 22:58:24,982 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 22:58:24,982 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 22:58:24,982 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Fol@@', 'ie', 'ist', 'ein', 'besch@@', 'le@@', 'un@@', 'ig@@', 'te', 'Ver@@', 'sion', 'des', 'letzten', '25', 'Jahren', 'gesch@@', 'windig@@', 'keit', 'der', 'letzten', '25', 'Jahre', 'gesch@@', 'ehen', 'ist.', '</s>']
2023-05-30 22:58:24,982 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 22:58:24,982 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 22:58:24,982 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie ist ein beschleunigte Version des letzten 25 Jahren geschwindigkeit der letzten 25 Jahre geschehen ist.
2023-05-30 22:58:44,501 - INFO - joeynmt.training - Epoch   7, Step:    23600, Batch Loss:     2.002136, Batch Acc: 0.475825, Tokens per Sec:     3634, Lr: 0.000300
2023-05-30 22:59:03,561 - INFO - joeynmt.training - Epoch   7, Step:    23700, Batch Loss:     1.981205, Batch Acc: 0.479758, Tokens per Sec:     3830, Lr: 0.000300
2023-05-30 22:59:23,070 - INFO - joeynmt.training - Epoch   7, Step:    23800, Batch Loss:     1.981238, Batch Acc: 0.479040, Tokens per Sec:     3748, Lr: 0.000300
2023-05-30 22:59:42,821 - INFO - joeynmt.training - Epoch   7, Step:    23900, Batch Loss:     1.836354, Batch Acc: 0.478285, Tokens per Sec:     3675, Lr: 0.000300
2023-05-30 23:00:02,365 - INFO - joeynmt.training - Epoch   7, Step:    24000, Batch Loss:     1.958163, Batch Acc: 0.477948, Tokens per Sec:     3595, Lr: 0.000300
2023-05-30 23:00:02,365 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 23:00:02,365 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 23:00:53,605 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.26, ppl:   9.60, acc:   0.41, generation: 51.2328[sec], evaluation: 0.0000[sec]
2023-05-30 23:00:53,701 - INFO - joeynmt.helpers - delete models/transformer_model3/22000.ckpt
2023-05-30 23:00:53,704 - INFO - joeynmt.training - Example #0
2023-05-30 23:00:53,704 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 23:00:53,704 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 23:00:53,704 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'ge@@', 'zeigt', 'habe,', 'die', 'Pol@@', 'iz@@', 'iz@@', 'iz@@', 'is@@', 'sp@@', 'ort@@', 'is@@', 'ierte', 'drei', 'Millionen', 'Jahre', 'ungefähr', 'die', 'Größe', 'des', 'F@@', 'est@@', 'es', 'von', 'ungefähr', 'drei', 'Millionen', 'Jahre', 'auf', 'der', 'U@@', '-@@', 'Prozent', 'des', 'F@@', 'est@@', 'es', 'war', 'mit', '40', 'Prozent', 'des', 'F@@', 'est@@', 'es', 'war.', '</s>']
2023-05-30 23:00:53,704 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 23:00:53,704 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 23:00:53,704 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Dias gezeigt habe, die Polizizizissportisierte drei Millionen Jahre ungefähr die Größe des Festes von ungefähr drei Millionen Jahre auf der U-Prozent des Festes war mit 40 Prozent des Festes war.
2023-05-30 23:00:53,704 - INFO - joeynmt.training - Example #1
2023-05-30 23:00:53,704 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 23:00:53,704 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 23:00:53,704 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Be@@', 'gr@@', 'iff', 'dieses', 'spezi@@', 'elle', 'Problem', 'dieses', 'spezi@@', 'elle', 'Problem', 'weil', 'es', 'nicht', 'die', 'Di@@', 'ff@@', 'er@@', 'enz@@', 'ung', 'des', 'E@@', 'is', 'zu', 'zeigen.', '</s>']
2023-05-30 23:00:53,704 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 23:00:53,704 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 23:00:53,705 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Begriff dieses spezielle Problem dieses spezielle Problem weil es nicht die Differenzung des Eis zu zeigen.
2023-05-30 23:00:53,705 - INFO - joeynmt.training - Example #2
2023-05-30 23:00:53,705 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 23:00:53,705 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 23:00:53,705 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'E@@', 'is', 'der', 'Eis@@', 'sch@@', 'ap', 'auf', 'den', 'Nor@@', 'd@@', 'pol@@', ',', 'das', 'ist', 'ein', 'Sinn', 'unser', 'glob@@', 'ales', 'Kl@@', 'im@@', 'a', 'zu', 'er@@', 'fahr@@', 'en.', '</s>']
2023-05-30 23:00:53,705 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 23:00:53,705 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 23:00:53,705 - INFO - joeynmt.training - 	Hypothesis: Der Eis der Eisschap auf den Nordpol, das ist ein Sinn unser globales Klima zu erfahren.
2023-05-30 23:00:53,705 - INFO - joeynmt.training - Example #3
2023-05-30 23:00:53,705 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 23:00:53,705 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 23:00:53,705 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'sch@@', 'w@@', 'and', 'aus', 'dem', 'Win@@', 'ter', 'und', 'kr@@', 'im@@', 'ft', 'im', 'S@@', 'omm@@', 'er', 'und', 'es', 'sch@@', 'w@@', 'ing@@', 't.', '</s>']
2023-05-30 23:00:53,705 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 23:00:53,705 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 23:00:53,705 - INFO - joeynmt.training - 	Hypothesis: Es schwand aus dem Winter und krimft im Sommer und es schwingt.
2023-05-30 23:00:53,705 - INFO - joeynmt.training - Example #4
2023-05-30 23:00:53,705 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 23:00:53,705 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 23:00:53,705 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'nächste', 'Fol@@', 'ie', 'zeigt', 'eine', 'besch@@', 'le@@', 'un@@', 'ig@@', 'te', 'Ver@@', 'sion', 'von', 'dem,', 'was', 'die', 'letzten', '25', 'Jahre', 'passiert.', '</s>']
2023-05-30 23:00:53,705 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 23:00:53,705 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 23:00:53,705 - INFO - joeynmt.training - 	Hypothesis: Und die nächste Folie zeigt eine beschleunigte Version von dem, was die letzten 25 Jahre passiert.
2023-05-30 23:01:13,404 - INFO - joeynmt.training - Epoch   7, Step:    24100, Batch Loss:     1.859986, Batch Acc: 0.480967, Tokens per Sec:     3714, Lr: 0.000300
2023-05-30 23:01:32,063 - INFO - joeynmt.training - Epoch   7, Step:    24200, Batch Loss:     1.984830, Batch Acc: 0.475484, Tokens per Sec:     3904, Lr: 0.000300
2023-05-30 23:01:51,512 - INFO - joeynmt.training - Epoch   7, Step:    24300, Batch Loss:     1.973921, Batch Acc: 0.480096, Tokens per Sec:     3672, Lr: 0.000300
2023-05-30 23:02:10,900 - INFO - joeynmt.training - Epoch   7, Step:    24400, Batch Loss:     1.846085, Batch Acc: 0.483271, Tokens per Sec:     3808, Lr: 0.000300
2023-05-30 23:02:30,257 - INFO - joeynmt.training - Epoch   7, Step:    24500, Batch Loss:     2.024207, Batch Acc: 0.480278, Tokens per Sec:     3675, Lr: 0.000300
2023-05-30 23:02:30,258 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 23:02:30,258 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 23:03:30,694 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.24, ppl:   9.43, acc:   0.41, generation: 60.4294[sec], evaluation: 0.0000[sec]
2023-05-30 23:03:30,695 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 23:03:30,784 - INFO - joeynmt.helpers - delete models/transformer_model3/22500.ckpt
2023-05-30 23:03:30,784 - INFO - joeynmt.training - Example #0
2023-05-30 23:03:30,785 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 23:03:30,785 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 23:03:30,785 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'ge@@', 'zeigt', 'habe,', 'dass', 'die', 'Pol@@', 'ar@@', 'is', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahre', 'lang', 'der', 'letzten', 'drei', 'Millionen', 'Jahre', 'Jahre', 'in', 'der', 'Lage', 'war,', 'mit', '40', 'Prozent', 'der', 'F@@', 'est@@', 'plat@@', 'z@@', 't.', '</s>']
2023-05-30 23:03:30,785 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 23:03:30,785 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 23:03:30,785 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Dias gezeigt habe, dass die Polaris in den letzten drei Millionen Jahre lang der letzten drei Millionen Jahre Jahre in der Lage war, mit 40 Prozent der Festplatzt.
2023-05-30 23:03:30,785 - INFO - joeynmt.training - Example #1
2023-05-30 23:03:30,785 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 23:03:30,785 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 23:03:30,785 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Be@@', 'gr@@', 'iff', 'dieses', 'spezi@@', 'elle', 'Problem', 'dieses', 'spezi@@', 'f@@', 'ische', 'Problem', 'weil', 'es', 'nicht', 'die', 'Di@@', 'mensi@@', 'on', 'von', 'E@@', 'is', 'zeigt', 'sich,', 'dass', 'es', 'nicht', 'die', 'Di@@', 're@@', 'kt@@', 'ierung', 'des', 'E@@', 'is', 'zeigt', '</s>']
2023-05-30 23:03:30,785 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 23:03:30,785 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 23:03:30,785 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Begriff dieses spezielle Problem dieses spezifische Problem weil es nicht die Dimension von Eis zeigt sich, dass es nicht die Direktierung des Eis zeigt
2023-05-30 23:03:30,785 - INFO - joeynmt.training - Example #2
2023-05-30 23:03:30,785 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 23:03:30,785 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 23:03:30,785 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'Eis@@', 'en', 'der', 'Eis@@', 'sch@@', 'ap', 'in', 'gew@@', 'iss@@', 'em', 'Sin@@', 'ne,', 'die', 'so', 'kl@@', 'ei@@', 'g@@', 'nen', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'wandel@@', 's', 'zu', 'unserer', 'glob@@', 'alen', 'Klima@@', 'er@@', 'ei@@', '.', '</s>']
2023-05-30 23:03:30,785 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 23:03:30,785 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 23:03:30,786 - INFO - joeynmt.training - 	Hypothesis: Die Eisen der Eisschap in gewissem Sinne, die so kleignen Herz unseres globalen Klimawandels zu unserer globalen Klimaerei.
2023-05-30 23:03:30,786 - INFO - joeynmt.training - Example #3
2023-05-30 23:03:30,786 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 23:03:30,786 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 23:03:30,786 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'Win@@', 'ter', 'und', 'kr@@', 'im@@', 'p@@', 't.', '</s>']
2023-05-30 23:03:30,786 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 23:03:30,786 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 23:03:30,786 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und krimpt.
2023-05-30 23:03:30,786 - INFO - joeynmt.training - Example #4
2023-05-30 23:03:30,786 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 23:03:30,786 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 23:03:30,786 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Fol@@', 'ie', 'zeigt', 'eine', 'besch@@', 'le@@', 'un@@', 'ig@@', 'te', 'Ver@@', 'sion', 'von', 'den', 'letzten', '25', 'Jahren', 'gesch@@', 'ehen', 'ist.', '</s>']
2023-05-30 23:03:30,786 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 23:03:30,786 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 23:03:30,786 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie zeigt eine beschleunigte Version von den letzten 25 Jahren geschehen ist.
2023-05-30 23:03:51,034 - INFO - joeynmt.training - Epoch   7, Step:    24600, Batch Loss:     1.931425, Batch Acc: 0.473509, Tokens per Sec:     3508, Lr: 0.000300
2023-05-30 23:04:09,434 - INFO - joeynmt.training - Epoch   7, Step:    24700, Batch Loss:     1.694118, Batch Acc: 0.481363, Tokens per Sec:     3924, Lr: 0.000300
2023-05-30 23:04:19,967 - INFO - joeynmt.training - Epoch   7: total training loss 6762.92
2023-05-30 23:04:19,967 - INFO - joeynmt.training - EPOCH 8
2023-05-30 23:04:28,860 - INFO - joeynmt.training - Epoch   8, Step:    24800, Batch Loss:     1.658496, Batch Acc: 0.508843, Tokens per Sec:     3771, Lr: 0.000300
2023-05-30 23:04:47,374 - INFO - joeynmt.training - Epoch   8, Step:    24900, Batch Loss:     1.955524, Batch Acc: 0.506705, Tokens per Sec:     3935, Lr: 0.000300
2023-05-30 23:05:06,290 - INFO - joeynmt.training - Epoch   8, Step:    25000, Batch Loss:     1.861861, Batch Acc: 0.505795, Tokens per Sec:     3813, Lr: 0.000300
2023-05-30 23:05:06,290 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 23:05:06,290 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 23:06:12,970 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.25, ppl:   9.52, acc:   0.41, generation: 66.6716[sec], evaluation: 0.0000[sec]
2023-05-30 23:06:13,062 - INFO - joeynmt.helpers - delete models/transformer_model3/21000.ckpt
2023-05-30 23:06:13,062 - INFO - joeynmt.training - Example #0
2023-05-30 23:06:13,062 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 23:06:13,062 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 23:06:13,062 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'zu', 'zeigen,', 'dass', 'die', 'Pol@@', 'ar@@', 'ien', 'Eis@@', 'sch@@', 'ap@@', ',', 'der', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'Jahre', 'von', 'ungefähr', 'ungefähr', 'der', 'Größe', 'der', 'F@@', 'est@@', 'ung', 'der', 'U@@', 'S@@', ',', 'mit', '40', 'Prozent', 'gesch@@', 'ro@@', 'm@@', 'fen', 'hat.', '</s>']
2023-05-30 23:06:13,063 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 23:06:13,063 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 23:06:13,063 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Dias zu zeigen, dass die Polarien Eisschap, der die letzten drei Millionen Jahre Jahre von ungefähr ungefähr der Größe der Festung der US, mit 40 Prozent geschromfen hat.
2023-05-30 23:06:13,063 - INFO - joeynmt.training - Example #1
2023-05-30 23:06:13,063 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 23:06:13,063 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 23:06:13,063 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'hier', 'ist', 'der', 'S@@', 'icht', 'dieses', 'spezi@@', 'f@@', 'ische', 'Problem', 'weil', 'es', 'nicht', 'die', 'Di@@', 'ag@@', 'ram@@', 'm', 'des', 'E@@', 'is', 'zu', 'sehen.', '</s>']
2023-05-30 23:06:13,063 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 23:06:13,063 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 23:06:13,063 - INFO - joeynmt.training - 	Hypothesis: Aber das hier ist der Sicht dieses spezifische Problem weil es nicht die Diagramm des Eis zu sehen.
2023-05-30 23:06:13,063 - INFO - joeynmt.training - Example #2
2023-05-30 23:06:13,063 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 23:06:13,063 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 23:06:13,063 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'Eis@@', 'deck@@', 'e', 'ist', 'der', 'E@@', 'is.', 'Die', 'Eis@@', 'e', 'ist', 'in', 'gew@@', 'iss@@', 'er', 'Weise', 'das', 'wirklich', 'kl@@', 'app@@', 'end', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'wandel@@', 's.', '</s>']
2023-05-30 23:06:13,063 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 23:06:13,063 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 23:06:13,063 - INFO - joeynmt.training - 	Hypothesis: Die Eisdecke ist der Eis. Die Eise ist in gewisser Weise das wirklich klappend Herz unseres globalen Klimawandels.
2023-05-30 23:06:13,063 - INFO - joeynmt.training - Example #3
2023-05-30 23:06:13,063 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 23:06:13,063 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 23:06:13,063 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'Win@@', 'ter', 'und', 'kr@@', 'im@@', 'pf@@', 't', 'im', 'Som@@', 'mer@@', '.', '</s>']
2023-05-30 23:06:13,064 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 23:06:13,064 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 23:06:13,064 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und krimpft im Sommer.
2023-05-30 23:06:13,064 - INFO - joeynmt.training - Example #4
2023-05-30 23:06:13,064 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 23:06:13,064 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 23:06:13,064 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Fol@@', 'ie', 'zeigt,', 'ist', 'eine', 'besch@@', 'le@@', 'un@@', 'ig@@', 'te', 'Ver@@', 'sion', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahre', 'passiert.', '</s>']
2023-05-30 23:06:13,064 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 23:06:13,064 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 23:06:13,064 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie zeigt, ist eine beschleunigte Version von dem, was in den letzten 25 Jahre passiert.
2023-05-30 23:06:31,972 - INFO - joeynmt.training - Epoch   8, Step:    25100, Batch Loss:     1.828433, Batch Acc: 0.503443, Tokens per Sec:     3783, Lr: 0.000300
2023-05-30 23:06:51,410 - INFO - joeynmt.training - Epoch   8, Step:    25200, Batch Loss:     1.730624, Batch Acc: 0.499126, Tokens per Sec:     3736, Lr: 0.000300
2023-05-30 23:07:10,385 - INFO - joeynmt.training - Epoch   8, Step:    25300, Batch Loss:     1.870340, Batch Acc: 0.503708, Tokens per Sec:     3852, Lr: 0.000300
2023-05-30 23:07:30,307 - INFO - joeynmt.training - Epoch   8, Step:    25400, Batch Loss:     1.785146, Batch Acc: 0.503267, Tokens per Sec:     3588, Lr: 0.000300
2023-05-30 23:07:48,748 - INFO - joeynmt.training - Epoch   8, Step:    25500, Batch Loss:     1.724900, Batch Acc: 0.496980, Tokens per Sec:     3842, Lr: 0.000300
2023-05-30 23:07:48,749 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 23:07:48,749 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 23:08:59,074 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.26, ppl:   9.58, acc:   0.41, generation: 70.3184[sec], evaluation: 0.0000[sec]
2023-05-30 23:08:59,169 - INFO - joeynmt.helpers - delete models/transformer_model3/24000.ckpt
2023-05-30 23:08:59,172 - INFO - joeynmt.training - Example #0
2023-05-30 23:08:59,172 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 23:08:59,172 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 23:08:59,172 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'a@@', 'g', 'ge@@', 'zeigt,', 'dass', 'die', 'Pol@@', 'iz@@', 'ist@@', 'en,', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'in', 'der', 'Größe', 'des', 'F@@', 'est@@', 'es', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahre', 'in', 'der', 'Lage', 'war', 'mit', '40', 'Prozent', 'des', 'F@@', 'ro@@', 'm@@', 'els', 'war.', '</s>']
2023-05-30 23:08:59,172 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 23:08:59,172 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 23:08:59,172 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Diag gezeigt, dass die Polizisten, die die letzten drei Millionen Jahre in der Größe des Festes in den letzten drei Millionen Jahre in der Lage war mit 40 Prozent des Fromels war.
2023-05-30 23:08:59,172 - INFO - joeynmt.training - Example #1
2023-05-30 23:08:59,172 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 23:08:59,172 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 23:08:59,172 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Be@@', 'gr@@', 'iff', 'dieses', 'spezi@@', 'elle', 'Problem', 'zu', 'be@@', 'wahr@@', 'en,', 'weil', 'es', 'nicht', 'die', 'Di@@', 'ag@@', 'ram@@', 'me', 'des', 'E@@', 'is', 'zei@@', 'gt.', '</s>']
2023-05-30 23:08:59,172 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 23:08:59,172 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 23:08:59,172 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Begriff dieses spezielle Problem zu bewahren, weil es nicht die Diagramme des Eis zeigt.
2023-05-30 23:08:59,172 - INFO - joeynmt.training - Example #2
2023-05-30 23:08:59,172 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 23:08:59,172 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 23:08:59,172 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'Eis@@', 'sch@@', 'am@@', 'm@@', '-@@', 'Eis@@', 'sch@@', 'lag', 'in', 'gew@@', 'iss@@', 'em', 'Sinn', 'unseres', 'glob@@', 'alen', 'Klima@@', 'wandel@@', 's', 'zu', 'unserem', 'glob@@', 'alen', 'Klima@@', 'wandel@@', '.', '</s>']
2023-05-30 23:08:59,173 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 23:08:59,173 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 23:08:59,173 - INFO - joeynmt.training - 	Hypothesis: Der Eisschamm-Eisschlag in gewissem Sinn unseres globalen Klimawandels zu unserem globalen Klimawandel.
2023-05-30 23:08:59,173 - INFO - joeynmt.training - Example #3
2023-05-30 23:08:59,173 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 23:08:59,173 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 23:08:59,173 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'im', 'Win@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'p@@', 'iert', 'im', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'im@@', 'p@@', 't.', '</s>']
2023-05-30 23:08:59,173 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 23:08:59,173 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 23:08:59,173 - INFO - joeynmt.training - 	Hypothesis: Es ist im Winter und Krimpiert im Sommer und Krimpt.
2023-05-30 23:08:59,173 - INFO - joeynmt.training - Example #4
2023-05-30 23:08:59,173 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 23:08:59,173 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 23:08:59,173 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Fol@@', 'ie', 'zeigt,', 'ist', 'eine', 'besch@@', 'le@@', 'un@@', 'ig@@', 'te', 'Ver@@', 'sion', 'von', 'den', 'letzten', '25', 'Jahren', 'gesch@@', 'windig@@', 'keit', 'in', 'den', 'letzten', '25', 'Jahren', 'gesch@@', 'windig@@', 'keit', '</s>']
2023-05-30 23:08:59,173 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 23:08:59,173 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 23:08:59,173 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie zeigt, ist eine beschleunigte Version von den letzten 25 Jahren geschwindigkeit in den letzten 25 Jahren geschwindigkeit
2023-05-30 23:09:18,641 - INFO - joeynmt.training - Epoch   8, Step:    25600, Batch Loss:     1.848507, Batch Acc: 0.495666, Tokens per Sec:     3797, Lr: 0.000300
2023-05-30 23:09:37,734 - INFO - joeynmt.training - Epoch   8, Step:    25700, Batch Loss:     1.874500, Batch Acc: 0.500226, Tokens per Sec:     3832, Lr: 0.000300
2023-05-30 23:09:56,690 - INFO - joeynmt.training - Epoch   8, Step:    25800, Batch Loss:     1.762113, Batch Acc: 0.501500, Tokens per Sec:     3834, Lr: 0.000300
2023-05-30 23:10:15,708 - INFO - joeynmt.training - Epoch   8, Step:    25900, Batch Loss:     1.806991, Batch Acc: 0.499558, Tokens per Sec:     3749, Lr: 0.000300
2023-05-30 23:10:34,477 - INFO - joeynmt.training - Epoch   8, Step:    26000, Batch Loss:     1.793224, Batch Acc: 0.497973, Tokens per Sec:     3917, Lr: 0.000300
2023-05-30 23:10:34,480 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 23:10:34,480 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 23:11:43,835 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.26, ppl:   9.55, acc:   0.41, generation: 69.3480[sec], evaluation: 0.0000[sec]
2023-05-30 23:11:43,927 - INFO - joeynmt.helpers - delete models/transformer_model3/25500.ckpt
2023-05-30 23:11:43,927 - INFO - joeynmt.helpers - delete /Users/cyril/Desktop/krizzzzi/mt-exercise-5/models/transformer_model3/25500.ckpt
2023-05-30 23:11:43,928 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /Users/cyril/Desktop/krizzzzi/mt-exercise-5/models/transformer_model3/25500.ckpt but file does not exist. ([Errno 2] No such file or directory: '/Users/cyril/Desktop/krizzzzi/mt-exercise-5/models/transformer_model3/25500.ckpt')
2023-05-30 23:11:43,931 - INFO - joeynmt.training - Example #0
2023-05-30 23:11:43,931 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 23:11:43,931 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 23:11:43,931 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'a@@', 'h@@', 're,', 'um', 'zu', 'zeigen,', 'dass', 'die', 'Pol@@', 'ar@@', 'ien', 'Eis@@', 'sch@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'ungefähr', 'die', 'Größe', 'des', 'F@@', 'est@@', 'es', 'in', 'der', 'Größe', 'des', 'F@@', 'est@@', 'es', 'ge@@', 'druck@@', 'ten', 'ge@@', 'm', 'ge@@', 'zeigt', 'hatte.', '</s>']
2023-05-30 23:11:43,931 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 23:11:43,931 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 23:11:43,931 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Diahre, um zu zeigen, dass die Polarien Eisschap, die die letzten drei Millionen Jahre ungefähr die Größe des Festes in der Größe des Festes gedruckten gem gezeigt hatte.
2023-05-30 23:11:43,931 - INFO - joeynmt.training - Example #1
2023-05-30 23:11:43,931 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 23:11:43,931 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 23:11:43,931 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Be@@', 'sch@@', 'ätz@@', 'ung', 'dieses', 'spezi@@', 'elle', 'Problem', 'denn', 'es', 'ist', 'nicht', 'die', 'Di@@', 'cke', 'des', 'E@@', 'is', 'des', 'E@@', 'is', 'zei@@', 'g@@', 'ten', 'E@@', 'is', 'zei@@', 'gt.', '</s>']
2023-05-30 23:11:43,931 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 23:11:43,931 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 23:11:43,931 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Beschätzung dieses spezielle Problem denn es ist nicht die Dicke des Eis des Eis zeigten Eis zeigt.
2023-05-30 23:11:43,931 - INFO - joeynmt.training - Example #2
2023-05-30 23:11:43,931 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 23:11:43,931 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 23:11:43,931 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is', 'in', 'den', 'Nor@@', 'd@@', 'pol@@', ',', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'des', 'Kl@@', 'im@@', 'a', 'ist', 'das', 'Sch@@', 'l@@', 'z', 'unseres', 'Klima@@', 'sch@@', 'utz@@', 's', 'zu', 'unserem', 'glob@@', 'alen', 'Klima@@', 'sch@@', 'utz@@', '.', '</s>']
2023-05-30 23:11:43,932 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 23:11:43,932 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 23:11:43,932 - INFO - joeynmt.training - 	Hypothesis: Die Eis in den Nordpol, ist in gewissem Sinne des Klima ist das Schlz unseres Klimaschutzs zu unserem globalen Klimaschutz.
2023-05-30 23:11:43,932 - INFO - joeynmt.training - Example #3
2023-05-30 23:11:43,932 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 23:11:43,932 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 23:11:43,932 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'sch@@', 'ätz@@', 't', 'aus', 'im', 'Win@@', 'ter', 'und', 'kr@@', 'im@@', 'ft', 'im', 'S@@', 'omm@@', 'er', 'im', 'S@@', 'omm@@', 'er', 'im', 'S@@', 'omm@@', 'er', 'im', 'S@@', 'omm@@', 'er', 'im', 'S@@', 'omm@@', 'er', 'im', 'S@@', 'omm@@', 'er', 'im', 'S@@', 'omm@@', 'er', 'im', 'S@@', 'omm@@', 'er', 'im', 'S@@', 'omm@@', 'er', 'im', 'S@@', 'omm@@', 'er', 'im', 'S@@', 'omm@@', 'er', 'im', 'S@@', 'omm@@', 'er', 'r@@', 'sch@@', 'on.', '</s>']
2023-05-30 23:11:43,932 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 23:11:43,932 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 23:11:43,932 - INFO - joeynmt.training - 	Hypothesis: Es schätzt aus im Winter und krimft im Sommer im Sommer im Sommer im Sommer im Sommer im Sommer im Sommer im Sommer im Sommer im Sommer im Sommer im Sommer rschon.
2023-05-30 23:11:43,932 - INFO - joeynmt.training - Example #4
2023-05-30 23:11:43,932 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 23:11:43,932 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 23:11:43,932 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Fol@@', 'ie', 'die', 'ich', 'Ihnen', 'zeigen', 'ist', 'eine', 'besch@@', 'le@@', 'un@@', 'ig@@', 'te', 'Ver@@', 'sion', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'gesch@@', 'ehen', 'ist.', '</s>']
2023-05-30 23:11:43,932 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 23:11:43,932 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 23:11:43,932 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie die ich Ihnen zeigen ist eine beschleunigte Version von dem, was in den letzten 25 Jahren geschehen ist.
2023-05-30 23:12:03,560 - INFO - joeynmt.training - Epoch   8, Step:    26100, Batch Loss:     1.798140, Batch Acc: 0.494252, Tokens per Sec:     3687, Lr: 0.000300
2023-05-30 23:12:22,349 - INFO - joeynmt.training - Epoch   8, Step:    26200, Batch Loss:     1.900673, Batch Acc: 0.495198, Tokens per Sec:     3902, Lr: 0.000300
2023-05-30 23:12:40,489 - INFO - joeynmt.training - Epoch   8, Step:    26300, Batch Loss:     1.824181, Batch Acc: 0.490711, Tokens per Sec:     3935, Lr: 0.000300
2023-05-30 23:13:00,647 - INFO - joeynmt.training - Epoch   8, Step:    26400, Batch Loss:     2.019216, Batch Acc: 0.492609, Tokens per Sec:     3591, Lr: 0.000300
2023-05-30 23:13:19,979 - INFO - joeynmt.training - Epoch   8, Step:    26500, Batch Loss:     1.829658, Batch Acc: 0.490714, Tokens per Sec:     3707, Lr: 0.000300
2023-05-30 23:13:19,979 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 23:13:19,979 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 23:14:32,132 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.25, ppl:   9.46, acc:   0.41, generation: 72.1455[sec], evaluation: 0.0000[sec]
2023-05-30 23:14:32,225 - INFO - joeynmt.helpers - delete models/transformer_model3/23000.ckpt
2023-05-30 23:14:32,228 - INFO - joeynmt.training - Example #0
2023-05-30 23:14:32,228 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 23:14:32,228 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 23:14:32,228 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Di@@', 'as', 'ge@@', 'zeigt,', 'dass', 'die', 'Pol@@', 'ar@@', 'is@@', 'sk@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'in', 'der', 'letzten', 'drei', 'Millionen', 'Jahre', 'in', 'der', 'Größe', 'der', 'F@@', 'est@@', 'ung', 'der', 'U@@', 'S@@', ',', 'mit', '40@@', '%', 'Ge@@', 'ro@@', 'm@@', 'pen', 'war.', '</s>']
2023-05-30 23:14:32,229 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 23:14:32,229 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 23:14:32,229 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese beiden Dias gezeigt, dass die Polarisskap, die die letzten drei Millionen Jahre in der letzten drei Millionen Jahre in der Größe der Festung der US, mit 40% Gerompen war.
2023-05-30 23:14:32,229 - INFO - joeynmt.training - Example #1
2023-05-30 23:14:32,229 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 23:14:32,229 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 23:14:32,229 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'eigentlich', 'die', 'Be@@', 'sch@@', 'ätz@@', 'ung', 'dieses', 'spezi@@', 'f@@', 'ische', 'Problem', 'weil', 'es', 'nicht', 'die', 'Di@@', 'ff@@', 'er@@', 'enz', 'des', 'E@@', 'is', 'zeigt', 'wird.', '</s>']
2023-05-30 23:14:32,229 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 23:14:32,229 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 23:14:32,229 - INFO - joeynmt.training - 	Hypothesis: Aber das ist eigentlich die Beschätzung dieses spezifische Problem weil es nicht die Differenz des Eis zeigt wird.
2023-05-30 23:14:32,229 - INFO - joeynmt.training - Example #2
2023-05-30 23:14:32,229 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 23:14:32,229 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 23:14:32,229 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'Eis@@', 'deck@@', 'e', 'ist', 'die', 'E@@', 'is', 'in', 'gew@@', 'iss@@', 'er', 'Weise', 'das', 'wirklich', 'wirklich', 'wirklich', 'das', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'wandel@@', 's', 'zu', 'unserem', 'glob@@', 'alen', 'Klima@@', 'sch@@', 'utz@@', '.', '</s>']
2023-05-30 23:14:32,229 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 23:14:32,229 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 23:14:32,229 - INFO - joeynmt.training - 	Hypothesis: Die Eisdecke ist die Eis in gewisser Weise das wirklich wirklich wirklich das Herz unseres globalen Klimawandels zu unserem globalen Klimaschutz.
2023-05-30 23:14:32,229 - INFO - joeynmt.training - Example #3
2023-05-30 23:14:32,229 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 23:14:32,229 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 23:14:32,229 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 's@@', 'etzt', 'sich', 'im', 'Win@@', 'ter', 'und', 'kr@@', 'im@@', 'ft', 'im', 'S@@', 'omm@@', 'er', 'im', 'S@@', 'omm@@', 'er', 'im', 'S@@', 'omm@@', 'er', 'im', 'S@@', 'omm@@', 'er', 'im', 'S@@', 'omm@@', 'er', 'im', 'S@@', 'omm@@', 'er', 'im', 'S@@', 'omm@@', 'er', 'im', 'S@@', 'omm@@', 'er', 'im', 'S@@', 'omm@@', 'er', 'im', 'S@@', 'omm@@', 'er', 'im', 'S@@', 'omm@@', 'er', 'im', 'S@@', 'omm@@', 'er', 'des', 'Win@@', 'kel@@', '.', '</s>']
2023-05-30 23:14:32,230 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 23:14:32,230 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 23:14:32,230 - INFO - joeynmt.training - 	Hypothesis: Es setzt sich im Winter und krimft im Sommer im Sommer im Sommer im Sommer im Sommer im Sommer im Sommer im Sommer im Sommer im Sommer im Sommer im Sommer des Winkel.
2023-05-30 23:14:32,230 - INFO - joeynmt.training - Example #4
2023-05-30 23:14:32,230 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 23:14:32,230 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 23:14:32,230 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Di@@', 'a,', 'die', 'ich', 'Ihnen', 'zeigen', 'ist', 'eine', 'besch@@', 'le@@', 'un@@', 'ig@@', 'te', 'Ver@@', 'sion', 'von', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'gesch@@', 'windig@@', 'keit', 'gesch@@', 'windig@@', 'keit', 'zu', 'er@@', 'halten.', '</s>']
2023-05-30 23:14:32,230 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 23:14:32,230 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 23:14:32,230 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia, die ich Ihnen zeigen ist eine beschleunigte Version von was in den letzten 25 Jahren geschwindigkeit geschwindigkeit zu erhalten.
2023-05-30 23:14:51,643 - INFO - joeynmt.training - Epoch   8, Step:    26600, Batch Loss:     1.788171, Batch Acc: 0.485211, Tokens per Sec:     3690, Lr: 0.000300
2023-05-30 23:15:11,536 - INFO - joeynmt.training - Epoch   8, Step:    26700, Batch Loss:     1.768219, Batch Acc: 0.492572, Tokens per Sec:     3620, Lr: 0.000300
2023-05-30 23:15:31,457 - INFO - joeynmt.training - Epoch   8, Step:    26800, Batch Loss:     1.982358, Batch Acc: 0.490264, Tokens per Sec:     3625, Lr: 0.000300
2023-05-30 23:15:51,386 - INFO - joeynmt.training - Epoch   8, Step:    26900, Batch Loss:     1.916087, Batch Acc: 0.494845, Tokens per Sec:     3640, Lr: 0.000300
2023-05-30 23:16:09,450 - INFO - joeynmt.training - Epoch   8, Step:    27000, Batch Loss:     1.950321, Batch Acc: 0.489606, Tokens per Sec:     4008, Lr: 0.000300
2023-05-30 23:16:09,450 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 23:16:09,450 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 23:17:14,990 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.24, ppl:   9.39, acc:   0.42, generation: 65.5328[sec], evaluation: 0.0000[sec]
2023-05-30 23:17:14,990 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 23:17:15,082 - INFO - joeynmt.helpers - delete models/transformer_model3/26000.ckpt
2023-05-30 23:17:15,085 - INFO - joeynmt.training - Example #0
2023-05-30 23:17:15,085 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 23:17:15,085 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 23:17:15,085 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'ge@@', 'zeigt,', 'dass', 'die', 'Pol@@', 'ar@@', 'is@@', 'k@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'etwa', 'etwa', 'etwa', 'drei', 'Millionen', 'Jahre', 'auf', 'der', 'Größe', 'der', 'F@@', 'est@@', 'stellung', 'der', 'U@@', '.@@', 'S@@', ',', 'mit', '40@@', '%', 'ge@@', 'm', 'ge@@', 'tr@@', 'eten', 'war.', '</s>']
2023-05-30 23:17:15,085 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 23:17:15,085 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 23:17:15,085 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Dias gezeigt, dass die Polariskap, die die letzten drei Millionen Jahre etwa etwa etwa drei Millionen Jahre auf der Größe der Feststellung der U.S, mit 40% gem getreten war.
2023-05-30 23:17:15,085 - INFO - joeynmt.training - Example #1
2023-05-30 23:17:15,085 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 23:17:15,085 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 23:17:15,085 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'tatsächlich', 'der', 'Be@@', 'gr@@', 'iff', 'dieses', 'hier', 'im', 'Grunde', 'genommen', 'die', 'Be@@', 'gr@@', 'iff', 'des', 'E@@', 'is', 'zu', 'sehen.', '</s>']
2023-05-30 23:17:15,085 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 23:17:15,085 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 23:17:15,085 - INFO - joeynmt.training - 	Hypothesis: Aber das ist tatsächlich der Begriff dieses hier im Grunde genommen die Begriff des Eis zu sehen.
2023-05-30 23:17:15,085 - INFO - joeynmt.training - Example #2
2023-05-30 23:17:15,085 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 23:17:15,085 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 23:17:15,085 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is', 'in', 'der', 'Nor@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'Sinn', 'unseres', 'glob@@', 'alen', 'Klima@@', 'wandel@@', 's', 'des', 'Klima@@', 'wandel@@', 's', 'zu', 'unserem', 'glob@@', 'alen', 'Klima@@', 'wan@@', 'del', 'des', 'Klima@@', 'wandel@@', 's', 'zu', 'unserem', 'glob@@', 'alen', 'Klima@@', 'wan@@', 'del', 'des', 'Klima@@', 'wandel@@', 's', 'zu', 'be@@', 'wei@@', 'sen.', '</s>']
2023-05-30 23:17:15,086 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 23:17:15,086 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 23:17:15,086 - INFO - joeynmt.training - 	Hypothesis: Die Eis in der Nordpol ist in gewissem Sinn unseres globalen Klimawandels des Klimawandels zu unserem globalen Klimawandel des Klimawandels zu unserem globalen Klimawandel des Klimawandels zu beweisen.
2023-05-30 23:17:15,086 - INFO - joeynmt.training - Example #3
2023-05-30 23:17:15,086 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 23:17:15,086 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 23:17:15,086 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 's@@', 'etzt', 'aus', 'dem', 'Win@@', 'ter', 'und', 'kr@@', 'im@@', 't', 'im', 'S@@', 'omm@@', 'er', 'und', 'im', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', '</s>']
2023-05-30 23:17:15,086 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 23:17:15,086 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 23:17:15,086 - INFO - joeynmt.training - 	Hypothesis: Es setzt aus dem Winter und krimt im Sommer und im Sommer in den Sommer und
2023-05-30 23:17:15,086 - INFO - joeynmt.training - Example #4
2023-05-30 23:17:15,086 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 23:17:15,086 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 23:17:15,086 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Fol@@', 'ie', 'zeigt,', 'die', 'ich', 'Ihnen', 'zeigen', 'wer@@', 'de,', 'ist', 'eine', 'Gesch@@', 'windig@@', 'keit', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.', '</s>']
2023-05-30 23:17:15,086 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 23:17:15,086 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 23:17:15,086 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie zeigt, die ich Ihnen zeigen werde, ist eine Geschwindigkeit von dem, was in den letzten 25 Jahren passiert ist.
2023-05-30 23:17:34,970 - INFO - joeynmt.training - Epoch   8, Step:    27100, Batch Loss:     2.173947, Batch Acc: 0.490005, Tokens per Sec:     3548, Lr: 0.000300
2023-05-30 23:17:54,451 - INFO - joeynmt.training - Epoch   8, Step:    27200, Batch Loss:     1.847905, Batch Acc: 0.491597, Tokens per Sec:     3678, Lr: 0.000300
2023-05-30 23:18:13,964 - INFO - joeynmt.training - Epoch   8, Step:    27300, Batch Loss:     1.925910, Batch Acc: 0.489082, Tokens per Sec:     3713, Lr: 0.000300
2023-05-30 23:18:32,512 - INFO - joeynmt.training - Epoch   8, Step:    27400, Batch Loss:     1.817621, Batch Acc: 0.485205, Tokens per Sec:     3850, Lr: 0.000300
2023-05-30 23:18:51,393 - INFO - joeynmt.training - Epoch   8, Step:    27500, Batch Loss:     1.845853, Batch Acc: 0.487827, Tokens per Sec:     3897, Lr: 0.000300
2023-05-30 23:18:51,393 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 23:18:51,393 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 23:20:00,597 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.24, ppl:   9.41, acc:   0.41, generation: 69.1966[sec], evaluation: 0.0000[sec]
2023-05-30 23:20:00,690 - INFO - joeynmt.helpers - delete models/transformer_model3/23500.ckpt
2023-05-30 23:20:00,692 - INFO - joeynmt.training - Example #0
2023-05-30 23:20:00,693 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 23:20:00,693 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 23:20:00,693 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'dass', 'die', 'Pol@@', 'iz@@', 'isten', 'drei', 'Millionen', 'Jahre', 'ge@@', 'zeigt', 'hat,', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'ungefähr', 'ungefähr', 'die', 'Größe', 'der', 'F@@', 'est@@', 'ung', 'der', 'U@@', 'l@@', 'and', 'der', 'U@@', 'S@@', ',', 'mit', '40@@', '%', 'ge@@', 'ro@@', 'ff@@', 'en@@', 'heit', 'war.', '</s>']
2023-05-30 23:20:00,693 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 23:20:00,693 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 23:20:00,693 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Folien gezeigt, dass die Polizisten drei Millionen Jahre gezeigt hat, die letzten drei Millionen Jahre ungefähr ungefähr die Größe der Festung der Uland der US, mit 40% geroffenheit war.
2023-05-30 23:20:00,693 - INFO - joeynmt.training - Example #1
2023-05-30 23:20:00,693 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 23:20:00,693 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 23:20:00,693 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Be@@', 'sch@@', 'ätz@@', 'ung', 'dieses', 'spezi@@', 'elle', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'Di@@', 'ff@@', 'er@@', 'enz@@', 'ung', 'des', 'E@@', 'is', 'zei@@', 'g@@', 'ten', 'E@@', 'is', 'zei@@', 'gt.', '</s>']
2023-05-30 23:20:00,693 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 23:20:00,693 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 23:20:00,693 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Beschätzung dieses spezielle Problem ist, weil es nicht die Differenzung des Eis zeigten Eis zeigt.
2023-05-30 23:20:00,693 - INFO - joeynmt.training - Example #2
2023-05-30 23:20:00,693 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 23:20:00,693 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 23:20:00,693 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'Eis@@', 'sch@@', 'ap', 'am', 'Nor@@', 'd@@', 'pol@@', '.', 'Es', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'das', 'wahr@@', 'e', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Kl@@', 'im@@', '-@@', 'A@@', 'ch@@', 'te@@', 'y@@', '-@@', 'Er@@', 'd@@', 'ung.', '</s>']
2023-05-30 23:20:00,693 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 23:20:00,694 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 23:20:00,694 - INFO - joeynmt.training - 	Hypothesis: Die Eisschap am Nordpol. Es ist in gewissem Sinne ist das wahre Herz unseres globalen Klim-Achtey-Erdung.
2023-05-30 23:20:00,694 - INFO - joeynmt.training - Example #3
2023-05-30 23:20:00,694 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 23:20:00,694 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 23:20:00,694 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'Win@@', 'ter', 'und', 'kr@@', 'im@@', 't', 'im', 'S@@', 'omm@@', 'er', 'und', 'im', 'S@@', 'omm@@', 'er', 'im', 'S@@', 'omm@@', 'er', 'und', 'im', 'S@@', 'omm@@', 'er', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'en.', '</s>']
2023-05-30 23:20:00,694 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 23:20:00,694 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 23:20:00,694 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und krimt im Sommer und im Sommer im Sommer und im Sommer Sommer in den Sommen.
2023-05-30 23:20:00,694 - INFO - joeynmt.training - Example #4
2023-05-30 23:20:00,694 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 23:20:00,694 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 23:20:00,694 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'das', 'nächste', 'Fol@@', 'ie', 'ist', 'eine', 'besch@@', 'le@@', 'un@@', 'ig@@', 'te', 'Ver@@', 'sion', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahre', 'passiert.', '</s>']
2023-05-30 23:20:00,694 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 23:20:00,694 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 23:20:00,694 - INFO - joeynmt.training - 	Hypothesis: Und das nächste Folie ist eine beschleunigte Version von dem, was in den letzten 25 Jahre passiert.
2023-05-30 23:20:20,588 - INFO - joeynmt.training - Epoch   8, Step:    27600, Batch Loss:     1.902560, Batch Acc: 0.496398, Tokens per Sec:     3722, Lr: 0.000300
2023-05-30 23:20:40,114 - INFO - joeynmt.training - Epoch   8, Step:    27700, Batch Loss:     1.843341, Batch Acc: 0.489057, Tokens per Sec:     3625, Lr: 0.000300
2023-05-30 23:20:59,442 - INFO - joeynmt.training - Epoch   8, Step:    27800, Batch Loss:     1.763903, Batch Acc: 0.483032, Tokens per Sec:     3706, Lr: 0.000300
2023-05-30 23:21:18,863 - INFO - joeynmt.training - Epoch   8, Step:    27900, Batch Loss:     2.028049, Batch Acc: 0.485864, Tokens per Sec:     3761, Lr: 0.000300
2023-05-30 23:21:37,827 - INFO - joeynmt.training - Epoch   8, Step:    28000, Batch Loss:     1.851428, Batch Acc: 0.486844, Tokens per Sec:     3752, Lr: 0.000300
2023-05-30 23:21:37,827 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 23:21:37,827 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 23:22:48,205 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.23, ppl:   9.29, acc:   0.42, generation: 70.3699[sec], evaluation: 0.0000[sec]
2023-05-30 23:22:48,206 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 23:22:48,297 - INFO - joeynmt.helpers - delete models/transformer_model3/25000.ckpt
2023-05-30 23:22:48,300 - INFO - joeynmt.training - Example #0
2023-05-30 23:22:48,300 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 23:22:48,300 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 23:22:48,300 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'ge@@', 'zeigt,', 'dass', 'die', 'Pol@@', 'i@@', 'zei@@', 'sk@@', 'ap@@', ',', 'die', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahre', 'in', 'etwa', 'etwa', 'die', 'Größe', 'des', 'F@@', 'est@@', 'es', 'in', 'etwa', 'drei', 'Millionen', 'Jahre', 'ge@@', 'tr@@', 'enn@@', 't', 'hatte.', '</s>']
2023-05-30 23:22:48,301 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 23:22:48,301 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 23:22:48,301 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Dias gezeigt, dass die Polizeiskap, die die in den letzten drei Millionen Jahre in etwa etwa die Größe des Festes in etwa drei Millionen Jahre getrennt hatte.
2023-05-30 23:22:48,301 - INFO - joeynmt.training - Example #1
2023-05-30 23:22:48,301 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 23:22:48,301 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 23:22:48,301 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'tatsächlich', 'die', 'Be@@', 'gin@@', 'n', 'dieses', 'spezi@@', 'f@@', 'ische', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'Di@@', 'a@@', 'kt@@', 'es', 'des', 'E@@', 'is', 'ist.', '</s>']
2023-05-30 23:22:48,301 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 23:22:48,301 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 23:22:48,301 - INFO - joeynmt.training - 	Hypothesis: Aber das ist tatsächlich die Beginn dieses spezifische Problem ist, weil es nicht die Diaktes des Eis ist.
2023-05-30 23:22:48,301 - INFO - joeynmt.training - Example #2
2023-05-30 23:22:48,301 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 23:22:48,301 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 23:22:48,301 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'Eis@@', 'sch@@', 'ap', 'auf', 'die', 'Nor@@', 'd@@', 'pol@@', ',', 'die', 'sich', 'in', 'der', 'Art', 'und', 'Wei@@', 'se,', 'das', 'stimm@@', 't@@', "'@@", 's?', '</s>']
2023-05-30 23:22:48,301 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 23:22:48,301 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 23:22:48,301 - INFO - joeynmt.training - 	Hypothesis: Die Eisschap auf die Nordpol, die sich in der Art und Weise, das stimmt's?
2023-05-30 23:22:48,301 - INFO - joeynmt.training - Example #3
2023-05-30 23:22:48,301 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 23:22:48,301 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 23:22:48,301 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'Win@@', 'ter', 'und', 'kr@@', 'im@@', 't', 'im', 'S@@', 'omm@@', 'er', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', '</s>']
2023-05-30 23:22:48,302 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 23:22:48,302 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 23:22:48,302 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und krimt im Sommer Sommer in den Sommer und
2023-05-30 23:22:48,302 - INFO - joeynmt.training - Example #4
2023-05-30 23:22:48,302 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 23:22:48,302 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 23:22:48,302 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Fol@@', 'ie', 'die', 'ich', 'zeigen', 'wer@@', 'de,', 'ist', 'eine', 'besch@@', 'le@@', 'un@@', 'ig@@', 'te', 'Ver@@', 'sion', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.', '</s>']
2023-05-30 23:22:48,302 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 23:22:48,302 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 23:22:48,302 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie die ich zeigen werde, ist eine beschleunigte Version von dem, was in den letzten 25 Jahren passiert ist.
2023-05-30 23:23:07,363 - INFO - joeynmt.training - Epoch   8, Step:    28100, Batch Loss:     2.003152, Batch Acc: 0.482254, Tokens per Sec:     3799, Lr: 0.000300
2023-05-30 23:23:25,975 - INFO - joeynmt.training - Epoch   8, Step:    28200, Batch Loss:     1.774417, Batch Acc: 0.484217, Tokens per Sec:     3786, Lr: 0.000300
2023-05-30 23:23:41,476 - INFO - joeynmt.training - Epoch   8: total training loss 6580.79
2023-05-30 23:23:41,477 - INFO - joeynmt.training - EPOCH 9
2023-05-30 23:23:44,406 - INFO - joeynmt.training - Epoch   9, Step:    28300, Batch Loss:     1.768139, Batch Acc: 0.509905, Tokens per Sec:     4257, Lr: 0.000300
2023-05-30 23:24:03,025 - INFO - joeynmt.training - Epoch   9, Step:    28400, Batch Loss:     1.765768, Batch Acc: 0.516221, Tokens per Sec:     3798, Lr: 0.000300
2023-05-30 23:24:21,661 - INFO - joeynmt.training - Epoch   9, Step:    28500, Batch Loss:     1.904837, Batch Acc: 0.515151, Tokens per Sec:     3953, Lr: 0.000300
2023-05-30 23:24:21,661 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 23:24:21,661 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 23:25:29,868 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.24, ppl:   9.41, acc:   0.42, generation: 68.1998[sec], evaluation: 0.0000[sec]
2023-05-30 23:25:29,967 - INFO - joeynmt.helpers - delete models/transformer_model3/26500.ckpt
2023-05-30 23:25:29,970 - INFO - joeynmt.training - Example #0
2023-05-30 23:25:29,970 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 23:25:29,970 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 23:25:29,970 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'ge@@', 'zeigt,', 'dass', 'die', 'Pol@@', 'i@@', 'zei@@', 'zei@@', 'ge,', 'dass', 'die', 'Pol@@', 'i@@', 'ar@@', 'is@@', '-@@', 'Eis@@', 'sch@@', 'lag', 'der', 'Größe', 'der', 'U@@', 'S', 'F@@', 'est@@', ',', 'mit', '40@@', '%', 'ge@@', 'tra@@', 'gen.', '</s>']
2023-05-30 23:25:29,970 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 23:25:29,971 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 23:25:29,971 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Dias gezeigt, dass die Polizeizeige, dass die Poliaris-Eisschlag der Größe der US Fest, mit 40% getragen.
2023-05-30 23:25:29,971 - INFO - joeynmt.training - Example #1
2023-05-30 23:25:29,971 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 23:25:29,971 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 23:25:29,971 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Be@@', 'sch@@', 'ätz@@', 'ung', 'dieses', 'spezi@@', 'f@@', 'ischen', 'Proble@@', 'm,', 'weil', 'es', 'nicht', 'die', 'Di@@', 'a@@', 'kt', 'des', 'E@@', 'is', 'ist.', '</s>']
2023-05-30 23:25:29,971 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 23:25:29,971 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 23:25:29,971 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Beschätzung dieses spezifischen Problem, weil es nicht die Diakt des Eis ist.
2023-05-30 23:25:29,971 - INFO - joeynmt.training - Example #2
2023-05-30 23:25:29,971 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 23:25:29,971 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 23:25:29,971 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'Eis@@', 'sch@@', 'ap', 'auf', 'dem', 'Nor@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'Sinn', 'unseres', 'glob@@', 'alen', 'Kl@@', 'im@@', 'im@@', 'im@@', '-@@', 'T@@', 'yp@@', '-@@', 'Syste@@', 'm.', '</s>']
2023-05-30 23:25:29,971 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 23:25:29,971 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 23:25:29,971 - INFO - joeynmt.training - 	Hypothesis: Die Eisschap auf dem Nordpol ist in gewissem Sinn unseres globalen Klimimim-Typ-System.
2023-05-30 23:25:29,971 - INFO - joeynmt.training - Example #3
2023-05-30 23:25:29,971 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 23:25:29,971 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 23:25:29,971 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 's@@', 'etzt', 'sich', 'aus', 'dem', 'Win@@', 'ter', 'und', 'kr@@', 'im@@', 'imm@@', 't', 'im', 'Som@@', 'mer@@', '.', '</s>']
2023-05-30 23:25:29,972 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 23:25:29,972 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 23:25:29,972 - INFO - joeynmt.training - 	Hypothesis: Es setzt sich aus dem Winter und krimimmt im Sommer.
2023-05-30 23:25:29,972 - INFO - joeynmt.training - Example #4
2023-05-30 23:25:29,972 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 23:25:29,972 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 23:25:29,972 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Fol@@', 'ie', 'zeigen,', 'die', 'ich', 'Ihnen', 'zeigen', 'ist', 'eine', 'besch@@', 'le@@', 'un@@', 'ig@@', 'te', 'Ver@@', 'sion', 'von', 'dem,', 'was', 'die', 'letzten', '25', 'Jahre', 'passiert.', '</s>']
2023-05-30 23:25:29,972 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 23:25:29,972 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 23:25:29,972 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie zeigen, die ich Ihnen zeigen ist eine beschleunigte Version von dem, was die letzten 25 Jahre passiert.
2023-05-30 23:25:48,254 - INFO - joeynmt.training - Epoch   9, Step:    28600, Batch Loss:     1.770641, Batch Acc: 0.514269, Tokens per Sec:     3894, Lr: 0.000300
2023-05-30 23:26:07,567 - INFO - joeynmt.training - Epoch   9, Step:    28700, Batch Loss:     1.858940, Batch Acc: 0.514387, Tokens per Sec:     3736, Lr: 0.000300
2023-05-30 23:26:27,126 - INFO - joeynmt.training - Epoch   9, Step:    28800, Batch Loss:     1.727061, Batch Acc: 0.515159, Tokens per Sec:     3570, Lr: 0.000300
2023-05-30 23:26:46,612 - INFO - joeynmt.training - Epoch   9, Step:    28900, Batch Loss:     1.906316, Batch Acc: 0.511009, Tokens per Sec:     3727, Lr: 0.000300
2023-05-30 23:27:06,000 - INFO - joeynmt.training - Epoch   9, Step:    29000, Batch Loss:     1.841808, Batch Acc: 0.509893, Tokens per Sec:     3697, Lr: 0.000300
2023-05-30 23:27:06,001 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 23:27:06,001 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 23:28:24,156 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.26, ppl:   9.55, acc:   0.41, generation: 78.1482[sec], evaluation: 0.0000[sec]
2023-05-30 23:28:24,157 - INFO - joeynmt.training - Example #0
2023-05-30 23:28:24,157 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 23:28:24,157 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 23:28:24,157 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'dass', 'die', 'P@@', 'ool@@', 'e', 'Eis@@', 'sch@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'ungefähr', 'die', 'Größe', 'der', 'U@@', '.@@', 'S@@', '.@@', ',', 'mit', '40@@', '%', 'Ge@@', 'f@@', 'äl@@', 'de', 'des', 'U@@', 'U@@', '-@@', 'Prozent', 'gek@@', 'ro@@', 'chen.', '</s>']
2023-05-30 23:28:24,157 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 23:28:24,157 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 23:28:24,157 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Folien gezeigt, dass die Poole Eisschap, die die letzten drei Millionen Jahre ungefähr die Größe der U.S., mit 40% Gefälde des UU-Prozent gekrochen.
2023-05-30 23:28:24,157 - INFO - joeynmt.training - Example #1
2023-05-30 23:28:24,158 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 23:28:24,158 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 23:28:24,158 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Be@@', 'gin@@', 'n', 'dieses', 'spezi@@', 'elle', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'Di@@', 're@@', 'kt', 'des', 'E@@', 'is', 'zeigt', '–', '</s>']
2023-05-30 23:28:24,158 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 23:28:24,158 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 23:28:24,158 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Beginn dieses spezielle Problem ist, weil es nicht die Direkt des Eis zeigt –
2023-05-30 23:28:24,158 - INFO - joeynmt.training - Example #2
2023-05-30 23:28:24,158 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 23:28:24,158 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 23:28:24,158 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'Eis@@', 'sch@@', 'ap', 'auf', 'dem', 'Nor@@', 'd@@', 'po@@', 'l', 'ist', 'ein', 'gew@@', 'iss@@', 'es', 'Her@@', 'z', 'unseres', 'glob@@', 'al', 'Klima@@', 'wandel@@', '.', '</s>']
2023-05-30 23:28:24,158 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 23:28:24,158 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 23:28:24,158 - INFO - joeynmt.training - 	Hypothesis: Die Eisschap auf dem Nordpol ist ein gewisses Herz unseres global Klimawandel.
2023-05-30 23:28:24,158 - INFO - joeynmt.training - Example #3
2023-05-30 23:28:24,158 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 23:28:24,158 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 23:28:24,158 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'sch@@', 'al@@', 'tet', 'aus', 'dem', 'Win@@', 'ter', 'und', 'kr@@', 'im@@', 'p@@', 't.', '</s>']
2023-05-30 23:28:24,158 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 23:28:24,158 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 23:28:24,159 - INFO - joeynmt.training - 	Hypothesis: Es schaltet aus dem Winter und krimpt.
2023-05-30 23:28:24,159 - INFO - joeynmt.training - Example #4
2023-05-30 23:28:24,159 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 23:28:24,159 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 23:28:24,159 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Fol@@', 'ie', 'zeigt', 'eine', 'besch@@', 'le@@', 'un@@', 'ig@@', 'te', 'Ver@@', 'sion', 'von', 'dem,', 'was', 'die', 'letzten', '25', 'Jahre', 'gesch@@', 'ehen', 'ist.', '</s>']
2023-05-30 23:28:24,159 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 23:28:24,159 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 23:28:24,159 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie zeigt eine beschleunigte Version von dem, was die letzten 25 Jahre geschehen ist.
2023-05-30 23:28:43,113 - INFO - joeynmt.training - Epoch   9, Step:    29100, Batch Loss:     1.960331, Batch Acc: 0.508718, Tokens per Sec:     3718, Lr: 0.000300
2023-05-30 23:29:01,406 - INFO - joeynmt.training - Epoch   9, Step:    29200, Batch Loss:     1.771564, Batch Acc: 0.504175, Tokens per Sec:     3875, Lr: 0.000300
2023-05-30 23:29:20,246 - INFO - joeynmt.training - Epoch   9, Step:    29300, Batch Loss:     1.627418, Batch Acc: 0.510259, Tokens per Sec:     3878, Lr: 0.000300
2023-05-30 23:29:39,516 - INFO - joeynmt.training - Epoch   9, Step:    29400, Batch Loss:     1.948530, Batch Acc: 0.503776, Tokens per Sec:     3738, Lr: 0.000300
2023-05-30 23:29:59,541 - INFO - joeynmt.training - Epoch   9, Step:    29500, Batch Loss:     1.772993, Batch Acc: 0.505321, Tokens per Sec:     3487, Lr: 0.000300
2023-05-30 23:29:59,541 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 23:29:59,541 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 23:30:58,565 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.25, ppl:   9.50, acc:   0.41, generation: 59.0164[sec], evaluation: 0.0000[sec]
2023-05-30 23:30:58,565 - INFO - joeynmt.training - Example #0
2023-05-30 23:30:58,565 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 23:30:58,565 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 23:30:58,565 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'ge@@', 'zeigt,', 'dass', 'die', 'Pol@@', 'ar@@', 'ien', 'ge@@', 'zeigt', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'etwa', 'die', 'Größe', 'der', 'letzten', 'drei', 'Millionen', 'Jahre', 'ungefähr', 'die', 'Größe', 'der', 'V@@', 'S@@', ',', 'mit', '40', 'Prozent', 'ge@@', 'tr@@', 'enn@@', 't', 'war.', '</s>']
2023-05-30 23:30:58,566 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 23:30:58,566 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 23:30:58,566 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Dias gezeigt, dass die Polarien gezeigt die letzten drei Millionen Jahre etwa die Größe der letzten drei Millionen Jahre ungefähr die Größe der VS, mit 40 Prozent getrennt war.
2023-05-30 23:30:58,566 - INFO - joeynmt.training - Example #1
2023-05-30 23:30:58,566 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 23:30:58,566 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 23:30:58,566 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'hier', 'ist', 'eigentlich', 'die', 'Be@@', 'gin@@', 'n', 'dieses', 'spezi@@', 'f@@', 'ischen', 'Problem', 'weil', 'es', 'nicht', 'die', 'Di@@', 'ff@@', 'er@@', 'enz@@', '.', '</s>']
2023-05-30 23:30:58,566 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 23:30:58,566 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 23:30:58,566 - INFO - joeynmt.training - 	Hypothesis: Aber das hier ist eigentlich die Beginn dieses spezifischen Problem weil es nicht die Differenz.
2023-05-30 23:30:58,566 - INFO - joeynmt.training - Example #2
2023-05-30 23:30:58,566 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 23:30:58,566 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 23:30:58,566 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'Eis@@', 'k@@', 'ap@@', 'ut@@', 'ze', 'ist', 'die', 'Nor@@', 'd@@', 'po@@', 'l', 'des', 'Her@@', 'z@@', 'ens', 'der', 'glob@@', 'alen', 'Klima@@', 'wandel@@', 's', 'der', 'glob@@', 'alen', 'Klima@@', 'wandel@@', '.', '</s>']
2023-05-30 23:30:58,566 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 23:30:58,566 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 23:30:58,566 - INFO - joeynmt.training - 	Hypothesis: Die Eiskaputze ist die Nordpol des Herzens der globalen Klimawandels der globalen Klimawandel.
2023-05-30 23:30:58,567 - INFO - joeynmt.training - Example #3
2023-05-30 23:30:58,567 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 23:30:58,567 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 23:30:58,567 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 's@@', 'etzt', 'sich', 'im', 'Win@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'p@@', 't', 'im', 'S@@', 'omm@@', 'er', 'im', 'S@@', 'omm@@', 'er', 'und', 'das', 'S@@', 'omm@@', 'er', 'in', 'den', 'Som@@', 'mer@@', '.', '</s>']
2023-05-30 23:30:58,567 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 23:30:58,567 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 23:30:58,567 - INFO - joeynmt.training - 	Hypothesis: Es setzt sich im Winter und Krimpt im Sommer im Sommer und das Sommer in den Sommer.
2023-05-30 23:30:58,567 - INFO - joeynmt.training - Example #4
2023-05-30 23:30:58,567 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 23:30:58,567 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 23:30:58,567 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'nächste', 'Fol@@', 'ie', 'zeige', 'ich', 'eine', 'besch@@', 'le@@', 'un@@', 'ig@@', 'te', 'Ver@@', 'sion', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert.', '</s>']
2023-05-30 23:30:58,567 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 23:30:58,567 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 23:30:58,567 - INFO - joeynmt.training - 	Hypothesis: Und die nächste Folie zeige ich eine beschleunigte Version von dem, was in den letzten 25 Jahren passiert.
2023-05-30 23:31:18,701 - INFO - joeynmt.training - Epoch   9, Step:    29600, Batch Loss:     1.826313, Batch Acc: 0.502465, Tokens per Sec:     3627, Lr: 0.000300
2023-05-30 23:31:37,704 - INFO - joeynmt.training - Epoch   9, Step:    29700, Batch Loss:     2.038404, Batch Acc: 0.509123, Tokens per Sec:     3789, Lr: 0.000300
2023-05-30 23:31:57,317 - INFO - joeynmt.training - Epoch   9, Step:    29800, Batch Loss:     1.912616, Batch Acc: 0.502788, Tokens per Sec:     3758, Lr: 0.000300
2023-05-30 23:32:17,154 - INFO - joeynmt.training - Epoch   9, Step:    29900, Batch Loss:     1.965689, Batch Acc: 0.502019, Tokens per Sec:     3620, Lr: 0.000300
2023-05-30 23:32:36,173 - INFO - joeynmt.training - Epoch   9, Step:    30000, Batch Loss:     1.944265, Batch Acc: 0.500495, Tokens per Sec:     3828, Lr: 0.000300
2023-05-30 23:32:36,175 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 23:32:36,175 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 23:33:43,691 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.25, ppl:   9.45, acc:   0.41, generation: 67.5092[sec], evaluation: 0.0000[sec]
2023-05-30 23:33:43,693 - INFO - joeynmt.training - Example #0
2023-05-30 23:33:43,693 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 23:33:43,693 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 23:33:43,693 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'zu', 'zeigen,', 'dass', 'die', 'Pol@@', 'ar@@', 'is@@', 'k@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'ungefähr', 'ungefähr', 'die', 'Größe', 'des', 'F@@', 'est@@', 'es', 'von', 'den', 'letzten', 'drei', 'Millionen', 'Jahre', 'auf', 'den', 'F@@', 'est@@', 'land', 'mit', '40@@', '%', 'ge@@', 'tr@@', 'eten', 'war.', '</s>']
2023-05-30 23:33:43,693 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 23:33:43,693 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 23:33:43,693 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Dias zu zeigen, dass die Polariskap, die die letzten drei Millionen Jahre ungefähr ungefähr die Größe des Festes von den letzten drei Millionen Jahre auf den Festland mit 40% getreten war.
2023-05-30 23:33:43,693 - INFO - joeynmt.training - Example #1
2023-05-30 23:33:43,693 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 23:33:43,693 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 23:33:43,693 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'hier', 'ist', 'der', 'Be@@', 'sch@@', 'ät@@', 'zen', 'dieses', 'spezi@@', 'f@@', 'ischen', 'Proble@@', 'm,', 'weil', 'es', 'nicht', 'die', 'Di@@', 'ff@@', 'er@@', 'enz@@', 'ierung', 'des', 'E@@', 'is', 'zu', 'sehen.', '</s>']
2023-05-30 23:33:43,694 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 23:33:43,694 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 23:33:43,694 - INFO - joeynmt.training - 	Hypothesis: Aber das hier ist der Beschätzen dieses spezifischen Problem, weil es nicht die Differenzierung des Eis zu sehen.
2023-05-30 23:33:43,694 - INFO - joeynmt.training - Example #2
2023-05-30 23:33:43,694 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 23:33:43,694 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 23:33:43,694 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'Sch@@', 'ei@@', 'ter', 'auf', 'der', 'Nor@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'Kl@@', 'ein@@', 'er', 'des', 'Klima@@', 's', 'des', 'Klima@@', 'wandel@@', 's', 'des', 'Klima@@', 'wandel@@', 's', 'des', 'Klima@@', 'wandel@@', 's', 'des', 'Klima@@', 'wandel@@', 's', 'zu', 'sein.', '</s>']
2023-05-30 23:33:43,694 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 23:33:43,694 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 23:33:43,694 - INFO - joeynmt.training - 	Hypothesis: Der Scheiter auf der Nordpol ist in gewissem Kleiner des Klimas des Klimawandels des Klimawandels des Klimawandels des Klimawandels zu sein.
2023-05-30 23:33:43,694 - INFO - joeynmt.training - Example #3
2023-05-30 23:33:43,694 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 23:33:43,694 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 23:33:43,694 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'Win@@', 'ter', 'und', 'K@@', 'lu@@', 'm@@', 'p@@', 't', 'im', 'S@@', 'omm@@', 'er', 'und', 'im', 'S@@', 'omm@@', 'er', '</s>']
2023-05-30 23:33:43,694 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 23:33:43,694 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 23:33:43,694 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Klumpt im Sommer und im Sommer
2023-05-30 23:33:43,694 - INFO - joeynmt.training - Example #4
2023-05-30 23:33:43,694 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 23:33:43,694 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 23:33:43,694 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Fol@@', 'ie', 'zeigen,', 'die', 'ich', 'Ihnen', 'zeigen', 'ist', 'eine', 'besch@@', 'le@@', 'un@@', 'ig@@', 'te', 'Ver@@', 'sion', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passier@@', 'te.', '</s>']
2023-05-30 23:33:43,695 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 23:33:43,695 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 23:33:43,695 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie zeigen, die ich Ihnen zeigen ist eine beschleunigte Version von dem, was in den letzten 25 Jahren passierte.
2023-05-30 23:34:02,547 - INFO - joeynmt.training - Epoch   9, Step:    30100, Batch Loss:     1.864916, Batch Acc: 0.497842, Tokens per Sec:     3883, Lr: 0.000300
2023-05-30 23:34:20,619 - INFO - joeynmt.training - Epoch   9, Step:    30200, Batch Loss:     1.906408, Batch Acc: 0.500950, Tokens per Sec:     3933, Lr: 0.000300
2023-05-30 23:34:39,445 - INFO - joeynmt.training - Epoch   9, Step:    30300, Batch Loss:     1.863770, Batch Acc: 0.500174, Tokens per Sec:     3820, Lr: 0.000300
2023-05-30 23:34:58,780 - INFO - joeynmt.training - Epoch   9, Step:    30400, Batch Loss:     1.788631, Batch Acc: 0.496292, Tokens per Sec:     3752, Lr: 0.000300
2023-05-30 23:35:17,654 - INFO - joeynmt.training - Epoch   9, Step:    30500, Batch Loss:     1.940791, Batch Acc: 0.498802, Tokens per Sec:     3869, Lr: 0.000300
2023-05-30 23:35:17,654 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 23:35:17,654 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 23:36:26,076 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.24, ppl:   9.39, acc:   0.42, generation: 68.4151[sec], evaluation: 0.0000[sec]
2023-05-30 23:36:26,168 - INFO - joeynmt.helpers - delete models/transformer_model3/24500.ckpt
2023-05-30 23:36:26,168 - INFO - joeynmt.training - Example #0
2023-05-30 23:36:26,169 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 23:36:26,169 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 23:36:26,169 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'zu', 'zeigen,', 'dass', 'die', 'Pol@@', 'i@@', 'zei@@', 'zei@@', 'ch@@', 'nen', 'drei', 'Millionen', 'Jahre', 'etwa', 'etwa', 'die', 'Größe', 'des', 'F@@', 'est@@', 'and', 'der', 'U@@', '.@@', 'S@@', '.@@', ',', 'mit', '40@@', '%', 'ge@@', 'hal@@', 'ten', 'Ge@@', 'f@@', 'äl@@', 'de', 'in', 'den', 'US@@', 'A,', 'mit', '40@@', '%', 'ge@@', 'ge@@', 'tr@@', 'enn@@', 't', 'war.', '</s>']
2023-05-30 23:36:26,169 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 23:36:26,169 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 23:36:26,169 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Dias zu zeigen, dass die Polizeizeichnen drei Millionen Jahre etwa etwa die Größe des Festand der U.S., mit 40% gehalten Gefälde in den USA, mit 40% gegetrennt war.
2023-05-30 23:36:26,169 - INFO - joeynmt.training - Example #1
2023-05-30 23:36:26,169 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 23:36:26,169 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 23:36:26,169 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'unter@@', 'sch@@', 'ätz@@', 't', 'tatsächlich', 'die', 'Be@@', 'gr@@', 'iff', 'des', 'E@@', 'is', 'ist', 'der', 'Be@@', 'gr@@', 'iff', 'des', 'E@@', 'is', 'zei@@', 'g@@', 'ten', 'E@@', 'is', 'zei@@', 'g@@', 't.', '</s>']
2023-05-30 23:36:26,169 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 23:36:26,169 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 23:36:26,169 - INFO - joeynmt.training - 	Hypothesis: Aber das unterschätzt tatsächlich die Begriff des Eis ist der Begriff des Eis zeigten Eis zeigt.
2023-05-30 23:36:26,169 - INFO - joeynmt.training - Example #2
2023-05-30 23:36:26,169 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 23:36:26,169 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 23:36:26,169 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'Eis@@', 'sch@@', 'ap', 'auf', 'dem', 'Nor@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'Sinn', 'unseres', 'glob@@', 'ales', 'Kl@@', 'im@@', 'im@@', 'a', 'und', 'das', 'ist', 'das', 'wahr@@', 'e', 'Her@@', 'z', 'unseres', 'Klima@@', 'wandel@@', 's', 'des', 'Klima@@', 'wandel@@', 's', 'zu', 'er@@', 'weiter@@', 'n.', '</s>']
2023-05-30 23:36:26,169 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 23:36:26,170 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 23:36:26,170 - INFO - joeynmt.training - 	Hypothesis: Die Eisschap auf dem Nordpol ist in gewissem Sinn unseres globales Klimima und das ist das wahre Herz unseres Klimawandels des Klimawandels zu erweitern.
2023-05-30 23:36:26,170 - INFO - joeynmt.training - Example #3
2023-05-30 23:36:26,170 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 23:36:26,170 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 23:36:26,170 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 's@@', 'etzt', 'aus', 'dem', 'Win@@', 'ter', 'und', 'kr@@', 'im@@', 'p@@', 't', 'im', 'S@@', 'omm@@', 'er', 'und', 'kr@@', 'im@@', 'p@@', 't.', '</s>']
2023-05-30 23:36:26,170 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 23:36:26,170 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 23:36:26,170 - INFO - joeynmt.training - 	Hypothesis: Es setzt aus dem Winter und krimpt im Sommer und krimpt.
2023-05-30 23:36:26,170 - INFO - joeynmt.training - Example #4
2023-05-30 23:36:26,170 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 23:36:26,170 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 23:36:26,170 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Fol@@', 'ie', 'zeigt,', 'dass', 'ich', 'eine', 'besch@@', 'le@@', 'un@@', 'ig@@', 'te', 'Ver@@', 'sion', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.', '</s>']
2023-05-30 23:36:26,170 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 23:36:26,170 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 23:36:26,170 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie zeigt, dass ich eine beschleunigte Version von dem, was in den letzten 25 Jahren passiert ist.
2023-05-30 23:36:44,684 - INFO - joeynmt.training - Epoch   9, Step:    30600, Batch Loss:     1.767819, Batch Acc: 0.498300, Tokens per Sec:     3874, Lr: 0.000300
2023-05-30 23:37:03,967 - INFO - joeynmt.training - Epoch   9, Step:    30700, Batch Loss:     1.815583, Batch Acc: 0.499784, Tokens per Sec:     3836, Lr: 0.000300
2023-05-30 23:37:22,979 - INFO - joeynmt.training - Epoch   9, Step:    30800, Batch Loss:     1.823693, Batch Acc: 0.495706, Tokens per Sec:     3951, Lr: 0.000300
2023-05-30 23:37:42,259 - INFO - joeynmt.training - Epoch   9, Step:    30900, Batch Loss:     1.773980, Batch Acc: 0.494354, Tokens per Sec:     3656, Lr: 0.000300
2023-05-30 23:38:01,399 - INFO - joeynmt.training - Epoch   9, Step:    31000, Batch Loss:     1.906449, Batch Acc: 0.498576, Tokens per Sec:     3835, Lr: 0.000300
2023-05-30 23:38:01,399 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 23:38:01,399 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 23:39:14,609 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.24, ppl:   9.35, acc:   0.42, generation: 73.2021[sec], evaluation: 0.0000[sec]
2023-05-30 23:39:14,698 - INFO - joeynmt.helpers - delete models/transformer_model3/27500.ckpt
2023-05-30 23:39:14,698 - INFO - joeynmt.training - Example #0
2023-05-30 23:39:14,698 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 23:39:14,699 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 23:39:14,699 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'ge@@', 'zeigt', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'ge@@', 'zeigt', 'hat,', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'lang', 'ungefähr', 'ungefähr', 'die', 'Größe', 'des', 'F@@', 'est@@', 'els', 'der', 'F@@', 'est@@', 'ung', 'der', 'Vereinigten', 'Staaten', 'mit', '40', 'Prozent', 'ge@@', 'tr@@', 'enn@@', 't', 'war.', '</s>']
2023-05-30 23:39:14,699 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 23:39:14,699 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 23:39:14,699 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Dias gezeigt habe ich diese zwei Dias gezeigt hat, die letzten drei Millionen Jahre lang ungefähr ungefähr die Größe des Festels der Festung der Vereinigten Staaten mit 40 Prozent getrennt war.
2023-05-30 23:39:14,699 - INFO - joeynmt.training - Example #1
2023-05-30 23:39:14,699 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 23:39:14,699 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 23:39:14,699 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'hier', 'ist', 'die', 'Be@@', 'gin@@', 'n', 'dieses', 'spezi@@', 'f@@', 'ische', 'Problem', 'dieses', 'spezi@@', 'f@@', 'ische', 'Problem', 'weil', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'E@@', 'is', 'zeigt', '</s>']
2023-05-30 23:39:14,699 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 23:39:14,699 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 23:39:14,699 - INFO - joeynmt.training - 	Hypothesis: Aber das hier ist die Beginn dieses spezifische Problem dieses spezifische Problem weil es nicht die Dicke des Eis zeigt
2023-05-30 23:39:14,699 - INFO - joeynmt.training - Example #2
2023-05-30 23:39:14,699 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 23:39:14,699 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 23:39:14,699 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'Eis@@', 'deck@@', 'e', 'auf', 'dem', 'Nor@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'Sinn', 'unseres', 'glob@@', 'alen', 'Klima@@', 'wandel@@', 's', 'des', 'Her@@', 'zen', 'der', 'glob@@', 'alen', 'Klima@@', 'wandel@@', 's', 'zu', 'sein.', '</s>']
2023-05-30 23:39:14,699 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 23:39:14,699 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 23:39:14,699 - INFO - joeynmt.training - 	Hypothesis: Die Eisdecke auf dem Nordpol ist in gewissem Sinn unseres globalen Klimawandels des Herzen der globalen Klimawandels zu sein.
2023-05-30 23:39:14,699 - INFO - joeynmt.training - Example #3
2023-05-30 23:39:14,699 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 23:39:14,700 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 23:39:14,700 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 's@@', 'etzt', 'sich', 'im', 'Win@@', 'ter', 'und', 'kr@@', 'im@@', 't', 'im', 'S@@', 'omm@@', 'er', 'und', 'im', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'im', 'S@@', 'omm@@', 'er', 'K@@', 'lu@@', 'm@@', 's.', '</s>']
2023-05-30 23:39:14,700 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 23:39:14,700 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 23:39:14,700 - INFO - joeynmt.training - 	Hypothesis: Es setzt sich im Winter und krimt im Sommer und im Sommer in den Sommer und im Sommer Klums.
2023-05-30 23:39:14,700 - INFO - joeynmt.training - Example #4
2023-05-30 23:39:14,700 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 23:39:14,700 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 23:39:14,700 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Fol@@', 'ie', 'die', 'ich', 'Ihnen', 'zeigen', 'wer@@', 'de,', 'ist', 'eine', 'besch@@', 'le@@', 'un@@', 'ig@@', 'te', 'Ver@@', 'sion', 'von', 'dem', 'letzten', '25', 'Jahren', 'gesch@@', 'ehen', 'ist.', '</s>']
2023-05-30 23:39:14,700 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 23:39:14,700 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 23:39:14,700 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie die ich Ihnen zeigen werde, ist eine beschleunigte Version von dem letzten 25 Jahren geschehen ist.
2023-05-30 23:39:34,213 - INFO - joeynmt.training - Epoch   9, Step:    31100, Batch Loss:     1.967148, Batch Acc: 0.499929, Tokens per Sec:     3581, Lr: 0.000300
2023-05-30 23:39:53,541 - INFO - joeynmt.training - Epoch   9, Step:    31200, Batch Loss:     1.894879, Batch Acc: 0.497074, Tokens per Sec:     3758, Lr: 0.000300
2023-05-30 23:40:12,475 - INFO - joeynmt.training - Epoch   9, Step:    31300, Batch Loss:     1.902301, Batch Acc: 0.497181, Tokens per Sec:     3851, Lr: 0.000300
2023-05-30 23:40:31,834 - INFO - joeynmt.training - Epoch   9, Step:    31400, Batch Loss:     1.877911, Batch Acc: 0.502611, Tokens per Sec:     3571, Lr: 0.000300
2023-05-30 23:40:51,053 - INFO - joeynmt.training - Epoch   9, Step:    31500, Batch Loss:     1.921566, Batch Acc: 0.494326, Tokens per Sec:     3741, Lr: 0.000300
2023-05-30 23:40:51,053 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 23:40:51,053 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 23:41:59,509 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.23, ppl:   9.33, acc:   0.42, generation: 68.4486[sec], evaluation: 0.0000[sec]
2023-05-30 23:41:59,600 - INFO - joeynmt.helpers - delete models/transformer_model3/28500.ckpt
2023-05-30 23:41:59,600 - INFO - joeynmt.training - Example #0
2023-05-30 23:41:59,600 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 23:41:59,600 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 23:41:59,600 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Di@@', 'as', 'ge@@', 'zeigt,', 'dass', 'der', 'Pol@@', 'iz@@', 'isten', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'lang', 'der', 'Größe', 'der', 'P@@', 'ool@@', 'e', 'der', 'Größe', 'der', 'F@@', 'est@@', 'ung', 'der', 'USA', 'mit', '40@@', '%', 'ge@@', 'ho@@', 'ben.', '</s>']
2023-05-30 23:41:59,600 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 23:41:59,600 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 23:41:59,600 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese beiden Dias gezeigt, dass der Polizisten die letzten drei Millionen Jahre lang der Größe der Poole der Größe der Festung der USA mit 40% gehoben.
2023-05-30 23:41:59,600 - INFO - joeynmt.training - Example #1
2023-05-30 23:41:59,601 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 23:41:59,601 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 23:41:59,601 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Be@@', 'gr@@', 'iff', 'der', 'Be@@', 'gr@@', 'iff', 'dieses', 'spezi@@', 'f@@', 'ische', 'Problem', 'weil', 'es', 'nicht', 'die', 'Di@@', 'mensi@@', 'on', 'der', 'Di@@', 'mensi@@', 'on', 'zei@@', 'gt.', '</s>']
2023-05-30 23:41:59,601 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 23:41:59,601 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 23:41:59,601 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Begriff der Begriff dieses spezifische Problem weil es nicht die Dimension der Dimension zeigt.
2023-05-30 23:41:59,601 - INFO - joeynmt.training - Example #2
2023-05-30 23:41:59,601 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 23:41:59,601 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 23:41:59,601 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'E@@', 'is', 'in', 'der', 'E@@', 'is', 'ist', 'in', 'gew@@', 'iss@@', 'er', 'Weise', 'das', 'stimm@@', 't', 'das', 'Her@@', 'z', 'unserer', 'glob@@', 'alen', 'Klima@@', 'wandel@@', '.', '</s>']
2023-05-30 23:41:59,601 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 23:41:59,601 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 23:41:59,601 - INFO - joeynmt.training - 	Hypothesis: Der Eis in der Eis ist in gewisser Weise das stimmt das Herz unserer globalen Klimawandel.
2023-05-30 23:41:59,601 - INFO - joeynmt.training - Example #3
2023-05-30 23:41:59,601 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 23:41:59,601 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 23:41:59,601 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 's@@', 'etzt', 'aus', 'dem', 'Win@@', 'ter', 'und', 'kr@@', 'im@@', 'imm@@', 't', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'in', 'den', 'S@@', 'omm@@', 'er', '</s>']
2023-05-30 23:41:59,601 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 23:41:59,601 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 23:41:59,601 - INFO - joeynmt.training - 	Hypothesis: Es setzt aus dem Winter und krimimmt in den Sommer in den Sommer und in den Sommer
2023-05-30 23:41:59,601 - INFO - joeynmt.training - Example #4
2023-05-30 23:41:59,601 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 23:41:59,601 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 23:41:59,602 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Fol@@', 'ie', 'die', 'ich', 'Ihnen', 'zeigen', 'ist', 'eine', 'besch@@', 'le@@', 'un@@', 'ig@@', 'te', 'Ver@@', 'sion', 'von', 'dem,', 'was', 'die', 'letzten', '25', 'Jahre', 'passiert.', '</s>']
2023-05-30 23:41:59,602 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 23:41:59,602 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 23:41:59,602 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie die ich Ihnen zeigen ist eine beschleunigte Version von dem, was die letzten 25 Jahre passiert.
2023-05-30 23:42:19,919 - INFO - joeynmt.training - Epoch   9, Step:    31600, Batch Loss:     1.704170, Batch Acc: 0.496141, Tokens per Sec:     3548, Lr: 0.000300
2023-05-30 23:42:39,135 - INFO - joeynmt.training - Epoch   9, Step:    31700, Batch Loss:     1.934899, Batch Acc: 0.491175, Tokens per Sec:     3685, Lr: 0.000300
2023-05-30 23:42:58,452 - INFO - joeynmt.training - Epoch   9, Step:    31800, Batch Loss:     1.783359, Batch Acc: 0.497499, Tokens per Sec:     3768, Lr: 0.000300
2023-05-30 23:43:02,979 - INFO - joeynmt.training - Epoch   9: total training loss 6464.03
2023-05-30 23:43:02,979 - INFO - joeynmt.training - EPOCH 10
2023-05-30 23:43:17,362 - INFO - joeynmt.training - Epoch  10, Step:    31900, Batch Loss:     1.586762, Batch Acc: 0.527475, Tokens per Sec:     3922, Lr: 0.000300
2023-05-30 23:43:36,270 - INFO - joeynmt.training - Epoch  10, Step:    32000, Batch Loss:     1.937825, Batch Acc: 0.525757, Tokens per Sec:     3794, Lr: 0.000300
2023-05-30 23:43:36,270 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 23:43:36,271 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 23:44:51,289 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.24, ppl:   9.38, acc:   0.42, generation: 75.0101[sec], evaluation: 0.0000[sec]
2023-05-30 23:44:51,381 - INFO - joeynmt.helpers - delete models/transformer_model3/30500.ckpt
2023-05-30 23:44:51,384 - INFO - joeynmt.training - Example #0
2023-05-30 23:44:51,384 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 23:44:51,384 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 23:44:51,384 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Di@@', 'as', 'ge@@', 'zeigt,', 'dass', 'die', 'Pol@@', 'il@@', 'il@@', 'e', 'Sch@@', 'af@@', 'af@@', 'fe@@', 'e', 'ge@@', 'zeigt', 'hat,', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'lang', 'der', 'F@@', 'est@@', 'ung', 'der', 'USA', 'mit', '40@@', '%', 'ge@@', 'spr@@', 'ü@@', 'ch@@', 'lich', 'ver@@', 'letz@@', 'ungen', 'war.', '</s>']
2023-05-30 23:44:51,384 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 23:44:51,384 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 23:44:51,385 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese beiden Dias gezeigt, dass die Polilile Schafaffee gezeigt hat, die letzten drei Millionen Jahre lang der Festung der USA mit 40% gesprüchlich verletzungen war.
2023-05-30 23:44:51,385 - INFO - joeynmt.training - Example #1
2023-05-30 23:44:51,385 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 23:44:51,385 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 23:44:51,385 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Be@@', 'gr@@', 'iff@@', 'e', 'dieses', 'spezi@@', 'elle', 'Problem', 'weil', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'E@@', 'is', 'hier', 'sehen', 'kann.', '</s>']
2023-05-30 23:44:51,385 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 23:44:51,385 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 23:44:51,385 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Begriffe dieses spezielle Problem weil es nicht die Dicke des Eis hier sehen kann.
2023-05-30 23:44:51,385 - INFO - joeynmt.training - Example #2
2023-05-30 23:44:51,385 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 23:44:51,385 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 23:44:51,385 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is', 'in', 'der', 'Nor@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'Sinn', 'unseres', 'glob@@', 'alen', 'Kl@@', 'im@@', 'im@@', 'a', 'zu', 'unserem', 'glob@@', 'alen', 'Kl@@', 'im@@', 'im@@', 'im@@', 'a', 'zu', 'sein.', '</s>']
2023-05-30 23:44:51,385 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 23:44:51,385 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 23:44:51,385 - INFO - joeynmt.training - 	Hypothesis: Die Eis in der Nordpol ist in gewissem Sinn unseres globalen Klimima zu unserem globalen Klimimima zu sein.
2023-05-30 23:44:51,385 - INFO - joeynmt.training - Example #3
2023-05-30 23:44:51,385 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 23:44:51,385 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 23:44:51,385 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 's@@', 'etzt', 'sich', 'im', 'Win@@', 'ter', 'und', 'kr@@', 'im@@', 'imm@@', 't', 'im', 'S@@', 'omm@@', 'er', 'und', 'kr@@', 'im@@', 'imm@@', 't.', '</s>']
2023-05-30 23:44:51,385 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 23:44:51,385 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 23:44:51,385 - INFO - joeynmt.training - 	Hypothesis: Es setzt sich im Winter und krimimmt im Sommer und krimimmt.
2023-05-30 23:44:51,386 - INFO - joeynmt.training - Example #4
2023-05-30 23:44:51,386 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 23:44:51,386 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 23:44:51,386 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Fol@@', 'ie', 'die', 'ich', 'Ihnen', 'zeigen', 'ist', 'eine', 'besch@@', 'le@@', 'un@@', 'ig@@', 'te', 'Ver@@', 'sion', 'von', 'dem,', 'was', 'die', 'letzten', '25', 'Jahre', 'passier@@', 'te.', '</s>']
2023-05-30 23:44:51,386 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 23:44:51,386 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 23:44:51,386 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie die ich Ihnen zeigen ist eine beschleunigte Version von dem, was die letzten 25 Jahre passierte.
2023-05-30 23:45:10,276 - INFO - joeynmt.training - Epoch  10, Step:    32100, Batch Loss:     1.688586, Batch Acc: 0.527353, Tokens per Sec:     3919, Lr: 0.000300
2023-05-30 23:45:29,573 - INFO - joeynmt.training - Epoch  10, Step:    32200, Batch Loss:     1.688934, Batch Acc: 0.520914, Tokens per Sec:     3687, Lr: 0.000300
2023-05-30 23:45:49,068 - INFO - joeynmt.training - Epoch  10, Step:    32300, Batch Loss:     1.738539, Batch Acc: 0.521616, Tokens per Sec:     3653, Lr: 0.000300
2023-05-30 23:46:08,846 - INFO - joeynmt.training - Epoch  10, Step:    32400, Batch Loss:     1.897463, Batch Acc: 0.514334, Tokens per Sec:     3723, Lr: 0.000300
2023-05-30 23:46:28,193 - INFO - joeynmt.training - Epoch  10, Step:    32500, Batch Loss:     1.811500, Batch Acc: 0.519185, Tokens per Sec:     3784, Lr: 0.000300
2023-05-30 23:46:28,193 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 23:46:28,193 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 23:47:30,982 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.25, ppl:   9.48, acc:   0.42, generation: 62.7820[sec], evaluation: 0.0000[sec]
2023-05-30 23:47:30,985 - INFO - joeynmt.training - Example #0
2023-05-30 23:47:30,985 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 23:47:30,985 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 23:47:30,985 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'ge@@', 'zeigt', 'habe,', 'um', 'zu', 'zeigen,', 'dass', 'die', 'Pol@@', 'i@@', 'zei@@', 'ch@@', 'nen', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'auf', 'etwa', 'etwa', 'die', 'Größe', 'der', 'F@@', 'est@@', 'ung', 'der', 'U@@', 'S', 'F@@', 'est@@', 'plat@@', 'z', 'der', 'U@@', 'p@@', 'ha@@', 'sen', 'war.', '</s>']
2023-05-30 23:47:30,986 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 23:47:30,986 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 23:47:30,986 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Dias gezeigt habe, um zu zeigen, dass die Polizeichnen die letzten drei Millionen Jahre auf etwa etwa die Größe der Festung der US Festplatz der Uphasen war.
2023-05-30 23:47:30,986 - INFO - joeynmt.training - Example #1
2023-05-30 23:47:30,986 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 23:47:30,986 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 23:47:30,986 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'die', 'Be@@', 'sch@@', 'ätz@@', 'ung', 'dieses', 'spezi@@', 'f@@', 'ische', 'Problem', 'weil', 'es', 'nicht', 'die', 'Di@@', 'ag@@', 'ram@@', 'm', 'des', 'E@@', 'is', 'zei@@', 'gt.', '</s>']
2023-05-30 23:47:30,986 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 23:47:30,986 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 23:47:30,986 - INFO - joeynmt.training - 	Hypothesis: Aber das ist die Beschätzung dieses spezifische Problem weil es nicht die Diagramm des Eis zeigt.
2023-05-30 23:47:30,986 - INFO - joeynmt.training - Example #2
2023-05-30 23:47:30,986 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 23:47:30,986 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 23:47:30,986 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'E@@', 'is', 'in', 'der', 'Nor@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'Sinn', 'unser', 'glob@@', 'ales', 'Kl@@', 'im@@', 'a', 'zu', 'unserer', 'glob@@', 'alen', 'Klima@@', 'er@@', 'z', 'unseres', 'Klima@@', 'wandel@@', 's.', '</s>']
2023-05-30 23:47:30,986 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 23:47:30,986 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 23:47:30,986 - INFO - joeynmt.training - 	Hypothesis: Der Eis in der Nordpol ist in gewissem Sinn unser globales Klima zu unserer globalen Klimaerz unseres Klimawandels.
2023-05-30 23:47:30,986 - INFO - joeynmt.training - Example #3
2023-05-30 23:47:30,986 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 23:47:30,986 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 23:47:30,986 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 's@@', 'etzt', 'aus', 'dem', 'Win@@', 'ter', 'und', 'kr@@', 'im@@', 'ft', 'im', 'S@@', 'omm@@', 'er', 'im', 'S@@', 'omm@@', 'er', 'im', 'S@@', 'omm@@', 'er', '</s>']
2023-05-30 23:47:30,987 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 23:47:30,987 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 23:47:30,987 - INFO - joeynmt.training - 	Hypothesis: Es setzt aus dem Winter und krimft im Sommer im Sommer im Sommer
2023-05-30 23:47:30,987 - INFO - joeynmt.training - Example #4
2023-05-30 23:47:30,987 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 23:47:30,987 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 23:47:30,987 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Fol@@', 'ie', 'die', 'ich', 'zei@@', 'ge,', 'die', 'ich', 'Ihnen', 'zeigen', 'wer@@', 'de,', 'was', 'die', 'letzten', '25', 'Jahre', 'passiert.', '</s>']
2023-05-30 23:47:30,987 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 23:47:30,987 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 23:47:30,987 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie die ich zeige, die ich Ihnen zeigen werde, was die letzten 25 Jahre passiert.
2023-05-30 23:47:49,875 - INFO - joeynmt.training - Epoch  10, Step:    32600, Batch Loss:     1.741348, Batch Acc: 0.520336, Tokens per Sec:     3795, Lr: 0.000210
2023-05-30 23:48:08,729 - INFO - joeynmt.training - Epoch  10, Step:    32700, Batch Loss:     1.681026, Batch Acc: 0.526953, Tokens per Sec:     3894, Lr: 0.000210
2023-05-30 23:48:27,608 - INFO - joeynmt.training - Epoch  10, Step:    32800, Batch Loss:     1.662574, Batch Acc: 0.517669, Tokens per Sec:     3797, Lr: 0.000210
2023-05-30 23:48:47,615 - INFO - joeynmt.training - Epoch  10, Step:    32900, Batch Loss:     1.700335, Batch Acc: 0.520835, Tokens per Sec:     3566, Lr: 0.000210
2023-05-30 23:49:07,774 - INFO - joeynmt.training - Epoch  10, Step:    33000, Batch Loss:     1.716891, Batch Acc: 0.524886, Tokens per Sec:     3631, Lr: 0.000210
2023-05-30 23:49:07,774 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 23:49:07,774 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 23:50:09,609 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.23, ppl:   9.25, acc:   0.42, generation: 61.8275[sec], evaluation: 0.0000[sec]
2023-05-30 23:50:09,611 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 23:50:09,700 - INFO - joeynmt.helpers - delete models/transformer_model3/27000.ckpt
2023-05-30 23:50:09,700 - INFO - joeynmt.training - Example #0
2023-05-30 23:50:09,701 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 23:50:09,701 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 23:50:09,701 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'ge@@', 'zeigt,', 'dass', 'der', 'Pol@@', 'y@@', 'mer@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'in', 'etwa', 'die', 'Größe', 'des', 'F@@', 'est@@', 'es', 'in', 'etwa', 'drei', 'Millionen', 'Jahre', 'ge@@', 'zo@@', 'gen,', 'mit', '40', 'Prozent', 'gesch@@', 'ro@@', 'hl@@', 't', 'war.', '</s>']
2023-05-30 23:50:09,701 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 23:50:09,701 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 23:50:09,701 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Dias gezeigt, dass der Polymer, die die letzten drei Millionen Jahre in etwa die Größe des Festes in etwa drei Millionen Jahre gezogen, mit 40 Prozent geschrohlt war.
2023-05-30 23:50:09,701 - INFO - joeynmt.training - Example #1
2023-05-30 23:50:09,701 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 23:50:09,701 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 23:50:09,701 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'die', 'Be@@', 'sch@@', 'ätz@@', 'ung', 'dieses', 'spezi@@', 'f@@', 'ische', 'Problem', 'weil', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'E@@', 'is', 'zu', 'sehen.', '</s>']
2023-05-30 23:50:09,701 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 23:50:09,701 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 23:50:09,701 - INFO - joeynmt.training - 	Hypothesis: Aber das ist die Beschätzung dieses spezifische Problem weil es nicht die Dicke des Eis zu sehen.
2023-05-30 23:50:09,701 - INFO - joeynmt.training - Example #2
2023-05-30 23:50:09,701 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 23:50:09,701 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 23:50:09,701 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'Eis@@', 'sch@@', 'icht', 'des', 'Nor@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'Sinn', 'unseres', 'glob@@', 'alen', 'Klima@@', 'wandel@@', 's', 'des', 'Her@@', 'z@@', 'ens', 'des', 'Klima@@', 'wandel@@', 's', 'zu', 'er@@', 'hö@@', 'h@@', 't.', '</s>']
2023-05-30 23:50:09,701 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 23:50:09,701 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 23:50:09,701 - INFO - joeynmt.training - 	Hypothesis: Die Eisschicht des Nordpol ist in gewissem Sinn unseres globalen Klimawandels des Herzens des Klimawandels zu erhöht.
2023-05-30 23:50:09,702 - INFO - joeynmt.training - Example #3
2023-05-30 23:50:09,702 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 23:50:09,702 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 23:50:09,702 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 's@@', 'etzt', 'sich', 'in', 'den', 'Win@@', 'ter', 'und', 'kr@@', 'im@@', 'ft', 'im', 'S@@', 'omm@@', 'er', 'im', 'S@@', 'omm@@', 'er', 'und', 'im', 'S@@', 'omm@@', 'er', 'sch@@', 'w@@', 'äch@@', 't.', '</s>']
2023-05-30 23:50:09,702 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 23:50:09,702 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 23:50:09,702 - INFO - joeynmt.training - 	Hypothesis: Es setzt sich in den Winter und krimft im Sommer im Sommer und im Sommer schwächt.
2023-05-30 23:50:09,702 - INFO - joeynmt.training - Example #4
2023-05-30 23:50:09,702 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 23:50:09,702 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 23:50:09,702 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Fol@@', 'ie', 'die', 'ich', 'Ihnen', 'zeigen', 'wer@@', 'de,', 'ist', 'eine', 'besch@@', 'le@@', 'un@@', 'ig@@', 'te', 'Ver@@', 'sion', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.', '</s>']
2023-05-30 23:50:09,702 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 23:50:09,702 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 23:50:09,702 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie die ich Ihnen zeigen werde, ist eine beschleunigte Version von dem, was in den letzten 25 Jahren passiert ist.
2023-05-30 23:50:30,062 - INFO - joeynmt.training - Epoch  10, Step:    33100, Batch Loss:     1.948996, Batch Acc: 0.524029, Tokens per Sec:     3562, Lr: 0.000210
2023-05-30 23:50:48,542 - INFO - joeynmt.training - Epoch  10, Step:    33200, Batch Loss:     1.709835, Batch Acc: 0.523884, Tokens per Sec:     3910, Lr: 0.000210
2023-05-30 23:51:07,806 - INFO - joeynmt.training - Epoch  10, Step:    33300, Batch Loss:     1.863696, Batch Acc: 0.523788, Tokens per Sec:     3629, Lr: 0.000210
2023-05-30 23:51:27,825 - INFO - joeynmt.training - Epoch  10, Step:    33400, Batch Loss:     1.895316, Batch Acc: 0.523441, Tokens per Sec:     3737, Lr: 0.000210
2023-05-30 23:51:46,915 - INFO - joeynmt.training - Epoch  10, Step:    33500, Batch Loss:     1.654416, Batch Acc: 0.520848, Tokens per Sec:     3781, Lr: 0.000210
2023-05-30 23:51:46,915 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 23:51:46,915 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 23:52:52,119 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.22, ppl:   9.19, acc:   0.42, generation: 65.1961[sec], evaluation: 0.0000[sec]
2023-05-30 23:52:52,120 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 23:52:52,212 - INFO - joeynmt.helpers - delete models/transformer_model3/32000.ckpt
2023-05-30 23:52:52,215 - INFO - joeynmt.training - Example #0
2023-05-30 23:52:52,215 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 23:52:52,215 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 23:52:52,215 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'ge@@', 'zeigt,', 'dass', 'die', 'Pol@@', 'ar@@', 'z@@', 'ellen', 'Eis@@', 'sch@@', 'lag', 'die', 'drei', 'Millionen', 'Jahre', 'etwa', 'die', 'Größe', 'des', 'F@@', 'est@@', 'es', 'in', 'etwa', 'drei', 'Millionen', 'Jahren', 'ge@@', 'tr@@', 'eten', 'hatte,', 'mit', '40', 'Prozent', 'gesch@@', 'ro@@', 'm@@', 'utz@@', 't', 'hatte.', '</s>']
2023-05-30 23:52:52,215 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 23:52:52,215 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 23:52:52,215 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Dias gezeigt, dass die Polarzellen Eisschlag die drei Millionen Jahre etwa die Größe des Festes in etwa drei Millionen Jahren getreten hatte, mit 40 Prozent geschromutzt hatte.
2023-05-30 23:52:52,215 - INFO - joeynmt.training - Example #1
2023-05-30 23:52:52,215 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 23:52:52,215 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 23:52:52,215 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'die', 'Be@@', 'gr@@', 'iff', 'dieses', 'spezi@@', 'elle', 'Problem', 'dieses', 'spezi@@', 'elle', 'Problem', 'weil', 'es', 'nicht', 'die', 'Di@@', 'ff@@', 'er@@', 'enz@@', 'eit', 'des', 'E@@', 'is', 'zei@@', 'g@@', 'ten', 'sehen.', '</s>']
2023-05-30 23:52:52,216 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 23:52:52,216 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 23:52:52,216 - INFO - joeynmt.training - 	Hypothesis: Aber das ist die Begriff dieses spezielle Problem dieses spezielle Problem weil es nicht die Differenzeit des Eis zeigten sehen.
2023-05-30 23:52:52,216 - INFO - joeynmt.training - Example #2
2023-05-30 23:52:52,216 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 23:52:52,216 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 23:52:52,216 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is', 'des', 'Nor@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'P@@', 'aar@@', 'e', 'des', 'Her@@', 'z@@', 'ens', 'des', 'Klima@@', 'wandel@@', 's', 'zu', 'unserem', 'glob@@', 'alen', 'Kl@@', 'im@@', 'im@@', 'im@@', '-@@', 'Syste@@', 'm@@', 's.', '</s>']
2023-05-30 23:52:52,216 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 23:52:52,216 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 23:52:52,216 - INFO - joeynmt.training - 	Hypothesis: Die Eis des Nordpol ist in gewissem Paare des Herzens des Klimawandels zu unserem globalen Klimimim-Systems.
2023-05-30 23:52:52,216 - INFO - joeynmt.training - Example #3
2023-05-30 23:52:52,216 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 23:52:52,216 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 23:52:52,216 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 's@@', 'etzt', 'sich', 'im', 'Win@@', 'ter', 'und', 'kr@@', 'im@@', 'p@@', 't.', '</s>']
2023-05-30 23:52:52,216 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 23:52:52,216 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 23:52:52,216 - INFO - joeynmt.training - 	Hypothesis: Es setzt sich im Winter und krimpt.
2023-05-30 23:52:52,216 - INFO - joeynmt.training - Example #4
2023-05-30 23:52:52,216 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 23:52:52,216 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 23:52:52,216 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Fol@@', 'ie', 'die', 'ich', 'Ihnen', 'zeigen', 'ist', 'eine', 'besch@@', 'le@@', 'un@@', 'ig@@', 'te', 'Ver@@', 'sion', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'gesch@@', 'ehen', 'ist.', '</s>']
2023-05-30 23:52:52,217 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 23:52:52,217 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 23:52:52,217 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie die ich Ihnen zeigen ist eine beschleunigte Version von dem, was in den letzten 25 Jahren geschehen ist.
2023-05-30 23:53:11,066 - INFO - joeynmt.training - Epoch  10, Step:    33600, Batch Loss:     1.734137, Batch Acc: 0.527205, Tokens per Sec:     3671, Lr: 0.000210
2023-05-30 23:53:30,850 - INFO - joeynmt.training - Epoch  10, Step:    33700, Batch Loss:     1.782055, Batch Acc: 0.523881, Tokens per Sec:     3728, Lr: 0.000210
2023-05-30 23:53:49,982 - INFO - joeynmt.training - Epoch  10, Step:    33800, Batch Loss:     1.705088, Batch Acc: 0.524933, Tokens per Sec:     3820, Lr: 0.000210
2023-05-30 23:54:08,540 - INFO - joeynmt.training - Epoch  10, Step:    33900, Batch Loss:     1.654317, Batch Acc: 0.525102, Tokens per Sec:     3807, Lr: 0.000210
2023-05-30 23:54:27,371 - INFO - joeynmt.training - Epoch  10, Step:    34000, Batch Loss:     1.678621, Batch Acc: 0.515844, Tokens per Sec:     3846, Lr: 0.000210
2023-05-30 23:54:27,371 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 23:54:27,371 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 23:55:35,348 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.21, ppl:   9.15, acc:   0.42, generation: 67.9700[sec], evaluation: 0.0000[sec]
2023-05-30 23:55:35,350 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 23:55:35,438 - INFO - joeynmt.helpers - delete models/transformer_model3/31000.ckpt
2023-05-30 23:55:35,441 - INFO - joeynmt.training - Example #0
2023-05-30 23:55:35,441 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 23:55:35,441 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 23:55:35,441 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'ge@@', 'zeigt,', 'dass', 'die', 'Pol@@', 'iz@@', 'isten', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'in', 'etwa', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'etwa', 'etwa', 'die', 'Größe', 'der', 'F@@', 'est@@', 'ung', 'der', 'U@@', 'S', 'F@@', 'est@@', 'and', 'der', 'U@@', 'S', 'war.', '</s>']
2023-05-30 23:55:35,441 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 23:55:35,441 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 23:55:35,441 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Dias gezeigt, dass die Polizisten die letzten drei Millionen Jahre in etwa die letzten drei Millionen Jahre etwa etwa die Größe der Festung der US Festand der US war.
2023-05-30 23:55:35,442 - INFO - joeynmt.training - Example #1
2023-05-30 23:55:35,442 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 23:55:35,442 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 23:55:35,442 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'hier', 'ist', 'der', 'Be@@', 'gr@@', 'iff', 'dieses', 'spezi@@', 'f@@', 'ischen', 'Proble@@', 'm,', 'weil', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'E@@', 'is', 'zei@@', 'g@@', 'ten', 'E@@', 'is', 'zei@@', 'g@@', 'te.', '</s>']
2023-05-30 23:55:35,442 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 23:55:35,442 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 23:55:35,442 - INFO - joeynmt.training - 	Hypothesis: Aber das hier ist der Begriff dieses spezifischen Problem, weil es nicht die Dicke des Eis zeigten Eis zeigte.
2023-05-30 23:55:35,442 - INFO - joeynmt.training - Example #2
2023-05-30 23:55:35,442 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 23:55:35,442 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 23:55:35,442 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'Eis@@', 'sch@@', 'ap', 'auf', 'dem', 'Nor@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'Sinn', 'unseres', 'glob@@', 'alen', 'Kl@@', 'im@@', 'im@@', '-@@', 'Klima@@', 'wandel@@', '.', '</s>']
2023-05-30 23:55:35,442 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 23:55:35,442 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 23:55:35,442 - INFO - joeynmt.training - 	Hypothesis: Die Eisschap auf dem Nordpol ist in gewissem Sinn unseres globalen Klimim-Klimawandel.
2023-05-30 23:55:35,442 - INFO - joeynmt.training - Example #3
2023-05-30 23:55:35,442 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 23:55:35,442 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 23:55:35,442 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 's@@', 'etzt', 'sich', 'in', 'den', 'Win@@', 'ter', 'und', 'kr@@', 'im@@', 'p@@', 't', 'im', 'S@@', 'omm@@', 'er', 'und', 'im', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', '</s>']
2023-05-30 23:55:35,442 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 23:55:35,442 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 23:55:35,442 - INFO - joeynmt.training - 	Hypothesis: Es setzt sich in den Winter und krimpt im Sommer und im Sommer in den Sommer und
2023-05-30 23:55:35,442 - INFO - joeynmt.training - Example #4
2023-05-30 23:55:35,443 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 23:55:35,443 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 23:55:35,443 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Fol@@', 'ie', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'besch@@', 'le@@', 'un@@', 'ig@@', 'te', 'Ver@@', 'sion', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passier@@', 'te.', '</s>']
2023-05-30 23:55:35,443 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 23:55:35,443 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 23:55:35,443 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie die ich Ihnen zeige, ist eine beschleunigte Version von dem, was in den letzten 25 Jahren passierte.
2023-05-30 23:55:54,256 - INFO - joeynmt.training - Epoch  10, Step:    34100, Batch Loss:     1.753344, Batch Acc: 0.519189, Tokens per Sec:     3769, Lr: 0.000210
2023-05-30 23:56:13,341 - INFO - joeynmt.training - Epoch  10, Step:    34200, Batch Loss:     1.567863, Batch Acc: 0.524129, Tokens per Sec:     3740, Lr: 0.000210
2023-05-30 23:56:32,055 - INFO - joeynmt.training - Epoch  10, Step:    34300, Batch Loss:     1.794296, Batch Acc: 0.520380, Tokens per Sec:     3824, Lr: 0.000210
2023-05-30 23:56:52,137 - INFO - joeynmt.training - Epoch  10, Step:    34400, Batch Loss:     1.929918, Batch Acc: 0.518203, Tokens per Sec:     3630, Lr: 0.000210
2023-05-30 23:57:11,706 - INFO - joeynmt.training - Epoch  10, Step:    34500, Batch Loss:     1.941467, Batch Acc: 0.521825, Tokens per Sec:     3831, Lr: 0.000210
2023-05-30 23:57:11,706 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 23:57:11,706 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 23:58:18,147 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.20, ppl:   9.06, acc:   0.43, generation: 66.4337[sec], evaluation: 0.0000[sec]
2023-05-30 23:58:18,149 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 23:58:18,242 - INFO - joeynmt.helpers - delete models/transformer_model3/31500.ckpt
2023-05-30 23:58:18,245 - INFO - joeynmt.training - Example #0
2023-05-30 23:58:18,246 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 23:58:18,246 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 23:58:18,246 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'ge@@', 'zeigt,', 'dass', 'die', 'Pol@@', 'iz@@', 'ist', 'die', 'P@@', 'ool@@', 'ei@@', 'sk@@', 'ap@@', 's,', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'in', 'der', 'Größe', 'der', 'F@@', 'est@@', 'ung', 'der', 'US@@', '-@@', 'V@@', '.', 'S@@', ',', 'mit', '40@@', '%', 'ge@@', 'druck@@', 'en.', '</s>']
2023-05-30 23:58:18,246 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 23:58:18,246 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 23:58:18,246 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Dias gezeigt, dass die Polizist die Pooleiskaps, die die letzten drei Millionen Jahre in der Größe der Festung der US-V. S, mit 40% gedrucken.
2023-05-30 23:58:18,246 - INFO - joeynmt.training - Example #1
2023-05-30 23:58:18,246 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-30 23:58:18,246 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-30 23:58:18,246 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Be@@', 'gr@@', 'iff', 'der', 'Be@@', 'gr@@', 'iff', 'dieses', 'spezi@@', 'f@@', 'ischen', 'Problem', 'weil', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'E@@', 'is', 'zei@@', 'g@@', 'ten', 'ist.', '</s>']
2023-05-30 23:58:18,246 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 23:58:18,246 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 23:58:18,246 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Begriff der Begriff dieses spezifischen Problem weil es nicht die Dicke des Eis zeigten ist.
2023-05-30 23:58:18,246 - INFO - joeynmt.training - Example #2
2023-05-30 23:58:18,246 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-30 23:58:18,246 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-30 23:58:18,246 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'Eis@@', 'sch@@', 'ap', 'auf', 'dem', 'Nor@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'Sinn', 'unseres', 'glob@@', 'alen', 'Kl@@', 'im@@', 'im@@', 'a', 'des', 'Klima@@', 'wandel@@', 's', 'zu', 'unserem', 'glob@@', 'alen', 'Kl@@', 'im@@', 'im@@', 'im@@', 'at@@', 's', 'zu', 'sein.', '</s>']
2023-05-30 23:58:18,247 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 23:58:18,247 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 23:58:18,247 - INFO - joeynmt.training - 	Hypothesis: Die Eisschap auf dem Nordpol ist in gewissem Sinn unseres globalen Klimima des Klimawandels zu unserem globalen Klimimimats zu sein.
2023-05-30 23:58:18,247 - INFO - joeynmt.training - Example #3
2023-05-30 23:58:18,247 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-30 23:58:18,247 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-30 23:58:18,247 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 's@@', 'etzt', 'im', 'Win@@', 'ter', 'und', 'kr@@', 'im@@', 'p@@', 't', 'im', 'S@@', 'omm@@', 'er', 'und', 'im', 'S@@', 'omm@@', 'er', 'sch@@', 'on.', '</s>']
2023-05-30 23:58:18,247 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 23:58:18,247 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 23:58:18,247 - INFO - joeynmt.training - 	Hypothesis: Es setzt im Winter und krimpt im Sommer und im Sommer schon.
2023-05-30 23:58:18,247 - INFO - joeynmt.training - Example #4
2023-05-30 23:58:18,247 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 23:58:18,247 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-30 23:58:18,247 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Fol@@', 'ie', 'die', 'ich', 'Ihnen', 'zeigen', 'wer@@', 'de,', 'ist', 'eine', 'besch@@', 'le@@', 'un@@', 'ig@@', 'te', 'Ver@@', 'sion', 'von', 'dem,', 'was', 'die', 'letzten', '25', 'Jahre', 'passiert.', '</s>']
2023-05-30 23:58:18,247 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 23:58:18,247 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 23:58:18,247 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie die ich Ihnen zeigen werde, ist eine beschleunigte Version von dem, was die letzten 25 Jahre passiert.
2023-05-30 23:58:37,525 - INFO - joeynmt.training - Epoch  10, Step:    34600, Batch Loss:     1.750478, Batch Acc: 0.523987, Tokens per Sec:     3591, Lr: 0.000210
2023-05-30 23:58:56,836 - INFO - joeynmt.training - Epoch  10, Step:    34700, Batch Loss:     1.787636, Batch Acc: 0.521789, Tokens per Sec:     3817, Lr: 0.000210
2023-05-30 23:59:16,993 - INFO - joeynmt.training - Epoch  10, Step:    34800, Batch Loss:     1.704680, Batch Acc: 0.517579, Tokens per Sec:     3539, Lr: 0.000210
2023-05-30 23:59:37,125 - INFO - joeynmt.training - Epoch  10, Step:    34900, Batch Loss:     1.568191, Batch Acc: 0.520419, Tokens per Sec:     3659, Lr: 0.000210
2023-05-30 23:59:57,678 - INFO - joeynmt.training - Epoch  10, Step:    35000, Batch Loss:     1.589358, Batch Acc: 0.521845, Tokens per Sec:     3609, Lr: 0.000210
2023-05-30 23:59:57,679 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 23:59:57,679 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-31 00:01:09,687 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.21, ppl:   9.11, acc:   0.43, generation: 72.0010[sec], evaluation: 0.0000[sec]
2023-05-31 00:01:09,781 - INFO - joeynmt.helpers - delete models/transformer_model3/28000.ckpt
2023-05-31 00:01:09,785 - INFO - joeynmt.training - Example #0
2023-05-31 00:01:09,785 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', "a's", 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '40@@', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-31 00:01:09,785 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'ge@@', 'zeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-31 00:01:09,785 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Fol@@', 'ien', 'ge@@', 'zeigt', 'habe,', 'dass', 'die', 'Pol@@', 'iz@@', 'isten', 'der', 'letzten', 'drei', 'Millionen', 'Jahre', 'lang', 'etwa', 'die', 'Größe', 'des', 'F@@', 'est@@', 'es', 'der', 'U@@', 'hr', 'von', '40', 'Prozent', 'der', 'U@@', '.@@', 'S@@', '.@@', ',', 'mit', '40@@', '%', 'ge@@', 'dre@@', 'hen.', '</s>']
2023-05-31 00:01:09,785 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-31 00:01:09,785 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-31 00:01:09,785 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Folien gezeigt habe, dass die Polizisten der letzten drei Millionen Jahre lang etwa die Größe des Festes der Uhr von 40 Prozent der U.S., mit 40% gedrehen.
2023-05-31 00:01:09,785 - INFO - joeynmt.training - Example #1
2023-05-31 00:01:09,785 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specif@@', 'ieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dik@@', 'te', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-31 00:01:09,785 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zei@@', 'gt.']
2023-05-31 00:01:09,785 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Be@@', 'sch@@', 'ätz@@', 'ung', 'der', 'Be@@', 'gr@@', 'iff', 'des', 'E@@', 'is', 'ist', 'nicht', 'die', 'Di@@', 'mensi@@', 'on', 'be@@', 'fa@@', 'ssen', 'ist.', '</s>']
2023-05-31 00:01:09,786 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-31 00:01:09,786 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-31 00:01:09,786 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Beschätzung der Begriff des Eis ist nicht die Dimension befassen ist.
2023-05-31 00:01:09,786 - INFO - joeynmt.training - Example #2
2023-05-31 00:01:09,786 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klim@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em.']
2023-05-31 00:01:09,786 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'Sinn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unseres', 'glob@@', 'alen', 'Klima@@', 'syste@@', 'm@@', 's.']
2023-05-31 00:01:09,786 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'Eis@@', 'sch@@', 'ap', 'am', 'Nor@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'Sinn', 'unseres', 'glob@@', 'alen', 'Klima@@', 'wandel@@', 's', '</s>']
2023-05-31 00:01:09,786 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-31 00:01:09,786 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-31 00:01:09,786 - INFO - joeynmt.training - 	Hypothesis: Der Eisschap am Nordpol ist in gewissem Sinn unseres globalen Klimawandels
2023-05-31 00:01:09,786 - INFO - joeynmt.training - Example #3
2023-05-31 00:01:09,786 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er.']
2023-05-31 00:01:09,786 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'Som@@', 'mer@@', '.']
2023-05-31 00:01:09,786 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 's@@', 'etzt', 'aus', 'dem', 'Win@@', 'ter', 'und', 'kr@@', 'im@@', 'pf@@', 't.', '</s>']
2023-05-31 00:01:09,786 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-31 00:01:09,786 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-31 00:01:09,786 - INFO - joeynmt.training - 	Hypothesis: Es setzt aus dem Winter und krimpft.
2023-05-31 00:01:09,786 - INFO - joeynmt.training - Example #4
2023-05-31 00:01:09,786 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-31 00:01:09,786 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Fol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-31 00:01:09,786 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', 'Fol@@', 'ie', 'die', 'ich', 'zei@@', 'ge,', 'ist', 'eine', 'besch@@', 'le@@', 'un@@', 'ig@@', 'te', 'Ver@@', 'sion', 'von', 'dem', 'letzten', '25', 'Jahre', 'gesch@@', 'ehen', 'ist.', '</s>']
2023-05-31 00:01:09,787 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-31 00:01:09,787 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-31 00:01:09,787 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie die ich zeige, ist eine beschleunigte Version von dem letzten 25 Jahre geschehen ist.
2023-05-31 00:01:29,841 - INFO - joeynmt.training - Epoch  10, Step:    35100, Batch Loss:     1.706100, Batch Acc: 0.518193, Tokens per Sec:     3580, Lr: 0.000210
2023-05-31 00:01:49,704 - INFO - joeynmt.training - Epoch  10, Step:    35200, Batch Loss:     1.720337, Batch Acc: 0.511444, Tokens per Sec:     3612, Lr: 0.000210
2023-05-31 00:02:08,413 - INFO - joeynmt.training - Epoch  10, Step:    35300, Batch Loss:     1.644496, Batch Acc: 0.515293, Tokens per Sec:     3964, Lr: 0.000210
2023-05-31 00:02:17,362 - INFO - joeynmt.training - Epoch  10: total training loss 6171.44
2023-05-31 00:02:17,362 - INFO - joeynmt.training - Training ended after  10 epochs.
2023-05-31 00:02:17,362 - INFO - joeynmt.training - Best validation result (greedy) at step    34500:   9.06 ppl.
2023-05-31 00:02:17,373 - INFO - joeynmt.model - Building an encoder-decoder model...
2023-05-31 00:02:17,422 - INFO - joeynmt.model - Enc-dec model built.
2023-05-31 00:02:17,454 - INFO - joeynmt.helpers - Load model from /Users/cyril/Desktop/krizzzzi/mt-exercise-5/models/transformer_model3/34500.ckpt.
2023-05-31 00:02:17,457 - INFO - joeynmt.prediction - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=6258),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=6258),
	loss_function=None)
2023-05-31 00:02:17,458 - INFO - joeynmt.prediction - Decoding on dev set...
2023-05-31 00:02:17,458 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-31 00:02:17,458 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-31 00:05:25,092 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 187.6272[sec], evaluation: 0.0000[sec]
2023-05-31 00:05:25,094 - INFO - joeynmt.prediction - Translations saved to: /Users/cyril/Desktop/krizzzzi/mt-exercise-5/models/transformer_model3/00034500.hyps.dev.
2023-05-31 00:05:25,094 - INFO - joeynmt.prediction - Decoding on test set...
2023-05-31 00:05:25,094 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-31 00:05:25,094 - INFO - joeynmt.prediction - Predicting 1779 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-31 00:09:03,042 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 217.9373[sec], evaluation: 0.0000[sec]
2023-05-31 00:09:03,043 - INFO - joeynmt.prediction - Translations saved to: /Users/cyril/Desktop/krizzzzi/mt-exercise-5/models/transformer_model3/00034500.hyps.test.
