2023-05-30 16:15:02,394 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2023-05-30 16:15:02,394 - INFO - joeynmt.helpers -                           cfg.name : transformer_model2
2023-05-30 16:15:02,394 - INFO - joeynmt.helpers -                cfg.joeynmt_version : 2.0.0
2023-05-30 16:15:02,394 - INFO - joeynmt.helpers -                     cfg.data.train : data/train
2023-05-30 16:15:02,394 - INFO - joeynmt.helpers -                       cfg.data.dev : data/dev
2023-05-30 16:15:02,394 - INFO - joeynmt.helpers -                      cfg.data.test : data/test
2023-05-30 16:15:02,394 - INFO - joeynmt.helpers -              cfg.data.dataset_type : plain
2023-05-30 16:15:02,394 - INFO - joeynmt.helpers -                  cfg.data.src.lang : nl
2023-05-30 16:15:02,394 - INFO - joeynmt.helpers -                 cfg.data.src.level : bpe
2023-05-30 16:15:02,394 - INFO - joeynmt.helpers -             cfg.data.src.lowercase : False
2023-05-30 16:15:02,394 - INFO - joeynmt.helpers -       cfg.data.src.max_sent_length : 100
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -              cfg.data.src.voc_file : data/bpe_vocab_2000.txt
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -        cfg.data.src.tokenizer_type : subword-nmt
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.num_merges : 2000
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -   cfg.data.src.tokenizer_cfg.codes : data/codes_file.2000
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.pretokenizer : none
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -                  cfg.data.trg.lang : de
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -                 cfg.data.trg.level : bpe
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -             cfg.data.trg.lowercase : False
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -       cfg.data.trg.max_sent_length : 100
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -              cfg.data.trg.voc_file : data/bpe_vocab_2000.txt
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -        cfg.data.trg.tokenizer_type : subword-nmt
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.num_merges : 2000
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -   cfg.data.trg.tokenizer_cfg.codes : data/codes_file.2000
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.pretokenizer : none
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -              cfg.testing.beam_size : 5
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -                  cfg.testing.alpha : 1.0
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -           cfg.training.random_seed : 42
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -             cfg.training.optimizer : adam
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -         cfg.training.normalization : tokens
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -         cfg.training.learning_rate : 0.0003
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -            cfg.training.batch_size : 2048
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -            cfg.training.batch_type : token
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -       cfg.training.eval_batch_size : 1024
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -       cfg.training.eval_batch_type : token
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -            cfg.training.scheduling : plateau
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -              cfg.training.patience : 8
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -          cfg.training.weight_decay : 0.0
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -       cfg.training.decrease_factor : 0.7
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -                cfg.training.epochs : 10
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -       cfg.training.validation_freq : 500
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -          cfg.training.logging_freq : 100
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -           cfg.training.eval_metric : bleu
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -             cfg.training.model_dir : models/transformer_model2
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -             cfg.training.overwrite : False
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -               cfg.training.shuffle : True
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -              cfg.training.use_cuda : False
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -     cfg.training.max_output_length : 100
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -     cfg.training.print_valid_sents : [0, 1, 2, 3, 4]
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -       cfg.training.label_smoothing : 0.3
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -              cfg.model.initializer : xavier_uniform
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -         cfg.model.bias_initializer : zeros
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -                cfg.model.init_gain : 1.0
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -        cfg.model.embed_initializer : xavier_uniform
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -          cfg.model.embed_init_gain : 1.0
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -          cfg.model.tied_embeddings : True
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -             cfg.model.tied_softmax : True
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -             cfg.model.encoder.type : transformer
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -       cfg.model.encoder.num_layers : 4
2023-05-30 16:15:02,395 - INFO - joeynmt.helpers -        cfg.model.encoder.num_heads : 2
2023-05-30 16:15:02,396 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256
2023-05-30 16:15:02,396 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2023-05-30 16:15:02,396 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0
2023-05-30 16:15:02,396 - INFO - joeynmt.helpers -      cfg.model.encoder.hidden_size : 256
2023-05-30 16:15:02,396 - INFO - joeynmt.helpers -          cfg.model.encoder.ff_size : 512
2023-05-30 16:15:02,396 - INFO - joeynmt.helpers -          cfg.model.encoder.dropout : 0
2023-05-30 16:15:02,396 - INFO - joeynmt.helpers -             cfg.model.decoder.type : transformer
2023-05-30 16:15:02,396 - INFO - joeynmt.helpers -       cfg.model.decoder.num_layers : 1
2023-05-30 16:15:02,396 - INFO - joeynmt.helpers -        cfg.model.decoder.num_heads : 2
2023-05-30 16:15:02,396 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256
2023-05-30 16:15:02,396 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2023-05-30 16:15:02,396 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0
2023-05-30 16:15:02,396 - INFO - joeynmt.helpers -      cfg.model.decoder.hidden_size : 256
2023-05-30 16:15:02,396 - INFO - joeynmt.helpers -          cfg.model.decoder.ff_size : 512
2023-05-30 16:15:02,396 - INFO - joeynmt.helpers -          cfg.model.decoder.dropout : 0
2023-05-30 16:15:02,397 - INFO - joeynmt.data - Building tokenizer...
2023-05-30 16:15:02,401 - INFO - joeynmt.tokenizers - nl tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2023-05-30 16:15:02,401 - INFO - joeynmt.tokenizers - de tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2023-05-30 16:15:02,401 - INFO - joeynmt.data - Loading train set...
2023-05-30 16:15:02,500 - INFO - joeynmt.data - Building vocabulary...
2023-05-30 16:15:02,537 - INFO - joeynmt.data - Loading dev set...
2023-05-30 16:15:02,538 - INFO - joeynmt.data - Loading test set...
2023-05-30 16:15:02,541 - INFO - joeynmt.data - Data loaded.
2023-05-30 16:15:02,541 - INFO - joeynmt.data - Train dataset: PlaintextDataset(split=train, len=100000, src_lang=nl, trg_lang=de, has_trg=True, random_subset=-1)
2023-05-30 16:15:02,541 - INFO - joeynmt.data - Valid dataset: PlaintextDataset(split=dev, len=1001, src_lang=nl, trg_lang=de, has_trg=True, random_subset=-1)
2023-05-30 16:15:02,541 - INFO - joeynmt.data -  Test dataset: PlaintextDataset(split=test, len=1779, src_lang=nl, trg_lang=de, has_trg=True, random_subset=-1)
2023-05-30 16:15:02,541 - INFO - joeynmt.data - First training example:
	[SRC] A@@ l G@@ or@@ e over het af@@ wen@@ den van de kl@@ im@@ aat@@ c@@ ris@@ is
	[TRG] A@@ l G@@ or@@ e@@ : Die Ab@@ wen@@ dung der K@@ li@@ ma@@ k@@ at@@ ast@@ rop@@ he
2023-05-30 16:15:02,541 - INFO - joeynmt.data - First 10 Src tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) de (5) en (6) die (7) in (8) een (9) .
2023-05-30 16:15:02,541 - INFO - joeynmt.data - First 10 Trg tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) de (5) en (6) die (7) in (8) een (9) .
2023-05-30 16:15:02,541 - INFO - joeynmt.data - Number of unique Src tokens (vocab_size): 2004
2023-05-30 16:15:02,541 - INFO - joeynmt.data - Number of unique Trg tokens (vocab_size): 2004
2023-05-30 16:15:02,542 - INFO - joeynmt.model - Building an encoder-decoder model...
2023-05-30 16:15:02,587 - INFO - joeynmt.model - Enc-dec model built.
2023-05-30 16:15:02,589 - INFO - joeynmt.model - Total params: 3412224
2023-05-30 16:15:02,589 - DEBUG - joeynmt.model - Trainable parameters: ['decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'src_embed.lut.weight']
2023-05-30 16:15:02,589 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=2004),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=2004),
	loss_function=XentLoss(criterion=KLDivLoss(), smoothing=0.3))
2023-05-30 16:15:02,590 - INFO - joeynmt.builders - Adam(lr=0.0003, weight_decay=0.0, betas=(0.9, 0.999))
2023-05-30 16:15:02,590 - INFO - joeynmt.builders - ReduceLROnPlateau(mode=min, verbose=False, threshold_mode=abs, eps=0.0, factor=0.7, patience=8)
2023-05-30 16:15:02,590 - INFO - joeynmt.training - Train stats:
	device: cpu
	n_gpu: 0
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 2048
	effective batch size (w. parallel & accumulation): 2048
2023-05-30 16:15:02,590 - INFO - joeynmt.training - EPOCH 1
2023-05-30 16:15:15,474 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     4.153544, Batch Acc: 0.034471, Tokens per Sec:     5897, Lr: 0.000300
2023-05-30 16:15:29,052 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     4.068456, Batch Acc: 0.048118, Tokens per Sec:     5774, Lr: 0.000300
2023-05-30 16:15:42,296 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     3.830305, Batch Acc: 0.056606, Tokens per Sec:     5726, Lr: 0.000300
2023-05-30 16:15:56,230 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     3.854748, Batch Acc: 0.065289, Tokens per Sec:     5452, Lr: 0.000300
2023-05-30 16:16:10,319 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     3.653621, Batch Acc: 0.072662, Tokens per Sec:     5385, Lr: 0.000300
2023-05-30 16:16:10,319 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 16:16:10,319 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 16:17:38,995 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.72, ppl:  41.38, acc:   0.07, generation: 88.6623[sec], evaluation: 0.0000[sec]
2023-05-30 16:17:38,997 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 16:17:39,079 - INFO - joeynmt.training - Example #0
2023-05-30 16:17:39,079 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 16:17:39,079 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 16:17:39,079 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich']
2023-05-30 16:17:39,079 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 16:17:39,079 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 16:17:39,079 - INFO - joeynmt.training - 	Hypothesis: Ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich
2023-05-30 16:17:39,079 - INFO - joeynmt.training - Example #1
2023-05-30 16:17:39,079 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 16:17:39,079 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 16:17:39,079 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'die', 'die', 'die', 'die']
2023-05-30 16:17:39,080 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 16:17:39,080 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 16:17:39,080 - INFO - joeynmt.training - 	Hypothesis: Aber nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht die die die die
2023-05-30 16:17:39,080 - INFO - joeynmt.training - Example #2
2023-05-30 16:17:39,080 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 16:17:39,080 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 16:17:39,080 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'K@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', '.', '</s>']
2023-05-30 16:17:39,080 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 16:17:39,080 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 16:17:39,080 - INFO - joeynmt.training - 	Hypothesis: Die Kaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa.
2023-05-30 16:17:39,080 - INFO - joeynmt.training - Example #3
2023-05-30 16:17:39,080 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 16:17:39,080 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 16:17:39,080 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'die', 'K@@', 'ü@@', 'ü@@', '-@@', 'K@@', 'ü@@', 'i@@', 'i@@', '.', '</s>']
2023-05-30 16:17:39,080 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 16:17:39,080 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 16:17:39,080 - INFO - joeynmt.training - 	Hypothesis: Es ist die Küü-Küii.
2023-05-30 16:17:39,080 - INFO - joeynmt.training - Example #4
2023-05-30 16:17:39,080 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 16:17:39,080 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 16:17:39,080 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'K@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', '.', '</s>']
2023-05-30 16:17:39,081 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 16:17:39,081 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 16:17:39,081 - INFO - joeynmt.training - 	Hypothesis: Die Kaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa.
2023-05-30 16:17:53,826 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     3.662358, Batch Acc: 0.079291, Tokens per Sec:     5125, Lr: 0.000300
2023-05-30 16:18:07,516 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     3.554807, Batch Acc: 0.084779, Tokens per Sec:     5478, Lr: 0.000300
2023-05-30 16:18:21,548 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:     3.516339, Batch Acc: 0.089326, Tokens per Sec:     5333, Lr: 0.000300
2023-05-30 16:18:35,163 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:     3.465300, Batch Acc: 0.095984, Tokens per Sec:     5620, Lr: 0.000300
2023-05-30 16:18:49,092 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     3.412662, Batch Acc: 0.102411, Tokens per Sec:     5319, Lr: 0.000300
2023-05-30 16:18:49,092 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 16:18:49,092 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 16:20:10,373 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.45, ppl:  31.57, acc:   0.10, generation: 81.2670[sec], evaluation: 0.0000[sec]
2023-05-30 16:20:10,374 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 16:20:10,450 - INFO - joeynmt.training - Example #0
2023-05-30 16:20:10,450 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 16:20:10,450 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 16:20:10,450 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'ich', 'die', 'K@@', 'a@@', 'm', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'K@@', 'a@@', 'b@@', 'b@@', 'en@@', 'e', 'der', 'der', 'der', 'K@@', 'a@@', 'a@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'en@@', 'en@@', 'en@@', 'en@@', 'en@@', 'en@@', 'er', 'der', 'K@@', 'a@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'a@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'h@@', 'en@@', '.', '</s>']
2023-05-30 16:20:10,450 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 16:20:10,450 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 16:20:10,450 - INFO - joeynmt.training - 	Hypothesis: Und ich habe ich die Kam der der der der der der der der der Kabbene der der der Kaahhhhhhhhhhhhhhhhhhhhhhhhenenenenenener der Kahhhhhhhhhhahhhhhhhhhhhhhhhhhhhhhen.
2023-05-30 16:20:10,450 - INFO - joeynmt.training - Example #1
2023-05-30 16:20:10,450 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 16:20:10,450 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 16:20:10,450 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'es', 'ist', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht']
2023-05-30 16:20:10,450 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 16:20:10,450 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 16:20:10,450 - INFO - joeynmt.training - 	Hypothesis: Aber es ist nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht
2023-05-30 16:20:10,450 - INFO - joeynmt.training - Example #2
2023-05-30 16:20:10,451 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 16:20:10,451 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 16:20:10,451 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'K@@', 'a@@', 'a@@', 'a@@', 'd', 'in', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'K@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'a@@', 'ch@@', '.', '</s>']
2023-05-30 16:20:10,451 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 16:20:10,451 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 16:20:10,451 - INFO - joeynmt.training - 	Hypothesis: Die Kaaad in der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der der Kaaaaaaaaaaach.
2023-05-30 16:20:10,451 - INFO - joeynmt.training - Example #3
2023-05-30 16:20:10,451 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 16:20:10,451 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 16:20:10,451 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in']
2023-05-30 16:20:10,451 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 16:20:10,451 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 16:20:10,451 - INFO - joeynmt.training - 	Hypothesis: Es ist in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in
2023-05-30 16:20:10,451 - INFO - joeynmt.training - Example #4
2023-05-30 16:20:10,451 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 16:20:10,451 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 16:20:10,451 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'M@@', 'a@@', 'm', 'der', 'der', 'der', 'der', 'der', 'K@@', 'a@@', 'a@@', 'm', 'der', 'der', 'der', 'der', 'der', 'der', 'K@@', 'a@@', 'ck@@', '.', '</s>']
2023-05-30 16:20:10,451 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 16:20:10,451 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 16:20:10,451 - INFO - joeynmt.training - 	Hypothesis: Die Mam der der der der der Kaam der der der der der der Kack.
2023-05-30 16:20:25,126 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:     3.422770, Batch Acc: 0.108968, Tokens per Sec:     5178, Lr: 0.000300
2023-05-30 16:20:38,572 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:     3.231189, Batch Acc: 0.127147, Tokens per Sec:     5654, Lr: 0.000300
2023-05-30 16:20:52,967 - INFO - joeynmt.training - Epoch   1, Step:     1300, Batch Loss:     3.257657, Batch Acc: 0.137889, Tokens per Sec:     5188, Lr: 0.000300
2023-05-30 16:21:07,557 - INFO - joeynmt.training - Epoch   1, Step:     1400, Batch Loss:     3.244782, Batch Acc: 0.148397, Tokens per Sec:     5306, Lr: 0.000300
2023-05-30 16:21:21,271 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:     3.143040, Batch Acc: 0.153207, Tokens per Sec:     5450, Lr: 0.000300
2023-05-30 16:21:21,271 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 16:21:21,271 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 16:22:55,719 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.12, ppl:  22.73, acc:   0.15, generation: 94.4358[sec], evaluation: 0.0000[sec]
2023-05-30 16:22:55,720 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 16:22:55,798 - INFO - joeynmt.training - Example #0
2023-05-30 16:22:55,798 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 16:22:55,798 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 16:22:55,798 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'ein', 'paar', 'M@@', 'äd@@', 'chen', 'ich', 'mit', 'dem', 'M@@', 'or@@', 'or@@', 'or@@', 't@@', 't@@', 't@@', 't@@', 'aus@@', 'ge@@', 'sam@@', 'e', 'zu', 'er@@', 'kenn@@', 'en,', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'M@@', 'al', 'zu', 'er@@', 'er@@', 'kenn@@', 'en,', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'M@@', 'or@@', 'or@@', 'or@@', 't@@', 't@@', 't@@', 't@@', 't@@', 't@@', 't@@', 't@@', 't@@', 'aus@@', 'ge@@', 'ge@@', 'ge@@', 'mach@@', 'en,', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'M@@', 'or@@', 'gen', 'zu', 'er@@', 'er@@', 'er@@', 'er@@', 'er@@', 'er@@', 'er@@', 'er@@', 'er@@', 'er@@', 'er@@', 'er@@', 'er@@']
2023-05-30 16:22:55,799 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 16:22:55,799 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 16:22:55,799 - INFO - joeynmt.training - 	Hypothesis: Ich habe ein paar Mädchen ich mit dem Morororttttausgesame zu erkennen, die die die die die die die Mal zu ererkennen, die die die die die die die die die die die die die die die die die Mororortttttttttausgegegemachen, die die die die die die die die die die die die die die die die Morgen zu ererererererererererererer
2023-05-30 16:22:55,799 - INFO - joeynmt.training - Example #1
2023-05-30 16:22:55,799 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 16:22:55,799 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 16:22:55,799 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'es', 'ist', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht']
2023-05-30 16:22:55,799 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 16:22:55,799 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 16:22:55,799 - INFO - joeynmt.training - 	Hypothesis: Aber es ist nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht
2023-05-30 16:22:55,799 - INFO - joeynmt.training - Example #2
2023-05-30 16:22:55,799 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 16:22:55,799 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 16:22:55,799 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'M@@', 'ein', 'M@@', 'om@@', 'om@@', 'en@@', 'n', 'in', 'der', 'K@@', 'om@@', 'om@@', 'om@@', 'en@@', 'en@@', 'en@@', 'n', 'in', 'der', 'K@@', 'om@@', 'om@@', 'en@@', 'en@@', 'en@@', 'n', 'in', 'der', 'K@@', 'om@@', 'om@@', 'en@@', 'en@@', 'en@@', 'n', 'in', 'der', 'K@@', 'om@@', 'om@@', 'en@@', 'en@@', 'en@@', 'en@@', 'en@@', 'n', '</s>']
2023-05-30 16:22:55,799 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 16:22:55,799 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 16:22:55,799 - INFO - joeynmt.training - 	Hypothesis: Die Mein Momomenn in der Komomomenenenn in der Komomenenenn in der Komomenenenn in der Komomenenenenenn
2023-05-30 16:22:55,799 - INFO - joeynmt.training - Example #3
2023-05-30 16:22:55,799 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 16:22:55,799 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 16:22:55,799 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'gibt', 'in', 'der', 'K@@', 'rie@@', 'g', 'in', 'der', 'K@@', 'om@@', 'om@@', 'en@@', 'en@@', 'en@@', 'n', 'und', 'in', 'der', 'K@@', 'rie@@', 'g', 'in', 'der', 'B@@', 'ü@@', 'ch@@', '.', '</s>']
2023-05-30 16:22:55,800 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 16:22:55,800 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 16:22:55,800 - INFO - joeynmt.training - 	Hypothesis: Es gibt in der Krieg in der Komomenenenn und in der Krieg in der Büch.
2023-05-30 16:22:55,800 - INFO - joeynmt.training - Example #4
2023-05-30 16:22:55,800 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 16:22:55,800 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 16:22:55,800 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'M@@', 'ein', 'paar', 'paar', 'paar', 'paar', 'M@@', 'äd@@', 'chen', 'zu', 'er@@', 'kenn@@', 'en,', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'M@@', 'äd@@', 'chen', 'zu', 'er@@', 'er@@', 'er@@', 'er@@', 'er@@', 'er@@', 'er@@', 'er@@', 'er@@', 'er@@', 'er@@', 'er@@', 'kenn@@', 'en.', '</s>']
2023-05-30 16:22:55,800 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 16:22:55,800 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 16:22:55,800 - INFO - joeynmt.training - 	Hypothesis: Die Mein paar paar paar paar Mädchen zu erkennen, die die die die die die die Mädchen zu ererererererererererererkennen.
2023-05-30 16:23:10,166 - INFO - joeynmt.training - Epoch   1, Step:     1600, Batch Loss:     3.042496, Batch Acc: 0.162002, Tokens per Sec:     5132, Lr: 0.000300
2023-05-30 16:23:25,761 - INFO - joeynmt.training - Epoch   1, Step:     1700, Batch Loss:     3.008900, Batch Acc: 0.168333, Tokens per Sec:     4830, Lr: 0.000300
2023-05-30 16:23:39,544 - INFO - joeynmt.training - Epoch   1, Step:     1800, Batch Loss:     2.914155, Batch Acc: 0.179633, Tokens per Sec:     5489, Lr: 0.000300
2023-05-30 16:23:53,949 - INFO - joeynmt.training - Epoch   1, Step:     1900, Batch Loss:     2.867718, Batch Acc: 0.184699, Tokens per Sec:     5447, Lr: 0.000300
2023-05-30 16:24:07,561 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:     2.886470, Batch Acc: 0.187081, Tokens per Sec:     5454, Lr: 0.000300
2023-05-30 16:24:07,562 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 16:24:07,562 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 16:25:33,805 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.95, ppl:  19.16, acc:   0.17, generation: 86.2338[sec], evaluation: 0.0000[sec]
2023-05-30 16:25:33,807 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 16:25:33,883 - INFO - joeynmt.training - Example #0
2023-05-30 16:25:33,883 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 16:25:33,883 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 16:25:33,883 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'die', 'M@@', 'om@@', 'ent', 'war', 'ich', 'die', 'die', 'T@@', 'r@@', 'r@@', 'r@@', 'ü@@', 'h@@', 't,', 'dass', 'die', 'die', 'die', 'T@@', 'r@@', 'ü@@', 'h@@', 'h@@', 'h@@', 'af@@', 't', 'in', 'den', 'Jahren', 'in', 'den', 'Jahren', 'in', 'den', 'Jahren', 'Jahren', 'Jahren', 'Jahren', 'Jahren', 'Jahren', 'Jahren', 'Jahren', 'Jahren', 'Jahren', 'Jahren', 'Jahren', 'Jahren', 'Jahren', 'Jahren', 'Jahren', 'Jahren', 'Jahren', 'ver@@', 'r@@', 'ü@@', 'h@@', 't', 'zu', 'er@@', 'f@@', 'lu@@', 'ss@@', ',', 'dass', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'F@@', 'lu@@', 'ss', 'von', '1@@', '5', 'Jahren', 'Jahren', 'ge@@', 'sehen', 'und', 'die', 'ich', 'habe', 'die', 'ich', 'ich', 'ich', 'ich', '1@@', '5', 'Jahren', 'Jahren', 'Jahren', 'Jahren', 'Jahren', 'Jahren', 'Jahren', 'Jahren', 'Jahren', 'Jahren', 'Jahren', 'Jahren', 'Jahren']
2023-05-30 16:25:33,884 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 16:25:33,884 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 16:25:33,884 - INFO - joeynmt.training - 	Hypothesis: Und ich habe die Moment war ich die die Trrrüht, dass die die die Trühhhaft in den Jahren in den Jahren in den Jahren Jahren Jahren Jahren Jahren Jahren Jahren Jahren Jahren Jahren Jahren Jahren Jahren Jahren Jahren Jahren Jahren Jahren verrüht zu erfluss, dass die die die die die die die Fluss von 15 Jahren Jahren gesehen und die ich habe die ich ich ich ich 15 Jahren Jahren Jahren Jahren Jahren Jahren Jahren Jahren Jahren Jahren Jahren Jahren Jahren
2023-05-30 16:25:33,884 - INFO - joeynmt.training - Example #1
2023-05-30 16:25:33,884 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 16:25:33,884 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 16:25:33,884 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'das', 'nicht', 'die', 'Welt', 'der', 'Welt', 'der', 'Welt', 'nicht', 'die', 'die', 'Welt', 'der', 'Welt', 'nicht', 'die', 'die', 'die', 'Welt', 'zu', 'er@@', 'kenn@@', 'en,', 'dass', 'es', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'nicht', 'die', 'die', 'Welt', 'zu', 'be@@', 'komm@@', 'en.', '</s>']
2023-05-30 16:25:33,884 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 16:25:33,884 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 16:25:33,884 - INFO - joeynmt.training - 	Hypothesis: Aber das ist das nicht die Welt der Welt der Welt nicht die die Welt der Welt nicht die die die Welt zu erkennen, dass es nicht nicht nicht nicht nicht nicht nicht nicht nicht nicht die die Welt zu bekommen.
2023-05-30 16:25:33,884 - INFO - joeynmt.training - Example #2
2023-05-30 16:25:33,884 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 16:25:33,884 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 16:25:33,884 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'S@@', 'el@@', 'b@@', 'b@@', 'ie@@', 'b@@', 'b@@', 'b@@', 'b@@', 'ar', 'ist', 'der', 'K@@', 'om@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'hy@@', 's@@', 'ik@@', '.', '</s>']
2023-05-30 16:25:33,884 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 16:25:33,884 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 16:25:33,884 - INFO - joeynmt.training - 	Hypothesis: Die Selbbiebbbbar ist der Kompppppppppppppppppppppppppppphysik.
2023-05-30 16:25:33,884 - INFO - joeynmt.training - Example #3
2023-05-30 16:25:33,884 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 16:25:33,884 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 16:25:33,884 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'K@@', 'om@@', 'om@@', 'ent', 'und', 'in', 'der', 'K@@', 'om@@', 'om@@', 'p@@', 'p@@', 'p@@', 'pen', 'in', 'den', 'K@@', 'ran@@', '.', '</s>']
2023-05-30 16:25:33,885 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 16:25:33,885 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 16:25:33,885 - INFO - joeynmt.training - 	Hypothesis: Es ist in der Komoment und in der Komomppppen in den Kran.
2023-05-30 16:25:33,885 - INFO - joeynmt.training - Example #4
2023-05-30 16:25:33,885 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 16:25:33,885 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 16:25:33,885 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'M@@', 'ein', 'paar', 'Jahren', 'war', 'ich', 'die', 'die', 'T@@', 'ier@@', 'e', 'von', '1@@', '5', 'Jahren', 'Jahren', 'war', 'die', 'F@@', 'lu@@', 'ss', 'der', 'F@@', 'all', 'in', 'der', 'T@@', 'r@@', 'ier@@', 'e', 'von', '1@@', '5', 'Jahren', '</s>']
2023-05-30 16:25:33,885 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 16:25:33,885 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 16:25:33,885 - INFO - joeynmt.training - 	Hypothesis: Die Mein paar Jahren war ich die die Tiere von 15 Jahren Jahren war die Fluss der Fall in der Triere von 15 Jahren
2023-05-30 16:25:49,491 - INFO - joeynmt.training - Epoch   1, Step:     2100, Batch Loss:     2.922838, Batch Acc: 0.188171, Tokens per Sec:     4839, Lr: 0.000300
2023-05-30 16:26:03,413 - INFO - joeynmt.training - Epoch   1, Step:     2200, Batch Loss:     2.812508, Batch Acc: 0.197359, Tokens per Sec:     5368, Lr: 0.000300
2023-05-30 16:26:17,264 - INFO - joeynmt.training - Epoch   1, Step:     2300, Batch Loss:     2.711901, Batch Acc: 0.202150, Tokens per Sec:     5434, Lr: 0.000300
2023-05-30 16:26:30,729 - INFO - joeynmt.training - Epoch   1, Step:     2400, Batch Loss:     2.935797, Batch Acc: 0.204899, Tokens per Sec:     5803, Lr: 0.000300
2023-05-30 16:26:44,555 - INFO - joeynmt.training - Epoch   1, Step:     2500, Batch Loss:     2.898681, Batch Acc: 0.212123, Tokens per Sec:     5444, Lr: 0.000300
2023-05-30 16:26:44,557 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 16:26:44,557 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 16:28:02,766 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.83, ppl:  16.92, acc:   0.20, generation: 78.1993[sec], evaluation: 0.0000[sec]
2023-05-30 16:28:02,767 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 16:28:02,847 - INFO - joeynmt.training - Example #0
2023-05-30 16:28:02,847 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 16:28:02,847 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 16:28:02,847 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'zwei', 'Jahre', 'al@@', 'te', 'ich', 'zwei', 'Jahre', 'ge@@', 'macht', 'und', 'die', 'letzten', 'zwei', 'Jahre', 'al@@', 'te', 'von', 'drei', 'Jahren', 'ge@@', 'macht', 'wur@@', 'de,', 'dass', 'die', 'zwei', 'Jahre', 'al@@', 'ten', 'von', 'drei', 'Jahre', 'al@@', 'ten', 'zu', 'be@@', 'sser', 'zu', 'be@@', 'vor', 'zwei', 'Jahre', 'al@@', 'ten', 'Jahren', 'der', 'M@@', 'u@@', 'ster', 'zu', 'be@@', 'be@@', 'vor', 'zwei', 'Jahre', 'al@@', 'te', 'von', 'drei', 'Jahren', 'zu', 'be@@', 'komm@@', 'en.', '</s>']
2023-05-30 16:28:02,847 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 16:28:02,847 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 16:28:02,848 - INFO - joeynmt.training - 	Hypothesis: Und ich habe zwei Jahre alte ich zwei Jahre gemacht und die letzten zwei Jahre alte von drei Jahren gemacht wurde, dass die zwei Jahre alten von drei Jahre alten zu besser zu bevor zwei Jahre alten Jahren der Muster zu bebevor zwei Jahre alte von drei Jahren zu bekommen.
2023-05-30 16:28:02,848 - INFO - joeynmt.training - Example #1
2023-05-30 16:28:02,848 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 16:28:02,848 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 16:28:02,848 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'nicht', 'der', 'Welt', 'der', 'Welt', 'der', 'Welt', 'der', 'Welt', 'der', 'Welt', 'der', 'Welt', 'zu', 'be@@', 'sser', 'nicht', 'die', 'Welt', 'zu', 'be@@', 'sser', 'zu', 'be@@', 'sser', 'zu', 'be@@', 'sser', 'zu', 'be@@', 'sser', 'zu', 'be@@', 'sser', 'zu', 'tun@@', '.', '</s>']
2023-05-30 16:28:02,848 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 16:28:02,848 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 16:28:02,848 - INFO - joeynmt.training - 	Hypothesis: Aber das ist nicht der Welt der Welt der Welt der Welt der Welt der Welt zu besser nicht die Welt zu besser zu besser zu besser zu besser zu besser zu tun.
2023-05-30 16:28:02,848 - INFO - joeynmt.training - Example #2
2023-05-30 16:28:02,848 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 16:28:02,848 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 16:28:02,848 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'S@@', 'eite', 'der', 'K@@', 'om@@', 'p@@', 'p@@', 'p@@', 'on@@', 'on@@', 'e', 'in', 'der', 'K@@', 'om@@', 'p@@', 'p@@', 'p@@', 'on@@', 'on@@', 'e', 'in', 'der', 'K@@', 'om@@', 'p@@', 'p@@', 'p@@', 'on@@', 'on@@', 'on@@', 's@@', '-@@', 'K@@', 'y@@', 'y@@', 'y@@', 's', 'zu', 'tun@@', '.', '</s>']
2023-05-30 16:28:02,848 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 16:28:02,848 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 16:28:02,848 - INFO - joeynmt.training - 	Hypothesis: Die Seite der Komppponone in der Komppponone in der Kompppononons-Kyyys zu tun.
2023-05-30 16:28:02,848 - INFO - joeynmt.training - Example #3
2023-05-30 16:28:02,848 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 16:28:02,848 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 16:28:02,848 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'K@@', 'l@@', 'ö@@', 'pf@@', 'e', 'und', 'die', 'K@@', 'om@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'lo@@', 's@@', 'en.', '</s>']
2023-05-30 16:28:02,848 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 16:28:02,848 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 16:28:02,848 - INFO - joeynmt.training - 	Hypothesis: Es ist in der Klöpfe und die Komppppplosen.
2023-05-30 16:28:02,849 - INFO - joeynmt.training - Example #4
2023-05-30 16:28:02,849 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 16:28:02,849 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 16:28:02,849 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'erste', 'erste', 'erste', 'erste', 'erste', 'Jahre', 'al@@', 'te', 'ich', 'ein', 'paar', 'paar', 'Jahre', 'al@@', 'er', 'Jahr', 'in', 'der', 'Welt', 'ist', 'das', 'erste', 'erste', 'Jahr', 'in', 'der', 'Welt', 'ist', 'das', 'das', 'erste', 'erste', 'Jahre', 'al@@', 't.', '</s>']
2023-05-30 16:28:02,849 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 16:28:02,849 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 16:28:02,849 - INFO - joeynmt.training - 	Hypothesis: Die erste erste erste erste erste Jahre alte ich ein paar paar Jahre aler Jahr in der Welt ist das erste erste Jahr in der Welt ist das das erste erste Jahre alt.
2023-05-30 16:28:17,275 - INFO - joeynmt.training - Epoch   1, Step:     2600, Batch Loss:     2.646655, Batch Acc: 0.216175, Tokens per Sec:     5205, Lr: 0.000300
2023-05-30 16:28:31,102 - INFO - joeynmt.training - Epoch   1, Step:     2700, Batch Loss:     2.587235, Batch Acc: 0.221350, Tokens per Sec:     5565, Lr: 0.000300
2023-05-30 16:28:46,381 - INFO - joeynmt.training - Epoch   1, Step:     2800, Batch Loss:     2.704190, Batch Acc: 0.222818, Tokens per Sec:     4775, Lr: 0.000300
2023-05-30 16:29:01,934 - INFO - joeynmt.training - Epoch   1, Step:     2900, Batch Loss:     2.793125, Batch Acc: 0.230862, Tokens per Sec:     4792, Lr: 0.000300
2023-05-30 16:29:15,565 - INFO - joeynmt.training - Epoch   1, Step:     3000, Batch Loss:     2.539222, Batch Acc: 0.244690, Tokens per Sec:     5502, Lr: 0.000300
2023-05-30 16:29:15,565 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 16:29:15,565 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 16:30:41,721 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.72, ppl:  15.22, acc:   0.23, generation: 86.1457[sec], evaluation: 0.0000[sec]
2023-05-30 16:30:41,723 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 16:30:41,800 - INFO - joeynmt.helpers - delete models/transformer_model2/500.ckpt
2023-05-30 16:30:41,802 - INFO - joeynmt.training - Example #0
2023-05-30 16:30:41,802 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 16:30:41,802 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 16:30:41,802 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['M@@', 'eine', 'zwei', 'Jahre', 'al@@', 'so,', 'dass', 'ich', 'zwei', 'Jahre', 'von', 'zwei', 'Jahre', 'zu', 'be@@', 'tra@@', 'cht@@', 'en,', 'dass', 'die', 'zwei', 'Jahre', 'von', 'der', 'zwei', 'Jahre', 'von', '2@@', '0@@', ',', 'die', 'drei', 'drei', 'Jahren', 'von', 'drei', 'Jahren', 'zu', 'be@@', 'tra@@', 'cht@@', 'en.', '</s>']
2023-05-30 16:30:41,802 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 16:30:41,802 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 16:30:41,802 - INFO - joeynmt.training - 	Hypothesis: Meine zwei Jahre also, dass ich zwei Jahre von zwei Jahre zu betrachten, dass die zwei Jahre von der zwei Jahre von 20, die drei drei Jahren von drei Jahren zu betrachten.
2023-05-30 16:30:41,802 - INFO - joeynmt.training - Example #1
2023-05-30 16:30:41,802 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 16:30:41,802 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 16:30:41,802 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Er@@', 'de', 'des', 'M@@', 'ut@@', 'ter', 'der', 'Er@@', 'de', 'des', 'M@@', 'ut@@', 'ter', 'nicht', 'der', 'Er@@', 'de', 'des', 'M@@', 'ik@@', 'ik@@', 'um', 'zu', 'be@@', 'sonder@@', 's', 'zu', 'werden.', '</s>']
2023-05-30 16:30:41,803 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 16:30:41,803 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 16:30:41,803 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Erde des Mutter der Erde des Mutter nicht der Erde des Mikikum zu besonders zu werden.
2023-05-30 16:30:41,803 - INFO - joeynmt.training - Example #2
2023-05-30 16:30:41,803 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 16:30:41,803 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 16:30:41,803 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'S@@', 'ti@@', 'm@@', 'me', 'auf', 'der', 'K@@', 'om@@', 'p@@', 'li@@', 'z@@', 'ier@@', 'ten', 'in', 'der', 'K@@', 'ör@@', 'per@@', 'per@@', 'per@@', 'at@@', ',', 'in', 'der', 'K@@', 'om@@', 'p@@', 'hy@@', 's@@', 'ik@@', '.', '</s>']
2023-05-30 16:30:41,803 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 16:30:41,803 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 16:30:41,803 - INFO - joeynmt.training - 	Hypothesis: Die Stimme auf der Komplizierten in der Körperperperat, in der Komphysik.
2023-05-30 16:30:41,803 - INFO - joeynmt.training - Example #3
2023-05-30 16:30:41,803 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 16:30:41,803 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 16:30:41,803 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'K@@', 'ü@@', 'ch@@', 'en@@', 'zen', 'und', 'die', 'B@@', 'ü@@', 'ch@@', 'e', 'in', 'der', 'K@@', 'om@@', 'p@@', 'p@@', 'li@@', 'z@@', 'ier@@', 'te.', '</s>']
2023-05-30 16:30:41,803 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 16:30:41,803 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 16:30:41,803 - INFO - joeynmt.training - 	Hypothesis: Es ist in der Küchenzen und die Büche in der Kompplizierte.
2023-05-30 16:30:41,803 - INFO - joeynmt.training - Example #4
2023-05-30 16:30:41,803 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 16:30:41,803 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 16:30:41,803 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'erste', 'M@@', 'äd@@', 'te', 'ich', 'das', 'ist', 'eine', 'Fra@@', 'ge', 'von', 'der', 'M@@', 'ut@@', 'ter', 'der', 'M@@', 'ut@@', 'ter', 'der', 'M@@', 'ut@@', 'ter', 'ist', 'als', 'als', 'als', 'als', '1@@', '5', 'Jahre', 'al@@', 't.', '</s>']
2023-05-30 16:30:41,804 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 16:30:41,804 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 16:30:41,804 - INFO - joeynmt.training - 	Hypothesis: Die erste Mädte ich das ist eine Frage von der Mutter der Mutter der Mutter ist als als als als 15 Jahre alt.
2023-05-30 16:30:55,909 - INFO - joeynmt.training - Epoch   1, Step:     3100, Batch Loss:     2.854870, Batch Acc: 0.245766, Tokens per Sec:     5403, Lr: 0.000300
2023-05-30 16:31:09,346 - INFO - joeynmt.training - Epoch   1, Step:     3200, Batch Loss:     2.649835, Batch Acc: 0.249894, Tokens per Sec:     5808, Lr: 0.000300
2023-05-30 16:31:23,267 - INFO - joeynmt.training - Epoch   1, Step:     3300, Batch Loss:     2.681944, Batch Acc: 0.255913, Tokens per Sec:     5612, Lr: 0.000300
2023-05-30 16:31:36,732 - INFO - joeynmt.training - Epoch   1, Step:     3400, Batch Loss:     2.590199, Batch Acc: 0.262556, Tokens per Sec:     5717, Lr: 0.000300
2023-05-30 16:31:51,127 - INFO - joeynmt.training - Epoch   1, Step:     3500, Batch Loss:     2.584817, Batch Acc: 0.272224, Tokens per Sec:     5318, Lr: 0.000300
2023-05-30 16:31:51,128 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 16:31:51,128 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 16:33:08,221 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.63, ppl:  13.92, acc:   0.25, generation: 77.0836[sec], evaluation: 0.0000[sec]
2023-05-30 16:33:08,221 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 16:33:08,298 - INFO - joeynmt.helpers - delete models/transformer_model2/1000.ckpt
2023-05-30 16:33:08,298 - INFO - joeynmt.training - Example #0
2023-05-30 16:33:08,298 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 16:33:08,299 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 16:33:08,299 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['M@@', 'it', '1@@', '0@@', '00', 'Jahre', 'al@@', 't', 'ich', 'diese', 'zwei', 'Jahre', 'al@@', 'ten', 'St@@', 'a@@', 'dt', 'zu', 'zei@@', 'gen,', 'dass', 'drei', 'Jahre', 'al@@', 'ten', 'St@@', 'a@@', 'dt', 'der', 'letzten', 'drei', 'Jahren', 'der', 'letzten', 'drei', 'Jahren', 'in', 'der', 'letzten', 'drei', 'Jahren', 'der', 'letzten', '2@@', '0@@', '00', 'Jahre', 'al@@', 'ten', 'St@@', 'a@@', 'dt', 'von', '1@@', '0@@', '-@@', 'K@@', 'ran@@', 'k@@', 'hei@@', 'm@@', 'us', '</s>']
2023-05-30 16:33:08,299 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 16:33:08,299 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 16:33:08,299 - INFO - joeynmt.training - 	Hypothesis: Mit 1000 Jahre alt ich diese zwei Jahre alten Stadt zu zeigen, dass drei Jahre alten Stadt der letzten drei Jahren der letzten drei Jahren in der letzten drei Jahren der letzten 2000 Jahre alten Stadt von 10-Krankheimus
2023-05-30 16:33:08,299 - INFO - joeynmt.training - Example #1
2023-05-30 16:33:08,299 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 16:33:08,299 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 16:33:08,299 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'nicht', 'nur', 'die', 'K@@', 'ör@@', 'per@@', 'ung', 'des', 'Leben@@', 's', 'nicht', 'die', 'Proble@@', 'me', 'nicht', 'die', 'Ver@@', 'fü@@', 'hl', 'der', 'Welt', 'zu', 'be@@', 'komm@@', 'en.', '</s>']
2023-05-30 16:33:08,299 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 16:33:08,299 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 16:33:08,299 - INFO - joeynmt.training - 	Hypothesis: Aber das ist nicht nur die Körperung des Lebens nicht die Probleme nicht die Verfühl der Welt zu bekommen.
2023-05-30 16:33:08,299 - INFO - joeynmt.training - Example #2
2023-05-30 16:33:08,299 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 16:33:08,299 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 16:33:08,299 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'K@@', 'om@@', 'e', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'd@@', 'op@@', 'p@@', 's', 'in', 'der', 'K@@', 'om@@', 'p@@', 'hy@@', 's@@', 'ik', 'in', 'der', 'K@@', 'om@@', 'en@@', 'en@@', 'te', 'des', 'K@@', 'am@@', 's', 'des', 'B@@', 'eh@@', 'l@@', 's', 'des', 'K@@', 'am@@', 's', 'des', 'des', 'B@@', 'eh@@', 'l@@', 's', 'des', 'B@@', 'au@@', 'm@@', 's', 'in', 'der', 'K@@', 'li@@', 'ck', 'auf', 'der', 'K@@', 'am@@', 'p@@', 'p@@', 'el@@', 'b@@', 'st@@', 'st@@', 'ei@@', 'f@@', 'en.', '</s>']
2023-05-30 16:33:08,299 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 16:33:08,299 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 16:33:08,299 - INFO - joeynmt.training - 	Hypothesis: Die Kome auf der Norddopps in der Komphysik in der Komenente des Kams des Behls des Kams des des Behls des Baums in der Klick auf der Kamppelbststeifen.
2023-05-30 16:33:08,299 - INFO - joeynmt.training - Example #3
2023-05-30 16:33:08,300 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 16:33:08,300 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 16:33:08,300 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'B@@', 'eh@@', 'l@@', 'er,', 'und', 'die', 'in', 'der', 'B@@', 'eh@@', 'l@@', '.', '</s>']
2023-05-30 16:33:08,300 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 16:33:08,300 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 16:33:08,300 - INFO - joeynmt.training - 	Hypothesis: Es ist in der Behler, und die in der Behl.
2023-05-30 16:33:08,300 - INFO - joeynmt.training - Example #4
2023-05-30 16:33:08,300 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 16:33:08,300 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 16:33:08,300 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', 'ste', 'Jahr', 'in', 'der', 'letzten', 'Jahr', 'ist', 'ein', 'Jahr', 'ist', 'ein', 'Jahr', 'der', 'letzten', 'Jahr', 'vor', '2@@', '5', 'Jahre', 'al@@', 'ten', 'Jahren', 'in', '2@@', '5', 'Jahre', 'al@@', 't', 'ist.', '</s>']
2023-05-30 16:33:08,300 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 16:33:08,300 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 16:33:08,300 - INFO - joeynmt.training - 	Hypothesis: Die nächste Jahr in der letzten Jahr ist ein Jahr ist ein Jahr der letzten Jahr vor 25 Jahre alten Jahren in 25 Jahre alt ist.
2023-05-30 16:33:22,507 - INFO - joeynmt.training - Epoch   1, Step:     3600, Batch Loss:     2.626543, Batch Acc: 0.276273, Tokens per Sec:     5352, Lr: 0.000300
2023-05-30 16:33:36,367 - INFO - joeynmt.training - Epoch   1, Step:     3700, Batch Loss:     2.509251, Batch Acc: 0.278709, Tokens per Sec:     5505, Lr: 0.000300
2023-05-30 16:33:50,491 - INFO - joeynmt.training - Epoch   1, Step:     3800, Batch Loss:     2.565063, Batch Acc: 0.286228, Tokens per Sec:     5280, Lr: 0.000300
2023-05-30 16:34:05,029 - INFO - joeynmt.training - Epoch   1, Step:     3900, Batch Loss:     2.549743, Batch Acc: 0.289041, Tokens per Sec:     5175, Lr: 0.000300
2023-05-30 16:34:19,931 - INFO - joeynmt.training - Epoch   1, Step:     4000, Batch Loss:     2.643491, Batch Acc: 0.288709, Tokens per Sec:     5065, Lr: 0.000300
2023-05-30 16:34:19,931 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 16:34:19,931 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 16:35:30,028 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.55, ppl:  12.83, acc:   0.28, generation: 70.0876[sec], evaluation: 0.0000[sec]
2023-05-30 16:35:30,029 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 16:35:30,108 - INFO - joeynmt.helpers - delete models/transformer_model2/1500.ckpt
2023-05-30 16:35:30,111 - INFO - joeynmt.training - Example #0
2023-05-30 16:35:30,111 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 16:35:30,111 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 16:35:30,111 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or', 'or', 'Jahren', 'habe', 'ich', 'diese', 'zwei', 'Jahre', 'al@@', 'ten', 'St@@', 'a@@', 'di@@', 'schen', 'zu', 'be@@', 'tra@@', 'cht@@', 'en,', 'dass', 'die', 'die', 'F@@', 'ol@@', 'f@@', 'er', 'in', 'der', 'Jahr', 'Jahr', 'in', 'der', 'Jahr', 'in', 'der', 'Jahr', 'Jahr', 'in', 'der', 'S@@', 'el@@', 'b@@', 'b@@', 'ar', 'in', 'S@@', 'el@@', 'b@@', 'ar', 'zu', 'be@@', 'tra@@', 'cht@@', 'en.', '</s>']
2023-05-30 16:35:30,111 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 16:35:30,111 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 16:35:30,111 - INFO - joeynmt.training - 	Hypothesis: Vor or Jahren habe ich diese zwei Jahre alten Stadischen zu betrachten, dass die die Folfer in der Jahr Jahr in der Jahr in der Jahr Jahr in der Selbbar in Selbar zu betrachten.
2023-05-30 16:35:30,112 - INFO - joeynmt.training - Example #1
2023-05-30 16:35:30,112 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 16:35:30,112 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 16:35:30,112 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'das', 'nicht', 'die', 'L@@', 'ei@@', 'st@@', 'ung', 'von', 'der', 'Proble@@', 'me', 'der', 'Proble@@', 'me', 'nicht', 'die', 'Proble@@', 'me', 'nicht', 'die', 'die', 'Proble@@', 'me', 'zu', 'sehen.', '</s>']
2023-05-30 16:35:30,112 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 16:35:30,112 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 16:35:30,112 - INFO - joeynmt.training - 	Hypothesis: Aber das ist das nicht die Leistung von der Probleme der Probleme nicht die Probleme nicht die die Probleme zu sehen.
2023-05-30 16:35:30,112 - INFO - joeynmt.training - Example #2
2023-05-30 16:35:30,112 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 16:35:30,112 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 16:35:30,112 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'S@@', 'eite', 'der', 'N@@', 'or@@', 'd@@', 'd@@', 'd@@', 'op@@', 'p@@', 'el@@', 'e', 'ist', 'in', 'der', 'S@@', 'ich@@', 'er@@', 'kl@@', 'är@@', 'e', 'in', 'unser@@', 'en', 'S@@', 'ei@@', 'f@@', 'er', 'uns', 'in', 'unser@@', 'em', 'S@@', 'im@@', 'im@@', 'mer@@', '.', '</s>']
2023-05-30 16:35:30,112 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 16:35:30,112 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 16:35:30,112 - INFO - joeynmt.training - 	Hypothesis: Die Seite der Nordddoppele ist in der Sicherkläre in unseren Seifer uns in unserem Simimmer.
2023-05-30 16:35:30,112 - INFO - joeynmt.training - Example #3
2023-05-30 16:35:30,112 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 16:35:30,112 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 16:35:30,112 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'St@@', 'ra@@', 'ß@@', 'e', 'und', 'die', 'S@@', 'im@@', 'im@@', 'mer@@', '.', '</s>']
2023-05-30 16:35:30,112 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 16:35:30,112 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 16:35:30,112 - INFO - joeynmt.training - 	Hypothesis: Es ist in der Straße und die Simimmer.
2023-05-30 16:35:30,113 - INFO - joeynmt.training - Example #4
2023-05-30 16:35:30,113 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 16:35:30,113 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 16:35:30,113 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', 'ste', 'näch@@', 'ste', 'ich', 'Ihnen', 'zei@@', 'gen', 'ist', 'eine', 'B@@', 'r@@', 'r@@', 'ü@@', 'h@@', 'ig@@', 'en@@', 'z', 'der', '2@@', '5', 'Jahre', 'al@@', 't', 'ge@@', 'fü@@', 'hl', 'ist.', '</s>']
2023-05-30 16:35:30,113 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 16:35:30,113 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 16:35:30,113 - INFO - joeynmt.training - 	Hypothesis: Die nächste nächste ich Ihnen zeigen ist eine Brrühigenz der 25 Jahre alt gefühl ist.
2023-05-30 16:35:44,579 - INFO - joeynmt.training - Epoch   1, Step:     4100, Batch Loss:     2.349073, Batch Acc: 0.299686, Tokens per Sec:     5180, Lr: 0.000300
2023-05-30 16:35:52,246 - INFO - joeynmt.training - Epoch   1: total training loss 12678.05
2023-05-30 16:35:52,246 - INFO - joeynmt.training - EPOCH 2
2023-05-30 16:35:57,867 - INFO - joeynmt.training - Epoch   2, Step:     4200, Batch Loss:     2.243199, Batch Acc: 0.314674, Tokens per Sec:     6001, Lr: 0.000300
2023-05-30 16:36:11,141 - INFO - joeynmt.training - Epoch   2, Step:     4300, Batch Loss:     2.378038, Batch Acc: 0.318151, Tokens per Sec:     5797, Lr: 0.000300
2023-05-30 16:36:24,138 - INFO - joeynmt.training - Epoch   2, Step:     4400, Batch Loss:     2.396199, Batch Acc: 0.322180, Tokens per Sec:     5813, Lr: 0.000300
2023-05-30 16:36:36,727 - INFO - joeynmt.training - Epoch   2, Step:     4500, Batch Loss:     2.277671, Batch Acc: 0.324691, Tokens per Sec:     5999, Lr: 0.000300
2023-05-30 16:36:36,727 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 16:36:36,727 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 16:37:51,947 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.47, ppl:  11.82, acc:   0.30, generation: 75.2102[sec], evaluation: 0.0000[sec]
2023-05-30 16:37:51,947 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 16:37:52,027 - INFO - joeynmt.helpers - delete models/transformer_model2/2000.ckpt
2023-05-30 16:37:52,027 - INFO - joeynmt.training - Example #0
2023-05-30 16:37:52,027 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 16:37:52,027 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 16:37:52,027 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'ich', 'habe', 'diese', 'zwei', 'Jahre', 'spä@@', 'ter', 'zwei', 'Jahre', 'al@@', 'ten', 'und', 'die', 'P@@', 'ol@@', 'it@@', 'ik@@', ',', 'die', 'P@@', 'ol@@', 'it@@', 'ik@@', ',', 'die', 'P@@', 'ol@@', 'it@@', 'i@@', ',', 'die', 'F@@', 'el@@', 'el@@', 'b@@', 'st@@', '-@@', 'F@@', 'el@@', 'b@@', 'ru@@', 'ch', 'von', 'S@@', 'el@@', 'b@@', 'st', 'von', 'S@@', 'ü@@', 'f@@', 'el@@', 'n', 'von', '4@@', '0@@', '.', '</s>']
2023-05-30 16:37:52,027 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 16:37:52,027 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 16:37:52,027 - INFO - joeynmt.training - 	Hypothesis: Und ich habe diese zwei Jahre später zwei Jahre alten und die Politik, die Politik, die Politi, die Felelbst-Felbruch von Selbst von Süfeln von 40.
2023-05-30 16:37:52,027 - INFO - joeynmt.training - Example #1
2023-05-30 16:37:52,027 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 16:37:52,028 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 16:37:52,028 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'das', 'Problem', 'der', 'F@@', 'ern@@', 'ern@@', 'st', 'der', 'F@@', 'ern@@', 'ern@@', 'st@@', 'st@@', 'es', 'nicht', 'die', 'W@@', 'ik@@', 'el', 'des', 'L@@', 'ich@@', 'ten', 'zu', 'sehen.', '</s>']
2023-05-30 16:37:52,028 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 16:37:52,028 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 16:37:52,028 - INFO - joeynmt.training - 	Hypothesis: Aber das ist das Problem der Fernernst der Fernernststes nicht die Wikel des Lichten zu sehen.
2023-05-30 16:37:52,028 - INFO - joeynmt.training - Example #2
2023-05-30 16:37:52,028 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 16:37:52,028 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 16:37:52,028 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'S@@', 'eite', 'des', 'N@@', 'or@@', 'd@@', 'n@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'e', 'ist', 'in', 'der', 'S@@', 'ti@@', 'f@@', 'er', 'in', 'der', 'P@@', 'art@@', 'ik@@', 'am@@', 'm@@', 'us', 'in', 'der', 'K@@', 'ra@@', 'm@@', 'y@@', 'ste@@', 'm.', '</s>']
2023-05-30 16:37:52,028 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 16:37:52,028 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 16:37:52,028 - INFO - joeynmt.training - 	Hypothesis: Die Seite des Nordnordpole ist in der Stifer in der Partikammus in der Kramystem.
2023-05-30 16:37:52,028 - INFO - joeynmt.training - Example #3
2023-05-30 16:37:52,028 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 16:37:52,028 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 16:37:52,028 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'aus', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'om@@', 'p@@', 'li@@', 'z@@', 'ier@@', 'te.', '</s>']
2023-05-30 16:37:52,028 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 16:37:52,028 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 16:37:52,028 - INFO - joeynmt.training - 	Hypothesis: Es ist aus der Winter und Komplizierte.
2023-05-30 16:37:52,028 - INFO - joeynmt.training - Example #4
2023-05-30 16:37:52,028 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 16:37:52,029 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 16:37:52,029 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', 'ste', 'näch@@', 'ste', 'Jahre', 'ist', 'ein', 'wen@@', 'ig', 'be@@', 'tra@@', 'cht@@', 'et,', 'dass', 'die', 'F@@', 'el@@', 'b@@', 'st@@', 'ör@@', 't', 'von', '2@@', '5', 'Jahre', 'ist', 'in', '2@@', '5', 'Jahren', 'ist', 'in', 'der', 'F@@', 'el@@', 't.', '</s>']
2023-05-30 16:37:52,029 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 16:37:52,029 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 16:37:52,029 - INFO - joeynmt.training - 	Hypothesis: Die nächste nächste Jahre ist ein wenig betrachtet, dass die Felbstört von 25 Jahre ist in 25 Jahren ist in der Felt.
2023-05-30 16:38:04,684 - INFO - joeynmt.training - Epoch   2, Step:     4600, Batch Loss:     2.348676, Batch Acc: 0.334026, Tokens per Sec:     6050, Lr: 0.000300
2023-05-30 16:38:18,965 - INFO - joeynmt.training - Epoch   2, Step:     4700, Batch Loss:     2.452814, Batch Acc: 0.338829, Tokens per Sec:     5364, Lr: 0.000300
2023-05-30 16:38:33,312 - INFO - joeynmt.training - Epoch   2, Step:     4800, Batch Loss:     2.578137, Batch Acc: 0.336431, Tokens per Sec:     5228, Lr: 0.000300
2023-05-30 16:38:47,880 - INFO - joeynmt.training - Epoch   2, Step:     4900, Batch Loss:     2.268581, Batch Acc: 0.347468, Tokens per Sec:     5294, Lr: 0.000300
2023-05-30 16:39:02,617 - INFO - joeynmt.training - Epoch   2, Step:     5000, Batch Loss:     2.355649, Batch Acc: 0.346333, Tokens per Sec:     5101, Lr: 0.000300
2023-05-30 16:39:02,618 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 16:39:02,618 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 16:40:26,185 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.40, ppl:  10.99, acc:   0.32, generation: 83.5582[sec], evaluation: 0.0000[sec]
2023-05-30 16:40:26,186 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 16:40:26,266 - INFO - joeynmt.helpers - delete models/transformer_model2/2500.ckpt
2023-05-30 16:40:26,267 - INFO - joeynmt.training - Example #0
2023-05-30 16:40:26,267 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 16:40:26,267 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 16:40:26,267 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or', 'or', 'or', 'der', 'T@@', 'at@@', 's@@', 'ach@@', 'e', 'ich', 'diese', 'zwei', 'Jahre', 'al@@', 't', 'zu', 't@@', 'onen', 'der', 'P@@', 'ol@@', 'it@@', 'ik@@', 'er', 'der', 'P@@', 'ol@@', 'it@@', 'ik@@', 'er', 'hat', 'drei', 'Millionen', 'von', 'drei', 'Millionen', 'Jahre', 'al@@', 'ten', 'der', 'S@@', 'el@@', 'b@@', 'a@@', 'g', 'von', 'der', 'S@@', 'eite', 'der', 'S@@', 'eite', 'der', 'S@@', 'a@@', 'v@@', ',', 'mit', '4@@', '0@@', '-@@', 'S@@', 'ü@@', 'f@@', 'te', 'ge@@', 'macht', 'wur@@', 'de.', '</s>']
2023-05-30 16:40:26,267 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 16:40:26,267 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 16:40:26,267 - INFO - joeynmt.training - 	Hypothesis: Vor or or der Tatsache ich diese zwei Jahre alt zu tonen der Politiker der Politiker hat drei Millionen von drei Millionen Jahre alten der Selbag von der Seite der Seite der Sav, mit 40-Süfte gemacht wurde.
2023-05-30 16:40:26,267 - INFO - joeynmt.training - Example #1
2023-05-30 16:40:26,267 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 16:40:26,267 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 16:40:26,267 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Er@@', 'kl@@', 'är@@', 'ung', 'der', 'Er@@', 'de', 'des', 'Univer@@', 's@@', 'um', 'das', 'ist', 'nicht', 'die', 'Er@@', 'de', 'des', 'E@@', 'ig@@', 'ig@@', 'enschaf@@', 'ten', 'der', 'Er@@', 'de', 'des', 'L@@', 'ei@@', 'st@@', 'ens', 'zei@@', 'gen.', '</s>']
2023-05-30 16:40:26,267 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 16:40:26,267 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 16:40:26,267 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Erklärung der Erde des Universum das ist nicht die Erde des Eigigenschaften der Erde des Leistens zeigen.
2023-05-30 16:40:26,268 - INFO - joeynmt.training - Example #2
2023-05-30 16:40:26,268 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 16:40:26,268 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 16:40:26,268 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'S@@', 'eite', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'l', 'ist', 'in', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'l', 'in', 'der', 'K@@', 'l@@', 'im@@', 'mer@@', '.', '</s>']
2023-05-30 16:40:26,268 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 16:40:26,268 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 16:40:26,268 - INFO - joeynmt.training - 	Hypothesis: Die Seite der Nordpoll ist in der Nordpoll in der Klimmer.
2023-05-30 16:40:26,268 - INFO - joeynmt.training - Example #3
2023-05-30 16:40:26,268 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 16:40:26,268 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 16:40:26,268 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'l@@', 'im@@', 'mer@@', '.', '</s>']
2023-05-30 16:40:26,268 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 16:40:26,268 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 16:40:26,268 - INFO - joeynmt.training - 	Hypothesis: Es ist in der Winter und Klimmer.
2023-05-30 16:40:26,268 - INFO - joeynmt.training - Example #4
2023-05-30 16:40:26,268 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 16:40:26,268 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 16:40:26,268 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', 'ste', 'ste', 'ich', 'Ihnen', 'die', 'näch@@', 'ste', 'Jahre', 'al@@', 't', 'ist,', 'was', 'die', 'ich', 'ge@@', 'sam@@', 'te', '2@@', '5', 'Jahre', 'ist', 'der', '2@@', '5', 'Jahre', 'ist', 'pass@@', 'iert', 'wur@@', 'de.', '</s>']
2023-05-30 16:40:26,268 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 16:40:26,268 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 16:40:26,268 - INFO - joeynmt.training - 	Hypothesis: Die nächste ste ich Ihnen die nächste Jahre alt ist, was die ich gesamte 25 Jahre ist der 25 Jahre ist passiert wurde.
2023-05-30 16:40:40,408 - INFO - joeynmt.training - Epoch   2, Step:     5100, Batch Loss:     2.242326, Batch Acc: 0.351398, Tokens per Sec:     5330, Lr: 0.000300
2023-05-30 16:40:54,955 - INFO - joeynmt.training - Epoch   2, Step:     5200, Batch Loss:     2.386212, Batch Acc: 0.358136, Tokens per Sec:     5190, Lr: 0.000300
2023-05-30 16:41:09,669 - INFO - joeynmt.training - Epoch   2, Step:     5300, Batch Loss:     2.273550, Batch Acc: 0.359780, Tokens per Sec:     5010, Lr: 0.000300
2023-05-30 16:41:24,895 - INFO - joeynmt.training - Epoch   2, Step:     5400, Batch Loss:     2.247195, Batch Acc: 0.360782, Tokens per Sec:     4968, Lr: 0.000300
2023-05-30 16:41:38,734 - INFO - joeynmt.training - Epoch   2, Step:     5500, Batch Loss:     2.107511, Batch Acc: 0.363134, Tokens per Sec:     5508, Lr: 0.000300
2023-05-30 16:41:38,734 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 16:41:38,734 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 16:42:55,341 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.35, ppl:  10.48, acc:   0.34, generation: 76.5982[sec], evaluation: 0.0000[sec]
2023-05-30 16:42:55,342 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 16:42:55,419 - INFO - joeynmt.helpers - delete models/transformer_model2/3000.ckpt
2023-05-30 16:42:55,419 - INFO - joeynmt.training - Example #0
2023-05-30 16:42:55,419 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 16:42:55,419 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 16:42:55,419 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'diese', 'zwei', 'Jahre', 'al@@', 't', 'ge@@', 'zei@@', 'gt', 'haben,', 'um', 'zu', 't@@', 'onen', 'zu', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'it@@', 'ik@@', 'er', 'ge@@', 'gen@@', 's@@', 'ei@@', 'ts', 'drei', 'Millionen', 'Jahren', 'vor', 'drei', 'Millionen', 'Jahre', 'al@@', 'ten', 'von', 'U@@', 'S@@', ',', 'die', 'die', 'S@@', 'and', 'der', 'S@@', 'A', 'ge@@', 'k@@', 'ü@@', 'm@@', 'pf@@', 'te', 'von', '4@@', '0@@', '%', '</s>']
2023-05-30 16:42:55,419 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 16:42:55,419 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 16:42:55,419 - INFO - joeynmt.training - 	Hypothesis: Ich habe diese zwei Jahre alt gezeigt haben, um zu tonen zu zeigen, dass die Politiker gegenseits drei Millionen Jahren vor drei Millionen Jahre alten von US, die die Sand der SA gekümpfte von 40%
2023-05-30 16:42:55,419 - INFO - joeynmt.training - Example #1
2023-05-30 16:42:55,419 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 16:42:55,419 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 16:42:55,419 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'M@@', 'al', 'der', 'K@@', 'om@@', 'p@@', 'ie@@', 'ß', 'dieses', 'spe@@', 'zi@@', 'al@@', 'es', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'T@@', 'ik@@', 'el', 'des', 'M@@', 'al', 'zu', 'sehen.', '</s>']
2023-05-30 16:42:55,420 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 16:42:55,420 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 16:42:55,420 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Mal der Kompieß dieses speziales Problem ist, weil es nicht die Tikel des Mal zu sehen.
2023-05-30 16:42:55,420 - INFO - joeynmt.training - Example #2
2023-05-30 16:42:55,420 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 16:42:55,420 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 16:42:55,420 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'Re@@', 's@@', 'ult@@', 'at', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'e', 'in', 'der', 'K@@', 'l@@', 'im@@', 'mer@@', 'k@@', 's@@', 'einen', 'K@@', 'l@@', 'im@@', 'mer@@', 'k@@', 's@@', 'er', 'zu', 'unser@@', 'em', 'K@@', 'l@@', 'im@@', 'im@@', 'mer@@', '.', '</s>']
2023-05-30 16:42:55,420 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 16:42:55,420 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 16:42:55,420 - INFO - joeynmt.training - 	Hypothesis: Der Resultat auf der Nordpole in der Klimmerkseinen Klimmerkser zu unserem Klimimmer.
2023-05-30 16:42:55,420 - INFO - joeynmt.training - Example #3
2023-05-30 16:42:55,420 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 16:42:55,420 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 16:42:55,420 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'aus', 'dem', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'l@@', 'im@@', 'en', 'und', 'K@@', 'l@@', 'im@@', 'im@@', 'm', 'und', 'K@@', 'l@@', 'im@@', 'im@@', 'mer@@', '.', '</s>']
2023-05-30 16:42:55,420 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 16:42:55,420 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 16:42:55,420 - INFO - joeynmt.training - 	Hypothesis: Es ist aus dem Winter und Klimen und Klimimm und Klimimmer.
2023-05-30 16:42:55,420 - INFO - joeynmt.training - Example #4
2023-05-30 16:42:55,420 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 16:42:55,420 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 16:42:55,420 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', 'ste', 'näch@@', 'ste', 'M@@', 'it', 'ist', 'ein', 'ver@@', 's@@', 'icht', 'und', 'das', 'ist', 'ein', 'ver@@', 'schn@@', 'ell@@', 'er', 'und', 'was', 'die', 'Re@@', 'gel@@', 'n', '2@@', '5', 'Jahren', 'ist', 'pass@@', 'iert.', '</s>']
2023-05-30 16:42:55,421 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 16:42:55,421 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 16:42:55,421 - INFO - joeynmt.training - 	Hypothesis: Die nächste nächste Mit ist ein versicht und das ist ein verschneller und was die Regeln 25 Jahren ist passiert.
2023-05-30 16:43:09,118 - INFO - joeynmt.training - Epoch   2, Step:     5600, Batch Loss:     2.359777, Batch Acc: 0.373103, Tokens per Sec:     5544, Lr: 0.000300
2023-05-30 16:43:23,245 - INFO - joeynmt.training - Epoch   2, Step:     5700, Batch Loss:     2.115847, Batch Acc: 0.374172, Tokens per Sec:     5342, Lr: 0.000300
2023-05-30 16:43:37,741 - INFO - joeynmt.training - Epoch   2, Step:     5800, Batch Loss:     2.144441, Batch Acc: 0.377011, Tokens per Sec:     5309, Lr: 0.000300
2023-05-30 16:43:51,733 - INFO - joeynmt.training - Epoch   2, Step:     5900, Batch Loss:     2.297953, Batch Acc: 0.378171, Tokens per Sec:     5431, Lr: 0.000300
2023-05-30 16:44:05,801 - INFO - joeynmt.training - Epoch   2, Step:     6000, Batch Loss:     1.925698, Batch Acc: 0.380440, Tokens per Sec:     5376, Lr: 0.000300
2023-05-30 16:44:05,801 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 16:44:05,801 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 16:45:22,700 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.29, ppl:   9.84, acc:   0.35, generation: 76.8903[sec], evaluation: 0.0000[sec]
2023-05-30 16:45:22,701 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 16:45:22,777 - INFO - joeynmt.helpers - delete models/transformer_model2/3500.ckpt
2023-05-30 16:45:22,777 - INFO - joeynmt.training - Example #0
2023-05-30 16:45:22,777 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 16:45:22,777 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 16:45:22,777 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'diese', 'zwei', 'T@@', 'age', 'age', 'age', 'age', 'diese', 'zwei', 'T@@', 'ag@@', ',', 'um', 'zu', 't@@', 'onen', 'zu', 't@@', 'un,', 'die', 'P@@', 'ol@@', 'ik@@', 'an@@', 'z@@', ',', 'die', 'die', 'P@@', 'ol@@', 'ik@@', 'el', 'von', 'F@@', 'a@@', 'hr@@', 'zeu@@', 'g', 'von', 'V@@', ',', 'mit', '4@@', '0@@', '%', 'der', 'V@@', ',', 'mit', '4@@', '0@@', '%', 'der', 'V@@', 'ol@@', 'ge@@', 'k@@', 'z@@', 'ä@@', 'hl@@', 't', 'war.', '</s>']
2023-05-30 16:45:22,778 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 16:45:22,778 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 16:45:22,778 - INFO - joeynmt.training - 	Hypothesis: Ich habe diese zwei Tage age age age diese zwei Tag, um zu tonen zu tun, die Polikanz, die die Polikel von Fahrzeug von V, mit 40% der V, mit 40% der Volgekzählt war.
2023-05-30 16:45:22,778 - INFO - joeynmt.training - Example #1
2023-05-30 16:45:22,778 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 16:45:22,778 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 16:45:22,778 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'ein', 'bis@@', 'schen', 'der', 'Er@@', 'geb@@', 'n@@', 'is@@', 'se', 'der', 'Ar@@', 'bei@@', 'ts@@', '-@@', 'Problem', 'weil', 'es', 'nicht', 'die', 'T@@', 'ik@@', 'el', 'des', 'E@@', 'is@@', 'e', 'des', 'E@@', 'is@@', 'e', 'der', 'E@@', 'is@@', 'e', 'sehen.', '</s>']
2023-05-30 16:45:22,778 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 16:45:22,778 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 16:45:22,778 - INFO - joeynmt.training - 	Hypothesis: Aber das ist ein bisschen der Ergebnisse der Arbeits-Problem weil es nicht die Tikel des Eise des Eise der Eise sehen.
2023-05-30 16:45:22,778 - INFO - joeynmt.training - Example #2
2023-05-30 16:45:22,778 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 16:45:22,778 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 16:45:22,778 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'k@@', 'al@@', 'ität', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'e', 'in', 'der', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 'n', 'von', 'uns', 'uns', 'in', 'der', 'G@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', '.', '</s>']
2023-05-30 16:45:22,778 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 16:45:22,778 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 16:45:22,778 - INFO - joeynmt.training - 	Hypothesis: Die Eiskalität auf der Nordpole in der Klimawandeln von uns uns in der Globalen Klimawandel.
2023-05-30 16:45:22,778 - INFO - joeynmt.training - Example #3
2023-05-30 16:45:22,778 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 16:45:22,778 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 16:45:22,779 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'gibt', 'es', 'aus', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'ä@@', 'f@@', 't.', '</s>']
2023-05-30 16:45:22,779 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 16:45:22,779 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 16:45:22,779 - INFO - joeynmt.training - 	Hypothesis: Es gibt es aus der Winter und Kräft.
2023-05-30 16:45:22,779 - INFO - joeynmt.training - Example #4
2023-05-30 16:45:22,779 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 16:45:22,779 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 16:45:22,779 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', 'ste', 'T@@', 'ag@@', ',', 'die', 'ich', 'zei@@', 'ge', 'der', 'Ver@@', 'schn@@', 'ell@@', 'er', 'der', 'Ver@@', 'schn@@', 'ell@@', 'er', 'der', 'F@@', 'a@@', 'hr@@', 'zeu@@', 'ge', 'des', 'Jahr', '2@@', '5', 'Jahre', 'pass@@', 'iert.', '</s>']
2023-05-30 16:45:22,779 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 16:45:22,779 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 16:45:22,779 - INFO - joeynmt.training - 	Hypothesis: Die nächste Tag, die ich zeige der Verschneller der Verschneller der Fahrzeuge des Jahr 25 Jahre passiert.
2023-05-30 16:45:36,468 - INFO - joeynmt.training - Epoch   2, Step:     6100, Batch Loss:     2.238838, Batch Acc: 0.385150, Tokens per Sec:     5659, Lr: 0.000300
2023-05-30 16:45:50,348 - INFO - joeynmt.training - Epoch   2, Step:     6200, Batch Loss:     2.168785, Batch Acc: 0.385789, Tokens per Sec:     5547, Lr: 0.000300
2023-05-30 16:46:04,188 - INFO - joeynmt.training - Epoch   2, Step:     6300, Batch Loss:     1.985222, Batch Acc: 0.390503, Tokens per Sec:     5502, Lr: 0.000300
2023-05-30 16:46:18,331 - INFO - joeynmt.training - Epoch   2, Step:     6400, Batch Loss:     2.207566, Batch Acc: 0.396688, Tokens per Sec:     5261, Lr: 0.000300
2023-05-30 16:46:32,317 - INFO - joeynmt.training - Epoch   2, Step:     6500, Batch Loss:     2.209450, Batch Acc: 0.393594, Tokens per Sec:     5426, Lr: 0.000300
2023-05-30 16:46:32,317 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 16:46:32,317 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 16:47:42,557 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.24, ppl:   9.40, acc:   0.36, generation: 70.2312[sec], evaluation: 0.0000[sec]
2023-05-30 16:47:42,558 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 16:47:42,636 - INFO - joeynmt.helpers - delete models/transformer_model2/4000.ckpt
2023-05-30 16:47:42,637 - INFO - joeynmt.training - Example #0
2023-05-30 16:47:42,637 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 16:47:42,637 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 16:47:42,637 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'diese', 'zwei', 'T@@', 'age', 'age', 'age', 'age', 'ich', 'diese', 'zwei', 'T@@', 'onen', 'von', 'T@@', 'onen', 'von', 'T@@', 'onen', 'von', 'den', 'P@@', 'ol@@', 'i@@', 'sk@@', 'ap@@', ',', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'zu', 'be@@', 'tr@@', 'ie@@', 'b', 'von', 'den', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te.', '</s>']
2023-05-30 16:47:42,637 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 16:47:42,637 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 16:47:42,637 - INFO - joeynmt.training - 	Hypothesis: Ich habe diese zwei Tage age age age ich diese zwei Tonen von Tonen von Tonen von den Poliskap, die letzten drei Millionen Jahre alt zu betrieb von den letzten drei Millionen Jahre alt hatte.
2023-05-30 16:47:42,637 - INFO - joeynmt.training - Example #1
2023-05-30 16:47:42,637 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 16:47:42,637 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 16:47:42,637 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Er@@', 'fol@@', 'g', 'der', 'L@@', 'ei@@', 'st@@', 'ung', 'der', 'P@@', 'f@@', 'ik@@', 'er', 'ist', 'nicht', 'die', 'T@@', 'ik@@', 'er@@', 'ie', 'der', 'T@@', 'ik@@', 'er@@', 'at@@', 's@@', 'ie.', '</s>']
2023-05-30 16:47:42,637 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 16:47:42,637 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 16:47:42,637 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Erfolg der Leistung der Pfiker ist nicht die Tikerie der Tikeratsie.
2023-05-30 16:47:42,637 - INFO - joeynmt.training - Example #2
2023-05-30 16:47:42,637 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 16:47:42,637 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 16:47:42,638 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'l', 'ist', 'in', 'der', 'N@@', 'or@@', 'd@@', 'l@@', 'ung', 'in', 'der', 'K@@', 'l@@', 'im@@', 'mer@@', ',', 'der', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', '.', '</s>']
2023-05-30 16:47:42,638 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 16:47:42,638 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 16:47:42,638 - INFO - joeynmt.training - 	Hypothesis: Die Eis auf der Nordpoll ist in der Nordlung in der Klimmer, der Klimawandel.
2023-05-30 16:47:42,638 - INFO - joeynmt.training - Example #3
2023-05-30 16:47:42,638 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 16:47:42,638 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 16:47:42,638 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'p@@', 'li@@', 'z@@', 'ier@@', 'en@@', 'd.', '</s>']
2023-05-30 16:47:42,638 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 16:47:42,638 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 16:47:42,638 - INFO - joeynmt.training - 	Hypothesis: Es ist in der Winter und Krimplizierend.
2023-05-30 16:47:42,638 - INFO - joeynmt.training - Example #4
2023-05-30 16:47:42,638 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 16:47:42,638 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 16:47:42,638 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', 'ste', 'T@@', 'ag@@', ',', 'die', 'ich', 'zei@@', 'ge', 'von', 'der', 'näch@@', 'sten', 'St@@', 'ra@@', 'ß@@', 'e', 'der', 'letzten', '2@@', '5', 'Jahre', 'pass@@', 'iert.', '</s>']
2023-05-30 16:47:42,638 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 16:47:42,638 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 16:47:42,638 - INFO - joeynmt.training - 	Hypothesis: Die nächste Tag, die ich zeige von der nächsten Straße der letzten 25 Jahre passiert.
2023-05-30 16:47:56,449 - INFO - joeynmt.training - Epoch   2, Step:     6600, Batch Loss:     2.125076, Batch Acc: 0.401040, Tokens per Sec:     5540, Lr: 0.000300
2023-05-30 16:48:11,452 - INFO - joeynmt.training - Epoch   2, Step:     6700, Batch Loss:     2.148603, Batch Acc: 0.395024, Tokens per Sec:     5037, Lr: 0.000300
2023-05-30 16:48:24,696 - INFO - joeynmt.training - Epoch   2, Step:     6800, Batch Loss:     2.109884, Batch Acc: 0.394244, Tokens per Sec:     5716, Lr: 0.000300
2023-05-30 16:48:38,575 - INFO - joeynmt.training - Epoch   2, Step:     6900, Batch Loss:     2.031787, Batch Acc: 0.400038, Tokens per Sec:     5379, Lr: 0.000300
2023-05-30 16:48:52,584 - INFO - joeynmt.training - Epoch   2, Step:     7000, Batch Loss:     2.164955, Batch Acc: 0.400888, Tokens per Sec:     5305, Lr: 0.000300
2023-05-30 16:48:52,584 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 16:48:52,584 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 16:50:02,872 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.22, ppl:   9.17, acc:   0.37, generation: 70.2803[sec], evaluation: 0.0000[sec]
2023-05-30 16:50:02,874 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 16:50:02,952 - INFO - joeynmt.helpers - delete models/transformer_model2/4500.ckpt
2023-05-30 16:50:02,952 - INFO - joeynmt.training - Example #0
2023-05-30 16:50:02,953 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 16:50:02,953 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 16:50:02,953 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'diese', 'zwei', 'Di@@', 'a@@', 'st', 'auf', 'zwei', 'Di@@', 'a@@', 'st', 'sehen', 'um', 'zu', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'it@@', 'i@@', 'i@@', ',', 'die', 'P@@', 'ol@@', 'it@@', 'i@@', '-@@', 'S@@', 'in@@', 'n', 'von', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'zu', 'er@@', 'kenn@@', 'en,', 'um', '4@@', '0@@', '%', 'der', 'S@@', ',', 'mit', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', '</s>']
2023-05-30 16:50:02,953 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 16:50:02,953 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 16:50:02,953 - INFO - joeynmt.training - 	Hypothesis: Ich habe diese zwei Diast auf zwei Diast sehen um zu zeigen, dass die Politii, die Politi-Sinn von drei Millionen Jahre alt zu erkennen, um 40% der S, mit 40% gekrompen
2023-05-30 16:50:02,953 - INFO - joeynmt.training - Example #1
2023-05-30 16:50:02,953 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 16:50:02,953 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 16:50:02,953 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'L@@', 'ehr@@', 'e', 'des', 'L@@', 'ehr@@', 'er', 'des', 'E@@', 'ben@@', 'fall@@', 's', 'das', 'nicht', 'die', 'D@@', 'ik@@', 'er', 'zu', 'der', 'D@@', 'ik@@', 'er', 'zei@@', 'gen.', '</s>']
2023-05-30 16:50:02,953 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 16:50:02,953 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 16:50:02,953 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Lehre des Lehrer des Ebenfalls das nicht die Diker zu der Diker zeigen.
2023-05-30 16:50:02,953 - INFO - joeynmt.training - Example #2
2023-05-30 16:50:02,953 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 16:50:02,953 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 16:50:02,953 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'e', 'S@@', 'er@@', 'k@@', 'a@@', 'hr@@', 'er', 'S@@', 'in@@', 'n', 'des', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 's', 'uns', 'G@@', 'lob@@', 'al', 'kl@@', 'im@@', 'mer@@', '.', '</s>']
2023-05-30 16:50:02,953 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 16:50:02,953 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 16:50:02,953 - INFO - joeynmt.training - 	Hypothesis: Die Eis auf der Nordpole Serkahrer Sinn des Klimawandels uns Global klimmer.
2023-05-30 16:50:02,953 - INFO - joeynmt.training - Example #3
2023-05-30 16:50:02,954 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 16:50:02,954 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 16:50:02,954 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'aus', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'ä@@', 'f@@', 'te', 'in', 'der', 'S@@', 'om@@', 'mer@@', '.', '</s>']
2023-05-30 16:50:02,954 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 16:50:02,954 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 16:50:02,954 - INFO - joeynmt.training - 	Hypothesis: Es ist aus der Winter und Kräfte in der Sommer.
2023-05-30 16:50:02,954 - INFO - joeynmt.training - Example #4
2023-05-30 16:50:02,954 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 16:50:02,954 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 16:50:02,954 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', 'ste', 'Di@@', 'a', 'der', 'ich', 'zei@@', 'ge', 'von', 'der', 'Ver@@', 'schn@@', 'ell@@', 'ten', 'Ver@@', 'si@@', 'on', 'von', 'der', 'Ver@@', 'si@@', 'on', 'von', '2@@', '5', 'Jahren', 'ist', 'pass@@', 'iert.', '</s>']
2023-05-30 16:50:02,954 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 16:50:02,954 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 16:50:02,954 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia der ich zeige von der Verschnellten Version von der Version von 25 Jahren ist passiert.
2023-05-30 16:50:17,237 - INFO - joeynmt.training - Epoch   2, Step:     7100, Batch Loss:     2.080206, Batch Acc: 0.400716, Tokens per Sec:     5176, Lr: 0.000300
2023-05-30 16:50:31,553 - INFO - joeynmt.training - Epoch   2, Step:     7200, Batch Loss:     2.041030, Batch Acc: 0.403419, Tokens per Sec:     5160, Lr: 0.000300
2023-05-30 16:50:45,032 - INFO - joeynmt.training - Epoch   2, Step:     7300, Batch Loss:     2.026825, Batch Acc: 0.410233, Tokens per Sec:     5490, Lr: 0.000300
2023-05-30 16:50:58,643 - INFO - joeynmt.training - Epoch   2, Step:     7400, Batch Loss:     2.005537, Batch Acc: 0.410660, Tokens per Sec:     5577, Lr: 0.000300
2023-05-30 16:51:11,681 - INFO - joeynmt.training - Epoch   2, Step:     7500, Batch Loss:     2.034124, Batch Acc: 0.409067, Tokens per Sec:     5933, Lr: 0.000300
2023-05-30 16:51:11,681 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 16:51:11,681 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 16:52:17,900 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.18, ppl:   8.84, acc:   0.38, generation: 66.2100[sec], evaluation: 0.0000[sec]
2023-05-30 16:52:17,901 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 16:52:17,977 - INFO - joeynmt.helpers - delete models/transformer_model2/5000.ckpt
2023-05-30 16:52:17,977 - INFO - joeynmt.training - Example #0
2023-05-30 16:52:17,978 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 16:52:17,978 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 16:52:17,978 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'diese', 'zwei', 'Di@@', 'a@@', 's,', 'die', 'zwei', 'Di@@', 'a@@', 's', 'sehen,', 'um', 'die', 'P@@', 'ol@@', 'it@@', 'ä@@', 'ts@@', 'sk@@', 'ap@@', ',', 'die', 'die', 'P@@', 'ol@@', 'it@@', 'ik@@', 'er', 'in', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'zu', 'einer', 'der', 'Gr@@', 'ö@@', 'ß@@', 'e', 'des', 'V@@', 'ol@@', 'an@@', 'ge@@', 'k@@', 'ehr@@', 't', 'hat@@', 'te,', 'mit', '4@@', '0@@', '%', 'Prozent', 'des', 'V@@', 'ol@@', 'l', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pf@@', 'el@@', 'n', 'war.', '</s>']
2023-05-30 16:52:17,978 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 16:52:17,978 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 16:52:17,978 - INFO - joeynmt.training - 	Hypothesis: Ich habe diese zwei Dias, die zwei Dias sehen, um die Politätsskap, die die Politiker in drei Millionen Jahre alt zu einer der Größe des Volangekehrt hatte, mit 40% Prozent des Voll gekrompfeln war.
2023-05-30 16:52:17,978 - INFO - joeynmt.training - Example #1
2023-05-30 16:52:17,978 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 16:52:17,978 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 16:52:17,978 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'Bil@@', 'd@@', 'sch@@', 'ir@@', 'ma@@', ',', 'dass', 'es', 'nicht', 'die', 'An@@', 'za@@', 'hl', 'der', 'Sp@@', 'e@@', 'zi@@', 'al@@', 'es', 'Problem', 'der', 'T@@', 'ik@@', 'er', 'der', 'E@@', 'is@@', 'e', 'der', 'E@@', 'is@@', 'e', 'der', 'E@@', 'is@@', 'e', 'zei@@', 'gen.', '</s>']
2023-05-30 16:52:17,978 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 16:52:17,978 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 16:52:17,978 - INFO - joeynmt.training - 	Hypothesis: Aber das Bildschirma, dass es nicht die Anzahl der Speziales Problem der Tiker der Eise der Eise der Eise zeigen.
2023-05-30 16:52:17,978 - INFO - joeynmt.training - Example #2
2023-05-30 16:52:17,978 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 16:52:17,978 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 16:52:17,978 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sk@@', 'it@@', 'it@@', 'ä@@', 'ts@@', '-@@', 'S@@', 'ol@@', 'ar@@', 'p@@', 'l', 'ist', 'in', 'der', 'K@@', 'la@@', 'ss@@', 'en@@', 'der', 'uns', 'in', 'den', 'K@@', 'l@@', 'im@@', 'a@@', '-@@', 'St@@', 'ra@@', 'ß@@', 'en@@', '-@@', 'St@@', 'ru@@', 'kt@@', 'ur@@', 'y@@', 'ste@@', 'm.', '</s>']
2023-05-30 16:52:17,979 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 16:52:17,979 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 16:52:17,979 - INFO - joeynmt.training - 	Hypothesis: Die Eisskititäts-Solarpl ist in der Klassender uns in den Klima-Straßen-Strukturystem.
2023-05-30 16:52:17,979 - INFO - joeynmt.training - Example #3
2023-05-30 16:52:17,979 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 16:52:17,979 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 16:52:17,979 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'sch@@', 'ließ@@', 't', 'aus', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'p@@', 'li@@', 'z@@', 'ier@@', 'en@@', 'd.', '</s>']
2023-05-30 16:52:17,979 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 16:52:17,979 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 16:52:17,979 - INFO - joeynmt.training - 	Hypothesis: Es schließt aus der Winter und Krimplizierend.
2023-05-30 16:52:17,979 - INFO - joeynmt.training - Example #4
2023-05-30 16:52:17,979 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 16:52:17,979 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 16:52:17,979 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', 'ste', 'Di@@', 'a', 'die', 'näch@@', 'ste', 'Di@@', 'a', 'ist', 'eine', 'Ver@@', 'schn@@', 'ell@@', 'ung', 'der', 'Ver@@', 'br@@', 'eit@@', 'ung', 'der', 'letzten', '2@@', '5', 'Jahre', 'pass@@', 'iert.', '</s>']
2023-05-30 16:52:17,979 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 16:52:17,979 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 16:52:17,979 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia die nächste Dia ist eine Verschnellung der Verbreitung der letzten 25 Jahre passiert.
2023-05-30 16:52:31,578 - INFO - joeynmt.training - Epoch   2, Step:     7600, Batch Loss:     2.101719, Batch Acc: 0.410066, Tokens per Sec:     5346, Lr: 0.000300
2023-05-30 16:52:46,026 - INFO - joeynmt.training - Epoch   2, Step:     7700, Batch Loss:     2.043952, Batch Acc: 0.411138, Tokens per Sec:     5161, Lr: 0.000300
2023-05-30 16:53:00,735 - INFO - joeynmt.training - Epoch   2, Step:     7800, Batch Loss:     2.161407, Batch Acc: 0.414222, Tokens per Sec:     5079, Lr: 0.000300
2023-05-30 16:53:14,844 - INFO - joeynmt.training - Epoch   2, Step:     7900, Batch Loss:     2.092507, Batch Acc: 0.419651, Tokens per Sec:     5389, Lr: 0.000300
2023-05-30 16:53:28,421 - INFO - joeynmt.training - Epoch   2, Step:     8000, Batch Loss:     2.047928, Batch Acc: 0.409323, Tokens per Sec:     5457, Lr: 0.000300
2023-05-30 16:53:28,422 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 16:53:28,422 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 16:54:38,630 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.16, ppl:   8.67, acc:   0.38, generation: 70.1996[sec], evaluation: 0.0000[sec]
2023-05-30 16:54:38,631 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 16:54:38,707 - INFO - joeynmt.helpers - delete models/transformer_model2/5500.ckpt
2023-05-30 16:54:38,708 - INFO - joeynmt.training - Example #0
2023-05-30 16:54:38,708 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 16:54:38,708 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 16:54:38,708 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'diese', 'zwei', 'Di@@', 'a@@', 'st', 'be@@', 'l', 'diese', 'zwei', 'Di@@', 'a@@', 's,', 'die', 'die', 'P@@', 'ol@@', 'it@@', 'i@@', '-@@', 'S@@', 'eite', 'der', 'P@@', 'ol@@', 'i@@', 'sk@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'hatte', 'die', 'die', 'U@@', 'S@@', 'A', 'mit', '4@@', '0@@', '%', 'der', 'U@@', 'S@@', 'A', '</s>']
2023-05-30 16:54:38,708 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 16:54:38,708 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 16:54:38,708 - INFO - joeynmt.training - 	Hypothesis: Ich habe diese zwei Diast bel diese zwei Dias, die die Politi-Seite der Poliskap, die die letzten drei Millionen Jahre alt hatte, hatte die die USA mit 40% der USA
2023-05-30 16:54:38,708 - INFO - joeynmt.training - Example #1
2023-05-30 16:54:38,708 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 16:54:38,708 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 16:54:38,708 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'Bil@@', 'd', 'ist', 'der', 'der', 'L@@', 'ehr@@', 'er@@', 'st@@', 'är@@', 't', 'das', 'nicht', 'die', 'D@@', 'ik@@', 'er@@', 'n,', 'weil', 'es', 'nicht', 'die', 'D@@', 'ik@@', 'er@@', 'n.', '</s>']
2023-05-30 16:54:38,709 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 16:54:38,709 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 16:54:38,709 - INFO - joeynmt.training - 	Hypothesis: Aber das Bild ist der der Lehrerstärt das nicht die Dikern, weil es nicht die Dikern.
2023-05-30 16:54:38,709 - INFO - joeynmt.training - Example #2
2023-05-30 16:54:38,709 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 16:54:38,709 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 16:54:38,709 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sk@@', 'it@@', 'ä@@', 'ten', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ö@@', 'l', 'ist', 'in', 'der', 'K@@', 'la@@', 'ss@@', 'en@@', 'der', 'uns', 'g@@', 'lob@@', 'al@@', 'er', 'S@@', 'ie@@', 'ß@@', 'e', 'der', 'G@@', 'lob@@', 'al@@', 'er', 'K@@', 'l@@', 'im@@', 'a', '</s>']
2023-05-30 16:54:38,709 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 16:54:38,709 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 16:54:38,709 - INFO - joeynmt.training - 	Hypothesis: Die Eisskitäten auf der Nordpöl ist in der Klassender uns globaler Sieße der Globaler Klima
2023-05-30 16:54:38,709 - INFO - joeynmt.training - Example #3
2023-05-30 16:54:38,709 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 16:54:38,709 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 16:54:38,709 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'aus', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'ä@@', 'f@@', 't,', '</s>']
2023-05-30 16:54:38,709 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 16:54:38,709 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 16:54:38,709 - INFO - joeynmt.training - 	Hypothesis: Es ist aus der Winter und Kräft,
2023-05-30 16:54:38,709 - INFO - joeynmt.training - Example #4
2023-05-30 16:54:38,709 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 16:54:38,709 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 16:54:38,709 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'näch@@', 'ste', 'Di@@', 'a', 'der', 'ich', 'zei@@', 'ge', 'Ihnen', 'ist', 'eine', 'ver@@', 'r@@', 'ück@@', 'te', 'Ver@@', 'si@@', 'on', 'der', 'letzten', '2@@', '5', 'Jahre', 'pass@@', 'iert.', '</s>']
2023-05-30 16:54:38,710 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 16:54:38,710 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 16:54:38,710 - INFO - joeynmt.training - 	Hypothesis: Und die nächste Dia der ich zeige Ihnen ist eine verrückte Version der letzten 25 Jahre passiert.
2023-05-30 16:54:52,246 - INFO - joeynmt.training - Epoch   2, Step:     8100, Batch Loss:     2.055658, Batch Acc: 0.419306, Tokens per Sec:     5389, Lr: 0.000300
2023-05-30 16:55:06,004 - INFO - joeynmt.training - Epoch   2, Step:     8200, Batch Loss:     2.153287, Batch Acc: 0.411767, Tokens per Sec:     5433, Lr: 0.000300
2023-05-30 16:55:20,201 - INFO - joeynmt.training - Epoch   2, Step:     8300, Batch Loss:     2.222172, Batch Acc: 0.421189, Tokens per Sec:     5388, Lr: 0.000300
2023-05-30 16:55:24,529 - INFO - joeynmt.training - Epoch   2: total training loss 9113.14
2023-05-30 16:55:24,529 - INFO - joeynmt.training - EPOCH 3
2023-05-30 16:55:34,109 - INFO - joeynmt.training - Epoch   3, Step:     8400, Batch Loss:     1.825882, Batch Acc: 0.433385, Tokens per Sec:     5700, Lr: 0.000300
2023-05-30 16:55:47,391 - INFO - joeynmt.training - Epoch   3, Step:     8500, Batch Loss:     1.923081, Batch Acc: 0.437248, Tokens per Sec:     5638, Lr: 0.000300
2023-05-30 16:55:47,391 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 16:55:47,391 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 16:57:00,815 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.13, ppl:   8.45, acc:   0.39, generation: 73.4149[sec], evaluation: 0.0000[sec]
2023-05-30 16:57:00,817 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 16:57:00,894 - INFO - joeynmt.helpers - delete models/transformer_model2/6000.ckpt
2023-05-30 16:57:00,894 - INFO - joeynmt.training - Example #0
2023-05-30 16:57:00,894 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 16:57:00,894 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 16:57:00,895 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or', 'un@@', 'gefä@@', 'hr', 'ich', 'diese', 'zwei', 'Di@@', 'a@@', 'st', 'be@@', 'tra@@', 'cht@@', 'en,', 'dass', 'die', 'P@@', 'ol@@', 'ol@@', 'it@@', 'y', 'zu', 't@@', 'onen', 'dass', 'die', 'P@@', 'ol@@', 'it@@', 'ik@@', '-@@', 'U@@', 'S@@', '-@@', 'Ja@@', 'h@@', 're,', 'die', 'letzten', 'drei', 'Millionen', 'Jahren', 'wurde', 'von', 'den', 'U@@', 'S@@', 'S@@', 'A', 'mit', '4@@', '0@@', '%', 'ge@@', 'k@@', 'rie@@', 'g@@', 's@@', ':', '</s>']
2023-05-30 16:57:00,895 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 16:57:00,895 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 16:57:00,895 - INFO - joeynmt.training - 	Hypothesis: Vor ungefähr ich diese zwei Diast betrachten, dass die Pololity zu tonen dass die Politik-US-Jahre, die letzten drei Millionen Jahren wurde von den USSA mit 40% gekriegs:
2023-05-30 16:57:00,895 - INFO - joeynmt.training - Example #1
2023-05-30 16:57:00,895 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 16:57:00,895 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 16:57:00,895 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Zeit', 'der', 'Er@@', 'n@@', 'ähr@@', 'ung', 'der', 'Zeit', 'der', 'Zeit', 'der', 'Zeit', 'der', 'Be@@', 'de@@', 'ut@@', 'ung', 'der', 'E@@', 'is@@', 'e', 'der', 'E@@', 'is@@', 'e', 'der', 'E@@', 'is@@', 'e', 'der', 'E@@', 'is@@', 'e', 'der', 'E@@', 'is@@', 'e', 'der', 'E@@', 'is@@', 'e', 'der', 'E@@', 'is@@', 'e', 'der', 'E@@', 'is@@', 'e', 'der', 'L@@', 'ehr@@', 'er@@', 'n.', '</s>']
2023-05-30 16:57:00,895 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 16:57:00,895 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 16:57:00,895 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Zeit der Ernährung der Zeit der Zeit der Zeit der Bedeutung der Eise der Eise der Eise der Eise der Eise der Eise der Eise der Eise der Lehrern.
2023-05-30 16:57:00,895 - INFO - joeynmt.training - Example #2
2023-05-30 16:57:00,895 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 16:57:00,895 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 16:57:00,895 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sk@@', 'it@@', 'on@@', 'd@@', 'p@@', 'ol@@', 'e', 'ist', 'in', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'e', 'S@@', 'eite', 'der', 'G@@', 'lob@@', 'ale', 'K@@', 'l@@', 'im@@', 'mer@@', '.', '</s>']
2023-05-30 16:57:00,895 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 16:57:00,895 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 16:57:00,895 - INFO - joeynmt.training - 	Hypothesis: Die Eisskitondpole ist in der Nordpole Seite der Globale Klimmer.
2023-05-30 16:57:00,895 - INFO - joeynmt.training - Example #3
2023-05-30 16:57:00,896 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 16:57:00,896 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 16:57:00,896 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'sch@@', 'ließ@@', 't', 'aus', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'der', 'S@@', 'om@@', 'mer@@', '.', '</s>']
2023-05-30 16:57:00,896 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 16:57:00,896 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 16:57:00,896 - INFO - joeynmt.training - 	Hypothesis: Es schließt aus der Winter und Krimft in der Sommer.
2023-05-30 16:57:00,896 - INFO - joeynmt.training - Example #4
2023-05-30 16:57:00,896 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 16:57:00,896 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 16:57:00,896 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', 'ste', 'Di@@', 'a', 'die', 'ich', 'Ihnen', 'zei@@', 'gen,', 'dass', 'ich', 'Ihnen', 'eine', 'Ver@@', 'schn@@', 'ell@@', 'ten', '2@@', '5', 'Jahren', 'ist', 'ein', 'Ver@@', 'letz@@', 't@@', 'lich', 'der', '2@@', '5', 'Jahren', 'pass@@', 'iert.', '</s>']
2023-05-30 16:57:00,896 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 16:57:00,896 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 16:57:00,896 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia die ich Ihnen zeigen, dass ich Ihnen eine Verschnellten 25 Jahren ist ein Verletztlich der 25 Jahren passiert.
2023-05-30 16:57:14,798 - INFO - joeynmt.training - Epoch   3, Step:     8600, Batch Loss:     1.909795, Batch Acc: 0.430919, Tokens per Sec:     5211, Lr: 0.000300
2023-05-30 16:57:29,210 - INFO - joeynmt.training - Epoch   3, Step:     8700, Batch Loss:     1.964884, Batch Acc: 0.440122, Tokens per Sec:     5317, Lr: 0.000300
2023-05-30 16:57:43,331 - INFO - joeynmt.training - Epoch   3, Step:     8800, Batch Loss:     2.177100, Batch Acc: 0.435877, Tokens per Sec:     5280, Lr: 0.000300
2023-05-30 16:57:58,281 - INFO - joeynmt.training - Epoch   3, Step:     8900, Batch Loss:     1.987160, Batch Acc: 0.433739, Tokens per Sec:     5111, Lr: 0.000300
2023-05-30 16:58:11,714 - INFO - joeynmt.training - Epoch   3, Step:     9000, Batch Loss:     1.983124, Batch Acc: 0.437454, Tokens per Sec:     5725, Lr: 0.000300
2023-05-30 16:58:11,714 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 16:58:11,714 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 16:59:24,185 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.12, ppl:   8.36, acc:   0.40, generation: 72.4623[sec], evaluation: 0.0000[sec]
2023-05-30 16:59:24,187 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 16:59:24,264 - INFO - joeynmt.helpers - delete models/transformer_model2/6500.ckpt
2023-05-30 16:59:24,265 - INFO - joeynmt.training - Example #0
2023-05-30 16:59:24,265 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 16:59:24,265 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 16:59:24,265 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I@@', 'm', 'Jahr', 'lie@@', 'ß', 'ich', 'diese', 'zwei', 'Di@@', 'a@@', 'st', 'be@@', 'l', 'zu', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'ol@@', 'le@@', 'sk@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'von', 'der', 'U@@', 'S@@', 'A', 'in', 'den', 'U@@', 'S@@', 'A', 'in', 'den', 'U@@', 'S@@', 'A', 'in', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pf@@', 'lan@@', 'z@@', 'en.', '</s>']
2023-05-30 16:59:24,265 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 16:59:24,265 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 16:59:24,265 - INFO - joeynmt.training - 	Hypothesis: Im Jahr ließ ich diese zwei Diast bel zu zeigen, dass die Pololleskap, die die letzten drei Millionen Jahre alt von der USA in den USA in den USA in 40% gekrompflanzen.
2023-05-30 16:59:24,265 - INFO - joeynmt.training - Example #1
2023-05-30 16:59:24,265 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 16:59:24,265 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 16:59:24,265 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Er@@', 'geb@@', 'nis', 'der', 'Er@@', 'n@@', 'is@@', 'se', 'der', 'Er@@', 'geb@@', 'nis', 'der', 'von', 'der', 'E@@', 'is@@', 'en@@', '-@@', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'D@@', 'ik@@', 'er@@', 'h@@', 'äl@@', 't', 'sehen.', '</s>']
2023-05-30 16:59:24,265 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 16:59:24,265 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 16:59:24,265 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Ergebnis der Ernisse der Ergebnis der von der Eisen-Problem ist, weil es nicht die Dikerhält sehen.
2023-05-30 16:59:24,265 - INFO - joeynmt.training - Example #2
2023-05-30 16:59:24,265 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 16:59:24,265 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 16:59:24,266 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sk@@', 'it@@', 'op', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'is', 'in', 'der', 'K@@', 'la@@', 'ss@@', 'en@@', 'des', 'K@@', 'la@@', 'ss@@', 'en@@', 'des', 'uns', 'g@@', 'lob@@', 'al@@', 'er', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 'y@@', 'ste@@', 'm.', '</s>']
2023-05-30 16:59:24,266 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 16:59:24,266 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 16:59:24,266 - INFO - joeynmt.training - 	Hypothesis: Die Eisskitop der Nordpolis in der Klassendes Klassendes uns globaler Klimawandelystem.
2023-05-30 16:59:24,266 - INFO - joeynmt.training - Example #3
2023-05-30 16:59:24,266 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 16:59:24,266 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 16:59:24,266 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'den', 'S@@', 'om@@', 'mer@@', '.', '</s>']
2023-05-30 16:59:24,266 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 16:59:24,266 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 16:59:24,266 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Krimft in den Sommer.
2023-05-30 16:59:24,266 - INFO - joeynmt.training - Example #4
2023-05-30 16:59:24,266 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 16:59:24,266 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 16:59:24,266 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', 'ste', 'Di@@', 'a', 'der', 'ich', 'zei@@', 'ge', 'von', 'der', 'Ver@@', 'br@@', 'eit@@', 'ung', 'von', 'der', 'Ver@@', 'si@@', 'on', 'von', 'der', 'letzten', '2@@', '5', 'Jahre', 'ist', 'pass@@', 'iert.', '</s>']
2023-05-30 16:59:24,266 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 16:59:24,266 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 16:59:24,266 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia der ich zeige von der Verbreitung von der Version von der letzten 25 Jahre ist passiert.
2023-05-30 16:59:39,275 - INFO - joeynmt.training - Epoch   3, Step:     9100, Batch Loss:     2.121418, Batch Acc: 0.438746, Tokens per Sec:     5078, Lr: 0.000300
2023-05-30 16:59:53,910 - INFO - joeynmt.training - Epoch   3, Step:     9200, Batch Loss:     2.173015, Batch Acc: 0.442046, Tokens per Sec:     5132, Lr: 0.000300
2023-05-30 17:00:09,557 - INFO - joeynmt.training - Epoch   3, Step:     9300, Batch Loss:     1.971468, Batch Acc: 0.434087, Tokens per Sec:     4816, Lr: 0.000300
2023-05-30 17:00:24,710 - INFO - joeynmt.training - Epoch   3, Step:     9400, Batch Loss:     2.036789, Batch Acc: 0.435629, Tokens per Sec:     5072, Lr: 0.000300
2023-05-30 17:00:40,990 - INFO - joeynmt.training - Epoch   3, Step:     9500, Batch Loss:     1.847748, Batch Acc: 0.441189, Tokens per Sec:     4642, Lr: 0.000300
2023-05-30 17:00:40,990 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 17:00:40,990 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 17:02:13,342 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.10, ppl:   8.20, acc:   0.40, generation: 92.3433[sec], evaluation: 0.0000[sec]
2023-05-30 17:02:13,344 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 17:02:13,423 - INFO - joeynmt.helpers - delete models/transformer_model2/7000.ckpt
2023-05-30 17:02:13,424 - INFO - joeynmt.training - Example #0
2023-05-30 17:02:13,424 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 17:02:13,424 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 17:02:13,424 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'diese', 'zwei', 'Di@@', 'a@@', 'st', 'sehen', 'ich', 'diese', 'zwei', 'Di@@', 'a@@', 'st', 'sehen,', 'um', 'zu', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'it@@', 'y', 'in', 'der', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 'ten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hatte', 'der', 'Gro@@', 'ß@@', 'br@@', 'it@@', 'ä@@', 'ten', 'von', 'V@@', 'S@@', ',', 'mit', '4@@', '0@@', '%', 'der', 'U@@', 'S@@', 'A', '</s>']
2023-05-30 17:02:13,424 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 17:02:13,424 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 17:02:13,424 - INFO - joeynmt.training - 	Hypothesis: Ich habe diese zwei Diast sehen ich diese zwei Diast sehen, um zu zeigen, dass die Polity in der letzten drei Millionen Jahre alten drei Millionen Jahre alt hatte der Großbritäten von VS, mit 40% der USA
2023-05-30 17:02:13,424 - INFO - joeynmt.training - Example #1
2023-05-30 17:02:13,424 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 17:02:13,424 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 17:02:13,424 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'wirklich', 'der', 'L@@', 'ehr@@', 'er@@', 'st@@', 'es', 'ist', 'der', 'spe@@', 'zi@@', 'elle', 'Problem', 'weil', 'es', 'nicht', 'die', 'D@@', 'ik@@', 'er@@', 'h@@', 'äl@@', 't', 'sehen.', '</s>']
2023-05-30 17:02:13,424 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 17:02:13,425 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 17:02:13,425 - INFO - joeynmt.training - 	Hypothesis: Aber das ist wirklich der Lehrerstes ist der spezielle Problem weil es nicht die Dikerhält sehen.
2023-05-30 17:02:13,425 - INFO - joeynmt.training - Example #2
2023-05-30 17:02:13,425 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 17:02:13,425 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 17:02:13,425 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sk@@', 'it@@', 'on@@', 'd@@', 'p@@', 'ol@@', 'l', 'ist', 'in', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'l', 'ist', 'in', 'der', 'K@@', 'li@@', 'ma@@', 'wan@@', 'd@@', '-@@', 'K@@', 'li@@', 'ma@@', 'wan@@', 'd@@', '-@@', 'K@@', 'li@@', 'ma@@', 'wan@@', 'd@@', '-@@', 'K@@', 'li@@', 'ma@@', 'wan@@', 'd@@', 'm@@', 's.', '</s>']
2023-05-30 17:02:13,425 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 17:02:13,425 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 17:02:13,425 - INFO - joeynmt.training - 	Hypothesis: Die Eisskitondpoll ist in der Nordpoll ist in der Klimawand-Klimawand-Klimawand-Klimawandms.
2023-05-30 17:02:13,425 - INFO - joeynmt.training - Example #3
2023-05-30 17:02:13,425 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 17:02:13,425 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 17:02:13,425 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'sch@@', 'ließ@@', 'lich', 'in', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'ä@@', 'm@@', 'pf@@', 'er', 'in', 'der', 'S@@', 'om@@', 'mer@@', '.', '</s>']
2023-05-30 17:02:13,425 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 17:02:13,425 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 17:02:13,425 - INFO - joeynmt.training - 	Hypothesis: Es schließlich in der Winter und Krämpfer in der Sommer.
2023-05-30 17:02:13,425 - INFO - joeynmt.training - Example #4
2023-05-30 17:02:13,425 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 17:02:13,425 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 17:02:13,425 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', 'ste', 'Di@@', 'a', 'die', 'ich', 'zei@@', 'ge', 'der', 'Zeit', 'ist', 'eine', 'Ver@@', 'br@@', 'eit@@', 'ung', 'von', 'was', 'die', 'letzten', '2@@', '5', 'Jahre', 'ist', 'pass@@', 'iert.', '</s>']
2023-05-30 17:02:13,425 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 17:02:13,425 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 17:02:13,425 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia die ich zeige der Zeit ist eine Verbreitung von was die letzten 25 Jahre ist passiert.
2023-05-30 17:02:28,952 - INFO - joeynmt.training - Epoch   3, Step:     9600, Batch Loss:     1.949600, Batch Acc: 0.434152, Tokens per Sec:     4882, Lr: 0.000300
2023-05-30 17:02:44,333 - INFO - joeynmt.training - Epoch   3, Step:     9700, Batch Loss:     1.912865, Batch Acc: 0.439966, Tokens per Sec:     4934, Lr: 0.000300
2023-05-30 17:02:59,857 - INFO - joeynmt.training - Epoch   3, Step:     9800, Batch Loss:     1.955167, Batch Acc: 0.436145, Tokens per Sec:     4886, Lr: 0.000300
2023-05-30 17:03:15,156 - INFO - joeynmt.training - Epoch   3, Step:     9900, Batch Loss:     1.994341, Batch Acc: 0.444836, Tokens per Sec:     4931, Lr: 0.000300
2023-05-30 17:03:31,291 - INFO - joeynmt.training - Epoch   3, Step:    10000, Batch Loss:     1.855252, Batch Acc: 0.437936, Tokens per Sec:     4684, Lr: 0.000300
2023-05-30 17:03:31,291 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 17:03:31,291 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 17:04:46,787 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.08, ppl:   8.02, acc:   0.40, generation: 75.4867[sec], evaluation: 0.0000[sec]
2023-05-30 17:04:46,788 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 17:04:46,864 - INFO - joeynmt.helpers - delete models/transformer_model2/7500.ckpt
2023-05-30 17:04:46,865 - INFO - joeynmt.training - Example #0
2023-05-30 17:04:46,865 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 17:04:46,865 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 17:04:46,865 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'o@@', 'ch', 'Jahre', 'lie@@', 'ß', 'ich', 'diese', 'zwei', 'Di@@', 'a@@', 'st', 'be@@', 'tra@@', 'cht@@', 'en,', 'die', 'die', 'P@@', 'ol@@', 'it@@', 'ik@@', 'en', 'ge@@', 'sehen', 'ha@@', 'be,', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'war', 'der', 'V@@', 'S@@', ',', 'mit', '4@@', '0@@', '%', 'der', 'V@@', 'S@@', ',', 'mit', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'war.', '</s>']
2023-05-30 17:04:46,865 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 17:04:46,865 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 17:04:46,865 - INFO - joeynmt.training - 	Hypothesis: Loch Jahre ließ ich diese zwei Diast betrachten, die die Politiken gesehen habe, die die letzten drei Millionen Jahre alt war der VS, mit 40% der VS, mit 40% gekrompen war.
2023-05-30 17:04:46,865 - INFO - joeynmt.training - Example #1
2023-05-30 17:04:46,865 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 17:04:46,865 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 17:04:46,865 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'Bil@@', 'd', 'ist', 'der', 'ern@@', 'st@@', 'h@@', 'af@@', 't', 'in', 'diesem', 'spe@@', 'zi@@', 'f@@', 'isch@@', 'er', 'Problem', 'weil', 'es', 'nicht', 'die', 'D@@', 'ik@@', 'te', 'der', 'E@@', 'is@@', 'e', 'zei@@', 'gen.', '</s>']
2023-05-30 17:04:46,865 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 17:04:46,865 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 17:04:46,865 - INFO - joeynmt.training - 	Hypothesis: Aber das Bild ist der ernsthaft in diesem spezifischer Problem weil es nicht die Dikte der Eise zeigen.
2023-05-30 17:04:46,865 - INFO - joeynmt.training - Example #2
2023-05-30 17:04:46,865 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 17:04:46,865 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 17:04:46,866 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sk@@', 'it@@', 'on@@', 'on@@', 's@@', '-@@', 'C@@', 'om@@', 'ic@@', 'e', 'ist', 'in', 'der', 'K@@', 'la@@', 'p@@', 'en@@', 'en@@', 'z', 'von', 'uns', 'in', 'der', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 'n', 'von', 'uns', 'G@@', 'lob@@', 'al@@', 't@@', 't@@', 'y@@', 'ste@@', 'm.', '</s>']
2023-05-30 17:04:46,866 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 17:04:46,866 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 17:04:46,866 - INFO - joeynmt.training - 	Hypothesis: Die Eisskitonons-Comice ist in der Klapenenz von uns in der Klimawandeln von uns Globalttystem.
2023-05-30 17:04:46,866 - INFO - joeynmt.training - Example #3
2023-05-30 17:04:46,866 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 17:04:46,866 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 17:04:46,866 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'aus', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'der', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'im@@', 'p@@', 'en@@', 's.', '</s>']
2023-05-30 17:04:46,866 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 17:04:46,866 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 17:04:46,866 - INFO - joeynmt.training - 	Hypothesis: Es ist aus der Winter und Krimft in der Sommer und Krimpens.
2023-05-30 17:04:46,866 - INFO - joeynmt.training - Example #4
2023-05-30 17:04:46,866 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 17:04:46,866 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 17:04:46,866 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', 'ste', 'Di@@', 'a', 'die', 'näch@@', 'ste', 'Di@@', 'a', 'ist', 'eine', 'Ver@@', 'schn@@', 'ell@@', 'ung', 'von', 'was', 'die', 'letzten', '2@@', '5', 'Jahre', 'ist', 'pass@@', 'ier@@', 'ende', 'Jahre', 'pass@@', 'iert.', '</s>']
2023-05-30 17:04:46,866 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 17:04:46,866 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 17:04:46,866 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia die nächste Dia ist eine Verschnellung von was die letzten 25 Jahre ist passierende Jahre passiert.
2023-05-30 17:05:02,733 - INFO - joeynmt.training - Epoch   3, Step:    10100, Batch Loss:     1.861057, Batch Acc: 0.440272, Tokens per Sec:     4719, Lr: 0.000300
2023-05-30 17:05:18,562 - INFO - joeynmt.training - Epoch   3, Step:    10200, Batch Loss:     2.027142, Batch Acc: 0.446006, Tokens per Sec:     4832, Lr: 0.000300
2023-05-30 17:05:34,683 - INFO - joeynmt.training - Epoch   3, Step:    10300, Batch Loss:     1.864191, Batch Acc: 0.442279, Tokens per Sec:     4714, Lr: 0.000300
2023-05-30 17:05:50,339 - INFO - joeynmt.training - Epoch   3, Step:    10400, Batch Loss:     2.038133, Batch Acc: 0.440830, Tokens per Sec:     4789, Lr: 0.000300
2023-05-30 17:06:05,769 - INFO - joeynmt.training - Epoch   3, Step:    10500, Batch Loss:     1.890274, Batch Acc: 0.446127, Tokens per Sec:     4912, Lr: 0.000300
2023-05-30 17:06:05,769 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 17:06:05,769 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 17:07:23,928 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.07, ppl:   7.96, acc:   0.41, generation: 78.1500[sec], evaluation: 0.0000[sec]
2023-05-30 17:07:23,929 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 17:07:24,008 - INFO - joeynmt.helpers - delete models/transformer_model2/8000.ckpt
2023-05-30 17:07:24,008 - INFO - joeynmt.training - Example #0
2023-05-30 17:07:24,008 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 17:07:24,008 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 17:07:24,008 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'diese', 'zwei', 'Di@@', 'a@@', 'st', 'in', 'der', 'F@@', 'eu@@', 'er', 'zu', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'it@@', 'ik@@', 'er', 'in', 'der', 'P@@', 'ol@@', 'it@@', 'ik@@', 'er', 'ge@@', 'gan@@', 'gen', 'hat@@', 'te,', 'die', 'P@@', 'ol@@', 'it@@', 'ik', 'der', 'V@@', 'is@@', 'ion', 'der', 'V@@', 'S@@', ',', 'mit', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pf@@', 't.', '</s>']
2023-05-30 17:07:24,009 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 17:07:24,009 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 17:07:24,009 - INFO - joeynmt.training - 	Hypothesis: Ich habe diese zwei Diast in der Feuer zu zeigen, dass die Politiker in der Politiker gegangen hatte, die Politik der Vision der VS, mit 40% gekrompft.
2023-05-30 17:07:24,009 - INFO - joeynmt.training - Example #1
2023-05-30 17:07:24,009 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 17:07:24,009 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 17:07:24,009 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'L@@', 'and@@', 'schaft', 'der', 'L@@', 'ehr@@', 'e', 'des', 'Sp@@', 'e@@', 'zi@@', 'al@@', 'es', 'Proble@@', 'm@@', 's', 'zu', 'dem', 'E@@', 'is', 'des', 'E@@', 'is', 'sehen.', '</s>']
2023-05-30 17:07:24,009 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 17:07:24,009 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 17:07:24,009 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Landschaft der Lehre des Speziales Problems zu dem Eis des Eis sehen.
2023-05-30 17:07:24,009 - INFO - joeynmt.training - Example #2
2023-05-30 17:07:24,009 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 17:07:24,009 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 17:07:24,009 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sk@@', 'it@@', 'on@@', 'e', 'ist', 'in', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'is', 'in', 'der', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', ',', 'der', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 's@@', '-@@', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 's@@', '-@@', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', '.', '</s>']
2023-05-30 17:07:24,009 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 17:07:24,009 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 17:07:24,009 - INFO - joeynmt.training - 	Hypothesis: Die Eisskitone ist in der Nordpolis in der Klimawandel, der Klimawandels-Klimawandels-Klimawandel.
2023-05-30 17:07:24,009 - INFO - joeynmt.training - Example #3
2023-05-30 17:07:24,009 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 17:07:24,009 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 17:07:24,009 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'aus', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'der', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'der', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'im@@', 'ation', 'in', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'im@@', 'ation', 'in', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'ation', 'in', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'der', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'im@@', 'ation', 'in', 'der', 'S@@', 'omm@@', 'en.', '</s>']
2023-05-30 17:07:24,010 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 17:07:24,010 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 17:07:24,010 - INFO - joeynmt.training - 	Hypothesis: Es ist aus der Winter und Krimft in der Sommer und Krimft in der Sommer und Krimation in der Winter und Krimimation in der Winter und Krimation in der Winter und Krimft in der Sommer und Krimation in der Sommen.
2023-05-30 17:07:24,010 - INFO - joeynmt.training - Example #4
2023-05-30 17:07:24,010 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 17:07:24,010 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 17:07:24,010 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'näch@@', 'ste', 'Di@@', 'a', 'der', 'zei@@', 'gt', 'ist', 'eine', 'Ver@@', 'schn@@', 'ell@@', 'ten', 'Ver@@', 'n@@', 'un@@', 'd,', 'was', 'es', 'der', 'letzten', '2@@', '5', 'Jahre', 'pass@@', 'iert.', '</s>']
2023-05-30 17:07:24,010 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 17:07:24,010 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 17:07:24,010 - INFO - joeynmt.training - 	Hypothesis: Und die nächste Dia der zeigt ist eine Verschnellten Vernund, was es der letzten 25 Jahre passiert.
2023-05-30 17:07:39,600 - INFO - joeynmt.training - Epoch   3, Step:    10600, Batch Loss:     1.984009, Batch Acc: 0.440778, Tokens per Sec:     4853, Lr: 0.000300
2023-05-30 17:07:54,321 - INFO - joeynmt.training - Epoch   3, Step:    10700, Batch Loss:     1.903527, Batch Acc: 0.440456, Tokens per Sec:     5148, Lr: 0.000300
2023-05-30 17:08:10,281 - INFO - joeynmt.training - Epoch   3, Step:    10800, Batch Loss:     1.950430, Batch Acc: 0.452174, Tokens per Sec:     4773, Lr: 0.000300
2023-05-30 17:08:26,346 - INFO - joeynmt.training - Epoch   3, Step:    10900, Batch Loss:     2.052059, Batch Acc: 0.441329, Tokens per Sec:     4851, Lr: 0.000300
2023-05-30 17:08:41,173 - INFO - joeynmt.training - Epoch   3, Step:    11000, Batch Loss:     2.019093, Batch Acc: 0.447295, Tokens per Sec:     5089, Lr: 0.000300
2023-05-30 17:08:41,173 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 17:08:41,173 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 17:09:58,970 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.05, ppl:   7.80, acc:   0.41, generation: 77.7893[sec], evaluation: 0.0000[sec]
2023-05-30 17:09:58,971 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 17:09:59,049 - INFO - joeynmt.helpers - delete models/transformer_model2/8500.ckpt
2023-05-30 17:09:59,049 - INFO - joeynmt.training - Example #0
2023-05-30 17:09:59,049 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 17:09:59,049 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 17:09:59,049 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I@@', 'm', 'Jahr', 'lie@@', 'ß', 'ich', 'diese', 'zwei', 'Di@@', 'a@@', 'st', 'sehen', 'um', 'zu', 'zei@@', 'gen,', 'um', 'zu', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'le@@', 's@@', 'z@@', 'eit', 'der', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'die', 'die', 'U@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A', '</s>']
2023-05-30 17:09:59,050 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 17:09:59,050 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 17:09:59,050 - INFO - joeynmt.training - 	Hypothesis: Im Jahr ließ ich diese zwei Diast sehen um zu zeigen, um zu zeigen, dass die Polleszeit der letzten drei Millionen Jahre alt hatte, die die USA mit 40 Prozent der USA mit 40 Prozent der USA
2023-05-30 17:09:59,050 - INFO - joeynmt.training - Example #1
2023-05-30 17:09:59,050 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 17:09:59,050 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 17:09:59,050 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'das', 'ein', 'Teil', 'der', 'ern@@', 'st', 'dieses', 'spe@@', 'zi@@', 'f@@', 'ische', 'Problem', 'weil', 'es', 'nicht', 'die', 'D@@', 'ik@@', 'er@@', 'n.', '</s>']
2023-05-30 17:09:59,050 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 17:09:59,050 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 17:09:59,050 - INFO - joeynmt.training - 	Hypothesis: Aber das ist das ein Teil der ernst dieses spezifische Problem weil es nicht die Dikern.
2023-05-30 17:09:59,050 - INFO - joeynmt.training - Example #2
2023-05-30 17:09:59,050 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 17:09:59,050 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 17:09:59,050 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sk@@', 'it@@', 'on@@', 's', 'in', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'is', 'in', 'der', 'K@@', 'la@@', 'ss@@', 'en@@', 'er', 'in', 'der', 'K@@', 'la@@', 'ss@@', 'en@@', 'de@@', 's,', '</s>']
2023-05-30 17:09:59,050 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 17:09:59,050 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 17:09:59,050 - INFO - joeynmt.training - 	Hypothesis: Die Eisskitons in der Nordpolis in der Klassener in der Klassendes,
2023-05-30 17:09:59,050 - INFO - joeynmt.training - Example #3
2023-05-30 17:09:59,050 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 17:09:59,050 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 17:09:59,050 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'aus', 'dem', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'p@@', 'en@@', '-@@', 'S@@', 'om@@', 'er.', '</s>']
2023-05-30 17:09:59,051 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 17:09:59,051 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 17:09:59,051 - INFO - joeynmt.training - 	Hypothesis: Es ist aus dem Winter und Krimpen-Somer.
2023-05-30 17:09:59,051 - INFO - joeynmt.training - Example #4
2023-05-30 17:09:59,051 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 17:09:59,051 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 17:09:59,051 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', 'ste', 'Di@@', 'a', 'der', 'näch@@', 'sten', 'Di@@', 'a', 'ist', 'ein', 'Ver@@', 'schn@@', 'ell@@', 'ten', 'Ver@@', 'si@@', 'on', 'der', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert.', '</s>']
2023-05-30 17:09:59,051 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 17:09:59,051 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 17:09:59,051 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia der nächsten Dia ist ein Verschnellten Version der letzten 25 Jahren passiert.
2023-05-30 17:10:14,589 - INFO - joeynmt.training - Epoch   3, Step:    11100, Batch Loss:     1.897511, Batch Acc: 0.448872, Tokens per Sec:     4960, Lr: 0.000300
2023-05-30 17:10:30,331 - INFO - joeynmt.training - Epoch   3, Step:    11200, Batch Loss:     1.769837, Batch Acc: 0.446772, Tokens per Sec:     4812, Lr: 0.000300
2023-05-30 17:10:45,390 - INFO - joeynmt.training - Epoch   3, Step:    11300, Batch Loss:     1.852056, Batch Acc: 0.446361, Tokens per Sec:     4978, Lr: 0.000300
2023-05-30 17:11:00,702 - INFO - joeynmt.training - Epoch   3, Step:    11400, Batch Loss:     1.766607, Batch Acc: 0.448238, Tokens per Sec:     4969, Lr: 0.000300
2023-05-30 17:11:15,960 - INFO - joeynmt.training - Epoch   3, Step:    11500, Batch Loss:     1.777051, Batch Acc: 0.450083, Tokens per Sec:     4906, Lr: 0.000300
2023-05-30 17:11:15,960 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 17:11:15,960 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 17:12:22,404 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.04, ppl:   7.72, acc:   0.41, generation: 66.4355[sec], evaluation: 0.0000[sec]
2023-05-30 17:12:22,405 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 17:12:22,481 - INFO - joeynmt.helpers - delete models/transformer_model2/9000.ckpt
2023-05-30 17:12:22,482 - INFO - joeynmt.training - Example #0
2023-05-30 17:12:22,482 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 17:12:22,482 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 17:12:22,482 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'habe', 'diese', 'zwei', 'D@@', 'aten', 'an', 'diesem', 'Jahr', 'ge@@', 'zei@@', 'gt', 'ha@@', 'be,', 'um', 'zu', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'it@@', 'y', 'die', 'P@@', 'ol@@', 'it@@', 'y', 'der', 'U@@', 'S@@', 'A@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te.', '</s>']
2023-05-30 17:12:22,482 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 17:12:22,482 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 17:12:22,482 - INFO - joeynmt.training - 	Hypothesis: Ich habe diese zwei Daten an diesem Jahr gezeigt habe, um zu zeigen, dass die Polity die Polity der USA, die die letzten drei Millionen Jahre alt hatte.
2023-05-30 17:12:22,482 - INFO - joeynmt.training - Example #1
2023-05-30 17:12:22,482 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 17:12:22,482 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 17:12:22,482 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Teil', 'der', 'Zeit', 'der', 'S@@', 'in@@', 'n', 'dieses', 'spe@@', 'zi@@', 'f@@', 'isch@@', 'es', 'Problem', 'weil', 'es', 'nicht', 'die', 'D@@', 'ik@@', 'te', 'der', 'E@@', 'is', 'sehen.', '</s>']
2023-05-30 17:12:22,482 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 17:12:22,482 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 17:12:22,482 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Teil der Zeit der Sinn dieses spezifisches Problem weil es nicht die Dikte der Eis sehen.
2023-05-30 17:12:22,483 - INFO - joeynmt.training - Example #2
2023-05-30 17:12:22,483 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 17:12:22,483 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 17:12:22,483 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'k@@', 'ol@@', 'it@@', 'ä@@', 't@@', 'ige', 'S@@', 'eite', 'ist', 'in', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'e', 's@@', 'einen', 'G@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 's@@', '-@@', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', '-@@', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', '.', '</s>']
2023-05-30 17:12:22,483 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 17:12:22,483 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 17:12:22,483 - INFO - joeynmt.training - 	Hypothesis: Die Eiskolitätige Seite ist in der Nordpole seinen Globalen Klimawandels-Klimawandel-Klimawandel.
2023-05-30 17:12:22,483 - INFO - joeynmt.training - Example #3
2023-05-30 17:12:22,483 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 17:12:22,483 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 17:12:22,483 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'p@@', 'li@@', 'z@@', 'iert', 'in', 'der', 'S@@', 'om@@', 'mer@@', '.', '</s>']
2023-05-30 17:12:22,483 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 17:12:22,483 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 17:12:22,483 - INFO - joeynmt.training - 	Hypothesis: Es ist in der Winter und Krimpliziert in der Sommer.
2023-05-30 17:12:22,483 - INFO - joeynmt.training - Example #4
2023-05-30 17:12:22,483 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 17:12:22,483 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 17:12:22,483 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'näch@@', 'ste', 'Di@@', 'a', 'die', 'ich', 'Ihnen', 'zei@@', 'gen', 'zei@@', 'gt,', 'ist', 'ein', 'Ver@@', 'schn@@', 'ell@@', 'er', 'der', 'letzten', '2@@', '5', 'Jahre', 'pass@@', 'iert.', '</s>']
2023-05-30 17:12:22,483 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 17:12:22,483 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 17:12:22,483 - INFO - joeynmt.training - 	Hypothesis: Der nächste Dia die ich Ihnen zeigen zeigt, ist ein Verschneller der letzten 25 Jahre passiert.
2023-05-30 17:12:38,251 - INFO - joeynmt.training - Epoch   3, Step:    11600, Batch Loss:     1.898025, Batch Acc: 0.445390, Tokens per Sec:     4703, Lr: 0.000300
2023-05-30 17:12:55,007 - INFO - joeynmt.training - Epoch   3, Step:    11700, Batch Loss:     1.905699, Batch Acc: 0.446440, Tokens per Sec:     4464, Lr: 0.000300
2023-05-30 17:13:10,883 - INFO - joeynmt.training - Epoch   3, Step:    11800, Batch Loss:     1.878866, Batch Acc: 0.451519, Tokens per Sec:     4817, Lr: 0.000300
2023-05-30 17:13:26,868 - INFO - joeynmt.training - Epoch   3, Step:    11900, Batch Loss:     2.115523, Batch Acc: 0.448899, Tokens per Sec:     4820, Lr: 0.000300
2023-05-30 17:13:42,469 - INFO - joeynmt.training - Epoch   3, Step:    12000, Batch Loss:     1.756948, Batch Acc: 0.453478, Tokens per Sec:     4829, Lr: 0.000300
2023-05-30 17:13:42,469 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 17:13:42,469 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 17:15:08,519 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.03, ppl:   7.62, acc:   0.42, generation: 86.0411[sec], evaluation: 0.0000[sec]
2023-05-30 17:15:08,520 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 17:15:08,598 - INFO - joeynmt.helpers - delete models/transformer_model2/9500.ckpt
2023-05-30 17:15:08,599 - INFO - joeynmt.training - Example #0
2023-05-30 17:15:08,599 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 17:15:08,599 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 17:15:08,599 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I@@', 'm', 'Jahr', 'lie@@', 'ß', 'ich', 'diese', 'zwei', 'Di@@', 'a@@', 'st', 'auf', 'der', 'T@@', 'on@@', 's@@', 'äch@@', 'lich', 'zu', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'i@@', ',', 'die', 'letzten', 'drei', 'Millionen', 'Jahren', 'un@@', 'gefä@@', 'hr', 'drei', 'Millionen', 'Jahren', 'un@@', 'gefä@@', 'hr', 'die', 'U@@', 'S@@', 'A', 'des', 'V@@', 'S@@', 'S@@', ',', 'mit', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pf@@', 'en.', '</s>']
2023-05-30 17:15:08,599 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 17:15:08,599 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 17:15:08,599 - INFO - joeynmt.training - 	Hypothesis: Im Jahr ließ ich diese zwei Diast auf der Tonsächlich zu zeigen, dass die Poli, die letzten drei Millionen Jahren ungefähr drei Millionen Jahren ungefähr die USA des VSS, mit 40% gekrompfen.
2023-05-30 17:15:08,599 - INFO - joeynmt.training - Example #1
2023-05-30 17:15:08,600 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 17:15:08,600 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 17:15:08,600 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'die', 'Er@@', 'n@@', 'ähr@@', 'ung', 'der', 'An@@', 'fan@@', 'g', 'des', 'Sp@@', 'e@@', 'zi@@', 'f@@', 'ischen', 'Problem', 'weil', 'es', 'nicht', 'die', 'D@@', 'ik@@', 'te', 'der', 'D@@', 'ik@@', 'er@@', 'n.', '</s>']
2023-05-30 17:15:08,600 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 17:15:08,600 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 17:15:08,600 - INFO - joeynmt.training - 	Hypothesis: Aber das ist die Ernährung der Anfang des Spezifischen Problem weil es nicht die Dikte der Dikern.
2023-05-30 17:15:08,600 - INFO - joeynmt.training - Example #2
2023-05-30 17:15:08,600 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 17:15:08,600 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 17:15:08,600 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sk@@', 'it@@', 'on@@', 'on@@', 'e', 'ist', 'in', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'l', 'ist', 'in', 'der', 'K@@', 'li@@', 'ma@@', '-@@', 'K@@', 'li@@', 'ma@@', '-@@', 'K@@', 'li@@', 'ma@@', '-@@', 'K@@', 'li@@', 'ma@@', '-@@', 'St@@', 'ru@@', 'm@@', 's.', '</s>']
2023-05-30 17:15:08,600 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 17:15:08,600 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 17:15:08,600 - INFO - joeynmt.training - 	Hypothesis: Die Eisskitonone ist in der Nordpoll ist in der Klima-Klima-Klima-Klima-Strums.
2023-05-30 17:15:08,600 - INFO - joeynmt.training - Example #3
2023-05-30 17:15:08,600 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 17:15:08,600 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 17:15:08,600 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'p@@', 'el', 'in', 'der', 'S@@', 'omm@@', 'er', 'in', 'der', 'S@@', 'omm@@', 'er', 'in', 'der', 'S@@', 'om@@', 'mer@@', '.', '</s>']
2023-05-30 17:15:08,600 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 17:15:08,600 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 17:15:08,600 - INFO - joeynmt.training - 	Hypothesis: Es ist in der Winter und Krimpel in der Sommer in der Sommer in der Sommer.
2023-05-30 17:15:08,600 - INFO - joeynmt.training - Example #4
2023-05-30 17:15:08,600 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 17:15:08,600 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 17:15:08,601 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', 'ste', 'Di@@', 'a', 'die', 'ich', 'zei@@', 'ge', 'Ihnen', 'ist', 'eine', 'ver@@', 'stan@@', 'den', 'von', 'dem', 'T@@', 'er@@', 'h@@', 'af@@', 't', 'und', 'das', 'ist', 'die', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert.', '</s>']
2023-05-30 17:15:08,601 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 17:15:08,601 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 17:15:08,601 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia die ich zeige Ihnen ist eine verstanden von dem Terhaft und das ist die letzten 25 Jahren passiert.
2023-05-30 17:15:24,618 - INFO - joeynmt.training - Epoch   3, Step:    12100, Batch Loss:     2.096919, Batch Acc: 0.446749, Tokens per Sec:     4856, Lr: 0.000300
2023-05-30 17:15:40,419 - INFO - joeynmt.training - Epoch   3, Step:    12200, Batch Loss:     1.743142, Batch Acc: 0.457800, Tokens per Sec:     4926, Lr: 0.000300
2023-05-30 17:15:56,357 - INFO - joeynmt.training - Epoch   3, Step:    12300, Batch Loss:     1.835471, Batch Acc: 0.452110, Tokens per Sec:     4784, Lr: 0.000300
2023-05-30 17:16:11,969 - INFO - joeynmt.training - Epoch   3, Step:    12400, Batch Loss:     1.992568, Batch Acc: 0.448978, Tokens per Sec:     4852, Lr: 0.000300
2023-05-30 17:16:24,337 - INFO - joeynmt.training - Epoch   3: total training loss 8050.00
2023-05-30 17:16:24,337 - INFO - joeynmt.training - EPOCH 4
2023-05-30 17:16:27,897 - INFO - joeynmt.training - Epoch   4, Step:    12500, Batch Loss:     1.736340, Batch Acc: 0.473951, Tokens per Sec:     4545, Lr: 0.000300
2023-05-30 17:16:27,898 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 17:16:27,898 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 17:17:40,532 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.02, ppl:   7.52, acc:   0.42, generation: 72.6260[sec], evaluation: 0.0000[sec]
2023-05-30 17:17:40,534 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 17:17:40,615 - INFO - joeynmt.helpers - delete models/transformer_model2/10000.ckpt
2023-05-30 17:17:40,615 - INFO - joeynmt.training - Example #0
2023-05-30 17:17:40,616 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 17:17:40,616 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 17:17:40,616 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'zei@@', 'ge', 'ich', 'diese', 'zwei', 'Di@@', 'a@@', 'st', 'be@@', 'tra@@', 'cht@@', 'en,', 'die', 'die', 'P@@', 'ol@@', 'it@@', 'ik@@', 'en', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te.', '</s>']
2023-05-30 17:17:40,616 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 17:17:40,616 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 17:17:40,616 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr zeige ich diese zwei Diast betrachten, die die Politiken drei Millionen Jahre alt hatte, die die letzten drei Millionen Jahre alt hatte, die die letzten drei Millionen Jahre alt hatte.
2023-05-30 17:17:40,616 - INFO - joeynmt.training - Example #1
2023-05-30 17:17:40,616 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 17:17:40,616 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 17:17:40,616 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'ern@@', 'st', 'der', 'ern@@', 'st', 'dieses', 'spe@@', 'zi@@', 'ell', 'dieses', 'spe@@', 'zi@@', 'ell', 'ist,', 'weil', 'es', 'nicht', 'die', 'D@@', 'ik@@', 'te', 'der', 'E@@', 'is@@', 'e', 'der', 'E@@', 'is@@', 'e', 'zei@@', 'gen.', '</s>']
2023-05-30 17:17:40,616 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 17:17:40,616 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 17:17:40,616 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der ernst der ernst dieses speziell dieses speziell ist, weil es nicht die Dikte der Eise der Eise zeigen.
2023-05-30 17:17:40,616 - INFO - joeynmt.training - Example #2
2023-05-30 17:17:40,616 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 17:17:40,616 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 17:17:40,616 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'k@@', 'ul@@', 'ul@@', 'l', 'ist', 'in', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'l', 'ist', 'in', 'der', 'K@@', 'la@@', 'ss@@', 'en@@', 'der', 'uns', 'in', 'der', 'L@@', 'age', 'kl@@', 'im@@', 'it@@', 'ä@@', 'ts@@', 'y@@', 'ste@@', 'm@@', 's.', '</s>']
2023-05-30 17:17:40,616 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 17:17:40,617 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 17:17:40,617 - INFO - joeynmt.training - 	Hypothesis: Die Eiskulull ist in der Nordpoll ist in der Klassender uns in der Lage klimitätsystems.
2023-05-30 17:17:40,617 - INFO - joeynmt.training - Example #3
2023-05-30 17:17:40,617 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 17:17:40,617 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 17:17:40,617 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'p@@', 'pen', 'in', 'der', 'S@@', 'omm@@', 'er', 'und', 'in', 'der', 'S@@', 'omm@@', 'er', 'S@@', 'omm@@', 'er', 'in', 'der', 'S@@', 'omm@@', 'en.', '</s>']
2023-05-30 17:17:40,617 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 17:17:40,617 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 17:17:40,617 - INFO - joeynmt.training - 	Hypothesis: Es ist in der Winter und Krimppen in der Sommer und in der Sommer Sommer in der Sommen.
2023-05-30 17:17:40,617 - INFO - joeynmt.training - Example #4
2023-05-30 17:17:40,617 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 17:17:40,617 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 17:17:40,617 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', 'ste', 'Di@@', 'a', 'die', 'ich', 'zei@@', 'ge', 'Ihnen', 'ist', 'eine', 'Ver@@', 'schn@@', 'ell@@', 'te', 'Ver@@', 'si@@', 'on', 'der', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert.', '</s>']
2023-05-30 17:17:40,617 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 17:17:40,617 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 17:17:40,617 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia die ich zeige Ihnen ist eine Verschnellte Version der letzten 25 Jahren passiert.
2023-05-30 17:17:56,847 - INFO - joeynmt.training - Epoch   4, Step:    12600, Batch Loss:     1.704916, Batch Acc: 0.467850, Tokens per Sec:     4691, Lr: 0.000300
2023-05-30 17:18:12,986 - INFO - joeynmt.training - Epoch   4, Step:    12700, Batch Loss:     1.876549, Batch Acc: 0.472320, Tokens per Sec:     4663, Lr: 0.000300
2023-05-30 17:18:28,888 - INFO - joeynmt.training - Epoch   4, Step:    12800, Batch Loss:     1.912490, Batch Acc: 0.469245, Tokens per Sec:     4888, Lr: 0.000300
2023-05-30 17:18:44,545 - INFO - joeynmt.training - Epoch   4, Step:    12900, Batch Loss:     1.922553, Batch Acc: 0.474203, Tokens per Sec:     4947, Lr: 0.000300
2023-05-30 17:19:00,151 - INFO - joeynmt.training - Epoch   4, Step:    13000, Batch Loss:     1.818816, Batch Acc: 0.467628, Tokens per Sec:     4768, Lr: 0.000300
2023-05-30 17:19:00,151 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 17:19:00,151 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 17:20:09,889 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.02, ppl:   7.51, acc:   0.42, generation: 69.7294[sec], evaluation: 0.0000[sec]
2023-05-30 17:20:09,890 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 17:20:09,969 - INFO - joeynmt.helpers - delete models/transformer_model2/10500.ckpt
2023-05-30 17:20:09,970 - INFO - joeynmt.training - Example #0
2023-05-30 17:20:09,970 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 17:20:09,970 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 17:20:09,970 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'zei@@', 'ge', 'ich', 'diese', 'bei@@', 'den', 'Di@@', 'a@@', 'st', 'be@@', 'tra@@', 'cht@@', 'en,', 'dass', 'die', 'P@@', 'ol@@', 'it@@', 'ik@@', 'en', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'war', 'etwa', 'die', 'Ab@@', 's@@', 'icht', 'der', 'U@@', 'S@@', 'A', 'ge@@', 'k@@', 'ap@@', ',', 'mit', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pf@@', 'en.', '</s>']
2023-05-30 17:20:09,970 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 17:20:09,970 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 17:20:09,970 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr zeige ich diese beiden Diast betrachten, dass die Politiken drei Millionen Jahre alt war etwa die Absicht der USA gekap, mit 40% gekrompfen.
2023-05-30 17:20:09,970 - INFO - joeynmt.training - Example #1
2023-05-30 17:20:09,970 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 17:20:09,970 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 17:20:09,970 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'The@@', 'ma', 'der', 'ern@@', 'st@@', 'h@@', 'af@@', 't', 'das', 'Problem', 'der', 'Sp@@', 'e@@', 'zi@@', 'el@@', 'n', 'des', 'E@@', 'is', 'zei@@', 't@@', 'au@@', 'ch@@', 'te@@', 's,', 'weil', 'es', 'nicht', 'die', 'D@@', 'ik@@', 'er@@', 'kenn@@', 't', 'sehen.', '</s>']
2023-05-30 17:20:09,971 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 17:20:09,971 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 17:20:09,971 - INFO - joeynmt.training - 	Hypothesis: Aber das Thema der ernsthaft das Problem der Spezieln des Eis zeitauchtes, weil es nicht die Dikerkennt sehen.
2023-05-30 17:20:09,971 - INFO - joeynmt.training - Example #2
2023-05-30 17:20:09,971 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 17:20:09,971 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 17:20:09,971 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sk@@', 'it@@', 'on@@', 'e', 'in', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'is', 'in', 'gew@@', 'iss@@', 'er', 'S@@', 'in@@', 'n', 'des', 'Her@@', 'z', 'des', 'G@@', 'lob@@', 'alen', 'K@@', 'l@@', 'im@@', 'a', 'kl@@', 'im@@', 'a', 'zu', 'ver@@', 'br@@', 'eit@@', 'et', 'und', 'das', 'Z@@', 'eu@@', 'g', 'un@@', 'be@@', '.', '</s>']
2023-05-30 17:20:09,971 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 17:20:09,971 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 17:20:09,971 - INFO - joeynmt.training - 	Hypothesis: Die Eisskitone in der Nordpolis in gewisser Sinn des Herz des Globalen Klima klima zu verbreitet und das Zeug unbe.
2023-05-30 17:20:09,971 - INFO - joeynmt.training - Example #3
2023-05-30 17:20:09,971 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 17:20:09,971 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 17:20:09,971 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'also', 'in', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'rei@@', 'se', 'in', 'der', 'S@@', 'omm@@', 'er', 'in', 'der', 'S@@', 'omm@@', 'er', 'S@@', 'omm@@', 'er', 'in', 'der', 'S@@', 'omm@@', 'er', 'S@@', 'om@@', 'mer@@', '.', '</s>']
2023-05-30 17:20:09,971 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 17:20:09,971 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 17:20:09,971 - INFO - joeynmt.training - 	Hypothesis: Es ist also in der Winter und Kreise in der Sommer in der Sommer Sommer in der Sommer Sommer.
2023-05-30 17:20:09,971 - INFO - joeynmt.training - Example #4
2023-05-30 17:20:09,971 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 17:20:09,971 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 17:20:09,971 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', 'ste', 'Di@@', 'a', 'die', 'ich', 'zei@@', 'ge', 'ein', 'Ver@@', 'si@@', 'on', 'der', 'letzten', '2@@', '5', 'Jahre', 'pass@@', 'iert.', '</s>']
2023-05-30 17:20:09,972 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 17:20:09,972 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 17:20:09,972 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia die ich zeige ein Version der letzten 25 Jahre passiert.
2023-05-30 17:20:26,196 - INFO - joeynmt.training - Epoch   4, Step:    13100, Batch Loss:     1.842872, Batch Acc: 0.474142, Tokens per Sec:     4722, Lr: 0.000300
2023-05-30 17:20:41,187 - INFO - joeynmt.training - Epoch   4, Step:    13200, Batch Loss:     1.741494, Batch Acc: 0.463970, Tokens per Sec:     5046, Lr: 0.000300
2023-05-30 17:20:56,617 - INFO - joeynmt.training - Epoch   4, Step:    13300, Batch Loss:     1.779886, Batch Acc: 0.469735, Tokens per Sec:     4802, Lr: 0.000300
2023-05-30 17:21:12,565 - INFO - joeynmt.training - Epoch   4, Step:    13400, Batch Loss:     1.826351, Batch Acc: 0.459698, Tokens per Sec:     4782, Lr: 0.000300
2023-05-30 17:21:29,222 - INFO - joeynmt.training - Epoch   4, Step:    13500, Batch Loss:     1.801323, Batch Acc: 0.468049, Tokens per Sec:     4491, Lr: 0.000300
2023-05-30 17:21:29,222 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 17:21:29,222 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 17:22:58,288 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.00, ppl:   7.42, acc:   0.43, generation: 89.0576[sec], evaluation: 0.0000[sec]
2023-05-30 17:22:58,290 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 17:22:58,369 - INFO - joeynmt.helpers - delete models/transformer_model2/11000.ckpt
2023-05-30 17:22:58,369 - INFO - joeynmt.training - Example #0
2023-05-30 17:22:58,370 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 17:22:58,370 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 17:22:58,370 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'lie@@', 'ß', 'ich', 'diese', 'zwei', 'Di@@', 'a@@', 'st', 'be@@', 'tra@@', 'cht@@', 'en,', 'dass', 'die', 'P@@', 'ol@@', 'i@@', 'zi@@', 'f@@', 'i@@', 'ge@@', '-@@', 'S@@', 'k@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'die', 'die', 'V@@', 'S@@', 'A', 'von', 'V@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'von', 'V@@', 'S@@', ',', 'mit', '4@@', '0', 'Prozent', 'von', '4@@', '0', 'Prozent', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pf@@', 'en.', '</s>']
2023-05-30 17:22:58,370 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 17:22:58,370 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 17:22:58,370 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr ließ ich diese zwei Diast betrachten, dass die Polizifige-Skap, die die letzten drei Millionen Jahre alt hatte, die die VSA von VSA mit 40 Prozent von VS, mit 40 Prozent von 40 Prozent gekrompfen.
2023-05-30 17:22:58,370 - INFO - joeynmt.training - Example #1
2023-05-30 17:22:58,370 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 17:22:58,370 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 17:22:58,370 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'die', 'Er@@', 'n@@', 'ähr@@', 'ung', 'dieser', 'spe@@', 'zi@@', 'ell', 'dieses', 'spe@@', 'zi@@', 'ell', 'Problem', 'weil', 'es', 'nicht', 'die', 'T@@', 'ik@@', 'el', 'des', 'E@@', 'is', 'zei@@', 'gen.', '</s>']
2023-05-30 17:22:58,370 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 17:22:58,370 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 17:22:58,370 - INFO - joeynmt.training - 	Hypothesis: Aber das ist die Ernährung dieser speziell dieses speziell Problem weil es nicht die Tikel des Eis zeigen.
2023-05-30 17:22:58,370 - INFO - joeynmt.training - Example #2
2023-05-30 17:22:58,370 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 17:22:58,370 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 17:22:58,370 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sk@@', 'it@@', 'on@@', 'on@@', '-@@', 'P@@', 'ol@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'er', 'S@@', 'in@@', 'n', 'des', 'H@@', 'ol@@', 'z@@', 'es', 'uns', 'in', 'der', 'K@@', 'la@@', 'ss@@', 'en@@', 'des', 'H@@', 'and@@', 'y@@', 'ste@@', 'm@@', 's.', '</s>']
2023-05-30 17:22:58,370 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 17:22:58,370 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 17:22:58,370 - INFO - joeynmt.training - 	Hypothesis: Die Eisskitonon-Poll ist in gewisser Sinn des Holzes uns in der Klassendes Handystems.
2023-05-30 17:22:58,371 - INFO - joeynmt.training - Example #3
2023-05-30 17:22:58,371 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 17:22:58,371 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 17:22:58,371 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', 'in@@', 'ter', 'und', 'k@@', 'rei@@', 's@@', 'en.', '</s>']
2023-05-30 17:22:58,371 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 17:22:58,371 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 17:22:58,371 - INFO - joeynmt.training - 	Hypothesis: Es ist in der Winter und kreisen.
2023-05-30 17:22:58,371 - INFO - joeynmt.training - Example #4
2023-05-30 17:22:58,371 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 17:22:58,371 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 17:22:58,371 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', 'ste', 'Di@@', 'a', 'die', 'ich', 'zei@@', 'ge', 'Ihnen', 'zei@@', 'gt', 'eine', 'Ver@@', 'si@@', 'on', 'von', 'was', 'es', 'die', 'letzten', '2@@', '5', 'Jahre', 'pass@@', 'iert.', '</s>']
2023-05-30 17:22:58,371 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 17:22:58,371 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 17:22:58,371 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia die ich zeige Ihnen zeigt eine Version von was es die letzten 25 Jahre passiert.
2023-05-30 17:23:14,132 - INFO - joeynmt.training - Epoch   4, Step:    13600, Batch Loss:     1.871825, Batch Acc: 0.467031, Tokens per Sec:     4719, Lr: 0.000300
2023-05-30 17:23:28,693 - INFO - joeynmt.training - Epoch   4, Step:    13700, Batch Loss:     1.822012, Batch Acc: 0.462926, Tokens per Sec:     5031, Lr: 0.000300
2023-05-30 17:23:44,228 - INFO - joeynmt.training - Epoch   4, Step:    13800, Batch Loss:     2.009217, Batch Acc: 0.472989, Tokens per Sec:     4856, Lr: 0.000300
2023-05-30 17:24:01,179 - INFO - joeynmt.training - Epoch   4, Step:    13900, Batch Loss:     1.988052, Batch Acc: 0.469585, Tokens per Sec:     4422, Lr: 0.000300
2023-05-30 17:24:17,420 - INFO - joeynmt.training - Epoch   4, Step:    14000, Batch Loss:     1.959230, Batch Acc: 0.467292, Tokens per Sec:     4746, Lr: 0.000300
2023-05-30 17:24:17,420 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 17:24:17,420 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 17:25:32,752 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.00, ppl:   7.42, acc:   0.43, generation: 75.3231[sec], evaluation: 0.0000[sec]
2023-05-30 17:25:32,753 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 17:25:32,831 - INFO - joeynmt.helpers - delete models/transformer_model2/11500.ckpt
2023-05-30 17:25:32,831 - INFO - joeynmt.training - Example #0
2023-05-30 17:25:32,831 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 17:25:32,831 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 17:25:32,831 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'lie@@', 'ß', 'ich', 'diese', 'zwei', 'Di@@', 'a@@', 'st', 'sehen', 'um', 'die', 'P@@', 'ol@@', 'it@@', 'ik@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hatte', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hatte', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'war,', 'die', 'die', 'U@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A', 'war.', '</s>']
2023-05-30 17:25:32,831 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 17:25:32,831 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 17:25:32,831 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr ließ ich diese zwei Diast sehen um die Politik, die die letzten drei Millionen Jahre alt hatte die letzten drei Millionen Jahre alt hatte die letzten drei Millionen Jahre alt war, die die USA mit 40 Prozent der USA, mit 40 Prozent der USA war.
2023-05-30 17:25:32,831 - INFO - joeynmt.training - Example #1
2023-05-30 17:25:32,831 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 17:25:32,832 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 17:25:32,832 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'Bil@@', 'd@@', 'sch@@', 'ä@@', 'tz@@', 't', 'das', 'Er@@', 'st', 'dieser', 'spe@@', 'zi@@', 'f@@', 'ischen', 'Proble@@', 'me', 'weil', 'es', 'nicht', 'die', 'D@@', 'ik@@', 'te', 'der', 'E@@', 'is', 'zei@@', 'gt', 'sehen.', '</s>']
2023-05-30 17:25:32,832 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 17:25:32,832 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 17:25:32,832 - INFO - joeynmt.training - 	Hypothesis: Aber das Bildschätzt das Erst dieser spezifischen Probleme weil es nicht die Dikte der Eis zeigt sehen.
2023-05-30 17:25:32,832 - INFO - joeynmt.training - Example #2
2023-05-30 17:25:32,832 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 17:25:32,832 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 17:25:32,832 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sk@@', 'it@@', 'on@@', 'e', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'is', 'in', 'der', 'K@@', 'la@@', 'ss@@', 'en@@', 'de@@', 'ck@@', 't', 'der', 'G@@', 'lob@@', 'al@@', 'er', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 'n', '</s>']
2023-05-30 17:25:32,832 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 17:25:32,832 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 17:25:32,832 - INFO - joeynmt.training - 	Hypothesis: Die Eisskitone auf der Nordpolis in der Klassendeckt der Globaler Klimawandeln
2023-05-30 17:25:32,832 - INFO - joeynmt.training - Example #3
2023-05-30 17:25:32,832 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 17:25:32,832 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 17:25:32,832 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'p@@', 'fin@@', 'de@@', 't.', '</s>']
2023-05-30 17:25:32,832 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 17:25:32,832 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 17:25:32,832 - INFO - joeynmt.training - 	Hypothesis: Es ist in der Winter und Krimpfindet.
2023-05-30 17:25:32,832 - INFO - joeynmt.training - Example #4
2023-05-30 17:25:32,832 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 17:25:32,832 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 17:25:32,833 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'näch@@', 'ste', 'Di@@', 'a', 'der', 'zei@@', 'gt', 'eine', 'Ver@@', 'schn@@', 'ell@@', 'te', 'Ver@@', 'n@@', 'un@@', 'd,', 'was', 'die', 'letzten', '2@@', '5', 'Jahre', 'pass@@', 'iert.', '</s>']
2023-05-30 17:25:32,833 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 17:25:32,833 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 17:25:32,833 - INFO - joeynmt.training - 	Hypothesis: Und die nächste Dia der zeigt eine Verschnellte Vernund, was die letzten 25 Jahre passiert.
2023-05-30 17:25:48,190 - INFO - joeynmt.training - Epoch   4, Step:    14100, Batch Loss:     1.704718, Batch Acc: 0.467680, Tokens per Sec:     4822, Lr: 0.000300
2023-05-30 17:26:03,784 - INFO - joeynmt.training - Epoch   4, Step:    14200, Batch Loss:     1.817946, Batch Acc: 0.470686, Tokens per Sec:     4695, Lr: 0.000300
2023-05-30 17:26:20,054 - INFO - joeynmt.training - Epoch   4, Step:    14300, Batch Loss:     1.751450, Batch Acc: 0.469806, Tokens per Sec:     4578, Lr: 0.000300
2023-05-30 17:26:35,605 - INFO - joeynmt.training - Epoch   4, Step:    14400, Batch Loss:     1.852485, Batch Acc: 0.471228, Tokens per Sec:     5047, Lr: 0.000300
2023-05-30 17:26:50,837 - INFO - joeynmt.training - Epoch   4, Step:    14500, Batch Loss:     1.842724, Batch Acc: 0.467122, Tokens per Sec:     5077, Lr: 0.000300
2023-05-30 17:26:50,837 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 17:26:50,837 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 17:28:14,653 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.99, ppl:   7.29, acc:   0.43, generation: 83.8072[sec], evaluation: 0.0000[sec]
2023-05-30 17:28:14,653 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 17:28:14,734 - INFO - joeynmt.helpers - delete models/transformer_model2/12000.ckpt
2023-05-30 17:28:14,736 - INFO - joeynmt.training - Example #0
2023-05-30 17:28:14,736 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 17:28:14,736 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 17:28:14,736 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'lie@@', 'ß', 'ich', 'diese', 'zwei', 'Di@@', 'a@@', 'st', 'sehen', 'um', 'die', 'P@@', 'ol@@', 'i@@', 'sk@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hatte', 'etwa', 'die', 'Gr@@', 'ö@@', 'ß@@', 'e', 'der', 'U@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A', 'zu', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'it@@', 'ik@@', 'en', 'war.', '</s>']
2023-05-30 17:28:14,736 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 17:28:14,736 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 17:28:14,736 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr ließ ich diese zwei Diast sehen um die Poliskap, die die letzten drei Millionen Jahre alt hatte, die letzten drei Millionen Jahre alt hatte etwa die Größe der USA mit 40 Prozent der USA zu zeigen, dass die Politiken war.
2023-05-30 17:28:14,736 - INFO - joeynmt.training - Example #1
2023-05-30 17:28:14,736 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 17:28:14,737 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 17:28:14,737 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'F@@', 'ol@@', 'ie', 'der', 'Be@@', 'de@@', 'ut@@', 'ung', 'dieser', 'spe@@', 'zi@@', 'elle', 'Problem', 'weil', 'es', 'nicht', 'die', 'd@@', 'ik@@', 'te', 'D@@', 'ik@@', 'er@@', 'n.', '</s>']
2023-05-30 17:28:14,737 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 17:28:14,737 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 17:28:14,737 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Folie der Bedeutung dieser spezielle Problem weil es nicht die dikte Dikern.
2023-05-30 17:28:14,737 - INFO - joeynmt.training - Example #2
2023-05-30 17:28:14,737 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 17:28:14,737 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 17:28:14,737 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sk@@', 'it@@', 'o@@', 's', 'in', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'is', 'in', 'der', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 'n', 'in', 'der', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', '-@@', 'S@@', 'ti@@', 'm@@', 'me@@', '.', '</s>']
2023-05-30 17:28:14,737 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 17:28:14,737 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 17:28:14,737 - INFO - joeynmt.training - 	Hypothesis: Die Eisskitos in der Nordpolis in der Klimawandeln in der Klimawandel-Stimme.
2023-05-30 17:28:14,737 - INFO - joeynmt.training - Example #3
2023-05-30 17:28:14,737 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 17:28:14,737 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 17:28:14,737 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'sch@@', 'ließ@@', 't', 'in', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'im@@', 'p@@', 'la@@', 'sse', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'im@@', 'ation', 'in', 'den', 'S@@', 'omm@@', 'er', 'S@@', 'om@@', 'mer@@', '.', '</s>']
2023-05-30 17:28:14,737 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 17:28:14,737 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 17:28:14,737 - INFO - joeynmt.training - 	Hypothesis: Es schließt in der Winter und Kimplasse in den Sommer und Kimation in den Sommer Sommer.
2023-05-30 17:28:14,737 - INFO - joeynmt.training - Example #4
2023-05-30 17:28:14,737 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 17:28:14,737 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 17:28:14,737 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', 'ste', 'Di@@', 'a', 'der', 'der', 'ich', 'Ihnen', 'zei@@', 'gt', 'eine', 'ver@@', 'n@@', 'etz@@', 'te', 'Ver@@', 'si@@', 'on', 'von', 'dem', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert.', '</s>']
2023-05-30 17:28:14,738 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 17:28:14,738 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 17:28:14,738 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia der der ich Ihnen zeigt eine vernetzte Version von dem letzten 25 Jahren passiert.
2023-05-30 17:28:29,724 - INFO - joeynmt.training - Epoch   4, Step:    14600, Batch Loss:     1.687176, Batch Acc: 0.474010, Tokens per Sec:     4878, Lr: 0.000300
2023-05-30 17:28:45,305 - INFO - joeynmt.training - Epoch   4, Step:    14700, Batch Loss:     1.850237, Batch Acc: 0.471112, Tokens per Sec:     4816, Lr: 0.000300
2023-05-30 17:29:01,765 - INFO - joeynmt.training - Epoch   4, Step:    14800, Batch Loss:     1.845045, Batch Acc: 0.468377, Tokens per Sec:     4680, Lr: 0.000300
2023-05-30 17:29:18,276 - INFO - joeynmt.training - Epoch   4, Step:    14900, Batch Loss:     1.809523, Batch Acc: 0.469184, Tokens per Sec:     4668, Lr: 0.000300
2023-05-30 17:29:33,306 - INFO - joeynmt.training - Epoch   4, Step:    15000, Batch Loss:     1.755067, Batch Acc: 0.475056, Tokens per Sec:     4994, Lr: 0.000300
2023-05-30 17:29:33,306 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 17:29:33,306 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 17:30:42,091 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.98, ppl:   7.24, acc:   0.43, generation: 68.7765[sec], evaluation: 0.0000[sec]
2023-05-30 17:30:42,092 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 17:30:42,170 - INFO - joeynmt.helpers - delete models/transformer_model2/12500.ckpt
2023-05-30 17:30:42,170 - INFO - joeynmt.training - Example #0
2023-05-30 17:30:42,170 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 17:30:42,170 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 17:30:42,170 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'lie@@', 'ß', 'ich', 'diese', 'zwei', 'Di@@', 'a@@', 'st', 'sehen', 'um', 'zu', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'i@@', 'o', 'ge@@', 'zei@@', 'gt', 'ha@@', 'be,', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'etwa', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te.', '</s>']
2023-05-30 17:30:42,171 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 17:30:42,171 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 17:30:42,171 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr ließ ich diese zwei Diast sehen um zu zeigen, dass die Polio gezeigt habe, die letzten drei Millionen Jahre etwa die letzten drei Millionen Jahre alt hatte.
2023-05-30 17:30:42,171 - INFO - joeynmt.training - Example #1
2023-05-30 17:30:42,171 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 17:30:42,171 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 17:30:42,171 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Er@@', 'ste', 'der', 'ern@@', 'sten', 'dieses', 'spe@@', 'zi@@', 'f@@', 'ische', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'D@@', 'ik@@', 'te', 'des', 'E@@', 'is@@', 'e', 'zei@@', 'gen.', '</s>']
2023-05-30 17:30:42,171 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 17:30:42,171 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 17:30:42,171 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Erste der ernsten dieses spezifische Problem ist, weil es nicht die Dikte des Eise zeigen.
2023-05-30 17:30:42,171 - INFO - joeynmt.training - Example #2
2023-05-30 17:30:42,171 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 17:30:42,171 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 17:30:42,171 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sk@@', 'it@@', 'on@@', 'e', 'ist', 'in', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'is', 'in', 'der', 'K@@', 'la@@', 'ss@@', 'en@@', 'des', 'H@@', 'ar@@', 't', 'von', 'uns', 'g@@', 'lob@@', 'al@@', 'er', 'K@@', 'li@@', 'ma@@', 'wan@@', 'z@@', 'y@@', 'ste@@', 'm.', '</s>']
2023-05-30 17:30:42,171 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 17:30:42,171 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 17:30:42,171 - INFO - joeynmt.training - 	Hypothesis: Die Eisskitone ist in der Nordpolis in der Klassendes Hart von uns globaler Klimawanzystem.
2023-05-30 17:30:42,171 - INFO - joeynmt.training - Example #3
2023-05-30 17:30:42,171 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 17:30:42,171 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 17:30:42,171 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'rei@@', 'se', 'in', 'der', 'S@@', 'om@@', 'mer@@', '.', '</s>']
2023-05-30 17:30:42,172 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 17:30:42,172 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 17:30:42,172 - INFO - joeynmt.training - 	Hypothesis: Es ist in der Winter und Kreise in der Sommer.
2023-05-30 17:30:42,172 - INFO - joeynmt.training - Example #4
2023-05-30 17:30:42,172 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 17:30:42,172 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 17:30:42,172 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'der', 'näch@@', 'ste', 'Di@@', 'a', 'der', 'ich', 'zei@@', 'ge', 'Ihnen', 'ist', 'eine', 'Ver@@', 'si@@', 'on', 'der', 'letzten', '2@@', '5', 'Jahre', 'al@@', 't', 'ist.', '</s>']
2023-05-30 17:30:42,172 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 17:30:42,172 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 17:30:42,172 - INFO - joeynmt.training - 	Hypothesis: Und der nächste Dia der ich zeige Ihnen ist eine Version der letzten 25 Jahre alt ist.
2023-05-30 17:30:58,646 - INFO - joeynmt.training - Epoch   4, Step:    15100, Batch Loss:     1.822640, Batch Acc: 0.473467, Tokens per Sec:     4574, Lr: 0.000300
2023-05-30 17:31:14,645 - INFO - joeynmt.training - Epoch   4, Step:    15200, Batch Loss:     1.818011, Batch Acc: 0.477601, Tokens per Sec:     4712, Lr: 0.000300
2023-05-30 17:31:30,204 - INFO - joeynmt.training - Epoch   4, Step:    15300, Batch Loss:     1.962821, Batch Acc: 0.472377, Tokens per Sec:     4970, Lr: 0.000300
2023-05-30 17:31:45,924 - INFO - joeynmt.training - Epoch   4, Step:    15400, Batch Loss:     1.937416, Batch Acc: 0.476394, Tokens per Sec:     4864, Lr: 0.000300
2023-05-30 17:32:01,578 - INFO - joeynmt.training - Epoch   4, Step:    15500, Batch Loss:     1.830149, Batch Acc: 0.476021, Tokens per Sec:     4913, Lr: 0.000300
2023-05-30 17:32:01,578 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 17:32:01,578 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 17:33:12,082 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.98, ppl:   7.22, acc:   0.43, generation: 70.4964[sec], evaluation: 0.0000[sec]
2023-05-30 17:33:12,083 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 17:33:12,158 - INFO - joeynmt.helpers - delete models/transformer_model2/13000.ckpt
2023-05-30 17:33:12,161 - INFO - joeynmt.training - Example #0
2023-05-30 17:33:12,161 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 17:33:12,161 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 17:33:12,161 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'lie@@', 'ß', 'ich', 'diese', 'zwei', 'Di@@', 'a@@', 'st', 'auf', 'die', 'F@@', 'ol@@', 'ie', 'zu', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'it@@', 'ik', 'in', 'der', 'letzten', 'drei', 'Millionen', 'Jahre', 'etwa', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'un@@', 'gefä@@', 'hr', 'die', 'F@@', 'a@@', 'h@@', 'n', 'des', 'V@@', 'A@@', 'ut@@', 'o', 'der', 'V@@', 'or', '4@@', '0', 'Prozent', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'war.', '</s>']
2023-05-30 17:33:12,161 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 17:33:12,161 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 17:33:12,161 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr ließ ich diese zwei Diast auf die Folie zu zeigen, dass die Politik in der letzten drei Millionen Jahre etwa die letzten drei Millionen Jahre ungefähr die Fahn des VAuto der Vor 40 Prozent gekrompen war.
2023-05-30 17:33:12,161 - INFO - joeynmt.training - Example #1
2023-05-30 17:33:12,161 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 17:33:12,161 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 17:33:12,161 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'unter@@', 'sch@@', 'ä@@', 'tz@@', 't', 'sich', 'die', 'ern@@', 'st@@', 'h@@', 'af@@', 't', 'dieses', 'Sp@@', 'e@@', 'zi@@', 'f@@', 'ischen', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'D@@', 'ik@@', 'te', 'der', 'E@@', 'is', 'sehen.', '</s>']
2023-05-30 17:33:12,162 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 17:33:12,162 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 17:33:12,162 - INFO - joeynmt.training - 	Hypothesis: Aber das unterschätzt sich die ernsthaft dieses Spezifischen Problem ist, weil es nicht die Dikte der Eis sehen.
2023-05-30 17:33:12,162 - INFO - joeynmt.training - Example #2
2023-05-30 17:33:12,162 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 17:33:12,162 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 17:33:12,162 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'k@@', 'ut@@', 'ier@@', 'ung', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'is', 'in', 'der', 'K@@', 'l@@', 'im@@', 'a', 'in', 'der', 'K@@', 'l@@', 'im@@', 'a', 'zu', 'be@@', 'komm@@', 'en.', '</s>']
2023-05-30 17:33:12,162 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 17:33:12,162 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 17:33:12,162 - INFO - joeynmt.training - 	Hypothesis: Die Eiskutierung auf der Nordpolis in der Klima in der Klima zu bekommen.
2023-05-30 17:33:12,162 - INFO - joeynmt.training - Example #3
2023-05-30 17:33:12,162 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 17:33:12,162 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 17:33:12,162 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'den', 'S@@', 'om@@', 'mer@@', '.', '</s>']
2023-05-30 17:33:12,162 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 17:33:12,162 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 17:33:12,162 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Krimft in den Sommer.
2023-05-30 17:33:12,162 - INFO - joeynmt.training - Example #4
2023-05-30 17:33:12,162 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 17:33:12,162 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 17:33:12,162 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', 'ste', 'Di@@', 'a', 'die', 'ich', 'Ihnen', 'zei@@', 'gt', 'eine', 'ver@@', 'br@@', 'eit@@', 'ige', 'Ver@@', 'si@@', 'on', 'von', 'einem', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.', '</s>']
2023-05-30 17:33:12,163 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 17:33:12,163 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 17:33:12,163 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia die ich Ihnen zeigt eine verbreitige Version von einem letzten 25 Jahren passiert ist.
2023-05-30 17:33:28,171 - INFO - joeynmt.training - Epoch   4, Step:    15600, Batch Loss:     1.897890, Batch Acc: 0.474223, Tokens per Sec:     4785, Lr: 0.000300
2023-05-30 17:33:44,404 - INFO - joeynmt.training - Epoch   4, Step:    15700, Batch Loss:     2.005889, Batch Acc: 0.475110, Tokens per Sec:     4548, Lr: 0.000300
2023-05-30 17:34:00,110 - INFO - joeynmt.training - Epoch   4, Step:    15800, Batch Loss:     1.771759, Batch Acc: 0.474399, Tokens per Sec:     4694, Lr: 0.000300
2023-05-30 17:34:15,963 - INFO - joeynmt.training - Epoch   4, Step:    15900, Batch Loss:     1.799490, Batch Acc: 0.472962, Tokens per Sec:     4733, Lr: 0.000300
2023-05-30 17:34:31,026 - INFO - joeynmt.training - Epoch   4, Step:    16000, Batch Loss:     1.813697, Batch Acc: 0.471131, Tokens per Sec:     4956, Lr: 0.000300
2023-05-30 17:34:31,027 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 17:34:31,027 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 17:35:46,682 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.97, ppl:   7.18, acc:   0.43, generation: 75.6466[sec], evaluation: 0.0000[sec]
2023-05-30 17:35:46,683 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 17:35:46,760 - INFO - joeynmt.helpers - delete models/transformer_model2/13500.ckpt
2023-05-30 17:35:46,761 - INFO - joeynmt.training - Example #0
2023-05-30 17:35:46,761 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 17:35:46,761 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 17:35:46,761 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'o@@', 'ch', 'lie@@', 'ß', 'ich', 'diese', 'zwei', 'Di@@', 'a@@', 'st', 'auf', 'die', 'T@@', 'on@@', 'en,', 'die', 'die', 'P@@', 'ol@@', 'ol@@', 'ik@@', 'en', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hatte', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hatte', 'die', 'Re@@', 'de', 'der', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0', 'Prozent', 'von', '4@@', '0', 'Prozent', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'war.', '</s>']
2023-05-30 17:35:46,761 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 17:35:46,761 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 17:35:46,761 - INFO - joeynmt.training - 	Hypothesis: Loch ließ ich diese zwei Diast auf die Tonen, die die Pololiken drei Millionen Jahre alt hatte die letzten drei Millionen Jahre alt hatte die Rede der USA, mit 40 Prozent der USA, mit 40 Prozent von 40 Prozent gekrompen war.
2023-05-30 17:35:46,761 - INFO - joeynmt.training - Example #1
2023-05-30 17:35:46,761 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 17:35:46,761 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 17:35:46,761 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'die', 'Er@@', 'n@@', 'ähr@@', 'ung', 'der', 'Er@@', 'n@@', 'ähr@@', 'ung', 'dieses', 'spe@@', 'zi@@', 'f@@', 'ik@@', 'al@@', 'es', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'D@@', 'ik@@', 'te', 'der', 'E@@', 'is@@', 'e', 'des', 'E@@', 'is@@', 's', 'zei@@', 'gen.', '</s>']
2023-05-30 17:35:46,761 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 17:35:46,761 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 17:35:46,761 - INFO - joeynmt.training - 	Hypothesis: Aber das ist die Ernährung der Ernährung dieses spezifikales Problem ist, weil es nicht die Dikte der Eise des Eiss zeigen.
2023-05-30 17:35:46,761 - INFO - joeynmt.training - Example #2
2023-05-30 17:35:46,761 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 17:35:46,761 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 17:35:46,761 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'k@@', 'ut@@', 'iert', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'is', 'ist', 'in', 'gew@@', 'is@@', 'se', 'S@@', 'in@@', 'n', 'des', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 'n@@', 'is@@', 'se', 'von', 'uns', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'wan@@', 'd@@', '-@@', 'K@@', 'li@@', 'ma@@', 'wan@@', 'd@@', '-@@', 'K@@', 'li@@', 'ma@@', '-@@', 'K@@', 'li@@', 'ma@@', '-@@', 'K@@', 'li@@', 'ma@@', 'wan@@', 'd@@', 'l@@', 'ung', '</s>']
2023-05-30 17:35:46,762 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 17:35:46,762 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 17:35:46,762 - INFO - joeynmt.training - 	Hypothesis: Die Eiskutiert auf der Nordpolis ist in gewisse Sinn des Klimawandelnisse von uns globalen Klimawand-Klimawand-Klima-Klima-Klimawandlung
2023-05-30 17:35:46,762 - INFO - joeynmt.training - Example #3
2023-05-30 17:35:46,762 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 17:35:46,762 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 17:35:46,762 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'aus', 'dem', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'p@@', 'pen', 'in', 'der', 'S@@', 'omm@@', 'er', 'in', 'der', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'im@@', 'p@@', 'en@@', 'en@@', 'd.', '</s>']
2023-05-30 17:35:46,762 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 17:35:46,762 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 17:35:46,762 - INFO - joeynmt.training - 	Hypothesis: Es ist aus dem Winter und Krimppen in der Sommer in der Sommer und Krimpenend.
2023-05-30 17:35:46,762 - INFO - joeynmt.training - Example #4
2023-05-30 17:35:46,762 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 17:35:46,762 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 17:35:46,762 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'näch@@', 'ste', 'Di@@', 'a', 'die', 'ich', 'zei@@', 'ge', 'Ihnen', 'eine', 'ver@@', 'schn@@', 'ell@@', 'te', 'Ver@@', 'si@@', 'on', 'von', 'de@@', 'm,', 'was', 'die', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert.', '</s>']
2023-05-30 17:35:46,762 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 17:35:46,762 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 17:35:46,762 - INFO - joeynmt.training - 	Hypothesis: Und die nächste Dia die ich zeige Ihnen eine verschnellte Version von dem, was die letzten 25 Jahren passiert.
2023-05-30 17:36:02,489 - INFO - joeynmt.training - Epoch   4, Step:    16100, Batch Loss:     1.763061, Batch Acc: 0.479216, Tokens per Sec:     4840, Lr: 0.000300
2023-05-30 17:36:18,331 - INFO - joeynmt.training - Epoch   4, Step:    16200, Batch Loss:     1.892354, Batch Acc: 0.473408, Tokens per Sec:     4817, Lr: 0.000300
2023-05-30 17:36:33,999 - INFO - joeynmt.training - Epoch   4, Step:    16300, Batch Loss:     1.747302, Batch Acc: 0.475069, Tokens per Sec:     4906, Lr: 0.000300
2023-05-30 17:36:49,963 - INFO - joeynmt.training - Epoch   4, Step:    16400, Batch Loss:     1.803621, Batch Acc: 0.479155, Tokens per Sec:     4844, Lr: 0.000300
2023-05-30 17:37:05,897 - INFO - joeynmt.training - Epoch   4, Step:    16500, Batch Loss:     1.696074, Batch Acc: 0.473760, Tokens per Sec:     4564, Lr: 0.000300
2023-05-30 17:37:05,898 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 17:37:05,898 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 17:38:25,468 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.96, ppl:   7.07, acc:   0.44, generation: 79.5616[sec], evaluation: 0.0000[sec]
2023-05-30 17:38:25,469 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 17:38:25,550 - INFO - joeynmt.helpers - delete models/transformer_model2/14000.ckpt
2023-05-30 17:38:25,551 - INFO - joeynmt.training - Example #0
2023-05-30 17:38:25,551 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 17:38:25,551 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 17:38:25,551 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I@@', 'm', 'Jahr', 'lie@@', 'ß', 'ich', 'diese', 'zwei', 'Di@@', 'a@@', 'st', 'zei@@', 'g@@', 'te,', 'um', 'zu', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'it@@', 'ik', 'in', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hatte', 'etwa', 'die', 'Gr@@', 'ö@@', 'ß@@', 'e', 'der', 'U@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'war.', '</s>']
2023-05-30 17:38:25,551 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 17:38:25,551 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 17:38:25,551 - INFO - joeynmt.training - 	Hypothesis: Im Jahr ließ ich diese zwei Diast zeigte, um zu zeigen, dass die Politik in drei Millionen Jahre alt hatte, die die letzten drei Millionen Jahre alt hatte etwa die Größe der USA mit 40 Prozent gekrompen war.
2023-05-30 17:38:25,551 - INFO - joeynmt.training - Example #1
2023-05-30 17:38:25,551 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 17:38:25,551 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 17:38:25,551 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'wirklich', 'der', 'Er@@', 'st@@', 'ens', 'der', 'ern@@', 'st', 'dieses', 'spe@@', 'zi@@', 'f@@', 'ische', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'D@@', 'ik@@', 'te', 'des', 'E@@', 'is', 'zei@@', 'gen.', '</s>']
2023-05-30 17:38:25,551 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 17:38:25,551 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 17:38:25,552 - INFO - joeynmt.training - 	Hypothesis: Aber das ist wirklich der Erstens der ernst dieses spezifische Problem ist, weil es nicht die Dikte des Eis zeigen.
2023-05-30 17:38:25,552 - INFO - joeynmt.training - Example #2
2023-05-30 17:38:25,552 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 17:38:25,552 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 17:38:25,552 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'k@@', 'ut@@', 'iert', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'is', 'in', 'der', 'K@@', 'la@@', 'ss@@', 'en@@', 'der', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 'n', 'unserer', 'G@@', 'lob@@', 'al@@', 'er', 'K@@', 'li@@', 'ma@@', 'y@@', 'ste@@', 'm.', '</s>']
2023-05-30 17:38:25,552 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 17:38:25,552 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 17:38:25,552 - INFO - joeynmt.training - 	Hypothesis: Die Eiskutiert auf der Nordpolis in der Klassender Klimawandeln unserer Globaler Klimaystem.
2023-05-30 17:38:25,552 - INFO - joeynmt.training - Example #3
2023-05-30 17:38:25,552 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 17:38:25,552 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 17:38:25,552 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'rei@@', 's', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'k@@', 'rei@@', 's@@', 'en.', '</s>']
2023-05-30 17:38:25,552 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 17:38:25,552 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 17:38:25,552 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Kreis in den Sommer in den Sommer und Krimft in den Sommer und kreisen.
2023-05-30 17:38:25,552 - INFO - joeynmt.training - Example #4
2023-05-30 17:38:25,552 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 17:38:25,552 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 17:38:25,552 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', 'ste', 'Di@@', 'a', 'die', 'ich', 'zei@@', 'ge', 'zei@@', 'gt,', 'ist', 'ein', 'ver@@', 'n@@', 'etz@@', 't,', 'was', 'die', 'letzten', '2@@', '5', 'Jahre', 'gesch@@', 'eh@@', 'en', 'wird.', '</s>']
2023-05-30 17:38:25,552 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 17:38:25,552 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 17:38:25,552 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia die ich zeige zeigt, ist ein vernetzt, was die letzten 25 Jahre geschehen wird.
2023-05-30 17:38:41,473 - INFO - joeynmt.training - Epoch   4, Step:    16600, Batch Loss:     1.813331, Batch Acc: 0.477921, Tokens per Sec:     4767, Lr: 0.000300
2023-05-30 17:38:48,597 - INFO - joeynmt.training - Epoch   4: total training loss 7616.41
2023-05-30 17:38:48,597 - INFO - joeynmt.training - EPOCH 5
2023-05-30 17:38:57,063 - INFO - joeynmt.training - Epoch   5, Step:    16700, Batch Loss:     1.753597, Batch Acc: 0.482914, Tokens per Sec:     4708, Lr: 0.000300
2023-05-30 17:39:13,128 - INFO - joeynmt.training - Epoch   5, Step:    16800, Batch Loss:     1.819933, Batch Acc: 0.492160, Tokens per Sec:     4724, Lr: 0.000300
2023-05-30 17:39:29,214 - INFO - joeynmt.training - Epoch   5, Step:    16900, Batch Loss:     1.834442, Batch Acc: 0.489460, Tokens per Sec:     4686, Lr: 0.000300
2023-05-30 17:39:45,470 - INFO - joeynmt.training - Epoch   5, Step:    17000, Batch Loss:     1.633192, Batch Acc: 0.490549, Tokens per Sec:     4693, Lr: 0.000300
2023-05-30 17:39:45,470 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 17:39:45,470 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 17:41:03,414 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.96, ppl:   7.09, acc:   0.44, generation: 77.9346[sec], evaluation: 0.0000[sec]
2023-05-30 17:41:03,493 - INFO - joeynmt.helpers - delete models/transformer_model2/14500.ckpt
2023-05-30 17:41:03,494 - INFO - joeynmt.training - Example #0
2023-05-30 17:41:03,494 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 17:41:03,494 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 17:41:03,494 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'lie@@', 'ß', 'ich', 'diese', 'bei@@', 'den', 'Di@@', 'a@@', 'st', 'auf', 'die', 'P@@', 'ol@@', 'it@@', 'ik', 'sehen,', 'dass', 'die', 'P@@', 'ol@@', 'le@@', 'k@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hatte', 'die', 'U@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'der', 'V@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'der', 'V@@', 'S@@', '-@@', 'Pro@@', '-@@', 'F@@', 'a@@', 'hr@@', 'el@@', 'and', 'war.', '</s>']
2023-05-30 17:41:03,494 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 17:41:03,494 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 17:41:03,494 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr ließ ich diese beiden Diast auf die Politik sehen, dass die Pollekap, die die letzten drei Millionen Jahre alt hatte die USA mit 40 Prozent der VSA mit 40 Prozent der VS-Pro-Fahreland war.
2023-05-30 17:41:03,494 - INFO - joeynmt.training - Example #1
2023-05-30 17:41:03,494 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 17:41:03,494 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 17:41:03,495 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'das', 'Unter@@', 'sch@@', 'ä@@', 'tz@@', 'lich', 'der', 'ern@@', 'st@@', 'h@@', 'af@@', 't', 'ist,', 'weil', 'es', 'nicht', 'die', 'D@@', 'ik@@', 'er@@', 'kenn@@', 'en.', '</s>']
2023-05-30 17:41:03,495 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 17:41:03,495 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 17:41:03,495 - INFO - joeynmt.training - 	Hypothesis: Aber das ist das Unterschätzlich der ernsthaft ist, weil es nicht die Dikerkennen.
2023-05-30 17:41:03,495 - INFO - joeynmt.training - Example #2
2023-05-30 17:41:03,495 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 17:41:03,495 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 17:41:03,495 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sch@@', 'ien', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'is', 'in', 'der', 'K@@', 'la@@', 'ss@@', 'en@@', 'des', 'Her@@', 'z', 'unserer', 'G@@', 'lob@@', 'al@@', 'er', 'K@@', 'li@@', 'ma@@', 'y@@', 'ste@@', 'm.', '</s>']
2023-05-30 17:41:03,495 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 17:41:03,495 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 17:41:03,495 - INFO - joeynmt.training - 	Hypothesis: Die Eisschien auf der Nordpolis in der Klassendes Herz unserer Globaler Klimaystem.
2023-05-30 17:41:03,495 - INFO - joeynmt.training - Example #3
2023-05-30 17:41:03,495 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 17:41:03,495 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 17:41:03,495 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'der', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'im@@', 'm', '</s>']
2023-05-30 17:41:03,495 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 17:41:03,495 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 17:41:03,495 - INFO - joeynmt.training - 	Hypothesis: Es ist in der Winter und Krimft in der Sommer und Krimm
2023-05-30 17:41:03,495 - INFO - joeynmt.training - Example #4
2023-05-30 17:41:03,495 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 17:41:03,495 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 17:41:03,495 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'näch@@', 'ste', 'Di@@', 'a', 'der', 'ich', 'zei@@', 'ge', 'Ihnen', 'ist', 'eine', 'ver@@', 'schn@@', 'ell@@', 'te', 'Ver@@', 'si@@', 'on', 'von', 'de@@', 'm,', 'was', 'die', 'letzten', '2@@', '5', 'Jahre', 'pass@@', 'iert.', '</s>']
2023-05-30 17:41:03,496 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 17:41:03,496 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 17:41:03,496 - INFO - joeynmt.training - 	Hypothesis: Das nächste Dia der ich zeige Ihnen ist eine verschnellte Version von dem, was die letzten 25 Jahre passiert.
2023-05-30 17:41:19,385 - INFO - joeynmt.training - Epoch   5, Step:    17100, Batch Loss:     1.653474, Batch Acc: 0.492974, Tokens per Sec:     4848, Lr: 0.000300
2023-05-30 17:41:35,302 - INFO - joeynmt.training - Epoch   5, Step:    17200, Batch Loss:     1.732499, Batch Acc: 0.493660, Tokens per Sec:     4821, Lr: 0.000300
2023-05-30 17:41:51,088 - INFO - joeynmt.training - Epoch   5, Step:    17300, Batch Loss:     1.720160, Batch Acc: 0.494155, Tokens per Sec:     4802, Lr: 0.000300
2023-05-30 17:42:06,878 - INFO - joeynmt.training - Epoch   5, Step:    17400, Batch Loss:     1.686432, Batch Acc: 0.490750, Tokens per Sec:     4782, Lr: 0.000300
2023-05-30 17:42:23,455 - INFO - joeynmt.training - Epoch   5, Step:    17500, Batch Loss:     1.818058, Batch Acc: 0.492224, Tokens per Sec:     4554, Lr: 0.000300
2023-05-30 17:42:23,456 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 17:42:23,456 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 17:43:43,900 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.95, ppl:   7.03, acc:   0.44, generation: 80.4358[sec], evaluation: 0.0000[sec]
2023-05-30 17:43:43,901 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 17:43:43,981 - INFO - joeynmt.helpers - delete models/transformer_model2/15000.ckpt
2023-05-30 17:43:43,981 - INFO - joeynmt.training - Example #0
2023-05-30 17:43:43,981 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 17:43:43,981 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 17:43:43,981 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'lie@@', 'ß', 'ich', 'diese', 'zwei', 'D@@', 'aten', 'ge@@', 'zei@@', 'gt', 'ha@@', 'be,', 'um', 'zu', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'it@@', 'ik', 'in', 'der', 'letzten', 'drei', 'Millionen', 'Jahren', 'in', 'der', 'Gr@@', 'ö@@', 'ß@@', 'e', 'der', 'U@@', 'S@@', 'A', 'mit', '4@@', '0@@', '%', 'ge@@', 'k@@', 'auf@@', 't', 'hat@@', 'te,', 'die', 'die', 'U@@', 'S@@', 'A', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pf@@', 'en.', '</s>']
2023-05-30 17:43:43,981 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 17:43:43,981 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 17:43:43,981 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr ließ ich diese zwei Daten gezeigt habe, um zu zeigen, dass die Politik in der letzten drei Millionen Jahren in der Größe der USA mit 40% gekauft hatte, die die USA gekrompfen.
2023-05-30 17:43:43,982 - INFO - joeynmt.training - Example #1
2023-05-30 17:43:43,982 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 17:43:43,982 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 17:43:43,982 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'die', 'ern@@', 'st@@', 'h@@', 'af@@', 't', 'die', 'ern@@', 'st@@', 'h@@', 'af@@', 't', 'das', 'E@@', 'is', 'zei@@', 'gt', 'nicht', 'die', 'T@@', 'ik@@', 'el', 'des', 'E@@', 'is', 'zei@@', 'gt', 'da@@', 'ss@@', 'el@@', 'be', 'zei@@', 'gen.', '</s>']
2023-05-30 17:43:43,982 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 17:43:43,982 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 17:43:43,982 - INFO - joeynmt.training - 	Hypothesis: Aber das ist die ernsthaft die ernsthaft das Eis zeigt nicht die Tikel des Eis zeigt dasselbe zeigen.
2023-05-30 17:43:43,982 - INFO - joeynmt.training - Example #2
2023-05-30 17:43:43,982 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 17:43:43,982 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 17:43:43,982 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sk@@', 'it@@', 'on@@', '-@@', 'E@@', 'is@@', 'k@@', 'ul@@', 'pt@@', 'ur', 'ist', 'in', 'gew@@', 'iss@@', 'er', 'S@@', 'in@@', 'n', 'des', 'H@@', 'ar@@', 't', 'von', 'uns', 'g@@', 'lob@@', 'al@@', 'er', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 's', 'zu', 'ver@@', 'la@@', 'ssen.', '</s>']
2023-05-30 17:43:43,982 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 17:43:43,982 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 17:43:43,982 - INFO - joeynmt.training - 	Hypothesis: Die Eisskiton-Eiskulptur ist in gewisser Sinn des Hart von uns globaler Klimawandels zu verlassen.
2023-05-30 17:43:43,982 - INFO - joeynmt.training - Example #3
2023-05-30 17:43:43,982 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 17:43:43,982 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 17:43:43,982 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'ä@@', 'f@@', 't.', '</s>']
2023-05-30 17:43:43,982 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 17:43:43,982 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 17:43:43,982 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Krimft in den Sommer und Kräft.
2023-05-30 17:43:43,983 - INFO - joeynmt.training - Example #4
2023-05-30 17:43:43,983 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 17:43:43,983 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 17:43:43,983 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', 'ste', 'Di@@', 'a', 'die', 'ich', 'zei@@', 'ge', 'Ihnen', 'eine', 'ver@@', 'schn@@', 'ell@@', 'te', 'Ver@@', 'si@@', 'on', 'von', 'was', 'die', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert.', '</s>']
2023-05-30 17:43:43,983 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 17:43:43,983 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 17:43:43,983 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia die ich zeige Ihnen eine verschnellte Version von was die letzten 25 Jahren passiert.
2023-05-30 17:44:00,470 - INFO - joeynmt.training - Epoch   5, Step:    17600, Batch Loss:     1.652173, Batch Acc: 0.490761, Tokens per Sec:     4619, Lr: 0.000300
2023-05-30 17:44:16,149 - INFO - joeynmt.training - Epoch   5, Step:    17700, Batch Loss:     1.701603, Batch Acc: 0.494250, Tokens per Sec:     4969, Lr: 0.000300
2023-05-30 17:44:32,041 - INFO - joeynmt.training - Epoch   5, Step:    17800, Batch Loss:     1.966975, Batch Acc: 0.485921, Tokens per Sec:     4733, Lr: 0.000300
2023-05-30 17:44:48,704 - INFO - joeynmt.training - Epoch   5, Step:    17900, Batch Loss:     1.730139, Batch Acc: 0.487563, Tokens per Sec:     4483, Lr: 0.000300
2023-05-30 17:45:05,876 - INFO - joeynmt.training - Epoch   5, Step:    18000, Batch Loss:     1.660434, Batch Acc: 0.489686, Tokens per Sec:     4277, Lr: 0.000300
2023-05-30 17:45:05,876 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 17:45:05,876 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 17:46:20,460 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.95, ppl:   7.02, acc:   0.44, generation: 74.5761[sec], evaluation: 0.0000[sec]
2023-05-30 17:46:20,461 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 17:46:20,540 - INFO - joeynmt.helpers - delete models/transformer_model2/15500.ckpt
2023-05-30 17:46:20,540 - INFO - joeynmt.training - Example #0
2023-05-30 17:46:20,540 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 17:46:20,540 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 17:46:20,540 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'lie@@', 'ß', 'ich', 'diese', 'zwei', 'Di@@', 'a@@', 'st', 'auf', 'die', 'T@@', 'ö@@', 'pf@@', 'e', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'it@@', 'ik@@', '-@@', 'S@@', '-@@', 'U@@', '-@@', 'U@@', 'S@@', '-@@', 'A@@', ',', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'die', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A@@', ',', 'die', 'die', 'U@@', 'S@@', 'A', 'war', 'in', 'der', 'U@@', 'S@@', 'A@@', ',', 'die', 'die', 'U@@', 'S@@', 'A@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'die', 'F@@', 'a@@', 'hr@@']
2023-05-30 17:46:20,540 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 17:46:20,540 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 17:46:20,540 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr ließ ich diese zwei Diast auf die Töpfe zeigen, dass die Politik-S-U-US-A, die letzten drei Millionen Jahre alt hatte, die USA, mit 40 Prozent der USA, mit 40 Prozent der USA, mit 40 Prozent der USA, die die USA war in der USA, die die USA, die die letzten drei Millionen Jahre alt hatte, die Fahr
2023-05-30 17:46:20,540 - INFO - joeynmt.training - Example #1
2023-05-30 17:46:20,540 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 17:46:20,540 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 17:46:20,540 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'Unter@@', 'sch@@', 'ä@@', 'tz@@', 't', 'sich', 'die', 'ern@@', 'st', 'dieses', 'spe@@', 'zi@@', 'f@@', 'ische', 'Proble@@', 'm@@', 'l@@', 'ös@@', 'en,', 'weil', 'es', 'nicht', 'die', 'D@@', 'ik@@', 'te', 'des', 'E@@', 'is', 'zei@@', 'gen.', '</s>']
2023-05-30 17:46:20,541 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 17:46:20,541 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 17:46:20,541 - INFO - joeynmt.training - 	Hypothesis: Aber das Unterschätzt sich die ernst dieses spezifische Problemlösen, weil es nicht die Dikte des Eis zeigen.
2023-05-30 17:46:20,541 - INFO - joeynmt.training - Example #2
2023-05-30 17:46:20,541 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 17:46:20,541 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 17:46:20,541 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sch@@', 'ul@@', 'e', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'is', 'in', 'der', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', ',', 'in', 'gew@@', 'iss@@', 'er', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', '-@@', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 's@@', '-@@', 'K@@', 'li@@', 'ma@@', '-@@', 'S@@', 'ti@@', 'm@@', 'ul@@', 'l@@', '.', '</s>']
2023-05-30 17:46:20,541 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 17:46:20,541 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 17:46:20,541 - INFO - joeynmt.training - 	Hypothesis: Die Eisschule auf der Nordpolis in der Klimawandel, in gewisser Klimawandel-Klimawandels-Klima-Stimull.
2023-05-30 17:46:20,541 - INFO - joeynmt.training - Example #3
2023-05-30 17:46:20,541 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 17:46:20,541 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 17:46:20,541 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'der', 'S@@', 'omm@@', 'er', 'in', 'der', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'ä@@', 'f@@', 't.', '</s>']
2023-05-30 17:46:20,541 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 17:46:20,541 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 17:46:20,541 - INFO - joeynmt.training - 	Hypothesis: Es ist in der Winter und Krimft in der Sommer in der Sommer und Kräft.
2023-05-30 17:46:20,541 - INFO - joeynmt.training - Example #4
2023-05-30 17:46:20,541 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 17:46:20,541 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 17:46:20,541 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'näch@@', 'ste', 'Di@@', 'a', 'die', 'ich', 'zei@@', 'ge', 'Ihnen', 'eine', 'ver@@', 'br@@', 'eit@@', 'ige', 'Ver@@', 'si@@', 'on', 'von', 'der', 'letzten', '2@@', '5', 'Jahre', 'gesch@@', 'ie@@', 'h@@', 't', 'ist.', '</s>']
2023-05-30 17:46:20,542 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 17:46:20,542 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 17:46:20,542 - INFO - joeynmt.training - 	Hypothesis: Und die nächste Dia die ich zeige Ihnen eine verbreitige Version von der letzten 25 Jahre geschieht ist.
2023-05-30 17:46:36,316 - INFO - joeynmt.training - Epoch   5, Step:    18100, Batch Loss:     1.724779, Batch Acc: 0.485175, Tokens per Sec:     4848, Lr: 0.000300
2023-05-30 17:46:51,286 - INFO - joeynmt.training - Epoch   5, Step:    18200, Batch Loss:     1.657945, Batch Acc: 0.488318, Tokens per Sec:     5089, Lr: 0.000300
2023-05-30 17:47:06,652 - INFO - joeynmt.training - Epoch   5, Step:    18300, Batch Loss:     1.734061, Batch Acc: 0.488059, Tokens per Sec:     4870, Lr: 0.000300
2023-05-30 17:47:21,912 - INFO - joeynmt.training - Epoch   5, Step:    18400, Batch Loss:     1.790322, Batch Acc: 0.487604, Tokens per Sec:     4967, Lr: 0.000300
2023-05-30 17:47:38,001 - INFO - joeynmt.training - Epoch   5, Step:    18500, Batch Loss:     1.645678, Batch Acc: 0.495796, Tokens per Sec:     4701, Lr: 0.000300
2023-05-30 17:47:38,001 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 17:47:38,001 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 17:48:49,179 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.94, ppl:   6.99, acc:   0.44, generation: 71.1701[sec], evaluation: 0.0000[sec]
2023-05-30 17:48:49,181 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 17:48:49,261 - INFO - joeynmt.helpers - delete models/transformer_model2/16000.ckpt
2023-05-30 17:48:49,262 - INFO - joeynmt.training - Example #0
2023-05-30 17:48:49,262 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 17:48:49,262 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 17:48:49,262 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'zei@@', 'g@@', 'te', 'ich', 'diese', 'bei@@', 'den', 'Jahr', 'zei@@', 'gen', 'und', 'zu', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'i@@', 'sk@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'un@@', 'gefä@@', 'hr', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'mit', '4@@', '0', 'Prozent', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pf@@', 'en.', '</s>']
2023-05-30 17:48:49,262 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 17:48:49,262 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 17:48:49,262 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr zeigte ich diese beiden Jahr zeigen und zu zeigen, dass die Poliskap, die die letzten drei Millionen Jahre ungefähr die letzten drei Millionen Jahre alt hatte, mit 40 Prozent gekrompfen.
2023-05-30 17:48:49,262 - INFO - joeynmt.training - Example #1
2023-05-30 17:48:49,262 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 17:48:49,262 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 17:48:49,262 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Er@@', 'sch@@', 'ä@@', 'tz@@', 'ung', 'der', 'S@@', 'in@@', 'n', 'dieses', 'Sp@@', 'e@@', 'zi@@', 'f@@', 'ik@@', 'er', 'ist,', 'weil', 'es', 'nicht', 'die', 'T@@', 'ik@@', 'te', 'des', 'E@@', 'is', 'zei@@', 'gen.', '</s>']
2023-05-30 17:48:49,263 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 17:48:49,263 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 17:48:49,263 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Erschätzung der Sinn dieses Spezifiker ist, weil es nicht die Tikte des Eis zeigen.
2023-05-30 17:48:49,263 - INFO - joeynmt.training - Example #2
2023-05-30 17:48:49,263 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 17:48:49,263 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 17:48:49,263 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sch@@', 'e@@', '-@@', 'E@@', 'is@@', 'sk@@', 'ul@@', 'ier@@', 'ung', 'ist', 'in', 'gew@@', 'iss@@', 'er', 'S@@', 'inn@@', 'e', 'des', 'Her@@', 'z', 'unserer', 'G@@', 'lob@@', 'al@@', 'es', 'K@@', 'li@@', 'ma@@', 's@@', 'ch', 'der', 'G@@', 'lob@@', 'al@@', 't@@', 'y@@', 'ste@@', 'm.', '</s>']
2023-05-30 17:48:49,263 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 17:48:49,263 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 17:48:49,263 - INFO - joeynmt.training - 	Hypothesis: Die Eissche-Eisskulierung ist in gewisser Sinne des Herz unserer Globales Klimasch der Globaltystem.
2023-05-30 17:48:49,263 - INFO - joeynmt.training - Example #3
2023-05-30 17:48:49,263 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 17:48:49,263 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 17:48:49,263 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'aus', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'p@@', 'li@@', 'z@@', 'ieren.', '</s>']
2023-05-30 17:48:49,263 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 17:48:49,263 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 17:48:49,263 - INFO - joeynmt.training - 	Hypothesis: Es ist aus der Winter und Krimplizieren.
2023-05-30 17:48:49,263 - INFO - joeynmt.training - Example #4
2023-05-30 17:48:49,263 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 17:48:49,263 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 17:48:49,263 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', 'ste', 'Di@@', 'a', 'der', 'der', 'ich', 'zei@@', 'ge', 'Ihnen', 'ist', 'eine', 'ver@@', 'n@@', 'etz@@', 'te', 'Ver@@', 'si@@', 'on', 'von', 'de@@', 'm,', 'was', 'die', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert.', '</s>']
2023-05-30 17:48:49,263 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 17:48:49,263 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 17:48:49,264 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia der der ich zeige Ihnen ist eine vernetzte Version von dem, was die letzten 25 Jahren passiert.
2023-05-30 17:49:05,322 - INFO - joeynmt.training - Epoch   5, Step:    18600, Batch Loss:     1.723861, Batch Acc: 0.494247, Tokens per Sec:     4824, Lr: 0.000300
2023-05-30 17:49:21,470 - INFO - joeynmt.training - Epoch   5, Step:    18700, Batch Loss:     1.716783, Batch Acc: 0.488116, Tokens per Sec:     4745, Lr: 0.000300
2023-05-30 17:49:37,416 - INFO - joeynmt.training - Epoch   5, Step:    18800, Batch Loss:     1.668552, Batch Acc: 0.485517, Tokens per Sec:     4802, Lr: 0.000300
2023-05-30 17:49:53,707 - INFO - joeynmt.training - Epoch   5, Step:    18900, Batch Loss:     1.706943, Batch Acc: 0.490998, Tokens per Sec:     4593, Lr: 0.000300
2023-05-30 17:50:09,660 - INFO - joeynmt.training - Epoch   5, Step:    19000, Batch Loss:     1.704859, Batch Acc: 0.490466, Tokens per Sec:     4833, Lr: 0.000300
2023-05-30 17:50:09,661 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 17:50:09,661 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 17:51:23,029 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.93, ppl:   6.92, acc:   0.44, generation: 73.3602[sec], evaluation: 0.0000[sec]
2023-05-30 17:51:23,030 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 17:51:23,111 - INFO - joeynmt.helpers - delete models/transformer_model2/17000.ckpt
2023-05-30 17:51:23,111 - INFO - joeynmt.training - Example #0
2023-05-30 17:51:23,111 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 17:51:23,111 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 17:51:23,111 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'zei@@', 'ge', 'ich', 'diese', 'zwei', 'Di@@', 'a@@', 'st', 'auf', 'die', 'L@@', 'o@@', 's', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'i@@', 'sk@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'un@@', 'gefä@@', 'hr', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'die', 'die', 'die', 'F@@', 'äh@@', 'igkeit', 'des', 'V@@', 'S@@', ',', 'mit', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pf@@', 'en.', '</s>']
2023-05-30 17:51:23,111 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 17:51:23,111 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 17:51:23,111 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr zeige ich diese zwei Diast auf die Los zeigen, dass die Poliskap, die die letzten drei Millionen Jahre ungefähr drei Millionen Jahre alt hatte, die die die Fähigkeit des VS, mit 40% gekrompfen.
2023-05-30 17:51:23,111 - INFO - joeynmt.training - Example #1
2023-05-30 17:51:23,112 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 17:51:23,112 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 17:51:23,112 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'dieses', 'The@@', 'ma', 'ist', 'der', 'ern@@', 'st@@', 'h@@', 'af@@', 't', 'dieses', 'Sp@@', 'e@@', 'zi@@', 'f@@', 'isch@@', 'es', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'D@@', 'ik@@', 'te', 'des', 'E@@', 'is', 'zei@@', 'gen.', '</s>']
2023-05-30 17:51:23,112 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 17:51:23,112 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 17:51:23,112 - INFO - joeynmt.training - 	Hypothesis: Aber dieses Thema ist der ernsthaft dieses Spezifisches Problem ist, weil es nicht die Dikte des Eis zeigen.
2023-05-30 17:51:23,112 - INFO - joeynmt.training - Example #2
2023-05-30 17:51:23,112 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 17:51:23,112 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 17:51:23,112 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sk@@', 'it@@', 'on@@', 'on@@', '-@@', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'is', 'in', 'der', 'K@@', 'la@@', 'sse', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'S@@', 'in@@', 'n', 'des', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 's', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 's@@', '-@@', 'K@@', 'li@@', 'ma@@', '.', '</s>']
2023-05-30 17:51:23,112 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 17:51:23,112 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 17:51:23,112 - INFO - joeynmt.training - 	Hypothesis: Die Eisskitonon-Nordpolis in der Klasse ist in gewissem Sinn des Klimawandels Klimawandels-Klima.
2023-05-30 17:51:23,112 - INFO - joeynmt.training - Example #3
2023-05-30 17:51:23,112 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 17:51:23,112 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 17:51:23,112 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'aus', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'im@@', 'ft', 'in', 'der', 'S@@', 'omm@@', 'er', 'in', 'der', 'S@@', 'omm@@', 'er', 'her@@', 'vor@@', '.', '</s>']
2023-05-30 17:51:23,112 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 17:51:23,112 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 17:51:23,112 - INFO - joeynmt.training - 	Hypothesis: Es ist aus der Winter und Kimft in der Sommer in der Sommer hervor.
2023-05-30 17:51:23,112 - INFO - joeynmt.training - Example #4
2023-05-30 17:51:23,113 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 17:51:23,113 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 17:51:23,113 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', 'ste', 'Di@@', 'a', 'der', 'ich', 'zei@@', 'ge', 'Ihnen', 'eine', 'ver@@', 'st@@', 'al@@', 't@@', 'ung', 'von', 'de@@', 'm,', 'was', 'die', 'letzten', '2@@', '5', 'Jahre', 'pass@@', 'iert.', '</s>']
2023-05-30 17:51:23,113 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 17:51:23,113 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 17:51:23,113 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia der ich zeige Ihnen eine verstaltung von dem, was die letzten 25 Jahre passiert.
2023-05-30 17:51:39,725 - INFO - joeynmt.training - Epoch   5, Step:    19100, Batch Loss:     1.914899, Batch Acc: 0.494620, Tokens per Sec:     4571, Lr: 0.000300
2023-05-30 17:51:54,780 - INFO - joeynmt.training - Epoch   5, Step:    19200, Batch Loss:     1.813248, Batch Acc: 0.484882, Tokens per Sec:     5148, Lr: 0.000300
2023-05-30 17:52:09,950 - INFO - joeynmt.training - Epoch   5, Step:    19300, Batch Loss:     1.684563, Batch Acc: 0.490646, Tokens per Sec:     4951, Lr: 0.000300
2023-05-30 17:52:25,582 - INFO - joeynmt.training - Epoch   5, Step:    19400, Batch Loss:     1.771908, Batch Acc: 0.487654, Tokens per Sec:     4772, Lr: 0.000300
2023-05-30 17:52:41,562 - INFO - joeynmt.training - Epoch   5, Step:    19500, Batch Loss:     1.817433, Batch Acc: 0.490057, Tokens per Sec:     4739, Lr: 0.000300
2023-05-30 17:52:41,562 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 17:52:41,562 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 17:53:57,890 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.94, ppl:   6.93, acc:   0.44, generation: 76.3195[sec], evaluation: 0.0000[sec]
2023-05-30 17:53:57,967 - INFO - joeynmt.helpers - delete models/transformer_model2/16500.ckpt
2023-05-30 17:53:57,967 - INFO - joeynmt.training - Example #0
2023-05-30 17:53:57,967 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 17:53:57,967 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 17:53:57,967 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'a@@', 'hr@@', 'er@@', 'n,', 'dass', 'die', 'P@@', 'ol@@', 'it@@', 'i@@', 'sk@@', 'ap@@', ',', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'un@@', 'gefä@@', 'hr', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te.', '</s>']
2023-05-30 17:53:57,967 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 17:53:57,967 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 17:53:57,967 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese beiden Fahrern, dass die Politiskap, die letzten drei Millionen Jahre alt hatte, die letzten drei Millionen Jahre ungefähr die letzten drei Millionen Jahre alt hatte.
2023-05-30 17:53:57,967 - INFO - joeynmt.training - Example #1
2023-05-30 17:53:57,968 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 17:53:57,968 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 17:53:57,968 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'Unter@@', 'sch@@', 'lu@@', 'ss', 'das', 'F@@', 'ern@@', 'st', 'des', 'E@@', 'is', 'der', 'F@@', 'a@@', 'hr@@', 'er@@', 'e@@', 'i', 'ist', 'das', 'nicht', 'die', 'D@@', 'ik@@', 'te', 'des', 'E@@', 'is', 'zei@@', 'gen.', '</s>']
2023-05-30 17:53:57,968 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 17:53:57,968 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 17:53:57,968 - INFO - joeynmt.training - 	Hypothesis: Aber das Unterschluss das Fernst des Eis der Fahrerei ist das nicht die Dikte des Eis zeigen.
2023-05-30 17:53:57,968 - INFO - joeynmt.training - Example #2
2023-05-30 17:53:57,968 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 17:53:57,968 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 17:53:57,968 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sk@@', 'it@@', 'on@@', 'on@@', 'e', 'ist', 'in', 'gew@@', 'iss@@', 'er', 'Wei@@', 'se', 'in', 'gew@@', 'iss@@', 'er', 'S@@', 'in@@', 'n', 'des', 'H@@', 'ar@@', 't', 'der', 'G@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', '-@@', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', '.', '</s>']
2023-05-30 17:53:57,968 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 17:53:57,968 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 17:53:57,968 - INFO - joeynmt.training - 	Hypothesis: Die Eisskitonone ist in gewisser Weise in gewisser Sinn des Hart der Globalen Klimawandel-Klimawandel.
2023-05-30 17:53:57,968 - INFO - joeynmt.training - Example #3
2023-05-30 17:53:57,968 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 17:53:57,968 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 17:53:57,968 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'aus', 'dem', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'p@@', 'en@@', '-@@', 'K@@', 'r@@', 'im@@', 'p@@', 'pen', 'in', 'der', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'im@@', 'p@@', 'pen', 'in', 'der', 'S@@', 'om@@', 'mer@@', '.', '</s>']
2023-05-30 17:53:57,968 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 17:53:57,968 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 17:53:57,968 - INFO - joeynmt.training - 	Hypothesis: Es ist aus dem Winter und Krimpen-Krimppen in der Sommer und Krimppen in der Sommer.
2023-05-30 17:53:57,968 - INFO - joeynmt.training - Example #4
2023-05-30 17:53:57,968 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 17:53:57,968 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 17:53:57,969 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'näch@@', 'ste', 'Di@@', 'a', 'der', 'der', 'näch@@', 'ste', 'Di@@', 'en@@', 'st@@', 'ag@@', 'er@@', 'ung', 'ist', 'ein', 'ver@@', 'st@@', 'är@@', 'k@@', 'te,', 'was', 'die', 'letzten', '2@@', '5', 'Jahre', 'gesch@@', 'eh@@', 'en', 'ist.', '</s>']
2023-05-30 17:53:57,969 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 17:53:57,969 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 17:53:57,969 - INFO - joeynmt.training - 	Hypothesis: Der nächste Dia der der nächste Dienstagerung ist ein verstärkte, was die letzten 25 Jahre geschehen ist.
2023-05-30 17:54:14,351 - INFO - joeynmt.training - Epoch   5, Step:    19600, Batch Loss:     1.915170, Batch Acc: 0.486029, Tokens per Sec:     4666, Lr: 0.000300
2023-05-30 17:54:29,702 - INFO - joeynmt.training - Epoch   5, Step:    19700, Batch Loss:     1.687427, Batch Acc: 0.491543, Tokens per Sec:     4922, Lr: 0.000300
2023-05-30 17:54:45,047 - INFO - joeynmt.training - Epoch   5, Step:    19800, Batch Loss:     1.612341, Batch Acc: 0.486042, Tokens per Sec:     5045, Lr: 0.000300
2023-05-30 17:55:01,103 - INFO - joeynmt.training - Epoch   5, Step:    19900, Batch Loss:     1.562962, Batch Acc: 0.489931, Tokens per Sec:     4704, Lr: 0.000300
2023-05-30 17:55:16,397 - INFO - joeynmt.training - Epoch   5, Step:    20000, Batch Loss:     1.737851, Batch Acc: 0.490947, Tokens per Sec:     5088, Lr: 0.000300
2023-05-30 17:55:16,398 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 17:55:16,398 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 17:56:21,559 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.92, ppl:   6.85, acc:   0.45, generation: 65.1530[sec], evaluation: 0.0000[sec]
2023-05-30 17:56:21,561 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 17:56:21,637 - INFO - joeynmt.helpers - delete models/transformer_model2/17500.ckpt
2023-05-30 17:56:21,637 - INFO - joeynmt.training - Example #0
2023-05-30 17:56:21,637 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 17:56:21,637 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 17:56:21,637 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'zei@@', 'ge', 'ich', 'diese', 'bei@@', 'den', 'Di@@', 'as', 'be@@', 'tra@@', 'cht@@', 'en,', 'dass', 'die', 'P@@', 'ol@@', 'i@@', 'sk@@', 'ap@@', ',', 'die', 'die', 'P@@', 'ol@@', 'i@@', 'an@@', 'is@@', 'm@@', 'us', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', 'die', 'Gr@@', 'ö@@', 'ß@@', 'e', 'der', 'U@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A', 'ge@@', 'k@@', 'ü@@', 'm@@', 'mer@@', 't', 'war.', '</s>']
2023-05-30 17:56:21,638 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 17:56:21,638 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 17:56:21,638 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr zeige ich diese beiden Dias betrachten, dass die Poliskap, die die Polianismus in den letzten drei Millionen Jahren die Größe der USA mit 40 Prozent der USA gekümmert war.
2023-05-30 17:56:21,638 - INFO - joeynmt.training - Example #1
2023-05-30 17:56:21,638 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 17:56:21,638 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 17:56:21,638 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'The@@', 'ma', 'ist', 'eigentlich', 'der', 'ern@@', 'st', 'dieses', 'spe@@', 'zi@@', 'f@@', 'ische', 'Problem', 'weil', 'es', 'nicht', 'die', 'D@@', 'ik@@', 'te', 'der', 'E@@', 'is', 'zei@@', 'gen.', '</s>']
2023-05-30 17:56:21,638 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 17:56:21,638 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 17:56:21,638 - INFO - joeynmt.training - 	Hypothesis: Aber das Thema ist eigentlich der ernst dieses spezifische Problem weil es nicht die Dikte der Eis zeigen.
2023-05-30 17:56:21,638 - INFO - joeynmt.training - Example #2
2023-05-30 17:56:21,638 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 17:56:21,638 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 17:56:21,638 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sch@@', 'i@@', 'ck@@', 'e', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'is', 'in', 'der', 'K@@', 'li@@', 'ma@@', 'g', 'uns', 'in', 'der', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', '-@@', 'K@@', 'li@@', 'ma@@', 's@@', 'y@@', 'ste@@', 'm.', '</s>']
2023-05-30 17:56:21,638 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 17:56:21,638 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 17:56:21,638 - INFO - joeynmt.training - 	Hypothesis: Die Eisschicke auf der Nordpolis in der Klimag uns in der Klimawandel-Klimasystem.
2023-05-30 17:56:21,638 - INFO - joeynmt.training - Example #3
2023-05-30 17:56:21,638 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 17:56:21,638 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 17:56:21,638 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'rei@@', 'se', 'in', 'der', 'S@@', 'om@@', 'mer@@', '.', '</s>']
2023-05-30 17:56:21,639 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 17:56:21,639 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 17:56:21,639 - INFO - joeynmt.training - 	Hypothesis: Es ist in der Winter und Kreise in der Sommer.
2023-05-30 17:56:21,639 - INFO - joeynmt.training - Example #4
2023-05-30 17:56:21,639 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 17:56:21,639 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 17:56:21,639 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', 'ste', 'Di@@', 'a', 'der', 'näch@@', 'sten', 'F@@', 'ol@@', 'ie', 'ist', 'eine', 'ver@@', 'stan@@', 'den', 'von', 'dem', 'ich', 'den', 'letzten', '2@@', '5', 'Jahren', 'gesch@@', 'eh@@', 'en', 'ist.', '</s>']
2023-05-30 17:56:21,639 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 17:56:21,639 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 17:56:21,639 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia der nächsten Folie ist eine verstanden von dem ich den letzten 25 Jahren geschehen ist.
2023-05-30 17:56:37,560 - INFO - joeynmt.training - Epoch   5, Step:    20100, Batch Loss:     1.680613, Batch Acc: 0.490035, Tokens per Sec:     4701, Lr: 0.000300
2023-05-30 17:56:53,590 - INFO - joeynmt.training - Epoch   5, Step:    20200, Batch Loss:     1.736520, Batch Acc: 0.489927, Tokens per Sec:     4760, Lr: 0.000300
2023-05-30 17:57:10,826 - INFO - joeynmt.training - Epoch   5, Step:    20300, Batch Loss:     1.739597, Batch Acc: 0.490957, Tokens per Sec:     4196, Lr: 0.000300
2023-05-30 17:57:26,699 - INFO - joeynmt.training - Epoch   5, Step:    20400, Batch Loss:     1.593742, Batch Acc: 0.490500, Tokens per Sec:     4775, Lr: 0.000300
2023-05-30 17:57:42,232 - INFO - joeynmt.training - Epoch   5, Step:    20500, Batch Loss:     1.716180, Batch Acc: 0.494429, Tokens per Sec:     5085, Lr: 0.000300
2023-05-30 17:57:42,232 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 17:57:42,232 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 17:58:45,524 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.91, ppl:   6.77, acc:   0.45, generation: 63.2831[sec], evaluation: 0.0000[sec]
2023-05-30 17:58:45,525 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 17:58:45,603 - INFO - joeynmt.helpers - delete models/transformer_model2/18000.ckpt
2023-05-30 17:58:45,608 - INFO - joeynmt.training - Example #0
2023-05-30 17:58:45,608 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 17:58:45,608 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 17:58:45,608 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'zei@@', 'g@@', 'te', 'ich', 'diese', 'zwei', 'Di@@', 'a@@', 's', 'sehen,', 'um', 'zu', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'i@@', 'il@@', 's', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahre', 'un@@', 'gefä@@', 'hr', 'die', 'Gr@@', 'ö@@', 'ß@@', 'e', 'der', 'U@@', 'S@@', 'A', 'mit', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ü@@', 'm@@', 'mer@@', 'n', 'war.', '</s>']
2023-05-30 17:58:45,608 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 17:58:45,608 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 17:58:45,608 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr zeigte ich diese zwei Dias sehen, um zu zeigen, dass die Poliils in den letzten drei Millionen Jahre ungefähr die Größe der USA mit 40% gekümmern war.
2023-05-30 17:58:45,608 - INFO - joeynmt.training - Example #1
2023-05-30 17:58:45,608 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 17:58:45,608 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 17:58:45,608 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'ein', 'The@@', 'ma', 'der', 'ern@@', 'st@@', 'h@@', 'af@@', 't', 'dieses', 'Sp@@', 'e@@', 'zi@@', 'f@@', 'isch@@', 'es', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'D@@', 'ik@@', 'te', 'des', 'E@@', 'is', 'zei@@', 'gen.', '</s>']
2023-05-30 17:58:45,608 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 17:58:45,608 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 17:58:45,608 - INFO - joeynmt.training - 	Hypothesis: Aber das ist ein Thema der ernsthaft dieses Spezifisches Problem ist, weil es nicht die Dikte des Eis zeigen.
2023-05-30 17:58:45,608 - INFO - joeynmt.training - Example #2
2023-05-30 17:58:45,608 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 17:58:45,608 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 17:58:45,608 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sk@@', 'it@@', 'on@@', 'a@@', 'te', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'is', 'in', 'der', 'K@@', 'la@@', 'ss@@', 'e,', 'die', 'Her@@', 'z', 'des', 'H@@', 'ar@@', 'd@@', '-@@', 'K@@', 'li@@', 'ma@@', 's@@', 'ch', 'des', 'G@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 's@@', 'ch', 'zu', 'ver@@', 'wen@@', 'den.', '</s>']
2023-05-30 17:58:45,609 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 17:58:45,609 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 17:58:45,609 - INFO - joeynmt.training - 	Hypothesis: Die Eisskitonate auf der Nordpolis in der Klasse, die Herz des Hard-Klimasch des Globalen Klimasch zu verwenden.
2023-05-30 17:58:45,609 - INFO - joeynmt.training - Example #3
2023-05-30 17:58:45,609 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 17:58:45,609 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 17:58:45,609 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'p@@', 'en@@', 'en@@', 's.', '</s>']
2023-05-30 17:58:45,609 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 17:58:45,609 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 17:58:45,609 - INFO - joeynmt.training - 	Hypothesis: Es ist in der Winter und Krimpenens.
2023-05-30 17:58:45,609 - INFO - joeynmt.training - Example #4
2023-05-30 17:58:45,609 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 17:58:45,609 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 17:58:45,609 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', 'ste', 'Di@@', 'a', 'der', 'ich', 'zei@@', 'ge', 'Ihnen', 'ist', 'eine', 'ver@@', 'n@@', 'etz@@', 'te', 'Ver@@', 'si@@', 'on', 'von', 'de@@', 'm,', 'was', 'die', 'letzten', '2@@', '5', 'Jahre', 'pass@@', 'iert', 'ist.', '</s>']
2023-05-30 17:58:45,609 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 17:58:45,609 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 17:58:45,609 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia der ich zeige Ihnen ist eine vernetzte Version von dem, was die letzten 25 Jahre passiert ist.
2023-05-30 17:59:00,552 - INFO - joeynmt.training - Epoch   5, Step:    20600, Batch Loss:     1.827928, Batch Acc: 0.490112, Tokens per Sec:     4987, Lr: 0.000300
2023-05-30 17:59:15,612 - INFO - joeynmt.training - Epoch   5, Step:    20700, Batch Loss:     1.893153, Batch Acc: 0.492104, Tokens per Sec:     4992, Lr: 0.000300
2023-05-30 17:59:30,255 - INFO - joeynmt.training - Epoch   5: total training loss 7292.86
2023-05-30 17:59:30,255 - INFO - joeynmt.training - EPOCH 6
2023-05-30 17:59:30,834 - INFO - joeynmt.training - Epoch   6, Step:    20800, Batch Loss:     1.769426, Batch Acc: 0.484776, Tokens per Sec:     3632, Lr: 0.000300
2023-05-30 17:59:45,916 - INFO - joeynmt.training - Epoch   6, Step:    20900, Batch Loss:     1.679629, Batch Acc: 0.507329, Tokens per Sec:     5016, Lr: 0.000300
2023-05-30 18:00:00,436 - INFO - joeynmt.training - Epoch   6, Step:    21000, Batch Loss:     1.849728, Batch Acc: 0.505226, Tokens per Sec:     5107, Lr: 0.000300
2023-05-30 18:00:00,436 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 18:00:00,436 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 18:01:06,888 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.91, ppl:   6.78, acc:   0.45, generation: 66.4437[sec], evaluation: 0.0000[sec]
2023-05-30 18:01:06,965 - INFO - joeynmt.helpers - delete models/transformer_model2/18500.ckpt
2023-05-30 18:01:06,969 - INFO - joeynmt.training - Example #0
2023-05-30 18:01:06,969 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 18:01:06,969 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 18:01:06,969 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'D@@', 'ur@@', 'ch@@', 'b@@', 'ar', 'ge@@', 'zei@@', 'chn@@', 'et,', 'dass', 'die', 'P@@', 'ol@@', 'i@@', 'de@@', 'st@@', 'o', 'die', 'P@@', 'ol@@', 'i@@', 'de@@', 'st@@', 'o', 'im', 'letzten', 'drei', 'Millionen', 'Jahre', 'von', 'etwa', 'etwa', 'die', 'Gr@@', 'ö@@', 'ß@@', 'e', 'von', 'den', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pf@@', 'en.', '</s>']
2023-05-30 18:01:06,969 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 18:01:06,969 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 18:01:06,969 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Durchbar gezeichnet, dass die Polidesto die Polidesto im letzten drei Millionen Jahre von etwa etwa die Größe von den USA, mit 40% gekrompfen.
2023-05-30 18:01:06,969 - INFO - joeynmt.training - Example #1
2023-05-30 18:01:06,969 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 18:01:06,969 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 18:01:06,969 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'F@@', 'ern@@', 'st', 'des', 'E@@', 'is', 'der', 'be@@', 'sonder@@', 's', 'der', 'Sp@@', 'r@@', 'ung', 'der', 'D@@', 'ik@@', 'an@@', 'ischen', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'D@@', 'ik@@', 'te', 'des', 'E@@', 'is', 'zei@@', 'chn@@', 'en.', '</s>']
2023-05-30 18:01:06,969 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 18:01:06,969 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 18:01:06,969 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Fernst des Eis der besonders der Sprung der Dikanischen Problem ist, weil es nicht die Dikte des Eis zeichnen.
2023-05-30 18:01:06,969 - INFO - joeynmt.training - Example #2
2023-05-30 18:01:06,969 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 18:01:06,969 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 18:01:06,970 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sch@@', 'ul@@', 'e', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'is', 'in', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'l', 'ist', 'in', 'der', 'G@@', 'lob@@', 'al@@', 'es', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 'n', 'des', 'G@@', 'lob@@', 'al@@', 'es', 'K@@', 'li@@', 'ma@@', '.', '</s>']
2023-05-30 18:01:06,970 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 18:01:06,970 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 18:01:06,970 - INFO - joeynmt.training - 	Hypothesis: Die Eisschule auf der Nordpolis in der Nordpoll ist in der Globales Klimawandeln des Globales Klima.
2023-05-30 18:01:06,970 - INFO - joeynmt.training - Example #3
2023-05-30 18:01:06,970 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 18:01:06,970 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 18:01:06,970 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'p@@', 'en@@', 'd.', '</s>']
2023-05-30 18:01:06,970 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 18:01:06,970 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 18:01:06,970 - INFO - joeynmt.training - 	Hypothesis: Es ist in der Winter und Krimpend.
2023-05-30 18:01:06,970 - INFO - joeynmt.training - Example #4
2023-05-30 18:01:06,970 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 18:01:06,970 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 18:01:06,970 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'näch@@', 'ste', 'Di@@', 'a', 'die', 'ich', 'zei@@', 'ge', 'Ihnen', 'eine', 'ver@@', 'n@@', 'etz@@', 'te', 'Ver@@', 'si@@', 'on', 'von', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'wur@@', 'de.', '</s>']
2023-05-30 18:01:06,970 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 18:01:06,970 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 18:01:06,970 - INFO - joeynmt.training - 	Hypothesis: Und die nächste Dia die ich zeige Ihnen eine vernetzte Version von 25 Jahren passiert wurde.
2023-05-30 18:01:22,477 - INFO - joeynmt.training - Epoch   6, Step:    21100, Batch Loss:     1.646793, Batch Acc: 0.506065, Tokens per Sec:     4866, Lr: 0.000300
2023-05-30 18:01:37,526 - INFO - joeynmt.training - Epoch   6, Step:    21200, Batch Loss:     1.798331, Batch Acc: 0.502618, Tokens per Sec:     4963, Lr: 0.000300
2023-05-30 18:01:52,619 - INFO - joeynmt.training - Epoch   6, Step:    21300, Batch Loss:     1.611530, Batch Acc: 0.505182, Tokens per Sec:     5019, Lr: 0.000300
2023-05-30 18:02:08,232 - INFO - joeynmt.training - Epoch   6, Step:    21400, Batch Loss:     1.583615, Batch Acc: 0.507191, Tokens per Sec:     4948, Lr: 0.000300
2023-05-30 18:02:24,380 - INFO - joeynmt.training - Epoch   6, Step:    21500, Batch Loss:     1.788116, Batch Acc: 0.507558, Tokens per Sec:     4588, Lr: 0.000300
2023-05-30 18:02:24,381 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 18:02:24,381 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 18:03:44,413 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.92, ppl:   6.84, acc:   0.45, generation: 80.0240[sec], evaluation: 0.0000[sec]
2023-05-30 18:03:44,494 - INFO - joeynmt.helpers - delete models/transformer_model2/19500.ckpt
2023-05-30 18:03:44,497 - INFO - joeynmt.training - Example #0
2023-05-30 18:03:44,498 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 18:03:44,498 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 18:03:44,498 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'zei@@', 'ge', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'zei@@', 'ge', 'zu', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'i@@', 'o@@', 's', 'zei@@', 'gen,', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 'ten', 'St@@', 'aa@@', 'ten', 'des', 'F@@', 'ast@@', 'el@@', 's', 'von', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A@@', ',', '</s>']
2023-05-30 18:03:44,498 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 18:03:44,498 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 18:03:44,498 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr zeige ich diese zwei Dias zeige zu zeigen, dass die Polios zeigen, die die letzten drei Millionen Jahre alten Staaten des Fastels von 40 Prozent der USA, mit 40 Prozent der USA, mit 40 Prozent der USA, mit 40 Prozent der USA,
2023-05-30 18:03:44,498 - INFO - joeynmt.training - Example #1
2023-05-30 18:03:44,498 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 18:03:44,498 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 18:03:44,498 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'The@@', 'ma', 'ist', 'die', 'ern@@', 'st@@', 'h@@', 'af@@', 't', 'das', 'Sp@@', 'e@@', 'zi@@', 'f@@', 'isch@@', 'es', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'D@@', 'ik@@', 'te', 'des', 'E@@', 'is', 'zei@@', 'gt.', '</s>']
2023-05-30 18:03:44,498 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 18:03:44,498 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 18:03:44,498 - INFO - joeynmt.training - 	Hypothesis: Aber das Thema ist die ernsthaft das Spezifisches Problem ist, weil es nicht die Dikte des Eis zeigt.
2023-05-30 18:03:44,498 - INFO - joeynmt.training - Example #2
2023-05-30 18:03:44,498 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 18:03:44,498 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 18:03:44,498 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sch@@', 'e@@', '-@@', 'S@@', 'k@@', 'ul@@', 'pt@@', 'u@@', 'e', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'S@@', 'in@@', 'n', 'des', 'G@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 's', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 's', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', '.', '</s>']
2023-05-30 18:03:44,498 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 18:03:44,498 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 18:03:44,498 - INFO - joeynmt.training - 	Hypothesis: Die Eissche-Skulptue ist in gewissem Sinn des Globalen Klimawandels Klimawandels Klimawandel.
2023-05-30 18:03:44,498 - INFO - joeynmt.training - Example #3
2023-05-30 18:03:44,499 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 18:03:44,499 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 18:03:44,499 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'sch@@', 'ließ@@', 't', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'den', 'S@@', 'om@@', 'mer@@', '.', '</s>']
2023-05-30 18:03:44,499 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 18:03:44,499 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 18:03:44,499 - INFO - joeynmt.training - 	Hypothesis: Es schließt in den Winter und Krimft in den Sommer.
2023-05-30 18:03:44,499 - INFO - joeynmt.training - Example #4
2023-05-30 18:03:44,499 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 18:03:44,499 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 18:03:44,499 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', 'ste', 'Di@@', 'a', 'die', 'ich', 'zei@@', 'ge', 'Ihnen', 'eine', 'ver@@', 'r@@', 'ück@@', 't', 'ist,', 'was', 'die', 'letzten', '2@@', '5', 'Jahre', 'gesch@@', 'a@@', 'h@@', 'n', 'pass@@', 'iert', 'ist.', '</s>']
2023-05-30 18:03:44,499 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 18:03:44,499 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 18:03:44,499 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia die ich zeige Ihnen eine verrückt ist, was die letzten 25 Jahre geschahn passiert ist.
2023-05-30 18:04:01,067 - INFO - joeynmt.training - Epoch   6, Step:    21600, Batch Loss:     1.702434, Batch Acc: 0.505384, Tokens per Sec:     4557, Lr: 0.000300
2023-05-30 18:04:16,262 - INFO - joeynmt.training - Epoch   6, Step:    21700, Batch Loss:     1.718347, Batch Acc: 0.500562, Tokens per Sec:     4864, Lr: 0.000300
2023-05-30 18:04:31,204 - INFO - joeynmt.training - Epoch   6, Step:    21800, Batch Loss:     1.549002, Batch Acc: 0.504354, Tokens per Sec:     4942, Lr: 0.000300
2023-05-30 18:04:45,502 - INFO - joeynmt.training - Epoch   6, Step:    21900, Batch Loss:     1.715557, Batch Acc: 0.502432, Tokens per Sec:     5162, Lr: 0.000300
2023-05-30 18:05:00,600 - INFO - joeynmt.training - Epoch   6, Step:    22000, Batch Loss:     1.640162, Batch Acc: 0.508996, Tokens per Sec:     5037, Lr: 0.000300
2023-05-30 18:05:00,600 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 18:05:00,600 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 18:06:11,017 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.92, ppl:   6.82, acc:   0.45, generation: 70.4089[sec], evaluation: 0.0000[sec]
2023-05-30 18:06:11,095 - INFO - joeynmt.helpers - delete models/transformer_model2/19000.ckpt
2023-05-30 18:06:11,097 - INFO - joeynmt.training - Example #0
2023-05-30 18:06:11,097 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 18:06:11,098 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 18:06:11,098 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'zei@@', 'g@@', 'te', 'ich', 'diese', 'bei@@', 'den', 'Di@@', 'a@@', 'st', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'i@@', 'o@@', 's', 'zei@@', 'g@@', 'te', 'sich', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'die', 'die', 'U@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A', 'ge@@', 'k@@', 'auf@@', 't', 'wur@@', 'de.', '</s>']
2023-05-30 18:06:11,098 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 18:06:11,098 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 18:06:11,098 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr zeigte ich diese beiden Diast zeigen, dass die Polios zeigte sich die letzten drei Millionen Jahre alt hatte, die die letzten drei Millionen Jahre alt hatte, die die USA mit 40 Prozent der USA mit 40 Prozent der USA gekauft wurde.
2023-05-30 18:06:11,098 - INFO - joeynmt.training - Example #1
2023-05-30 18:06:11,098 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 18:06:11,098 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 18:06:11,098 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'ein', 'paar', 'der', 'F@@', 'ern@@', 'st@@', 'h@@', 'af@@', 'tes', 'Proble@@', 'm,', 'weil', 'es', 'nicht', 'die', 'D@@', 'ik@@', 'te', 'des', 'E@@', 'is', 'zei@@', 'gen.', '</s>']
2023-05-30 18:06:11,098 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 18:06:11,098 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 18:06:11,098 - INFO - joeynmt.training - 	Hypothesis: Aber das ist ein paar der Fernsthaftes Problem, weil es nicht die Dikte des Eis zeigen.
2023-05-30 18:06:11,098 - INFO - joeynmt.training - Example #2
2023-05-30 18:06:11,098 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 18:06:11,098 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 18:06:11,098 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sch@@', 'il@@', 'd@@', '-@@', 'K@@', 'li@@', 'ma@@', '-@@', 'P@@', 'ol@@', 'is', 'in', 'der', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', ',', 'das', 'kl@@', 'op@@', 'p@@', 'elt', 'von', 'unser@@', 'em', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', '-@@', 'K@@', 'li@@', 'ma@@', '-@@', 'S@@', 'ti@@', 'm@@', 'me', 'zu', 'ver@@', 'sor@@', 'gen.', '</s>']
2023-05-30 18:06:11,098 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 18:06:11,098 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 18:06:11,098 - INFO - joeynmt.training - 	Hypothesis: Die Eisschild-Klima-Polis in der Klimawandel, das kloppelt von unserem globalen Klima-Klima-Stimme zu versorgen.
2023-05-30 18:06:11,099 - INFO - joeynmt.training - Example #3
2023-05-30 18:06:11,099 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 18:06:11,099 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 18:06:11,099 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'sch@@', 'ließ@@', 'lich', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'im@@', 'ul@@', 'ation', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'im@@', 'p@@', 'pen', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'den', 'S@@', 'omm@@', 'er', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'S@@', 'om@@', 'er.', '</s>']
2023-05-30 18:06:11,099 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 18:06:11,099 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 18:06:11,099 - INFO - joeynmt.training - 	Hypothesis: Es schließlich in den Winter und Krimft in den Sommer und Krimft in den Sommer und Krimft in den Sommer und Krimulation in den Sommer und Krimppen in den Sommer und Krimft in den Sommer Sommer in den Sommer Sommer in den Sommer Somer.
2023-05-30 18:06:11,099 - INFO - joeynmt.training - Example #4
2023-05-30 18:06:11,099 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 18:06:11,099 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 18:06:11,099 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'näch@@', 'ste', 'Di@@', 'a', 'der', 'ich', 'zei@@', 'ge', 'Ihnen', 'ist', 'ein', 'ver@@', 'n@@', 'ell@@', 'er', 'Ver@@', 'si@@', 'on', 'von', 'dem', 'letzten', '2@@', '5', 'Jahre', 'pass@@', 'iert.', '</s>']
2023-05-30 18:06:11,099 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 18:06:11,099 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 18:06:11,099 - INFO - joeynmt.training - 	Hypothesis: Der nächste Dia der ich zeige Ihnen ist ein verneller Version von dem letzten 25 Jahre passiert.
2023-05-30 18:06:27,126 - INFO - joeynmt.training - Epoch   6, Step:    22100, Batch Loss:     1.673513, Batch Acc: 0.506253, Tokens per Sec:     4741, Lr: 0.000300
2023-05-30 18:06:42,598 - INFO - joeynmt.training - Epoch   6, Step:    22200, Batch Loss:     1.668736, Batch Acc: 0.509801, Tokens per Sec:     4979, Lr: 0.000300
2023-05-30 18:06:58,122 - INFO - joeynmt.training - Epoch   6, Step:    22300, Batch Loss:     1.672778, Batch Acc: 0.501941, Tokens per Sec:     4830, Lr: 0.000300
2023-05-30 18:07:13,982 - INFO - joeynmt.training - Epoch   6, Step:    22400, Batch Loss:     1.616071, Batch Acc: 0.504518, Tokens per Sec:     4766, Lr: 0.000300
2023-05-30 18:07:29,192 - INFO - joeynmt.training - Epoch   6, Step:    22500, Batch Loss:     1.583325, Batch Acc: 0.509078, Tokens per Sec:     5052, Lr: 0.000300
2023-05-30 18:07:29,193 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 18:07:29,193 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 18:08:43,071 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.91, ppl:   6.78, acc:   0.45, generation: 73.8695[sec], evaluation: 0.0000[sec]
2023-05-30 18:08:43,151 - INFO - joeynmt.helpers - delete models/transformer_model2/20000.ckpt
2023-05-30 18:08:43,153 - INFO - joeynmt.training - Example #0
2023-05-30 18:08:43,153 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 18:08:43,153 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 18:08:43,153 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ich', 'zei@@', 'ge', 'mich', 'diese', 'zwei', 'Di@@', 'a@@', 'st', 'zei@@', 'g@@', 'te', 'mir', 'diese', 'zwei', 'Di@@', 'a@@', 'st', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'i@@', 'de@@', 'st@@', 'o', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'un@@', 'gefä@@', 'hr', 'die', 'Gr@@', 'ö@@', 'ß@@', 'e', 'der', 'U@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'ge@@', 'k@@', 'ü@@', 'm@@', 'mer@@', 'n', 'war.', '</s>']
2023-05-30 18:08:43,153 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 18:08:43,153 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 18:08:43,153 - INFO - joeynmt.training - 	Hypothesis: Ich zeige mich diese zwei Diast zeigte mir diese zwei Diast zeigen, dass die Polidesto die letzten drei Millionen Jahre ungefähr die Größe der USA mit 40 Prozent gekümmern war.
2023-05-30 18:08:43,153 - INFO - joeynmt.training - Example #1
2023-05-30 18:08:43,154 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 18:08:43,154 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 18:08:43,154 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'The@@', 'ma', 'ist', 'tatsächlich', 'die', 'Er@@', 'ste', 'dieses', 'spe@@', 'zi@@', 'f@@', 'ischen', 'Problem', 'weil', 'es', 'nicht', 'die', 'T@@', 'ik@@', 'te', 'des', 'E@@', 'is', 'zei@@', 'gen.', '</s>']
2023-05-30 18:08:43,154 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 18:08:43,154 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 18:08:43,154 - INFO - joeynmt.training - 	Hypothesis: Aber das Thema ist tatsächlich die Erste dieses spezifischen Problem weil es nicht die Tikte des Eis zeigen.
2023-05-30 18:08:43,154 - INFO - joeynmt.training - Example #2
2023-05-30 18:08:43,154 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 18:08:43,154 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 18:08:43,154 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'k@@', 'ut@@', 'ieren', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'er', 'S@@', 'k@@', 'ul@@', 'pt@@', 'ur', 'in', 'der', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 's@@', '-@@', 'K@@', 'li@@', 'ma@@', '-@@', 'K@@', 'li@@', 'ma@@', '-@@', 'S@@', 'k@@', 'a@@', 'y@@', 'ste@@', 'm.', '</s>']
2023-05-30 18:08:43,154 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 18:08:43,154 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 18:08:43,154 - INFO - joeynmt.training - 	Hypothesis: Die Eiskutieren auf der Nordpol ist in gewisser Skulptur in der Klimawandels-Klima-Klima-Skaystem.
2023-05-30 18:08:43,154 - INFO - joeynmt.training - Example #3
2023-05-30 18:08:43,154 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 18:08:43,154 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 18:08:43,154 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'den', 'S@@', 'om@@', 'mer@@', '.', '</s>']
2023-05-30 18:08:43,154 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 18:08:43,154 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 18:08:43,154 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Krimft in den Sommer.
2023-05-30 18:08:43,154 - INFO - joeynmt.training - Example #4
2023-05-30 18:08:43,155 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 18:08:43,155 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 18:08:43,155 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'der', 'näch@@', 'ste', 'Di@@', 'a', 'der', 'ich', 'zei@@', 'ge', 'Ihnen', 'ist', 'eine', 'ver@@', 'schn@@', 'ell@@', 'te', 'Ver@@', 'si@@', 'on', 'von', '2@@', '5', 'Jahre', 'pass@@', 'iert.', '</s>']
2023-05-30 18:08:43,155 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 18:08:43,155 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 18:08:43,155 - INFO - joeynmt.training - 	Hypothesis: Und der nächste Dia der ich zeige Ihnen ist eine verschnellte Version von 25 Jahre passiert.
2023-05-30 18:08:59,522 - INFO - joeynmt.training - Epoch   6, Step:    22600, Batch Loss:     1.675270, Batch Acc: 0.500249, Tokens per Sec:     4393, Lr: 0.000300
2023-05-30 18:09:16,361 - INFO - joeynmt.training - Epoch   6, Step:    22700, Batch Loss:     1.761825, Batch Acc: 0.503155, Tokens per Sec:     4461, Lr: 0.000300
2023-05-30 18:09:31,896 - INFO - joeynmt.training - Epoch   6, Step:    22800, Batch Loss:     1.663270, Batch Acc: 0.500609, Tokens per Sec:     5070, Lr: 0.000300
2023-05-30 18:09:47,833 - INFO - joeynmt.training - Epoch   6, Step:    22900, Batch Loss:     1.684646, Batch Acc: 0.507941, Tokens per Sec:     4737, Lr: 0.000300
2023-05-30 18:10:03,918 - INFO - joeynmt.training - Epoch   6, Step:    23000, Batch Loss:     1.794151, Batch Acc: 0.499967, Tokens per Sec:     4734, Lr: 0.000300
2023-05-30 18:10:03,918 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 18:10:03,918 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 18:11:19,546 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.90, ppl:   6.71, acc:   0.45, generation: 75.6192[sec], evaluation: 0.0000[sec]
2023-05-30 18:11:19,547 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 18:11:19,626 - INFO - joeynmt.helpers - delete models/transformer_model2/21500.ckpt
2023-05-30 18:11:19,628 - INFO - joeynmt.training - Example #0
2023-05-30 18:11:19,628 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 18:11:19,628 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 18:11:19,628 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'ge@@', 'zei@@', 'gt', 'ha@@', 'be,', 'um', 'zu', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'le@@', 'm', 'letzten', 'drei', 'Millionen', 'Jahre', 'un@@', 'gefä@@', 'hr', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'un@@', 'gefä@@', 'hr', 'die', 'Gr@@', 'ö@@', 'ß@@', 'e', 'der', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0', 'Prozent', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pf@@', 'en.', '</s>']
2023-05-30 18:11:19,628 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 18:11:19,628 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 18:11:19,628 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Dias gezeigt habe, um zu zeigen, dass die Pollem letzten drei Millionen Jahre ungefähr die letzten drei Millionen Jahre ungefähr die Größe der USA, mit 40 Prozent gekrompfen.
2023-05-30 18:11:19,628 - INFO - joeynmt.training - Example #1
2023-05-30 18:11:19,628 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 18:11:19,628 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 18:11:19,628 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'tatsächlich', 'die', 'Er@@', 'ste', 'dieser', 'Art', 'des', 'E@@', 'is', 'dieses', 'E@@', 'is', 'des', 'E@@', 'is', 'zei@@', 't@@', 's.', '</s>']
2023-05-30 18:11:19,629 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 18:11:19,629 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 18:11:19,629 - INFO - joeynmt.training - 	Hypothesis: Aber das ist tatsächlich die Erste dieser Art des Eis dieses Eis des Eis zeits.
2023-05-30 18:11:19,629 - INFO - joeynmt.training - Example #2
2023-05-30 18:11:19,629 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 18:11:19,629 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 18:11:19,629 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sk@@', 'ien', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'is', 'in', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'e', 'ist', 'in', 'der', 'S@@', 'eite', 'unser@@', 'es', 'G@@', 'lob@@', 'al@@', 'er', 'K@@', 'l@@', 'im@@', 'a', 'kl@@', 'at@@', 'ur@@', '.', '</s>']
2023-05-30 18:11:19,629 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 18:11:19,629 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 18:11:19,629 - INFO - joeynmt.training - 	Hypothesis: Die Eisskien auf der Nordpolis in der Nordpole ist in der Seite unseres Globaler Klima klatur.
2023-05-30 18:11:19,629 - INFO - joeynmt.training - Example #3
2023-05-30 18:11:19,629 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 18:11:19,629 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 18:11:19,629 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'der', 'S@@', 'om@@', 'mer@@', '.', '</s>']
2023-05-30 18:11:19,629 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 18:11:19,629 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 18:11:19,629 - INFO - joeynmt.training - 	Hypothesis: Es ist in der Winter und Krimft in den Sommer und Krimft in der Sommer.
2023-05-30 18:11:19,629 - INFO - joeynmt.training - Example #4
2023-05-30 18:11:19,629 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 18:11:19,629 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 18:11:19,629 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'näch@@', 'ste', 'Di@@', 'a', 'die', 'ich', 'zei@@', 'gt', 'eine', 'ver@@', 'n@@', 'un@@', 'gen@@', 'e', 'Ver@@', 'si@@', 'on', 'von', 'de@@', 'm,', 'was', 'die', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert.', '</s>']
2023-05-30 18:11:19,630 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 18:11:19,630 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 18:11:19,630 - INFO - joeynmt.training - 	Hypothesis: Und die nächste Dia die ich zeigt eine vernungene Version von dem, was die letzten 25 Jahren passiert.
2023-05-30 18:11:34,431 - INFO - joeynmt.training - Epoch   6, Step:    23100, Batch Loss:     1.656075, Batch Acc: 0.506990, Tokens per Sec:     5142, Lr: 0.000300
2023-05-30 18:11:49,724 - INFO - joeynmt.training - Epoch   6, Step:    23200, Batch Loss:     1.756891, Batch Acc: 0.502410, Tokens per Sec:     4992, Lr: 0.000300
2023-05-30 18:12:04,868 - INFO - joeynmt.training - Epoch   6, Step:    23300, Batch Loss:     1.676523, Batch Acc: 0.500144, Tokens per Sec:     5056, Lr: 0.000300
2023-05-30 18:12:20,293 - INFO - joeynmt.training - Epoch   6, Step:    23400, Batch Loss:     1.674270, Batch Acc: 0.506800, Tokens per Sec:     5063, Lr: 0.000300
2023-05-30 18:12:35,197 - INFO - joeynmt.training - Epoch   6, Step:    23500, Batch Loss:     1.578042, Batch Acc: 0.503218, Tokens per Sec:     5171, Lr: 0.000300
2023-05-30 18:12:35,197 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 18:12:35,197 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 18:13:50,330 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.90, ppl:   6.68, acc:   0.46, generation: 75.1250[sec], evaluation: 0.0000[sec]
2023-05-30 18:13:50,331 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 18:13:50,406 - INFO - joeynmt.helpers - delete models/transformer_model2/22000.ckpt
2023-05-30 18:13:50,407 - INFO - joeynmt.training - Example #0
2023-05-30 18:13:50,407 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 18:13:50,407 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 18:13:50,407 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'a@@', 's,', 'um', 'zu', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'it@@', 'ik@@', 'en', 'drei', 'Di@@', 'a@@', 'st', 'von', 'drei', 'Millionen', 'Jahre', 'un@@', 'gefä@@', 'hr', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'un@@', 'gefä@@', 'hr', 'die', 'Gr@@', 'ö@@', 'ß@@', 'e', 'der', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0', 'Prozent', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pf@@', 'en.', '</s>']
2023-05-30 18:13:50,407 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 18:13:50,407 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 18:13:50,407 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Dias, um zu zeigen, dass die Politiken drei Diast von drei Millionen Jahre ungefähr die letzten drei Millionen Jahre ungefähr die Größe der USA, mit 40 Prozent gekrompfen.
2023-05-30 18:13:50,407 - INFO - joeynmt.training - Example #1
2023-05-30 18:13:50,407 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 18:13:50,407 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 18:13:50,407 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'tatsächlich', 'die', 'Er@@', 'st@@', 'är@@', 'ung', 'der', 'F@@', 'ern@@', 'sten', 'des', 'E@@', 'is', 'des', 'E@@', 'is', 'des', 'E@@', 'is', 'des', 'E@@', 'is', 'zei@@', 't@@', 'et.', '</s>']
2023-05-30 18:13:50,407 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 18:13:50,408 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 18:13:50,408 - INFO - joeynmt.training - 	Hypothesis: Aber das ist tatsächlich die Erstärung der Fernsten des Eis des Eis des Eis des Eis zeitet.
2023-05-30 18:13:50,408 - INFO - joeynmt.training - Example #2
2023-05-30 18:13:50,408 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 18:13:50,408 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 18:13:50,408 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'k@@', 'ul@@', 'l', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'is', 'in', 'gew@@', 'iss@@', 'em', 'S@@', 'in@@', 'n', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'S@@', 'in@@', 'n', 'des', 'G@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 's', 'kl@@', 'am@@', 'p@@', 'f', 'ist', 'der', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', '.', '</s>']
2023-05-30 18:13:50,408 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 18:13:50,408 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 18:13:50,408 - INFO - joeynmt.training - 	Hypothesis: Die Eiskull auf der Nordpolis in gewissem Sinn ist in gewissem Sinn des Globalen Klimawandels klampf ist der globalen Klimawandel.
2023-05-30 18:13:50,408 - INFO - joeynmt.training - Example #3
2023-05-30 18:13:50,408 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 18:13:50,408 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 18:13:50,408 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'ä@@', 'f@@', 'te', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'ä@@', 'f@@', 't.', '</s>']
2023-05-30 18:13:50,408 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 18:13:50,408 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 18:13:50,408 - INFO - joeynmt.training - 	Hypothesis: Es ist in der Winter und Krimft in den Sommer in den Sommer und Kräfte in den Sommer und Kräft.
2023-05-30 18:13:50,408 - INFO - joeynmt.training - Example #4
2023-05-30 18:13:50,408 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 18:13:50,408 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 18:13:50,408 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'näch@@', 'ste', 'Di@@', 'a', 'die', 'ich', 'zei@@', 'ge', 'Ihnen', 'ist', 'eine', 'ver@@', 'n@@', 'etz@@', 'te', 'Ver@@', 'si@@', 'on', 'von', 'dem', 'letzten', '2@@', '5', 'Jahre', 'pass@@', 'iert.', '</s>']
2023-05-30 18:13:50,408 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 18:13:50,408 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 18:13:50,409 - INFO - joeynmt.training - 	Hypothesis: Und die nächste Dia die ich zeige Ihnen ist eine vernetzte Version von dem letzten 25 Jahre passiert.
2023-05-30 18:14:07,050 - INFO - joeynmt.training - Epoch   6, Step:    23600, Batch Loss:     1.772082, Batch Acc: 0.502609, Tokens per Sec:     4620, Lr: 0.000300
2023-05-30 18:14:22,494 - INFO - joeynmt.training - Epoch   6, Step:    23700, Batch Loss:     1.808309, Batch Acc: 0.503032, Tokens per Sec:     5071, Lr: 0.000300
2023-05-30 18:14:37,918 - INFO - joeynmt.training - Epoch   6, Step:    23800, Batch Loss:     1.563138, Batch Acc: 0.506251, Tokens per Sec:     4901, Lr: 0.000300
2023-05-30 18:14:53,462 - INFO - joeynmt.training - Epoch   6, Step:    23900, Batch Loss:     1.615382, Batch Acc: 0.501159, Tokens per Sec:     4883, Lr: 0.000300
2023-05-30 18:15:09,340 - INFO - joeynmt.training - Epoch   6, Step:    24000, Batch Loss:     1.802546, Batch Acc: 0.505706, Tokens per Sec:     4658, Lr: 0.000300
2023-05-30 18:15:09,340 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 18:15:09,340 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 18:16:23,702 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.90, ppl:   6.66, acc:   0.45, generation: 74.3529[sec], evaluation: 0.0000[sec]
2023-05-30 18:16:23,703 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 18:16:23,775 - INFO - joeynmt.helpers - delete models/transformer_model2/22500.ckpt
2023-05-30 18:16:23,776 - INFO - joeynmt.training - Example #0
2023-05-30 18:16:23,776 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 18:16:23,776 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 18:16:23,776 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'D@@', 'ir@@', 'ch@@', 'te@@', 'u@@', 'er', 'zu', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'i@@', 'sk@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hatte', 'die', 'Gr@@', 'ö@@', 'ß@@', 'e', 'der', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0', 'Prozent', 'ge@@', 'k@@', 'ü@@', 'm@@', 'ten', 'der', 'U@@', 'S@@', 'A', 'ge@@', 'k@@', 'ü@@', 'm@@', 'ten', 'war.', '</s>']
2023-05-30 18:16:23,777 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 18:16:23,777 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 18:16:23,777 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Dirchteuer zu zeigen, dass die Poliskap, die die letzten drei Millionen Jahre alt hatte die Größe der USA, mit 40 Prozent gekümten der USA gekümten war.
2023-05-30 18:16:23,777 - INFO - joeynmt.training - Example #1
2023-05-30 18:16:23,777 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 18:16:23,777 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 18:16:23,777 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'eigentlich', 'der', 'F@@', 'ol@@', 'gen@@', 'des', 'E@@', 'is', 'der', 'F@@', 'a@@', 'hr@@', 'e', 'des', 'E@@', 'is', 'zei@@', 't@@', 'lichen', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'D@@', 'ik@@', 'te', 'der', 'E@@', 'is', 'sehen.', '</s>']
2023-05-30 18:16:23,777 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 18:16:23,777 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 18:16:23,777 - INFO - joeynmt.training - 	Hypothesis: Aber das ist eigentlich der Folgendes Eis der Fahre des Eis zeitlichen Problem ist, weil es nicht die Dikte der Eis sehen.
2023-05-30 18:16:23,777 - INFO - joeynmt.training - Example #2
2023-05-30 18:16:23,777 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 18:16:23,777 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 18:16:23,777 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'k@@', 'ul@@', 'ar@@', 'e', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'is', 'in', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'er', 'Wei@@', 'se', 'kl@@', 'op@@', 'f@@', 'el@@', 'n', '</s>']
2023-05-30 18:16:23,777 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 18:16:23,777 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 18:16:23,777 - INFO - joeynmt.training - 	Hypothesis: Die Eiskulare auf der Nordpolis in der Nordpoll ist in gewisser Weise klopfeln
2023-05-30 18:16:23,777 - INFO - joeynmt.training - Example #3
2023-05-30 18:16:23,777 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 18:16:23,777 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 18:16:23,777 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'der', 'S@@', 'om@@', 'mer@@', '.', '</s>']
2023-05-30 18:16:23,778 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 18:16:23,778 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 18:16:23,778 - INFO - joeynmt.training - 	Hypothesis: Es ist in der Winter und Krimft in der Sommer.
2023-05-30 18:16:23,778 - INFO - joeynmt.training - Example #4
2023-05-30 18:16:23,778 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 18:16:23,778 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 18:16:23,778 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', 'ste', 'Di@@', 'a', 'die', 'ich', 'zei@@', 'ge', 'Ihnen', 'ist', 'ein', 'ver@@', 'schn@@', 'ell@@', 'te', 'Ver@@', 'si@@', 'on', 'von', 'dem', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert.', '</s>']
2023-05-30 18:16:23,778 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 18:16:23,778 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 18:16:23,778 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia die ich zeige Ihnen ist ein verschnellte Version von dem letzten 25 Jahren passiert.
2023-05-30 18:16:40,677 - INFO - joeynmt.training - Epoch   6, Step:    24100, Batch Loss:     2.041742, Batch Acc: 0.505175, Tokens per Sec:     4479, Lr: 0.000300
2023-05-30 18:16:56,522 - INFO - joeynmt.training - Epoch   6, Step:    24200, Batch Loss:     1.555450, Batch Acc: 0.507401, Tokens per Sec:     4797, Lr: 0.000300
2023-05-30 18:17:12,007 - INFO - joeynmt.training - Epoch   6, Step:    24300, Batch Loss:     1.730138, Batch Acc: 0.499120, Tokens per Sec:     4883, Lr: 0.000300
2023-05-30 18:17:27,120 - INFO - joeynmt.training - Epoch   6, Step:    24400, Batch Loss:     1.701221, Batch Acc: 0.500731, Tokens per Sec:     4936, Lr: 0.000300
2023-05-30 18:17:43,206 - INFO - joeynmt.training - Epoch   6, Step:    24500, Batch Loss:     1.631873, Batch Acc: 0.500059, Tokens per Sec:     4772, Lr: 0.000300
2023-05-30 18:17:43,206 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 18:17:43,206 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 18:19:01,825 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.89, ppl:   6.61, acc:   0.46, generation: 78.6100[sec], evaluation: 0.0000[sec]
2023-05-30 18:19:01,826 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 18:19:01,900 - INFO - joeynmt.helpers - delete models/transformer_model2/21000.ckpt
2023-05-30 18:19:01,901 - INFO - joeynmt.training - Example #0
2023-05-30 18:19:01,901 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 18:19:01,901 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 18:19:01,901 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'zei@@', 'ge', 'ich', 'diese', 'zwei', 'D@@', 'ur@@', 'ch@@', 'b@@', 'ar', 'zu', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'i@@', 'o', 'der', 'letzten', 'drei', 'Millionen', 'Jahre', 'un@@', 'gefä@@', 'hr', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'un@@', 'gefä@@', 'hr', 'die', 'Gr@@', 'ö@@', 'ß@@', 'e', 'des', 'V@@', 'A@@', 'st@@', 'el@@', 'and', 'der', 'U@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pf@@', 'en.', '</s>']
2023-05-30 18:19:01,901 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 18:19:01,901 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 18:19:01,901 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr zeige ich diese zwei Durchbar zu zeigen, dass die Polio der letzten drei Millionen Jahre ungefähr die letzten drei Millionen Jahre ungefähr die Größe des VAsteland der USA mit 40 Prozent der USA gekrompfen.
2023-05-30 18:19:01,901 - INFO - joeynmt.training - Example #1
2023-05-30 18:19:01,901 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 18:19:01,901 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 18:19:01,901 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'die', 'F@@', 'ern@@', 'st', 'des', 'E@@', 'is', 'der', 'F@@', 'ern@@', 'st@@', 'h@@', 'af@@', 't', 'das', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'D@@', 'ik@@', 'te', 'der', 'D@@', 'ik@@', 'te', 'des', 'E@@', 'is', 'zei@@', 't.', '</s>']
2023-05-30 18:19:01,901 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 18:19:01,901 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 18:19:01,901 - INFO - joeynmt.training - 	Hypothesis: Aber das ist die Fernst des Eis der Fernsthaft das Problem ist, weil es nicht die Dikte der Dikte des Eis zeit.
2023-05-30 18:19:01,901 - INFO - joeynmt.training - Example #2
2023-05-30 18:19:01,901 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 18:19:01,901 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 18:19:01,901 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'k@@', 'ut@@', 'ier@@', 'ung', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'is', 'in', 'der', 'K@@', 'l@@', 'im@@', 'a', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'der', 'G@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 'h@@', 'af@@', 't', 'unser@@', 'es', 'G@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 's@@', 'z@@', 'y@@', 'ste@@', 'm.', '</s>']
2023-05-30 18:19:01,902 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 18:19:01,902 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 18:19:01,902 - INFO - joeynmt.training - 	Hypothesis: Die Eiskutierung auf der Nordpolis in der Klima ist in gewissem Sinne der Globalen Klimawandelhaft unseres Globalen Klimawandelszystem.
2023-05-30 18:19:01,902 - INFO - joeynmt.training - Example #3
2023-05-30 18:19:01,902 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 18:19:01,902 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 18:19:01,902 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'ä@@', 'm@@', 'pf@@', 't.', '</s>']
2023-05-30 18:19:01,902 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 18:19:01,902 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 18:19:01,902 - INFO - joeynmt.training - 	Hypothesis: Es ist in der Winter und Krämpft.
2023-05-30 18:19:01,902 - INFO - joeynmt.training - Example #4
2023-05-30 18:19:01,902 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 18:19:01,902 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 18:19:01,902 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'der', 'näch@@', 'ste', 'Di@@', 'a', 'die', 'ich', 'zei@@', 'ge', 'Ihnen', 'ist', 'eine', 'ver@@', 'schn@@', 'ell@@', 'te', 'Ver@@', 'si@@', 'on', 'von', 'dem', 'letzten', '2@@', '5', 'Jahre', 'gesch@@', 'eh@@', 'en', 'ist.', '</s>']
2023-05-30 18:19:01,902 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 18:19:01,902 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 18:19:01,902 - INFO - joeynmt.training - 	Hypothesis: Und der nächste Dia die ich zeige Ihnen ist eine verschnellte Version von dem letzten 25 Jahre geschehen ist.
2023-05-30 18:19:17,618 - INFO - joeynmt.training - Epoch   6, Step:    24600, Batch Loss:     1.774231, Batch Acc: 0.497150, Tokens per Sec:     4788, Lr: 0.000300
2023-05-30 18:19:33,599 - INFO - joeynmt.training - Epoch   6, Step:    24700, Batch Loss:     1.678852, Batch Acc: 0.506932, Tokens per Sec:     4798, Lr: 0.000300
2023-05-30 18:19:48,630 - INFO - joeynmt.training - Epoch   6, Step:    24800, Batch Loss:     1.904828, Batch Acc: 0.503046, Tokens per Sec:     5024, Lr: 0.000300
2023-05-30 18:20:04,087 - INFO - joeynmt.training - Epoch   6, Step:    24900, Batch Loss:     1.661606, Batch Acc: 0.501461, Tokens per Sec:     4937, Lr: 0.000300
2023-05-30 18:20:12,990 - INFO - joeynmt.training - Epoch   6: total training loss 7081.11
2023-05-30 18:20:12,990 - INFO - joeynmt.training - EPOCH 7
2023-05-30 18:20:20,262 - INFO - joeynmt.training - Epoch   7, Step:    25000, Batch Loss:     1.588984, Batch Acc: 0.529782, Tokens per Sec:     4717, Lr: 0.000300
2023-05-30 18:20:20,263 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 18:20:20,263 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 18:21:43,595 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.89, ppl:   6.59, acc:   0.46, generation: 83.3232[sec], evaluation: 0.0000[sec]
2023-05-30 18:21:43,596 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 18:21:43,670 - INFO - joeynmt.helpers - delete models/transformer_model2/20500.ckpt
2023-05-30 18:21:43,670 - INFO - joeynmt.training - Example #0
2023-05-30 18:21:43,671 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 18:21:43,671 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 18:21:43,671 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'a@@', 'st', 'ge@@', 'zei@@', 'gt', 'ha@@', 'be,', 'um', 'die', 'P@@', 'ol@@', 'i@@', 'sk@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'die', 'die', 'Gr@@', 'ö@@', 'ß@@', 'e', 'der', 'U@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A', 'ge@@', 'k@@', 'ü@@', 'm@@', 'mer@@', 'n', 'war.', '</s>']
2023-05-30 18:21:43,671 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 18:21:43,671 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 18:21:43,671 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Diast gezeigt habe, um die Poliskap, die die letzten drei Millionen Jahre alt hatte, die die letzten drei Millionen Jahre alt hatte, die die Größe der USA mit 40 Prozent der USA gekümmern war.
2023-05-30 18:21:43,671 - INFO - joeynmt.training - Example #1
2023-05-30 18:21:43,671 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 18:21:43,671 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 18:21:43,671 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'ein', 'Unter@@', 'sch@@', 'ä@@', 'tz@@', 'en,', 'der', 'es', 'spe@@', 'zi@@', 'f@@', 'ische', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'D@@', 'ik@@', 'te', 'des', 'E@@', 'is', 'zei@@', 'gen.', '</s>']
2023-05-30 18:21:43,671 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 18:21:43,671 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 18:21:43,671 - INFO - joeynmt.training - 	Hypothesis: Aber das ist ein Unterschätzen, der es spezifische Problem ist, weil es nicht die Dikte des Eis zeigen.
2023-05-30 18:21:43,671 - INFO - joeynmt.training - Example #2
2023-05-30 18:21:43,671 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 18:21:43,671 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 18:21:43,671 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sk@@', 'ar@@', 'e', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'S@@', 'in@@', 'n', 'des', 'H@@', 'ar@@', 'z', 'von', 'uns', 'g@@', 'lob@@', 'al', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', '-@@', 'K@@', 'li@@', 'ma@@', '-@@', 'K@@', 'li@@', 'ma@@', '.', '</s>']
2023-05-30 18:21:43,672 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 18:21:43,672 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 18:21:43,672 - INFO - joeynmt.training - 	Hypothesis: Die Eisskare auf der Nordpol ist in gewissem Sinn des Harz von uns global Klimawandel-Klima-Klima.
2023-05-30 18:21:43,672 - INFO - joeynmt.training - Example #3
2023-05-30 18:21:43,672 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 18:21:43,672 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 18:21:43,672 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'den', 'S@@', 'om@@', 'mer@@', '.', '</s>']
2023-05-30 18:21:43,672 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 18:21:43,672 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 18:21:43,672 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Krimft in den Sommer.
2023-05-30 18:21:43,672 - INFO - joeynmt.training - Example #4
2023-05-30 18:21:43,672 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 18:21:43,672 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 18:21:43,672 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'näch@@', 'ste', 'Di@@', 'a', 'der', 'ich', 'Ihnen', 'zei@@', 'gt', 'eine', 'ver@@', 'schn@@', 'ell@@', 'te', 'Ver@@', 'si@@', 'on', 'von', 'dem', 'letzten', '2@@', '5', 'Jahren', 'gesch@@', 'eh@@', 'en', 'ist.', '</s>']
2023-05-30 18:21:43,672 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 18:21:43,672 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 18:21:43,672 - INFO - joeynmt.training - 	Hypothesis: Der nächste Dia der ich Ihnen zeigt eine verschnellte Version von dem letzten 25 Jahren geschehen ist.
2023-05-30 18:21:59,939 - INFO - joeynmt.training - Epoch   7, Step:    25100, Batch Loss:     1.819564, Batch Acc: 0.525817, Tokens per Sec:     4632, Lr: 0.000300
2023-05-30 18:22:16,491 - INFO - joeynmt.training - Epoch   7, Step:    25200, Batch Loss:     1.737889, Batch Acc: 0.526078, Tokens per Sec:     4505, Lr: 0.000300
2023-05-30 18:22:31,919 - INFO - joeynmt.training - Epoch   7, Step:    25300, Batch Loss:     1.595097, Batch Acc: 0.522509, Tokens per Sec:     4793, Lr: 0.000300
2023-05-30 18:22:47,297 - INFO - joeynmt.training - Epoch   7, Step:    25400, Batch Loss:     1.725986, Batch Acc: 0.524474, Tokens per Sec:     4898, Lr: 0.000300
2023-05-30 18:23:02,224 - INFO - joeynmt.training - Epoch   7, Step:    25500, Batch Loss:     1.690029, Batch Acc: 0.523911, Tokens per Sec:     5021, Lr: 0.000300
2023-05-30 18:23:02,224 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 18:23:02,224 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 18:24:06,862 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.89, ppl:   6.62, acc:   0.46, generation: 64.6293[sec], evaluation: 0.0000[sec]
2023-05-30 18:24:06,940 - INFO - joeynmt.helpers - delete models/transformer_model2/23000.ckpt
2023-05-30 18:24:06,941 - INFO - joeynmt.training - Example #0
2023-05-30 18:24:06,941 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 18:24:06,941 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 18:24:06,941 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'zei@@', 'g@@', 'te', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'be@@', 'ob@@', 'ach@@', 'ten,', 'dass', 'die', 'P@@', 'ol@@', 'i@@', 'sk@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'die', 'die', 'U@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'ge@@', 'k@@', 'ü@@', 'm@@', 'pen', 'war.', '</s>']
2023-05-30 18:24:06,941 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 18:24:06,941 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 18:24:06,942 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr zeigte ich diese zwei Dias beobachten, dass die Poliskap, die die letzten drei Millionen Jahre alt hatte, die die letzten drei Millionen Jahre alt hatte, die die USA mit 40 Prozent der USA mit 40 Prozent gekümpen war.
2023-05-30 18:24:06,942 - INFO - joeynmt.training - Example #1
2023-05-30 18:24:06,942 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 18:24:06,942 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 18:24:06,942 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'dieses', 'Unter@@', 'sch@@', 'ä@@', 'tz@@', 'te', 'im', 'Gr@@', 'unde', 'dieses', 'spe@@', 'zi@@', 'f@@', 'ische', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'D@@', 'ik@@', 'te', 'des', 'E@@', 'is', 'zei@@', 'gen.', '</s>']
2023-05-30 18:24:06,942 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 18:24:06,942 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 18:24:06,942 - INFO - joeynmt.training - 	Hypothesis: Aber dieses Unterschätzte im Grunde dieses spezifische Problem ist, weil es nicht die Dikte des Eis zeigen.
2023-05-30 18:24:06,942 - INFO - joeynmt.training - Example #2
2023-05-30 18:24:06,942 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 18:24:06,942 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 18:24:06,942 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sch@@', 'ich@@', 'te', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'po@@', 'l', 'in', 'gew@@', 'iss@@', 'em', 'S@@', 'in@@', 'n', 'des', 'H@@', 'är@@', 'z@@', 's', 'unserer', 'G@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 'n@@', '?', '</s>']
2023-05-30 18:24:06,942 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 18:24:06,942 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 18:24:06,942 - INFO - joeynmt.training - 	Hypothesis: Die Eisschichte auf der Nordpol in gewissem Sinn des Härzs unserer Globalen Klimawandeln?
2023-05-30 18:24:06,942 - INFO - joeynmt.training - Example #3
2023-05-30 18:24:06,942 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 18:24:06,942 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 18:24:06,942 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'gibt', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'den', 'S@@', 'om@@', 'mer@@', '.', '</s>']
2023-05-30 18:24:06,942 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 18:24:06,942 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 18:24:06,942 - INFO - joeynmt.training - 	Hypothesis: Es gibt in den Winter und Krimft in den Sommer.
2023-05-30 18:24:06,942 - INFO - joeynmt.training - Example #4
2023-05-30 18:24:06,943 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 18:24:06,943 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 18:24:06,943 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', 'ste', 'Di@@', 'a', 'die', 'ich', 'Ihnen', 'zei@@', 'gen', 'mö@@', 'chte,', 'ist', 'eine', 'ver@@', 'n@@', 'etz@@', 'te', 'Ver@@', 'si@@', 'on', 'von', 'de@@', 'm,', 'was', 'die', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert.', '</s>']
2023-05-30 18:24:06,943 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 18:24:06,943 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 18:24:06,943 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia die ich Ihnen zeigen möchte, ist eine vernetzte Version von dem, was die letzten 25 Jahren passiert.
2023-05-30 18:24:23,639 - INFO - joeynmt.training - Epoch   7, Step:    25600, Batch Loss:     1.588832, Batch Acc: 0.517282, Tokens per Sec:     4602, Lr: 0.000300
2023-05-30 18:24:40,553 - INFO - joeynmt.training - Epoch   7, Step:    25700, Batch Loss:     1.719035, Batch Acc: 0.520515, Tokens per Sec:     4552, Lr: 0.000300
2023-05-30 18:24:56,758 - INFO - joeynmt.training - Epoch   7, Step:    25800, Batch Loss:     1.789783, Batch Acc: 0.513566, Tokens per Sec:     4688, Lr: 0.000300
2023-05-30 18:25:12,044 - INFO - joeynmt.training - Epoch   7, Step:    25900, Batch Loss:     1.601086, Batch Acc: 0.515422, Tokens per Sec:     4972, Lr: 0.000300
2023-05-30 18:25:29,101 - INFO - joeynmt.training - Epoch   7, Step:    26000, Batch Loss:     1.636172, Batch Acc: 0.517779, Tokens per Sec:     4547, Lr: 0.000300
2023-05-30 18:25:29,101 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 18:25:29,101 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 18:26:41,973 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.89, ppl:   6.61, acc:   0.46, generation: 72.8635[sec], evaluation: 0.0000[sec]
2023-05-30 18:26:42,050 - INFO - joeynmt.helpers - delete models/transformer_model2/23500.ckpt
2023-05-30 18:26:42,053 - INFO - joeynmt.training - Example #0
2023-05-30 18:26:42,053 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 18:26:42,053 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 18:26:42,053 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'zei@@', 'g@@', 'te', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'i@@', 'k@@', 'ap@@', ',', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'von', 'un@@', 'gefä@@', 'hr', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'k@@', 'ro@@', 'm@@', 'pen', 'war.', '</s>']
2023-05-30 18:26:42,053 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 18:26:42,053 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 18:26:42,053 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr zeigte ich diese zwei Dias zeigen, dass die Polikap, die letzten drei Millionen Jahre alt von ungefähr die letzten drei Millionen Jahre alt hatte, die letzten drei Millionen Jahre krompen war.
2023-05-30 18:26:42,053 - INFO - joeynmt.training - Example #1
2023-05-30 18:26:42,054 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 18:26:42,054 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 18:26:42,054 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'F@@', 'un@@', 'kti@@', 'on', 'der', 'F@@', 'ern@@', 'st', 'der', 'D@@', 'ik@@', 'te', 'dieses', 'Bil@@', 'd@@', 'sch@@', 'ir@@', 'm', 'zu', 'zei@@', 'gen.', '</s>']
2023-05-30 18:26:42,054 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 18:26:42,054 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 18:26:42,054 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Funktion der Fernst der Dikte dieses Bildschirm zu zeigen.
2023-05-30 18:26:42,054 - INFO - joeynmt.training - Example #2
2023-05-30 18:26:42,054 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 18:26:42,054 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 18:26:42,054 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'k@@', 'ir@@', 'e', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'S@@', 'in@@', 'n', 'der', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 'n', 'von', 'uns', 'g@@', 'lob@@', 'al', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 'n@@', '?', '</s>']
2023-05-30 18:26:42,054 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 18:26:42,054 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 18:26:42,054 - INFO - joeynmt.training - 	Hypothesis: Die Eiskire auf der Nordpol ist in gewissem Sinn der Klimawandeln von uns global Klimawandeln?
2023-05-30 18:26:42,054 - INFO - joeynmt.training - Example #3
2023-05-30 18:26:42,054 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 18:26:42,054 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 18:26:42,054 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'p@@', 'pen', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'im@@', 'p@@', 'pen', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'im@@', 'p@@', 'ri@@', 'pp@@', 'e', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'im@@', 'p@@', 'pen', '</s>']
2023-05-30 18:26:42,054 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 18:26:42,054 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 18:26:42,054 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Krimppen in den Sommer in den Sommer und Krimppen in den Sommer und Krimprippe in den Sommer und Krimppen
2023-05-30 18:26:42,054 - INFO - joeynmt.training - Example #4
2023-05-30 18:26:42,055 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 18:26:42,055 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 18:26:42,055 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'näch@@', 'ste', 'Di@@', 'a', 'der', 'ich', 'zei@@', 'ge', 'Ihnen', 'ist', 'eine', 'ver@@', 'n@@', 'ün@@', 'ft@@', 'ige', 'Ver@@', 'si@@', 'on', 'von', 'de@@', 'm,', 'was', 'die', 'letzten', '2@@', '5', 'Jahre', 'pass@@', 'iert', 'ist.', '</s>']
2023-05-30 18:26:42,055 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 18:26:42,055 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 18:26:42,055 - INFO - joeynmt.training - 	Hypothesis: Der nächste Dia der ich zeige Ihnen ist eine vernünftige Version von dem, was die letzten 25 Jahre passiert ist.
2023-05-30 18:26:58,891 - INFO - joeynmt.training - Epoch   7, Step:    26100, Batch Loss:     1.780949, Batch Acc: 0.517322, Tokens per Sec:     4474, Lr: 0.000300
2023-05-30 18:27:15,463 - INFO - joeynmt.training - Epoch   7, Step:    26200, Batch Loss:     1.667527, Batch Acc: 0.518856, Tokens per Sec:     4514, Lr: 0.000300
2023-05-30 18:27:31,327 - INFO - joeynmt.training - Epoch   7, Step:    26300, Batch Loss:     1.656405, Batch Acc: 0.513444, Tokens per Sec:     4771, Lr: 0.000300
2023-05-30 18:27:47,233 - INFO - joeynmt.training - Epoch   7, Step:    26400, Batch Loss:     1.730878, Batch Acc: 0.511841, Tokens per Sec:     4845, Lr: 0.000300
2023-05-30 18:28:02,232 - INFO - joeynmt.training - Epoch   7, Step:    26500, Batch Loss:     1.606444, Batch Acc: 0.514021, Tokens per Sec:     5050, Lr: 0.000300
2023-05-30 18:28:02,233 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 18:28:02,233 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 18:29:17,431 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.88, ppl:   6.56, acc:   0.46, generation: 75.1899[sec], evaluation: 0.0000[sec]
2023-05-30 18:29:17,432 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 18:29:17,514 - INFO - joeynmt.helpers - delete models/transformer_model2/24000.ckpt
2023-05-30 18:29:17,514 - INFO - joeynmt.training - Example #0
2023-05-30 18:29:17,514 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 18:29:17,514 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 18:29:17,514 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'Di@@', 'a@@', 'st', 'des', 'L@@', 'an@@', 'de@@', 's,', 'die', 'die', 'P@@', 'ol@@', 'i@@', 'sk@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'un@@', 'gefä@@', 'hr', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'un@@', 'gefä@@', 'hr', 'die', 'U@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'ge@@', 'k@@', 'ü@@', 'm@@', 'pf@@', 't.', '</s>']
2023-05-30 18:29:17,514 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 18:29:17,514 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 18:29:17,514 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese beiden Diast des Landes, die die Poliskap, die die letzten drei Millionen Jahre ungefähr die letzten drei Millionen Jahre ungefähr die USA mit 40 Prozent gekümpft.
2023-05-30 18:29:17,514 - INFO - joeynmt.training - Example #1
2023-05-30 18:29:17,514 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 18:29:17,514 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 18:29:17,515 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'Er@@', 'ste', 'tatsächlich', 'die', 'ern@@', 'st', 'dieses', 'spe@@', 'zi@@', 'f@@', 'ische', 'Proble@@', 'm@@', 'l@@', 'äu@@', 'f@@', 'ig', 'ist,', 'weil', 'es', 'nicht', 'die', 'T@@', 'ik@@', 'te', 'des', 'E@@', 'is', 'zei@@', 'gen.', '</s>']
2023-05-30 18:29:17,515 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 18:29:17,515 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 18:29:17,515 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Erste tatsächlich die ernst dieses spezifische Problemläufig ist, weil es nicht die Tikte des Eis zeigen.
2023-05-30 18:29:17,515 - INFO - joeynmt.training - Example #2
2023-05-30 18:29:17,515 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 18:29:17,515 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 18:29:17,515 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sch@@', 'a@@', 'b', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'er', 'Wei@@', 'se', 'in', 'der', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 'n', 'des', 'Her@@', 'z', 'unserer', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 's', 'zu', 'k@@', 'ä@@', 'm@@', 'pf@@', 'en.', '</s>']
2023-05-30 18:29:17,515 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 18:29:17,515 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 18:29:17,515 - INFO - joeynmt.training - 	Hypothesis: Die Eisschab auf der Nordpol ist in gewisser Weise in der Klimawandeln des Herz unserer globalen Klimawandels zu kämpfen.
2023-05-30 18:29:17,515 - INFO - joeynmt.training - Example #3
2023-05-30 18:29:17,515 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 18:29:17,515 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 18:29:17,515 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'rei@@', 's@@', 'im@@', 'ft', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'rei@@', 's@@', 'e.', '</s>']
2023-05-30 18:29:17,515 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 18:29:17,515 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 18:29:17,515 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Kreisimft in den Sommer und Kreise.
2023-05-30 18:29:17,515 - INFO - joeynmt.training - Example #4
2023-05-30 18:29:17,515 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 18:29:17,515 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 18:29:17,515 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'der', 'näch@@', 'sten', 'Di@@', 'a', 'der', 'ich', 'zei@@', 'gt', 'eine', 'ver@@', 'n@@', 'un@@', 'gen@@', 'e', 'Ver@@', 'si@@', 'on', 'von', 'dem', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'wird.', '</s>']
2023-05-30 18:29:17,516 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 18:29:17,516 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 18:29:17,516 - INFO - joeynmt.training - 	Hypothesis: Und der nächsten Dia der ich zeigt eine vernungene Version von dem letzten 25 Jahren passiert wird.
2023-05-30 18:29:33,435 - INFO - joeynmt.training - Epoch   7, Step:    26600, Batch Loss:     1.822788, Batch Acc: 0.515601, Tokens per Sec:     4606, Lr: 0.000300
2023-05-30 18:29:49,325 - INFO - joeynmt.training - Epoch   7, Step:    26700, Batch Loss:     1.890821, Batch Acc: 0.515424, Tokens per Sec:     4709, Lr: 0.000300
2023-05-30 18:30:04,907 - INFO - joeynmt.training - Epoch   7, Step:    26800, Batch Loss:     1.762571, Batch Acc: 0.507646, Tokens per Sec:     4663, Lr: 0.000300
2023-05-30 18:30:20,449 - INFO - joeynmt.training - Epoch   7, Step:    26900, Batch Loss:     1.729194, Batch Acc: 0.511946, Tokens per Sec:     4837, Lr: 0.000300
2023-05-30 18:30:35,515 - INFO - joeynmt.training - Epoch   7, Step:    27000, Batch Loss:     1.617324, Batch Acc: 0.514317, Tokens per Sec:     5033, Lr: 0.000300
2023-05-30 18:30:35,515 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 18:30:35,515 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 18:31:49,996 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.88, ppl:   6.55, acc:   0.46, generation: 74.4724[sec], evaluation: 0.0000[sec]
2023-05-30 18:31:49,997 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 18:31:50,071 - INFO - joeynmt.helpers - delete models/transformer_model2/25500.ckpt
2023-05-30 18:31:50,071 - INFO - joeynmt.training - Example #0
2023-05-30 18:31:50,071 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 18:31:50,071 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 18:31:50,071 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'zei@@', 'g@@', 'te', 'ich', 'diese', 'zwei', 'Di@@', 'a@@', 'st', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'i@@', 'sk@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'un@@', 'gefä@@', 'hr', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'un@@', 'gefä@@', 'hr', 'die', 'Gr@@', 'ö@@', 'ß@@', 'e', 'der', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0', 'Prozent', 'ge@@', 'k@@', 'ü@@', 'm@@', 'pf@@', 'en.', '</s>']
2023-05-30 18:31:50,071 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 18:31:50,071 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 18:31:50,071 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr zeigte ich diese zwei Diast zeigen, dass die Poliskap, die die letzten drei Millionen Jahre ungefähr die letzten drei Millionen Jahre ungefähr die Größe der USA, mit 40 Prozent der USA, mit 40 Prozent gekümpfen.
2023-05-30 18:31:50,071 - INFO - joeynmt.training - Example #1
2023-05-30 18:31:50,071 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 18:31:50,071 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 18:31:50,071 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'ein', 'Unter@@', 'sch@@', 'ä@@', 'tz@@', 'lich', 'der', 'ern@@', 'st', 'des', 'E@@', 'is', 'des', 'E@@', 'is', 'zei@@', 't.', '</s>']
2023-05-30 18:31:50,072 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 18:31:50,072 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 18:31:50,072 - INFO - joeynmt.training - 	Hypothesis: Aber das ist ein Unterschätzlich der ernst des Eis des Eis zeit.
2023-05-30 18:31:50,072 - INFO - joeynmt.training - Example #2
2023-05-30 18:31:50,072 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 18:31:50,072 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 18:31:50,072 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sk@@', 'a@@', 'te', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'is', 'in', 'gew@@', 'iss@@', 'er', 'Wei@@', 'se', 'die', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 'n', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 's@@', 'y@@', 'ste@@', 'm.', '</s>']
2023-05-30 18:31:50,072 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 18:31:50,072 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 18:31:50,072 - INFO - joeynmt.training - 	Hypothesis: Die Eisskate auf der Nordpolis in gewisser Weise die Klimawandeln unseres globalen Klimawandelsystem.
2023-05-30 18:31:50,072 - INFO - joeynmt.training - Example #3
2023-05-30 18:31:50,072 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 18:31:50,072 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 18:31:50,072 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'wird', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'rei@@', 's@@', 'e,', 'und', 'K@@', 'rei@@', 's@@', 'm@@', 'ä@@', 'ß@@', 'e', 'in', 'den', 'S@@', 'omm@@', 'er', 'zu', 'k@@', 'rei@@', 't.', '</s>']
2023-05-30 18:31:50,072 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 18:31:50,072 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 18:31:50,072 - INFO - joeynmt.training - 	Hypothesis: Es wird in den Sommer und Kreise, und Kreismäße in den Sommer zu kreit.
2023-05-30 18:31:50,072 - INFO - joeynmt.training - Example #4
2023-05-30 18:31:50,072 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 18:31:50,072 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 18:31:50,072 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'der', 'näch@@', 'ste', 'Di@@', 'a', 'die', 'ich', 'zei@@', 'ge', 'Ihnen', 'ist', 'eine', 'ver@@', 'n@@', 'etz@@', 'e', 'Ver@@', 'si@@', 'on', 'von', 'dem', 'letzten', '2@@', '5', 'Jahre', 'gesch@@', 'eh@@', 'en', 'ist.', '</s>']
2023-05-30 18:31:50,073 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 18:31:50,073 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 18:31:50,073 - INFO - joeynmt.training - 	Hypothesis: Und der nächste Dia die ich zeige Ihnen ist eine vernetze Version von dem letzten 25 Jahre geschehen ist.
2023-05-30 18:32:06,522 - INFO - joeynmt.training - Epoch   7, Step:    27100, Batch Loss:     1.675653, Batch Acc: 0.510970, Tokens per Sec:     4672, Lr: 0.000300
2023-05-30 18:32:23,371 - INFO - joeynmt.training - Epoch   7, Step:    27200, Batch Loss:     1.629946, Batch Acc: 0.509689, Tokens per Sec:     4459, Lr: 0.000300
2023-05-30 18:32:40,711 - INFO - joeynmt.training - Epoch   7, Step:    27300, Batch Loss:     1.706532, Batch Acc: 0.512033, Tokens per Sec:     4409, Lr: 0.000300
2023-05-30 18:32:56,598 - INFO - joeynmt.training - Epoch   7, Step:    27400, Batch Loss:     1.701237, Batch Acc: 0.515137, Tokens per Sec:     4863, Lr: 0.000300
2023-05-30 18:33:12,574 - INFO - joeynmt.training - Epoch   7, Step:    27500, Batch Loss:     1.827036, Batch Acc: 0.510901, Tokens per Sec:     4780, Lr: 0.000300
2023-05-30 18:33:12,574 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 18:33:12,574 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 18:34:29,443 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.88, ppl:   6.52, acc:   0.46, generation: 76.8610[sec], evaluation: 0.0000[sec]
2023-05-30 18:34:29,445 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 18:34:29,522 - INFO - joeynmt.helpers - delete models/transformer_model2/26000.ckpt
2023-05-30 18:34:29,523 - INFO - joeynmt.training - Example #0
2023-05-30 18:34:29,523 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 18:34:29,523 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 18:34:29,523 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'a@@', 'st', 'ge@@', 'sehen', 'um', 'zu', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'i@@', 'sk@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'etwa', 'die', 'Gr@@', 'ö@@', 'ß@@', 'e', 'von', 'der', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0', 'Prozent', 'ge@@', 'k@@', 'ü@@', 'm@@', 'mer@@', 'n.', '</s>']
2023-05-30 18:34:29,524 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 18:34:29,524 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 18:34:29,524 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Diast gesehen um zu zeigen, dass die Poliskap, die die letzten drei Millionen Jahre etwa die Größe von der USA, mit 40 Prozent der USA, mit 40 Prozent der USA, mit 40 Prozent der USA, mit 40 Prozent gekümmern.
2023-05-30 18:34:29,524 - INFO - joeynmt.training - Example #1
2023-05-30 18:34:29,524 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 18:34:29,524 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 18:34:29,524 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'Unter@@', 'sch@@', 'ä@@', 'tz@@', 'ung', 'der', 'F@@', 'ern@@', 'st', 'dieses', 'spe@@', 'zi@@', 'f@@', 'ischen', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'D@@', 'ik@@', 'te', 'des', 'E@@', 'is', 'zei@@', 'gen.', '</s>']
2023-05-30 18:34:29,524 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 18:34:29,524 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 18:34:29,524 - INFO - joeynmt.training - 	Hypothesis: Aber das Unterschätzung der Fernst dieses spezifischen Problem ist, weil es nicht die Dikte des Eis zeigen.
2023-05-30 18:34:29,524 - INFO - joeynmt.training - Example #2
2023-05-30 18:34:29,524 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 18:34:29,524 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 18:34:29,524 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sch@@', 'ri@@', 'ck@@', 'e', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'e', 'ist', 'in', 'gew@@', 'iss@@', 'er', 'S@@', 'in@@', 'n', 'des', 'Her@@', 'z', 'von', 'uns', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 's', 'zu', 'sein.', '</s>']
2023-05-30 18:34:29,524 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 18:34:29,524 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 18:34:29,524 - INFO - joeynmt.training - 	Hypothesis: Die Eisschricke auf der Nordpole ist in gewisser Sinn des Herz von uns globalen Klimawandels zu sein.
2023-05-30 18:34:29,524 - INFO - joeynmt.training - Example #3
2023-05-30 18:34:29,524 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 18:34:29,525 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 18:34:29,525 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'der', 'S@@', 'om@@', 'mer@@', '.', '</s>']
2023-05-30 18:34:29,525 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 18:34:29,525 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 18:34:29,525 - INFO - joeynmt.training - 	Hypothesis: Es ist in der Winter und Krimft in der Sommer.
2023-05-30 18:34:29,525 - INFO - joeynmt.training - Example #4
2023-05-30 18:34:29,525 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 18:34:29,525 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 18:34:29,525 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'der', 'näch@@', 'sten', 'Di@@', 'a', 'die', 'ich', 'zei@@', 'ge', 'Ihnen', 'zei@@', 'gt,', 'dass', 'die', 'Ver@@', 'si@@', 'on', 'von', 'de@@', 'm,', 'was', 'die', 'letzten', '2@@', '5', 'Jahre', 'pass@@', 'iert', 'ist.', '</s>']
2023-05-30 18:34:29,525 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 18:34:29,525 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 18:34:29,525 - INFO - joeynmt.training - 	Hypothesis: Und der nächsten Dia die ich zeige Ihnen zeigt, dass die Version von dem, was die letzten 25 Jahre passiert ist.
2023-05-30 18:34:46,210 - INFO - joeynmt.training - Epoch   7, Step:    27600, Batch Loss:     1.703140, Batch Acc: 0.509146, Tokens per Sec:     4526, Lr: 0.000300
2023-05-30 18:35:02,225 - INFO - joeynmt.training - Epoch   7, Step:    27700, Batch Loss:     1.668280, Batch Acc: 0.513179, Tokens per Sec:     4719, Lr: 0.000300
2023-05-30 18:35:18,516 - INFO - joeynmt.training - Epoch   7, Step:    27800, Batch Loss:     1.706967, Batch Acc: 0.511781, Tokens per Sec:     4611, Lr: 0.000300
2023-05-30 18:35:36,255 - INFO - joeynmt.training - Epoch   7, Step:    27900, Batch Loss:     1.674082, Batch Acc: 0.513081, Tokens per Sec:     4310, Lr: 0.000300
2023-05-30 18:35:53,699 - INFO - joeynmt.training - Epoch   7, Step:    28000, Batch Loss:     1.562894, Batch Acc: 0.513857, Tokens per Sec:     4379, Lr: 0.000300
2023-05-30 18:35:53,699 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 18:35:53,699 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 18:37:11,476 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.87, ppl:   6.52, acc:   0.46, generation: 77.7684[sec], evaluation: 0.0000[sec]
2023-05-30 18:37:11,478 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 18:37:11,553 - INFO - joeynmt.helpers - delete models/transformer_model2/24500.ckpt
2023-05-30 18:37:11,555 - INFO - joeynmt.training - Example #0
2023-05-30 18:37:11,555 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 18:37:11,555 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 18:37:11,555 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ie', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'i@@', 'zi@@', 'f@@', 'ik', 'in', 'der', 'letzten', 'drei', 'Millionen', 'Jahre', 'etwa', 'die', 'Gr@@', 'ö@@', 'ß@@', 'e', 'der', 'U@@', 'S@@', 'A', 'und', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ü@@', 'm@@', 'mer@@', 'n', 'war.', '</s>']
2023-05-30 18:37:11,556 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 18:37:11,556 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 18:37:11,556 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese beiden Folie gezeigt, um zu zeigen, dass die Polizifik in der letzten drei Millionen Jahre etwa die Größe der USA und 40% gekümmern war.
2023-05-30 18:37:11,556 - INFO - joeynmt.training - Example #1
2023-05-30 18:37:11,556 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 18:37:11,556 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 18:37:11,556 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'wirklich', 'die', 'F@@', 'ern@@', 'sehen', 'des', 'E@@', 'is', 'des', 'E@@', 'is', 'des', 'E@@', 'is', 'des', 'E@@', 'is', 'der', 'E@@', 'is', 'zei@@', 'gt,', 'weil', 'es', 'nicht', 'die', 'D@@', 'ik@@', 'te', 'des', 'E@@', 'is', 'zei@@', 't.', '</s>']
2023-05-30 18:37:11,556 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 18:37:11,556 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 18:37:11,556 - INFO - joeynmt.training - 	Hypothesis: Aber das ist wirklich die Fernsehen des Eis des Eis des Eis des Eis der Eis zeigt, weil es nicht die Dikte des Eis zeit.
2023-05-30 18:37:11,556 - INFO - joeynmt.training - Example #2
2023-05-30 18:37:11,556 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 18:37:11,556 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 18:37:11,556 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sch@@', 'ich@@', 'te', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'is', 'in', 'der', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', '.', '</s>']
2023-05-30 18:37:11,556 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 18:37:11,556 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 18:37:11,556 - INFO - joeynmt.training - 	Hypothesis: Die Eisschichte auf der Nordpolis in der Klimawandel.
2023-05-30 18:37:11,556 - INFO - joeynmt.training - Example #3
2023-05-30 18:37:11,556 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 18:37:11,556 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 18:37:11,557 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'wird', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'den', 'S@@', 'om@@', 'mer@@', '.', '</s>']
2023-05-30 18:37:11,557 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 18:37:11,557 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 18:37:11,557 - INFO - joeynmt.training - 	Hypothesis: Es wird in den Winter und Krimft in den Sommer.
2023-05-30 18:37:11,557 - INFO - joeynmt.training - Example #4
2023-05-30 18:37:11,557 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 18:37:11,557 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 18:37:11,557 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', 'zei@@', 'gt', 'eine', 'ver@@', 'n@@', 'etz@@', 'te', 'Ver@@', 'si@@', 'on', 'von', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.', '</s>']
2023-05-30 18:37:11,557 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 18:37:11,557 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 18:37:11,557 - INFO - joeynmt.training - 	Hypothesis: Und die nächste Folie zeigt eine vernetzte Version von 25 Jahren passiert ist.
2023-05-30 18:37:28,855 - INFO - joeynmt.training - Epoch   7, Step:    28100, Batch Loss:     1.555655, Batch Acc: 0.512454, Tokens per Sec:     4293, Lr: 0.000300
2023-05-30 18:37:45,188 - INFO - joeynmt.training - Epoch   7, Step:    28200, Batch Loss:     1.562235, Batch Acc: 0.516474, Tokens per Sec:     4675, Lr: 0.000300
2023-05-30 18:38:02,022 - INFO - joeynmt.training - Epoch   7, Step:    28300, Batch Loss:     1.659911, Batch Acc: 0.515086, Tokens per Sec:     4495, Lr: 0.000300
2023-05-30 18:38:16,962 - INFO - joeynmt.training - Epoch   7, Step:    28400, Batch Loss:     1.807930, Batch Acc: 0.513000, Tokens per Sec:     5059, Lr: 0.000300
2023-05-30 18:38:32,902 - INFO - joeynmt.training - Epoch   7, Step:    28500, Batch Loss:     1.662457, Batch Acc: 0.508705, Tokens per Sec:     4911, Lr: 0.000300
2023-05-30 18:38:32,902 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 18:38:32,902 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 18:39:55,757 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.87, ppl:   6.46, acc:   0.46, generation: 82.8466[sec], evaluation: 0.0000[sec]
2023-05-30 18:39:55,758 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 18:39:55,836 - INFO - joeynmt.helpers - delete models/transformer_model2/25000.ckpt
2023-05-30 18:39:55,837 - INFO - joeynmt.training - Example #0
2023-05-30 18:39:55,837 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 18:39:55,837 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 18:39:55,837 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'zei@@', 'g@@', 'te', 'ich', 'diese', 'bei@@', 'den', 'Di@@', 'as', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'i@@', 'sk@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'mit', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ü@@', 'm@@', 'mer@@', 'n', 'war.', '</s>']
2023-05-30 18:39:55,837 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 18:39:55,837 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 18:39:55,837 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr zeigte ich diese beiden Dias zeigen, dass die Poliskap, die die letzten drei Millionen Jahre alt hatte, die die letzten drei Millionen Jahre alt hatte, mit 40% gekümmern war.
2023-05-30 18:39:55,837 - INFO - joeynmt.training - Example #1
2023-05-30 18:39:55,837 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 18:39:55,837 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 18:39:55,837 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'Unter@@', 'sch@@', 'ä@@', 'tz@@', 'ung', 'der', 'F@@', 'äh@@', 'igkeit', 'dieses', 'spe@@', 'zi@@', 'f@@', 'ischen', 'Problem', 'da@@', 'v@@', 'on,', 'dass', 'es', 'nicht', 'die', 'D@@', 'ik@@', 'te', 'des', 'E@@', 'is', 'zei@@', 'gen.', '</s>']
2023-05-30 18:39:55,837 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 18:39:55,838 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 18:39:55,838 - INFO - joeynmt.training - 	Hypothesis: Aber das Unterschätzung der Fähigkeit dieses spezifischen Problem davon, dass es nicht die Dikte des Eis zeigen.
2023-05-30 18:39:55,838 - INFO - joeynmt.training - Example #2
2023-05-30 18:39:55,838 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 18:39:55,838 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 18:39:55,838 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'k@@', 'ut@@', 'ieren', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'S@@', 'in@@', 'n', 'des', 'Her@@', 'zen', 'unserer', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 's', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', '.', '</s>']
2023-05-30 18:39:55,838 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 18:39:55,838 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 18:39:55,838 - INFO - joeynmt.training - 	Hypothesis: Die Eiskutieren auf der Nordpoll ist in gewissem Sinn des Herzen unserer globalen Klimawandels Klimawandel.
2023-05-30 18:39:55,838 - INFO - joeynmt.training - Example #3
2023-05-30 18:39:55,838 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 18:39:55,838 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 18:39:55,838 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'ä@@', 'm@@', 'pf@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'ä@@', 'f@@', 't.', '</s>']
2023-05-30 18:39:55,838 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 18:39:55,838 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 18:39:55,838 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Krämpfer in den Sommer in den Sommer und Kräft.
2023-05-30 18:39:55,838 - INFO - joeynmt.training - Example #4
2023-05-30 18:39:55,838 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 18:39:55,838 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 18:39:55,838 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'der', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', 'ist', 'ein', 'ver@@', 'n@@', 'etz@@', 'tes', 'Ver@@', 'si@@', 'on', 'von', 'dem', 'letzten', '2@@', '5', 'Jahre', 'pass@@', 'iert.', '</s>']
2023-05-30 18:39:55,838 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 18:39:55,838 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 18:39:55,838 - INFO - joeynmt.training - 	Hypothesis: Und der nächste Folie ist ein vernetztes Version von dem letzten 25 Jahre passiert.
2023-05-30 18:40:11,377 - INFO - joeynmt.training - Epoch   7, Step:    28600, Batch Loss:     1.628201, Batch Acc: 0.515724, Tokens per Sec:     4719, Lr: 0.000300
2023-05-30 18:40:27,112 - INFO - joeynmt.training - Epoch   7, Step:    28700, Batch Loss:     1.712493, Batch Acc: 0.519243, Tokens per Sec:     4903, Lr: 0.000300
2023-05-30 18:40:43,939 - INFO - joeynmt.training - Epoch   7, Step:    28800, Batch Loss:     1.656916, Batch Acc: 0.517106, Tokens per Sec:     4447, Lr: 0.000300
2023-05-30 18:40:59,970 - INFO - joeynmt.training - Epoch   7, Step:    28900, Batch Loss:     1.776786, Batch Acc: 0.511535, Tokens per Sec:     4646, Lr: 0.000300
2023-05-30 18:41:16,165 - INFO - joeynmt.training - Epoch   7, Step:    29000, Batch Loss:     1.667557, Batch Acc: 0.511239, Tokens per Sec:     4673, Lr: 0.000300
2023-05-30 18:41:16,165 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 18:41:16,165 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 18:42:30,162 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.87, ppl:   6.46, acc:   0.47, generation: 73.9887[sec], evaluation: 0.0000[sec]
2023-05-30 18:42:30,239 - INFO - joeynmt.helpers - delete models/transformer_model2/26500.ckpt
2023-05-30 18:42:30,241 - INFO - joeynmt.training - Example #0
2023-05-30 18:42:30,242 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 18:42:30,242 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 18:42:30,242 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'i@@', 'sk@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'un@@', 'gefä@@', 'hr', 'die', 'Gr@@', 'ö@@', 'ß@@', 'e', 'von', 'der', 'U@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'ge@@', 'k@@', 'ü@@', 'm@@', 'ten', 'war.', '</s>']
2023-05-30 18:42:30,242 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 18:42:30,242 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 18:42:30,242 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Dias gezeigt, um zu zeigen, dass die Poliskap, die die letzten drei Millionen Jahre ungefähr die Größe von der USA mit 40 Prozent der USA mit 40 Prozent der USA mit 40 Prozent gekümten war.
2023-05-30 18:42:30,242 - INFO - joeynmt.training - Example #1
2023-05-30 18:42:30,242 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 18:42:30,242 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 18:42:30,242 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'das', 'The@@', 'ma', 'der', 'F@@', 'ern@@', 'sehen', 'von', 'diesem', 'spe@@', 'zi@@', 'ellen', 'Problem', 'der', 'T@@', 'ik@@', 'e', 'des', 'E@@', 'is', 'zei@@', 't.', '</s>']
2023-05-30 18:42:30,242 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 18:42:30,242 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 18:42:30,242 - INFO - joeynmt.training - 	Hypothesis: Aber das ist das Thema der Fernsehen von diesem speziellen Problem der Tike des Eis zeit.
2023-05-30 18:42:30,242 - INFO - joeynmt.training - Example #2
2023-05-30 18:42:30,242 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 18:42:30,242 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 18:42:30,242 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'k@@', 'ut@@', 'ieren', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'er', 'S@@', 'inn@@', 'e', 'des', 'H@@', 'ar@@', 'de@@', 's,', 'der', 'sich', 'von', 'uns', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'wan@@', 'z@@', '.', '</s>']
2023-05-30 18:42:30,243 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 18:42:30,243 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 18:42:30,243 - INFO - joeynmt.training - 	Hypothesis: Die Eiskutieren auf der Nordpol ist in gewisser Sinne des Hardes, der sich von uns globalen Klimawanz.
2023-05-30 18:42:30,243 - INFO - joeynmt.training - Example #3
2023-05-30 18:42:30,243 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 18:42:30,243 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 18:42:30,243 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'p@@', 'pen', 'in', 'den', 'S@@', 'om@@', 'mer@@', '.', '</s>']
2023-05-30 18:42:30,243 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 18:42:30,243 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 18:42:30,243 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Krimppen in den Sommer.
2023-05-30 18:42:30,243 - INFO - joeynmt.training - Example #4
2023-05-30 18:42:30,243 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 18:42:30,243 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 18:42:30,243 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', 'zei@@', 'gt', 'eine', 'ver@@', 'n@@', 'etz@@', 'te', 'Ver@@', 'si@@', 'on', 'von', 'de@@', 'm,', 'was', 'die', 'letzten', '2@@', '5', 'Jahre', 'pass@@', 'iert.', '</s>']
2023-05-30 18:42:30,243 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 18:42:30,243 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 18:42:30,243 - INFO - joeynmt.training - 	Hypothesis: Der nächste Folie zeigt eine vernetzte Version von dem, was die letzten 25 Jahre passiert.
2023-05-30 18:42:46,976 - INFO - joeynmt.training - Epoch   7, Step:    29100, Batch Loss:     1.739041, Batch Acc: 0.516598, Tokens per Sec:     4587, Lr: 0.000300
2023-05-30 18:42:50,024 - INFO - joeynmt.training - Epoch   7: total training loss 6912.18
2023-05-30 18:42:50,024 - INFO - joeynmt.training - EPOCH 8
2023-05-30 18:43:04,079 - INFO - joeynmt.training - Epoch   8, Step:    29200, Batch Loss:     1.425701, Batch Acc: 0.535290, Tokens per Sec:     4459, Lr: 0.000300
2023-05-30 18:43:21,262 - INFO - joeynmt.training - Epoch   8, Step:    29300, Batch Loss:     1.626127, Batch Acc: 0.528955, Tokens per Sec:     4441, Lr: 0.000300
2023-05-30 18:43:38,710 - INFO - joeynmt.training - Epoch   8, Step:    29400, Batch Loss:     1.598670, Batch Acc: 0.531883, Tokens per Sec:     4331, Lr: 0.000300
2023-05-30 18:43:54,546 - INFO - joeynmt.training - Epoch   8, Step:    29500, Batch Loss:     1.589447, Batch Acc: 0.531563, Tokens per Sec:     4871, Lr: 0.000300
2023-05-30 18:43:54,546 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 18:43:54,546 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 18:45:08,737 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.87, ppl:   6.47, acc:   0.46, generation: 74.1833[sec], evaluation: 0.0000[sec]
2023-05-30 18:45:08,814 - INFO - joeynmt.helpers - delete models/transformer_model2/27000.ckpt
2023-05-30 18:45:08,814 - INFO - joeynmt.training - Example #0
2023-05-30 18:45:08,814 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 18:45:08,814 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 18:45:08,814 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'zei@@', 'ge', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'an', 'die', 'P@@', 'ol@@', 'it@@', 'ik@@', 'a', 'ge@@', 'zei@@', 'gt,', 'dass', 'die', 'P@@', 'ol@@', 'it@@', 'ik@@', '-@@', 'E@@', 'is@@', 'sch@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'die', 'die', 'Gr@@', 'ö@@', 'ß@@', 'e', 'der', 'U@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pf@@', 'en.', '</s>']
2023-05-30 18:45:08,815 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 18:45:08,815 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 18:45:08,815 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr zeige ich diese zwei Dias an die Politika gezeigt, dass die Politik-Eissch, die die letzten drei Millionen Jahre alt hatte, die die Größe der USA mit 40 Prozent gekrompfen.
2023-05-30 18:45:08,815 - INFO - joeynmt.training - Example #1
2023-05-30 18:45:08,815 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 18:45:08,815 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 18:45:08,815 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'ein', 'Teil', 'der', 'F@@', 'ern@@', 'st', 'des', 'Sp@@', 'e@@', 'zi@@', 'f@@', 'ischen', 'Problem', 'weil', 'es', 'nicht', 'die', 'T@@', 'ik@@', 'el', 'zei@@', 'gt', 'nicht', 'die', 'T@@', 'ik@@', 'el', 'zei@@', 'gen.', '</s>']
2023-05-30 18:45:08,815 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 18:45:08,815 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 18:45:08,815 - INFO - joeynmt.training - 	Hypothesis: Aber das ist ein Teil der Fernst des Spezifischen Problem weil es nicht die Tikel zeigt nicht die Tikel zeigen.
2023-05-30 18:45:08,815 - INFO - joeynmt.training - Example #2
2023-05-30 18:45:08,815 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 18:45:08,815 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 18:45:08,815 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'k@@', 'ul@@', 'ar@@', 'e', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'is', 'in', 'gew@@', 'iss@@', 'em', 'S@@', 'in@@', 'n', 'der', 'H@@', 'ar@@', 'z', 'von', 'uns', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 'n@@', '?', '</s>']
2023-05-30 18:45:08,815 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 18:45:08,815 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 18:45:08,815 - INFO - joeynmt.training - 	Hypothesis: Die Eiskulare auf der Nordpolis in gewissem Sinn der Harz von uns globalen Klimawandeln?
2023-05-30 18:45:08,815 - INFO - joeynmt.training - Example #3
2023-05-30 18:45:08,815 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 18:45:08,815 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 18:45:08,816 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', '</s>']
2023-05-30 18:45:08,816 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 18:45:08,816 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 18:45:08,816 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Krimft in den Sommer in den Sommer in den Sommer in den Sommer in den Sommer in den Sommer in den Sommer in den Sommer in den Sommer in den Sommer
2023-05-30 18:45:08,816 - INFO - joeynmt.training - Example #4
2023-05-30 18:45:08,816 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 18:45:08,816 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 18:45:08,816 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', 'ist', 'ein', 'ver@@', 'n@@', 'etz@@', 'te', 'Ver@@', 'si@@', 'on', 'von', 'de@@', 'm,', 'was', 'die', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.', '</s>']
2023-05-30 18:45:08,816 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 18:45:08,816 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 18:45:08,816 - INFO - joeynmt.training - 	Hypothesis: Der nächste Folie ist ein vernetzte Version von dem, was die letzten 25 Jahren passiert ist.
2023-05-30 18:45:25,337 - INFO - joeynmt.training - Epoch   8, Step:    29600, Batch Loss:     1.789625, Batch Acc: 0.525990, Tokens per Sec:     4633, Lr: 0.000300
2023-05-30 18:45:41,701 - INFO - joeynmt.training - Epoch   8, Step:    29700, Batch Loss:     1.634153, Batch Acc: 0.533628, Tokens per Sec:     4584, Lr: 0.000300
2023-05-30 18:45:57,957 - INFO - joeynmt.training - Epoch   8, Step:    29800, Batch Loss:     1.603799, Batch Acc: 0.527798, Tokens per Sec:     4571, Lr: 0.000300
2023-05-30 18:46:13,993 - INFO - joeynmt.training - Epoch   8, Step:    29900, Batch Loss:     1.696559, Batch Acc: 0.532649, Tokens per Sec:     4726, Lr: 0.000300
2023-05-30 18:46:29,935 - INFO - joeynmt.training - Epoch   8, Step:    30000, Batch Loss:     1.467295, Batch Acc: 0.525973, Tokens per Sec:     4766, Lr: 0.000300
2023-05-30 18:46:29,935 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 18:46:29,935 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 18:47:45,482 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.87, ppl:   6.49, acc:   0.46, generation: 75.5385[sec], evaluation: 0.0000[sec]
2023-05-30 18:47:45,560 - INFO - joeynmt.helpers - delete models/transformer_model2/27500.ckpt
2023-05-30 18:47:45,563 - INFO - joeynmt.training - Example #0
2023-05-30 18:47:45,564 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 18:47:45,564 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 18:47:45,564 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'zei@@', 'g@@', 'te', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'be@@', 'tra@@', 'cht@@', 'en,', 'um', 'zu', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'i@@', 'sk@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'die', 'die', 'Gr@@', 'ö@@', 'ß@@', 'e', 'der', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A@@', ',', 'der', 'die', 'P@@', 'ol@@', 'it@@', 'ik@@', 'en', 'war.', '</s>']
2023-05-30 18:47:45,564 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 18:47:45,564 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 18:47:45,564 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr zeigte ich diese zwei Dias betrachten, um zu zeigen, dass die Poliskap, die die letzten drei Millionen Jahre alt hatte, die die Größe der USA, mit 40 Prozent der USA, mit 40 Prozent der USA, mit 40 Prozent der USA, der die Politiken war.
2023-05-30 18:47:45,564 - INFO - joeynmt.training - Example #1
2023-05-30 18:47:45,564 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 18:47:45,564 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 18:47:45,564 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'ein', 'paar', 'der', 'L@@', 'ehr@@', 'e', 'der', 'F@@', 'äh@@', 'igkeit', 'des', 'E@@', 'is', 'der', 'E@@', 'is', 'der', 'E@@', 'is', 'zei@@', 't.', '</s>']
2023-05-30 18:47:45,564 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 18:47:45,564 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 18:47:45,564 - INFO - joeynmt.training - 	Hypothesis: Aber das ist ein paar der Lehre der Fähigkeit des Eis der Eis der Eis zeit.
2023-05-30 18:47:45,564 - INFO - joeynmt.training - Example #2
2023-05-30 18:47:45,564 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 18:47:45,564 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 18:47:45,564 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'k@@', 'ut@@', 'ieren', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'S@@', 'in@@', 'n', 'der', 'H@@', 'ar@@', 'z', 'von', 'uns', 'g@@', 'lob@@', 'al@@', 'er', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 'n@@', '?', '</s>']
2023-05-30 18:47:45,564 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 18:47:45,564 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 18:47:45,564 - INFO - joeynmt.training - 	Hypothesis: Die Eiskutieren auf der Nordpol ist in gewissem Sinn der Harz von uns globaler Klimawandeln?
2023-05-30 18:47:45,565 - INFO - joeynmt.training - Example #3
2023-05-30 18:47:45,565 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 18:47:45,565 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 18:47:45,565 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'sch@@', 'ließ@@', 't', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'rei@@', 's', 'in', 'den', 'S@@', 'om@@', 'mer@@', '.', '</s>']
2023-05-30 18:47:45,565 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 18:47:45,565 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 18:47:45,565 - INFO - joeynmt.training - 	Hypothesis: Es schließt in den Winter und Kreis in den Sommer.
2023-05-30 18:47:45,565 - INFO - joeynmt.training - Example #4
2023-05-30 18:47:45,565 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 18:47:45,565 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 18:47:45,565 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', 'zei@@', 'gt', 'eine', 'ver@@', 'n@@', 'etz@@', 'te', 'Ver@@', 'si@@', 'on', 'von', 'de@@', 'm,', 'was', 'die', 'letzten', '2@@', '5', 'Jahre', 'al@@', 't', 'ist.', '</s>']
2023-05-30 18:47:45,565 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 18:47:45,565 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 18:47:45,565 - INFO - joeynmt.training - 	Hypothesis: Der nächste Folie zeigt eine vernetzte Version von dem, was die letzten 25 Jahre alt ist.
2023-05-30 18:48:01,598 - INFO - joeynmt.training - Epoch   8, Step:    30100, Batch Loss:     1.525441, Batch Acc: 0.524834, Tokens per Sec:     4702, Lr: 0.000300
2023-05-30 18:48:17,775 - INFO - joeynmt.training - Epoch   8, Step:    30200, Batch Loss:     1.542224, Batch Acc: 0.521610, Tokens per Sec:     4700, Lr: 0.000300
2023-05-30 18:48:35,056 - INFO - joeynmt.training - Epoch   8, Step:    30300, Batch Loss:     1.741003, Batch Acc: 0.528195, Tokens per Sec:     4403, Lr: 0.000300
2023-05-30 18:48:52,355 - INFO - joeynmt.training - Epoch   8, Step:    30400, Batch Loss:     1.506935, Batch Acc: 0.530979, Tokens per Sec:     4319, Lr: 0.000300
2023-05-30 18:49:08,216 - INFO - joeynmt.training - Epoch   8, Step:    30500, Batch Loss:     1.727585, Batch Acc: 0.527478, Tokens per Sec:     4677, Lr: 0.000300
2023-05-30 18:49:08,216 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 18:49:08,216 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 18:50:26,895 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.87, ppl:   6.47, acc:   0.47, generation: 78.6712[sec], evaluation: 0.0000[sec]
2023-05-30 18:50:26,975 - INFO - joeynmt.helpers - delete models/transformer_model2/28000.ckpt
2023-05-30 18:50:26,975 - INFO - joeynmt.training - Example #0
2023-05-30 18:50:26,975 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 18:50:26,975 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 18:50:26,975 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'zei@@', 'g@@', 'te', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ie', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'it@@', 'ä@@', 'ts@@', 'am', 'am', 'am', 'letzten', 'drei', 'Millionen', 'Jahren', 'un@@', 'gefä@@', 'hr', 'die', 'Gr@@', 'ö@@', 'ß@@', 'e', 'der', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A', 'war.', '</s>']
2023-05-30 18:50:26,976 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 18:50:26,976 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 18:50:26,976 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr zeigte ich diese beiden Folie zeigen, dass die Politätsam am am letzten drei Millionen Jahren ungefähr die Größe der USA, mit 40 Prozent der USA, mit 40 Prozent der USA, mit 40 Prozent der USA, mit 40 Prozent der USA war.
2023-05-30 18:50:26,976 - INFO - joeynmt.training - Example #1
2023-05-30 18:50:26,976 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 18:50:26,976 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 18:50:26,976 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'also', 'die', 'F@@', 'ern@@', 'st', 'des', 'E@@', 'ig@@', 'ent@@', 'es', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'D@@', 'ik@@', 'an@@', 'isch@@', 'er', 'E@@', 'is', 'sehen', 'können.', '</s>']
2023-05-30 18:50:26,976 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 18:50:26,976 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 18:50:26,976 - INFO - joeynmt.training - 	Hypothesis: Aber das ist also die Fernst des Eigentes Problem ist, weil es nicht die Dikanischer Eis sehen können.
2023-05-30 18:50:26,976 - INFO - joeynmt.training - Example #2
2023-05-30 18:50:26,976 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 18:50:26,976 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 18:50:26,976 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'k@@', 'ut@@', 'ieren', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'S@@', 'in@@', 'n', 'der', 'H@@', 'ar@@', 't', 'von', 'uns', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 'n', 'und', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 'st@@', '?', '</s>']
2023-05-30 18:50:26,976 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 18:50:26,976 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 18:50:26,976 - INFO - joeynmt.training - 	Hypothesis: Die Eiskutieren auf der Nordpol ist in gewissem Sinn der Hart von uns globalen Klimawandeln und Klimawandelst?
2023-05-30 18:50:26,976 - INFO - joeynmt.training - Example #3
2023-05-30 18:50:26,976 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 18:50:26,976 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 18:50:26,976 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'den', 'S@@', 'omm@@', 'en.', '</s>']
2023-05-30 18:50:26,977 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 18:50:26,977 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 18:50:26,977 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Krimft in den Sommer in den Sommer und Krimft in den Sommer und Krimft in den Sommer und Krimft in den Sommer und Krimft in den Sommer und Krimft in den Sommen.
2023-05-30 18:50:26,977 - INFO - joeynmt.training - Example #4
2023-05-30 18:50:26,977 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 18:50:26,977 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 18:50:26,977 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'der', 'näch@@', 'sten', 'F@@', 'ol@@', 'ie', 'ist', 'eine', 'ver@@', 'n@@', 'ün@@', 'ft@@', 'ig@@', 'te', 'Ver@@', 'si@@', 'on', 'von', 'de@@', 'm,', 'was', 'die', 'letzten', '2@@', '5', 'Jahre', 'pass@@', 'iert', 'ist.', '</s>']
2023-05-30 18:50:26,977 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 18:50:26,977 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 18:50:26,977 - INFO - joeynmt.training - 	Hypothesis: Und der nächsten Folie ist eine vernünftigte Version von dem, was die letzten 25 Jahre passiert ist.
2023-05-30 18:50:43,594 - INFO - joeynmt.training - Epoch   8, Step:    30600, Batch Loss:     1.543614, Batch Acc: 0.533313, Tokens per Sec:     4637, Lr: 0.000300
2023-05-30 18:50:59,861 - INFO - joeynmt.training - Epoch   8, Step:    30700, Batch Loss:     1.431818, Batch Acc: 0.523578, Tokens per Sec:     4662, Lr: 0.000300
2023-05-30 18:51:17,072 - INFO - joeynmt.training - Epoch   8, Step:    30800, Batch Loss:     1.615860, Batch Acc: 0.528164, Tokens per Sec:     4414, Lr: 0.000300
2023-05-30 18:51:34,178 - INFO - joeynmt.training - Epoch   8, Step:    30900, Batch Loss:     1.552785, Batch Acc: 0.524299, Tokens per Sec:     4423, Lr: 0.000300
2023-05-30 18:51:51,256 - INFO - joeynmt.training - Epoch   8, Step:    31000, Batch Loss:     1.709766, Batch Acc: 0.521186, Tokens per Sec:     4410, Lr: 0.000300
2023-05-30 18:51:51,256 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 18:51:51,256 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 18:53:05,015 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.87, ppl:   6.47, acc:   0.46, generation: 73.7511[sec], evaluation: 0.0000[sec]
2023-05-30 18:53:05,095 - INFO - joeynmt.helpers - delete models/transformer_model2/30000.ckpt
2023-05-30 18:53:05,096 - INFO - joeynmt.training - Example #0
2023-05-30 18:53:05,096 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 18:53:05,096 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 18:53:05,096 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'zei@@', 'g@@', 'te', 'ich', 'diese', 'bei@@', 'den', 'Di@@', 'as', 'ge@@', 'zei@@', 'gt,', 'dass', 'die', 'P@@', 'ol@@', 'it@@', 'ik@@', 'an@@', 'ische', 'P@@', 'ol@@', 'i@@', 'sk@@', 'ap@@', ',', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'un@@', 'gefä@@', 'hr', 'die', 'Gr@@', 'ö@@', 'ß@@', 'e', 'von', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'ge@@', 'k@@', 'ü@@', 'm@@', 'pen', 'war.', '</s>']
2023-05-30 18:53:05,096 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 18:53:05,096 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 18:53:05,096 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr zeigte ich diese beiden Dias gezeigt, dass die Politikanische Poliskap, die letzten drei Millionen Jahre ungefähr die Größe von 40 Prozent der USA mit 40 Prozent gekümpen war.
2023-05-30 18:53:05,096 - INFO - joeynmt.training - Example #1
2023-05-30 18:53:05,096 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 18:53:05,096 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 18:53:05,097 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'F@@', 'ern@@', 'sehen', 'des', 'Sp@@', 'e@@', 'zi@@', 'al@@', 'es', 'Problem', 'der', 'spe@@', 'zi@@', 'f@@', 'ischen', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'T@@', 'ik@@', 'te', 'des', 'E@@', 'is', 'zei@@', 'gen.', '</s>']
2023-05-30 18:53:05,097 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 18:53:05,097 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 18:53:05,097 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Fernsehen des Speziales Problem der spezifischen Problem ist, weil es nicht die Tikte des Eis zeigen.
2023-05-30 18:53:05,097 - INFO - joeynmt.training - Example #2
2023-05-30 18:53:05,097 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 18:53:05,097 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 18:53:05,097 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sk@@', 'är@@', 'e', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'is', 'in', 'gew@@', 'iss@@', 'em', 'S@@', 'in@@', 'n', 'des', 'g@@', 'lob@@', 'al@@', 'es', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 's', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', '.', '</s>']
2023-05-30 18:53:05,097 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 18:53:05,097 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 18:53:05,097 - INFO - joeynmt.training - 	Hypothesis: Die Eisskäre auf der Nordpolis in gewissem Sinn des globales Klimawandels Klimawandel.
2023-05-30 18:53:05,097 - INFO - joeynmt.training - Example #3
2023-05-30 18:53:05,097 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 18:53:05,097 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 18:53:05,097 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'rei@@', 's', 'im', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'rei@@', 's@@', 'en.', '</s>']
2023-05-30 18:53:05,097 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 18:53:05,097 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 18:53:05,097 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Kreis im Sommer und Kreisen.
2023-05-30 18:53:05,097 - INFO - joeynmt.training - Example #4
2023-05-30 18:53:05,097 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 18:53:05,097 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 18:53:05,097 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'näch@@', 'ste', 'Di@@', 'a', 'die', 'ich', 'zei@@', 'ge', 'Ihnen', 'eine', 'ver@@', 'n@@', 'ell@@', 'ige', 'Ver@@', 'si@@', 'on', 'von', 'dem', 'letzten', '2@@', '5', 'Jahre', 'pass@@', 'iert', 'ist.', '</s>']
2023-05-30 18:53:05,098 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 18:53:05,098 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 18:53:05,098 - INFO - joeynmt.training - 	Hypothesis: Und die nächste Dia die ich zeige Ihnen eine vernellige Version von dem letzten 25 Jahre passiert ist.
2023-05-30 18:53:21,444 - INFO - joeynmt.training - Epoch   8, Step:    31100, Batch Loss:     1.490369, Batch Acc: 0.523679, Tokens per Sec:     4593, Lr: 0.000300
2023-05-30 18:53:37,452 - INFO - joeynmt.training - Epoch   8, Step:    31200, Batch Loss:     1.606875, Batch Acc: 0.521897, Tokens per Sec:     4740, Lr: 0.000300
2023-05-30 18:53:53,889 - INFO - joeynmt.training - Epoch   8, Step:    31300, Batch Loss:     1.582968, Batch Acc: 0.516960, Tokens per Sec:     4637, Lr: 0.000300
2023-05-30 18:54:11,011 - INFO - joeynmt.training - Epoch   8, Step:    31400, Batch Loss:     1.538034, Batch Acc: 0.525514, Tokens per Sec:     4460, Lr: 0.000300
2023-05-30 18:54:27,951 - INFO - joeynmt.training - Epoch   8, Step:    31500, Batch Loss:     1.631127, Batch Acc: 0.523626, Tokens per Sec:     4416, Lr: 0.000300
2023-05-30 18:54:27,951 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 18:54:27,951 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 18:55:53,839 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.86, ppl:   6.44, acc:   0.47, generation: 85.8786[sec], evaluation: 0.0000[sec]
2023-05-30 18:55:53,840 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 18:55:53,919 - INFO - joeynmt.helpers - delete models/transformer_model2/31000.ckpt
2023-05-30 18:55:53,920 - INFO - joeynmt.training - Example #0
2023-05-30 18:55:53,920 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 18:55:53,920 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 18:55:53,920 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'zei@@', 'ge', 'ich', 'diese', 'zwei', 'Di@@', 'a@@', 'st', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'i@@', 'il@@', 's', 'der', 'L@@', 'age', 'der', 'Ver@@', 'gan@@', 'gen@@', 'heit', 'der', 'U@@', 'S@@', 'A', 'der', 'U@@', 'S@@', 'A', 'von', 'der', 'U@@', 'S@@', 'A', 'der', 'U@@', 'S@@', 'A', 'von', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A', 'ge@@', 'k@@', 'ü@@', 'm@@', 'mer@@', 'n', 'war.', '</s>']
2023-05-30 18:55:53,920 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 18:55:53,920 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 18:55:53,920 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr zeige ich diese zwei Diast zeigen, dass die Poliils der Lage der Vergangenheit der USA der USA von der USA der USA von 40 Prozent der USA gekümmern war.
2023-05-30 18:55:53,920 - INFO - joeynmt.training - Example #1
2023-05-30 18:55:53,921 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 18:55:53,921 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 18:55:53,921 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'dieses', 'Unter@@', 'sch@@', 'ä@@', 'tz@@', 'ung', 'der', 'ern@@', 'st', 'des', 'E@@', 'is', 'dieses', 'spe@@', 'zi@@', 'f@@', 'isch@@', 'es', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'D@@', 'ik@@', 'te', 'des', 'E@@', 'is', 'zei@@', 'gen.', '</s>']
2023-05-30 18:55:53,921 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 18:55:53,921 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 18:55:53,921 - INFO - joeynmt.training - 	Hypothesis: Aber dieses Unterschätzung der ernst des Eis dieses spezifisches Problem ist, weil es nicht die Dikte des Eis zeigen.
2023-05-30 18:55:53,921 - INFO - joeynmt.training - Example #2
2023-05-30 18:55:53,921 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 18:55:53,921 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 18:55:53,921 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sch@@', 'il@@', 'd@@', '-@@', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'e', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'S@@', 'in@@', 'n', 'des', 'G@@', 'lob@@', 'al@@', 'es', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 's', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', '-@@', 'St@@', 'em@@', '.', '</s>']
2023-05-30 18:55:53,921 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 18:55:53,921 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 18:55:53,921 - INFO - joeynmt.training - 	Hypothesis: Die Eisschild-Nordpole ist in gewissem Sinn des Globales Klimawandels Klimawandel-Stem.
2023-05-30 18:55:53,921 - INFO - joeynmt.training - Example #3
2023-05-30 18:55:53,921 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 18:55:53,921 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 18:55:53,921 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'rei@@', 'se', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'rei@@', 'se', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'rei@@', 'se', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'rei@@', 'sl@@', 'auf@@', '.', '</s>']
2023-05-30 18:55:53,921 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 18:55:53,921 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 18:55:53,921 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Kreise in den Sommer und Kreise in den Sommer und Kreise in den Sommer und Kreislauf.
2023-05-30 18:55:53,921 - INFO - joeynmt.training - Example #4
2023-05-30 18:55:53,921 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 18:55:53,922 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 18:55:53,922 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'der', 'näch@@', 'ste', 'Di@@', 'a', 'die', 'ich', 'zei@@', 'ge', 'Ihnen', 'ist', 'eine', 'ver@@', 'n@@', 'etz@@', 'te', 'Ver@@', 'si@@', 'on', 'von', 'de@@', 'm,', 'was', 'die', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.', '</s>']
2023-05-30 18:55:53,922 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 18:55:53,922 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 18:55:53,922 - INFO - joeynmt.training - 	Hypothesis: Und der nächste Dia die ich zeige Ihnen ist eine vernetzte Version von dem, was die letzten 25 Jahren passiert ist.
2023-05-30 18:56:09,791 - INFO - joeynmt.training - Epoch   8, Step:    31600, Batch Loss:     1.588831, Batch Acc: 0.523192, Tokens per Sec:     4759, Lr: 0.000300
2023-05-30 18:56:26,664 - INFO - joeynmt.training - Epoch   8, Step:    31700, Batch Loss:     1.763724, Batch Acc: 0.525654, Tokens per Sec:     4556, Lr: 0.000300
2023-05-30 18:56:43,863 - INFO - joeynmt.training - Epoch   8, Step:    31800, Batch Loss:     1.483667, Batch Acc: 0.524268, Tokens per Sec:     4418, Lr: 0.000300
2023-05-30 18:57:00,238 - INFO - joeynmt.training - Epoch   8, Step:    31900, Batch Loss:     1.560977, Batch Acc: 0.521055, Tokens per Sec:     4648, Lr: 0.000300
2023-05-30 18:57:17,032 - INFO - joeynmt.training - Epoch   8, Step:    32000, Batch Loss:     1.653469, Batch Acc: 0.526237, Tokens per Sec:     4427, Lr: 0.000300
2023-05-30 18:57:17,034 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 18:57:17,034 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 18:58:35,243 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.86, ppl:   6.39, acc:   0.47, generation: 78.2010[sec], evaluation: 0.0000[sec]
2023-05-30 18:58:35,244 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 18:58:35,317 - INFO - joeynmt.helpers - delete models/transformer_model2/30500.ckpt
2023-05-30 18:58:35,318 - INFO - joeynmt.training - Example #0
2023-05-30 18:58:35,318 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 18:58:35,318 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 18:58:35,319 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'zei@@', 'ge', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'zei@@', 'g@@', 'ten,', 'dass', 'die', 'P@@', 'ol@@', 'i@@', 'sk@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'von', 'den', 'U@@', 'S@@', 'A', 'der', 'U@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'ge@@', 'k@@', 'ro@@', 't@@', 'et.', '</s>']
2023-05-30 18:58:35,319 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 18:58:35,319 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 18:58:35,319 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr zeige ich diese beiden Folien zeigten, dass die Poliskap, die die letzten drei Millionen Jahre alt von den USA der USA mit 40 Prozent der USA mit 40 Prozent gekrotet.
2023-05-30 18:58:35,319 - INFO - joeynmt.training - Example #1
2023-05-30 18:58:35,319 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 18:58:35,319 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 18:58:35,319 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'Unter@@', 'sch@@', 'ä@@', 'tz@@', 't', 'das', 'F@@', 'ern@@', 'st', 'der', 'F@@', 'äh@@', 'igkeit', 'des', 'E@@', 'is', 'zei@@', 't@@', 'wei@@', 't', 'zu', 'zei@@', 'gen.', '</s>']
2023-05-30 18:58:35,319 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 18:58:35,319 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 18:58:35,319 - INFO - joeynmt.training - 	Hypothesis: Aber das Unterschätzt das Fernst der Fähigkeit des Eis zeitweit zu zeigen.
2023-05-30 18:58:35,319 - INFO - joeynmt.training - Example #2
2023-05-30 18:58:35,319 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 18:58:35,319 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 18:58:35,319 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sch@@', 'ul@@', 'e', 'der', 'N@@', 'or@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'S@@', 'in@@', 'n', 'des', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 's', 'in', 'unser@@', 'em', 'G@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', '-@@', 'K@@', 'li@@', 'ma@@', '-@@', 'St@@', 'em@@', '.', '</s>']
2023-05-30 18:58:35,319 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 18:58:35,319 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 18:58:35,319 - INFO - joeynmt.training - 	Hypothesis: Die Eisschule der Nordpol ist in gewissem Sinn des Klimawandels in unserem Globalen Klimawandel-Klima-Stem.
2023-05-30 18:58:35,319 - INFO - joeynmt.training - Example #3
2023-05-30 18:58:35,319 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 18:58:35,319 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 18:58:35,320 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'rei@@', 's', 'in', 'den', 'S@@', 'om@@', 'er.', '</s>']
2023-05-30 18:58:35,320 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 18:58:35,320 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 18:58:35,320 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Kreis in den Somer.
2023-05-30 18:58:35,320 - INFO - joeynmt.training - Example #4
2023-05-30 18:58:35,320 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 18:58:35,320 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 18:58:35,320 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', 'zei@@', 'gt', 'eine', 'ver@@', 'schn@@', 'ell@@', 'te', 'Ver@@', 'si@@', 'on', 'von', 'de@@', 'm,', 'was', 'die', 'letzten', '2@@', '5', 'Jahre', 'pass@@', 'iert.', '</s>']
2023-05-30 18:58:35,320 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 18:58:35,320 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 18:58:35,320 - INFO - joeynmt.training - 	Hypothesis: Und die nächste Folie zeigt eine verschnellte Version von dem, was die letzten 25 Jahre passiert.
2023-05-30 18:58:51,279 - INFO - joeynmt.training - Epoch   8, Step:    32100, Batch Loss:     1.673918, Batch Acc: 0.521802, Tokens per Sec:     4764, Lr: 0.000300
2023-05-30 18:59:07,950 - INFO - joeynmt.training - Epoch   8, Step:    32200, Batch Loss:     1.592487, Batch Acc: 0.521887, Tokens per Sec:     4484, Lr: 0.000300
2023-05-30 18:59:23,701 - INFO - joeynmt.training - Epoch   8, Step:    32300, Batch Loss:     1.505981, Batch Acc: 0.521768, Tokens per Sec:     4930, Lr: 0.000300
2023-05-30 18:59:40,410 - INFO - joeynmt.training - Epoch   8, Step:    32400, Batch Loss:     1.664911, Batch Acc: 0.523697, Tokens per Sec:     4548, Lr: 0.000300
2023-05-30 18:59:56,855 - INFO - joeynmt.training - Epoch   8, Step:    32500, Batch Loss:     1.512111, Batch Acc: 0.523884, Tokens per Sec:     4645, Lr: 0.000300
2023-05-30 18:59:56,855 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 18:59:56,855 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 19:01:05,874 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.86, ppl:   6.42, acc:   0.47, generation: 69.0107[sec], evaluation: 0.0000[sec]
2023-05-30 19:01:05,953 - INFO - joeynmt.helpers - delete models/transformer_model2/29500.ckpt
2023-05-30 19:01:05,956 - INFO - joeynmt.training - Example #0
2023-05-30 19:01:05,956 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 19:01:05,956 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 19:01:05,956 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ie', 'ge@@', 'zei@@', 'gt', 'ha@@', 'be,', 'um', 'zu', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'i@@', 'sk@@', 'ap@@', ',', 'die', 'letz@@', 'te', 'drei', 'Millionen', 'Jahre', 'un@@', 'gefä@@', 'hr', 'die', 'Gr@@', 'ö@@', 'ß@@', 'e', 'der', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ü@@', 'm@@', 'pf@@', 'en.', '</s>']
2023-05-30 19:01:05,957 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 19:01:05,957 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 19:01:05,957 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese beiden Folie gezeigt habe, um zu zeigen, dass die Poliskap, die letzte drei Millionen Jahre ungefähr die Größe der USA, mit 40% gekümpfen.
2023-05-30 19:01:05,957 - INFO - joeynmt.training - Example #1
2023-05-30 19:01:05,957 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 19:01:05,957 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 19:01:05,957 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'tatsächlich', 'die', 'ern@@', 'ste', 'Proble@@', 'me', 'der', 'ern@@', 'sten', 'Proble@@', 'me,', 'weil', 'es', 'nicht', 'die', 'D@@', 'ik@@', 'te', 'des', 'E@@', 'is', 'zei@@', 't.', '</s>']
2023-05-30 19:01:05,957 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 19:01:05,957 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 19:01:05,957 - INFO - joeynmt.training - 	Hypothesis: Aber das ist tatsächlich die ernste Probleme der ernsten Probleme, weil es nicht die Dikte des Eis zeit.
2023-05-30 19:01:05,957 - INFO - joeynmt.training - Example #2
2023-05-30 19:01:05,957 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 19:01:05,957 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 19:01:05,957 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sch@@', 'ul@@', 'e', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'er', 'S@@', 'in@@', 'n', 'des', 'H@@', 'ar@@', 't', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', '-@@', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', '-@@', 'St@@', 'em@@', '.', '</s>']
2023-05-30 19:01:05,957 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 19:01:05,957 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 19:01:05,957 - INFO - joeynmt.training - 	Hypothesis: Die Eisschule auf der Nordpoll ist in gewisser Sinn des Hart unseres globalen Klimawandel-Klimawandel-Stem.
2023-05-30 19:01:05,957 - INFO - joeynmt.training - Example #3
2023-05-30 19:01:05,957 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 19:01:05,957 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 19:01:05,958 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'den', 'S@@', 'om@@', 'mer@@', '.', '</s>']
2023-05-30 19:01:05,958 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 19:01:05,958 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 19:01:05,958 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Krimft in den Sommer.
2023-05-30 19:01:05,958 - INFO - joeynmt.training - Example #4
2023-05-30 19:01:05,958 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 19:01:05,958 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 19:01:05,958 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', 'zei@@', 'gt', 'eine', 'ver@@', 'n@@', 'etz@@', 'te', 'Ver@@', 'si@@', 'on', 'von', 'de@@', 'm,', 'was', 'die', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert.', '</s>']
2023-05-30 19:01:05,958 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 19:01:05,958 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 19:01:05,958 - INFO - joeynmt.training - 	Hypothesis: Und die nächste Folie zeigt eine vernetzte Version von dem, was die letzten 25 Jahren passiert.
2023-05-30 19:01:22,089 - INFO - joeynmt.training - Epoch   8, Step:    32600, Batch Loss:     1.703586, Batch Acc: 0.522133, Tokens per Sec:     4627, Lr: 0.000300
2023-05-30 19:01:37,836 - INFO - joeynmt.training - Epoch   8, Step:    32700, Batch Loss:     1.701187, Batch Acc: 0.514651, Tokens per Sec:     4783, Lr: 0.000300
2023-05-30 19:01:56,145 - INFO - joeynmt.training - Epoch   8, Step:    32800, Batch Loss:     1.580777, Batch Acc: 0.523962, Tokens per Sec:     4216, Lr: 0.000300
2023-05-30 19:02:12,744 - INFO - joeynmt.training - Epoch   8, Step:    32900, Batch Loss:     1.421338, Batch Acc: 0.522097, Tokens per Sec:     4587, Lr: 0.000300
2023-05-30 19:02:28,836 - INFO - joeynmt.training - Epoch   8, Step:    33000, Batch Loss:     1.642509, Batch Acc: 0.523534, Tokens per Sec:     4646, Lr: 0.000300
2023-05-30 19:02:28,837 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 19:02:28,837 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 19:03:38,569 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.86, ppl:   6.40, acc:   0.47, generation: 69.7241[sec], evaluation: 0.0000[sec]
2023-05-30 19:03:38,647 - INFO - joeynmt.helpers - delete models/transformer_model2/29000.ckpt
2023-05-30 19:03:38,649 - INFO - joeynmt.training - Example #0
2023-05-30 19:03:38,649 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 19:03:38,649 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 19:03:38,649 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'zei@@', 'g@@', 'te', 'ich', 'diese', 'bei@@', 'den', 'Di@@', 'a@@', 'st', 'zei@@', 'g@@', 'te', 'ich', 'mich', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'it@@', 'ik', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'die', 'Gr@@', 'ö@@', 'ß@@', 'e', 'der', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A', 'war.', '</s>']
2023-05-30 19:03:38,649 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 19:03:38,649 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 19:03:38,649 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr zeigte ich diese beiden Diast zeigte ich mich zeigen, dass die Politik in den letzten drei Millionen Jahre alt hatte, die Größe der USA, mit 40 Prozent der USA, mit 40 Prozent der USA war.
2023-05-30 19:03:38,649 - INFO - joeynmt.training - Example #1
2023-05-30 19:03:38,649 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 19:03:38,649 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 19:03:38,649 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'dieses', 'Unter@@', 'sch@@', 'ä@@', 'tz@@', 'te', 'der', 'Er@@', 'n@@', 'st', 'dieses', 'spe@@', 'zi@@', 'f@@', 'ische', 'Proble@@', 'm@@', 'l@@', 'en@@', 'der', 'E@@', 'is', 'zei@@', 't.', '</s>']
2023-05-30 19:03:38,650 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 19:03:38,650 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 19:03:38,650 - INFO - joeynmt.training - 	Hypothesis: Aber dieses Unterschätzte der Ernst dieses spezifische Problemlender Eis zeit.
2023-05-30 19:03:38,650 - INFO - joeynmt.training - Example #2
2023-05-30 19:03:38,650 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 19:03:38,650 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 19:03:38,650 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'k@@', 'är@@', 'e', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'er', 'S@@', 'in@@', 'n', 'des', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 's', 'in', 'der', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', '.', '</s>']
2023-05-30 19:03:38,650 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 19:03:38,650 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 19:03:38,650 - INFO - joeynmt.training - 	Hypothesis: Die Eiskäre auf der Nordpol ist in gewisser Sinn des Klimawandels in der Klimawandel.
2023-05-30 19:03:38,650 - INFO - joeynmt.training - Example #3
2023-05-30 19:03:38,650 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 19:03:38,650 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 19:03:38,650 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'rei@@', 's', 'in', 'den', 'S@@', 'omm@@', 'er', 'ge@@', 'sam@@', 't.', '</s>']
2023-05-30 19:03:38,650 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 19:03:38,650 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 19:03:38,650 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Kreis in den Sommer gesamt.
2023-05-30 19:03:38,650 - INFO - joeynmt.training - Example #4
2023-05-30 19:03:38,650 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 19:03:38,650 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 19:03:38,650 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', 'zei@@', 'gt', 'eine', 'ver@@', 'n@@', 'etz@@', 'te', 'Ver@@', 'si@@', 'on', 'von', 'de@@', 'm,', 'was', 'die', 'letzten', '2@@', '5', 'Jahre', 'pass@@', 'iert', 'ist.', '</s>']
2023-05-30 19:03:38,651 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 19:03:38,651 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 19:03:38,651 - INFO - joeynmt.training - 	Hypothesis: Und die nächste Folie zeigt eine vernetzte Version von dem, was die letzten 25 Jahre passiert ist.
2023-05-30 19:03:54,598 - INFO - joeynmt.training - Epoch   8, Step:    33100, Batch Loss:     1.553151, Batch Acc: 0.515687, Tokens per Sec:     4821, Lr: 0.000300
2023-05-30 19:04:10,091 - INFO - joeynmt.training - Epoch   8, Step:    33200, Batch Loss:     1.699382, Batch Acc: 0.520932, Tokens per Sec:     4696, Lr: 0.000300
2023-05-30 19:04:21,748 - INFO - joeynmt.training - Epoch   8: total training loss 6755.44
2023-05-30 19:04:21,749 - INFO - joeynmt.training - EPOCH 9
2023-05-30 19:04:25,490 - INFO - joeynmt.training - Epoch   9, Step:    33300, Batch Loss:     1.428566, Batch Acc: 0.542461, Tokens per Sec:     5228, Lr: 0.000300
2023-05-30 19:04:41,370 - INFO - joeynmt.training - Epoch   9, Step:    33400, Batch Loss:     1.506588, Batch Acc: 0.538651, Tokens per Sec:     4669, Lr: 0.000300
2023-05-30 19:04:57,365 - INFO - joeynmt.training - Epoch   9, Step:    33500, Batch Loss:     1.560521, Batch Acc: 0.538433, Tokens per Sec:     4846, Lr: 0.000300
2023-05-30 19:04:57,365 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 19:04:57,365 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 19:06:04,793 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.85, ppl:   6.39, acc:   0.47, generation: 67.4192[sec], evaluation: 0.0000[sec]
2023-05-30 19:06:04,796 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 19:06:04,873 - INFO - joeynmt.helpers - delete models/transformer_model2/28500.ckpt
2023-05-30 19:06:04,875 - INFO - joeynmt.training - Example #0
2023-05-30 19:06:04,875 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 19:06:04,875 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 19:06:04,875 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'it@@', 'i@@', 'k@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'etwa', 'die', 'Gr@@', 'ö@@', 'ß@@', 'e', 'des', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0', 'Prozent', 'ge@@', 'k@@', 'ü@@', 'm@@', 'mer@@', 'n.', '</s>']
2023-05-30 19:06:04,875 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 19:06:04,875 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 19:06:04,875 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese beiden Folien gezeigt, um zu zeigen, dass die Politikap, die die letzten drei Millionen Jahre etwa die Größe des USA, mit 40 Prozent der USA, mit 40 Prozent gekümmern.
2023-05-30 19:06:04,876 - INFO - joeynmt.training - Example #1
2023-05-30 19:06:04,876 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 19:06:04,876 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 19:06:04,876 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'Unter@@', 'sch@@', 'ä@@', 'tz@@', 'te', 'im', 'Gr@@', 'unde', 'des', 'E@@', 'is', 'dieses', 'Sp@@', 'e@@', 'zi@@', 'al@@', 'es', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'T@@', 'ik@@', 'er@@', 'ei@@', 's@@', 'en.', '</s>']
2023-05-30 19:06:04,876 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 19:06:04,876 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 19:06:04,876 - INFO - joeynmt.training - 	Hypothesis: Aber das Unterschätzte im Grunde des Eis dieses Speziales Problem ist, weil es nicht die Tikereisen.
2023-05-30 19:06:04,876 - INFO - joeynmt.training - Example #2
2023-05-30 19:06:04,876 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 19:06:04,876 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 19:06:04,876 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'k@@', 'at@@', 'at@@', 'ische', 'E@@', 'is@@', 'k@@', 'at@@', 'ast@@', 'rop@@', 'he', 'in', 'gew@@', 'iss@@', 'er', 'S@@', 'inn@@', 'e', 'des', 'G@@', 'lob@@', 'al@@', '-@@', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 's', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 's@@', '-@@', 'St@@', 'em@@', '.', '</s>']
2023-05-30 19:06:04,876 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 19:06:04,876 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 19:06:04,876 - INFO - joeynmt.training - 	Hypothesis: Die Eiskatatische Eiskatastrophe in gewisser Sinne des Global-Klimawandels Klimawandels-Stem.
2023-05-30 19:06:04,876 - INFO - joeynmt.training - Example #3
2023-05-30 19:06:04,876 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 19:06:04,876 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 19:06:04,876 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'rei@@', 's', 'in', 'den', 'S@@', 'om@@', 'mer@@', '.', '</s>']
2023-05-30 19:06:04,876 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 19:06:04,876 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 19:06:04,876 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Kreis in den Sommer.
2023-05-30 19:06:04,876 - INFO - joeynmt.training - Example #4
2023-05-30 19:06:04,877 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 19:06:04,877 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 19:06:04,877 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', 'zei@@', 'gt', 'eine', 'ver@@', 'n@@', 'ell@@', 'te', 'Ver@@', 'si@@', 'on', 'von', 'de@@', 'm,', 'was', 'die', 'letzten', '2@@', '5', 'Jahre', 'pass@@', 'iert', 'ist.', '</s>']
2023-05-30 19:06:04,877 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 19:06:04,877 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 19:06:04,877 - INFO - joeynmt.training - 	Hypothesis: Und die nächste Folie zeigt eine vernellte Version von dem, was die letzten 25 Jahre passiert ist.
2023-05-30 19:06:21,108 - INFO - joeynmt.training - Epoch   9, Step:    33600, Batch Loss:     1.478919, Batch Acc: 0.540088, Tokens per Sec:     4785, Lr: 0.000300
2023-05-30 19:06:37,728 - INFO - joeynmt.training - Epoch   9, Step:    33700, Batch Loss:     1.450262, Batch Acc: 0.540420, Tokens per Sec:     4563, Lr: 0.000300
2023-05-30 19:06:54,068 - INFO - joeynmt.training - Epoch   9, Step:    33800, Batch Loss:     1.526001, Batch Acc: 0.536640, Tokens per Sec:     4640, Lr: 0.000300
2023-05-30 19:07:09,634 - INFO - joeynmt.training - Epoch   9, Step:    33900, Batch Loss:     1.669626, Batch Acc: 0.540481, Tokens per Sec:     4744, Lr: 0.000300
2023-05-30 19:07:25,632 - INFO - joeynmt.training - Epoch   9, Step:    34000, Batch Loss:     1.580743, Batch Acc: 0.534746, Tokens per Sec:     4800, Lr: 0.000300
2023-05-30 19:07:25,633 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 19:07:25,633 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 19:08:38,895 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.86, ppl:   6.42, acc:   0.47, generation: 73.2543[sec], evaluation: 0.0000[sec]
2023-05-30 19:08:38,973 - INFO - joeynmt.helpers - delete models/transformer_model2/31500.ckpt
2023-05-30 19:08:38,976 - INFO - joeynmt.training - Example #0
2023-05-30 19:08:38,976 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 19:08:38,976 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 19:08:38,976 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I@@', 'm', 'letzten', 'drei', 'Jahre', 'al@@', 't', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'ge@@', 'zei@@', 'gt', 'haben,', 'dass', 'die', 'P@@', 'ol@@', 'ar@@', 'i@@', 'o@@', '-@@', 'E@@', 'is@@', 'sch@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'etwa', 'die', 'Gr@@', 'ö@@', 'ß@@', 'e', 'der', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0', 'Prozent', 'der', 'Ver@@', 'ein@@', 'ig@@', 'ten', 'St@@', 'aa@@', 'ten', 'war.', '</s>']
2023-05-30 19:08:38,976 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 19:08:38,976 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 19:08:38,976 - INFO - joeynmt.training - 	Hypothesis: Im letzten drei Jahre alt ich diese zwei Dias gezeigt haben, dass die Polario-Eissch, die die letzten drei Millionen Jahre etwa die Größe der USA, mit 40 Prozent der USA, mit 40 Prozent der USA, mit 40 Prozent der Vereinigten Staaten war.
2023-05-30 19:08:38,976 - INFO - joeynmt.training - Example #1
2023-05-30 19:08:38,976 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 19:08:38,976 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 19:08:38,976 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'dieses', 'Unter@@', 'sch@@', 'ä@@', 'tz@@', 'en,', 'dass', 'es', 'wirklich', 'den', 'F@@', 'ern@@', 'st', 'dieses', 'Sp@@', 'e@@', 'zi@@', 'f@@', 'ik', 'der', 'E@@', 'is', 'zei@@', 't.', '</s>']
2023-05-30 19:08:38,976 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 19:08:38,976 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 19:08:38,976 - INFO - joeynmt.training - 	Hypothesis: Aber dieses Unterschätzen, dass es wirklich den Fernst dieses Spezifik der Eis zeit.
2023-05-30 19:08:38,977 - INFO - joeynmt.training - Example #2
2023-05-30 19:08:38,977 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 19:08:38,977 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 19:08:38,977 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'k@@', 'ul@@', 'ar@@', 'e', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'er', 'S@@', 'inn@@', 'e', 'des', 'G@@', 'lob@@', 'al', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 's', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', '.', '</s>']
2023-05-30 19:08:38,977 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 19:08:38,977 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 19:08:38,977 - INFO - joeynmt.training - 	Hypothesis: Die Eiskulare auf der Nordpol ist in gewisser Sinne des Global Klimawandels Klimawandel.
2023-05-30 19:08:38,977 - INFO - joeynmt.training - Example #3
2023-05-30 19:08:38,977 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 19:08:38,977 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 19:08:38,977 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'rei@@', 's', 'in', 'den', 'S@@', 'om@@', 'mer@@', '.', '</s>']
2023-05-30 19:08:38,977 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 19:08:38,977 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 19:08:38,977 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Kreis in den Sommer.
2023-05-30 19:08:38,977 - INFO - joeynmt.training - Example #4
2023-05-30 19:08:38,977 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 19:08:38,977 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 19:08:38,977 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'näch@@', 'sten', 'F@@', 'ol@@', 'ie', 'zei@@', 'gt', 'eine', 'ver@@', 'n@@', 'etz@@', 'te', 'Ver@@', 'si@@', 'on', 'von', 'dem', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'wird.', '</s>']
2023-05-30 19:08:38,977 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 19:08:38,977 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 19:08:38,977 - INFO - joeynmt.training - 	Hypothesis: Und die nächsten Folie zeigt eine vernetzte Version von dem letzten 25 Jahren passiert wird.
2023-05-30 19:08:55,382 - INFO - joeynmt.training - Epoch   9, Step:    34100, Batch Loss:     1.654788, Batch Acc: 0.535350, Tokens per Sec:     4608, Lr: 0.000300
2023-05-30 19:09:11,566 - INFO - joeynmt.training - Epoch   9, Step:    34200, Batch Loss:     1.556268, Batch Acc: 0.535656, Tokens per Sec:     4580, Lr: 0.000300
2023-05-30 19:09:28,024 - INFO - joeynmt.training - Epoch   9, Step:    34300, Batch Loss:     1.393441, Batch Acc: 0.531977, Tokens per Sec:     4503, Lr: 0.000300
2023-05-30 19:09:44,803 - INFO - joeynmt.training - Epoch   9, Step:    34400, Batch Loss:     1.413442, Batch Acc: 0.538538, Tokens per Sec:     4509, Lr: 0.000300
2023-05-30 19:10:00,379 - INFO - joeynmt.training - Epoch   9, Step:    34500, Batch Loss:     1.637247, Batch Acc: 0.535973, Tokens per Sec:     4957, Lr: 0.000300
2023-05-30 19:10:00,379 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 19:10:00,379 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 19:11:19,375 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.86, ppl:   6.39, acc:   0.47, generation: 78.9874[sec], evaluation: 0.0000[sec]
2023-05-30 19:11:19,452 - INFO - joeynmt.helpers - delete models/transformer_model2/32500.ckpt
2023-05-30 19:11:19,454 - INFO - joeynmt.training - Example #0
2023-05-30 19:11:19,454 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 19:11:19,454 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 19:11:19,454 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'zei@@', 'ge', 'ich', 'diese', 'zwei', 'Di@@', 'a@@', 'st', 'zei@@', 'ge', 'ge@@', 'zei@@', 'gt,', 'dass', 'die', 'P@@', 'ol@@', 'i@@', 'sk@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'mit', '4@@', '0', 'Prozent', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pf@@', 'en.', '</s>']
2023-05-30 19:11:19,454 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 19:11:19,454 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 19:11:19,454 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr zeige ich diese zwei Diast zeige gezeigt, dass die Poliskap, die die letzten drei Millionen Jahre alt hatte, die die letzten drei Millionen Jahre alt hatte, mit 40 Prozent gekrompfen.
2023-05-30 19:11:19,454 - INFO - joeynmt.training - Example #1
2023-05-30 19:11:19,454 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 19:11:19,454 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 19:11:19,454 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'wirklich', 'der', 'F@@', 'un@@', 'kti@@', 'on', 'des', 'E@@', 'is', 'dieses', 'best@@', 'imm@@', 'es', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'T@@', 'ik@@', 'te', 'des', 'E@@', 'is', 'zei@@', 't.', '</s>']
2023-05-30 19:11:19,455 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 19:11:19,455 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 19:11:19,455 - INFO - joeynmt.training - 	Hypothesis: Aber das ist wirklich der Funktion des Eis dieses bestimmes Problem ist, weil es nicht die Tikte des Eis zeit.
2023-05-30 19:11:19,455 - INFO - joeynmt.training - Example #2
2023-05-30 19:11:19,455 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 19:11:19,455 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 19:11:19,455 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'k@@', 'ut@@', 'iert', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'er', 'S@@', 'inn@@', 'e', 'des', 'H@@', 'ar@@', 'm@@', 'es', 'K@@', 'li@@', 'ma@@', 's', 'in', 'der', 'L@@', 'age', 'der', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 'st@@', 'am@@', 'm@@', 's.', '</s>']
2023-05-30 19:11:19,455 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 19:11:19,455 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 19:11:19,455 - INFO - joeynmt.training - 	Hypothesis: Die Eiskutiert auf der Nordpol ist in gewisser Sinne des Harmes Klimas in der Lage der Klimawandelstamms.
2023-05-30 19:11:19,455 - INFO - joeynmt.training - Example #3
2023-05-30 19:11:19,455 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 19:11:19,455 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 19:11:19,455 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'S@@', 'om@@', 'mer@@', 'n', 'und', 'K@@', 'rei@@', 's', 'in', 'den', 'S@@', 'om@@', 'mer@@', '.', '</s>']
2023-05-30 19:11:19,455 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 19:11:19,455 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 19:11:19,455 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Sommern und Kreis in den Sommer.
2023-05-30 19:11:19,455 - INFO - joeynmt.training - Example #4
2023-05-30 19:11:19,455 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 19:11:19,455 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 19:11:19,455 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', 'zei@@', 'gt', 'eine', 'ver@@', 'n@@', 'etz@@', 'te', 'Ver@@', 'si@@', 'on', 'von', 'dem', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert.', '</s>']
2023-05-30 19:11:19,456 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 19:11:19,456 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 19:11:19,456 - INFO - joeynmt.training - 	Hypothesis: Und die nächste Folie zeigt eine vernetzte Version von dem letzten 25 Jahren passiert.
2023-05-30 19:11:35,623 - INFO - joeynmt.training - Epoch   9, Step:    34600, Batch Loss:     1.696621, Batch Acc: 0.531072, Tokens per Sec:     4671, Lr: 0.000300
2023-05-30 19:11:53,088 - INFO - joeynmt.training - Epoch   9, Step:    34700, Batch Loss:     1.666092, Batch Acc: 0.535353, Tokens per Sec:     4177, Lr: 0.000300
2023-05-30 19:12:09,708 - INFO - joeynmt.training - Epoch   9, Step:    34800, Batch Loss:     1.663308, Batch Acc: 0.531968, Tokens per Sec:     4580, Lr: 0.000300
2023-05-30 19:12:26,562 - INFO - joeynmt.training - Epoch   9, Step:    34900, Batch Loss:     1.609594, Batch Acc: 0.536802, Tokens per Sec:     4447, Lr: 0.000300
2023-05-30 19:12:42,793 - INFO - joeynmt.training - Epoch   9, Step:    35000, Batch Loss:     1.539777, Batch Acc: 0.531458, Tokens per Sec:     4616, Lr: 0.000300
2023-05-30 19:12:42,794 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 19:12:42,794 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 19:14:11,104 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.85, ppl:   6.36, acc:   0.47, generation: 88.3021[sec], evaluation: 0.0000[sec]
2023-05-30 19:14:11,106 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 19:14:11,183 - INFO - joeynmt.helpers - delete models/transformer_model2/34000.ckpt
2023-05-30 19:14:11,184 - INFO - joeynmt.training - Example #0
2023-05-30 19:14:11,185 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 19:14:11,185 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 19:14:11,185 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'a@@', 's', 'ge@@', 'zei@@', 'gt', 'ha@@', 'be,', 'dass', 'die', 'P@@', 'ol@@', 'it@@', 'i@@', 'k@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'un@@', 'gefä@@', 'hr', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'un@@', 'gefä@@', 'hr', 'die', 'Gr@@', 'ö@@', 'ß@@', 'e', 'der', 'U@@', 'S@@', 'A', 'mit', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ü@@', 'm@@', 'pf@@', 'en.', '</s>']
2023-05-30 19:14:11,185 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 19:14:11,185 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 19:14:11,185 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Dias gezeigt habe, dass die Politikap, die die letzten drei Millionen Jahre ungefähr die letzten drei Millionen Jahre ungefähr die Größe der USA mit 40% gekümpfen.
2023-05-30 19:14:11,185 - INFO - joeynmt.training - Example #1
2023-05-30 19:14:11,185 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 19:14:11,185 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 19:14:11,185 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'ein', 'Unter@@', 'sch@@', 'ä@@', 'tz@@', 'ung', 'der', 'ern@@', 'st', 'des', 'Sp@@', 'e@@', 'zi@@', 'f@@', 'ischen', 'Proble@@', 'm@@', 's', 'zei@@', 'gt', 'es', 'nicht', 'die', 'T@@', 'ik@@', 'el', 'des', 'E@@', 'is', 'zei@@', 'gen.', '</s>']
2023-05-30 19:14:11,185 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 19:14:11,185 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 19:14:11,185 - INFO - joeynmt.training - 	Hypothesis: Aber das ist ein Unterschätzung der ernst des Spezifischen Problems zeigt es nicht die Tikel des Eis zeigen.
2023-05-30 19:14:11,185 - INFO - joeynmt.training - Example #2
2023-05-30 19:14:11,185 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 19:14:11,185 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 19:14:11,185 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sch@@', 'a@@', 'de,', 'die', 'E@@', 'is@@', 'sch@@', 'e@@', '-@@', 'S@@', 'k@@', 'it@@', 'z@@', 'ung', 'ist', 'in', 'gew@@', 'iss@@', 'er', 'Wei@@', 'se', 'gew@@', 'iss@@', 'er', 'S@@', 'inn@@', 'e', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', '.', '</s>']
2023-05-30 19:14:11,185 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 19:14:11,185 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 19:14:11,185 - INFO - joeynmt.training - 	Hypothesis: Die Eisschade, die Eissche-Skitzung ist in gewisser Weise gewisser Sinne unseres globalen Klimawandel.
2023-05-30 19:14:11,185 - INFO - joeynmt.training - Example #3
2023-05-30 19:14:11,186 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 19:14:11,186 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 19:14:11,186 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'wird', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'ä@@', 'm@@', 'pf@@', 't.', '</s>']
2023-05-30 19:14:11,186 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 19:14:11,186 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 19:14:11,186 - INFO - joeynmt.training - 	Hypothesis: Es wird in den Sommer und Krämpft.
2023-05-30 19:14:11,186 - INFO - joeynmt.training - Example #4
2023-05-30 19:14:11,186 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 19:14:11,186 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 19:14:11,186 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'der', 'näch@@', 'ste', 'Di@@', 'a', 'die', 'ich', 'zei@@', 'ge', 'Ihnen', 'ist', 'eine', 'ver@@', 'n@@', 'etz@@', 'te', 'Ver@@', 'si@@', 'on', 'von', 'de@@', 'm,', 'was', 'die', 'letzten', '2@@', '5', 'Jahre', 'pass@@', 'iert.', '</s>']
2023-05-30 19:14:11,186 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 19:14:11,186 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 19:14:11,186 - INFO - joeynmt.training - 	Hypothesis: Und der nächste Dia die ich zeige Ihnen ist eine vernetzte Version von dem, was die letzten 25 Jahre passiert.
2023-05-30 19:14:27,719 - INFO - joeynmt.training - Epoch   9, Step:    35100, Batch Loss:     1.647181, Batch Acc: 0.530756, Tokens per Sec:     4635, Lr: 0.000300
2023-05-30 19:14:45,022 - INFO - joeynmt.training - Epoch   9, Step:    35200, Batch Loss:     1.710999, Batch Acc: 0.530771, Tokens per Sec:     4356, Lr: 0.000300
2023-05-30 19:15:03,269 - INFO - joeynmt.training - Epoch   9, Step:    35300, Batch Loss:     1.531540, Batch Acc: 0.532769, Tokens per Sec:     4214, Lr: 0.000300
2023-05-30 19:15:19,444 - INFO - joeynmt.training - Epoch   9, Step:    35400, Batch Loss:     1.622493, Batch Acc: 0.524063, Tokens per Sec:     4778, Lr: 0.000300
2023-05-30 19:15:36,997 - INFO - joeynmt.training - Epoch   9, Step:    35500, Batch Loss:     1.513038, Batch Acc: 0.534497, Tokens per Sec:     4373, Lr: 0.000300
2023-05-30 19:15:36,997 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 19:15:36,997 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 19:16:48,694 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.85, ppl:   6.33, acc:   0.47, generation: 71.6889[sec], evaluation: 0.0000[sec]
2023-05-30 19:16:48,695 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 19:16:48,772 - INFO - joeynmt.helpers - delete models/transformer_model2/33000.ckpt
2023-05-30 19:16:48,774 - INFO - joeynmt.training - Example #0
2023-05-30 19:16:48,774 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 19:16:48,774 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 19:16:48,774 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'zei@@', 'ge', 'ich', 'diese', 'zwei', 'Di@@', 'a@@', 'st', 'zei@@', 'gen,', 'um', 'die', 'P@@', 'ol@@', 'i@@', 'k@@', 'ap@@', ',', 'die', 'die', 'P@@', 'ol@@', 'it@@', 'ik@@', '-@@', 'Z@@', 'a@@', 'hl@@', 'en', 'drei', 'Millionen', 'Jahre', 'un@@', 'gefä@@', 'hr', 'die', 'Gr@@', 'ö@@', 'ß@@', 'e', 'der', 'U@@', 'S@@', 'A', 'mit', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pf@@', 'en.', '</s>']
2023-05-30 19:16:48,774 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 19:16:48,774 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 19:16:48,774 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr zeige ich diese zwei Diast zeigen, um die Polikap, die die Politik-Zahlen drei Millionen Jahre ungefähr die Größe der USA mit 40% gekrompfen.
2023-05-30 19:16:48,774 - INFO - joeynmt.training - Example #1
2023-05-30 19:16:48,775 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 19:16:48,775 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 19:16:48,775 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'ein', 'Unter@@', 'sch@@', 'ä@@', 'tz@@', 't', 'der', 'Er@@', 'de', 'dieses', 'Sp@@', 'e@@', 'zi@@', 'al@@', 'es', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'T@@', 'ik@@', 'te', 'des', 'E@@', 'is', 'zei@@', 't.', '</s>']
2023-05-30 19:16:48,775 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 19:16:48,775 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 19:16:48,775 - INFO - joeynmt.training - 	Hypothesis: Aber das ist ein Unterschätzt der Erde dieses Speziales Problem ist, weil es nicht die Tikte des Eis zeit.
2023-05-30 19:16:48,775 - INFO - joeynmt.training - Example #2
2023-05-30 19:16:48,775 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 19:16:48,775 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 19:16:48,775 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sch@@', 'ri@@', 'ff@@', 'e', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'er', 'Wei@@', 'se', 'be@@', 'tra@@', 'cht@@', 'et', 'von', 'uns', 'g@@', 'lob@@', 'al@@', 'es', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 'st@@', 'am@@', 'm@@', 't.', '</s>']
2023-05-30 19:16:48,775 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 19:16:48,775 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 19:16:48,775 - INFO - joeynmt.training - 	Hypothesis: Die Eisschriffe auf der Nordpol ist in gewisser Weise betrachtet von uns globales Klimawandelstammt.
2023-05-30 19:16:48,775 - INFO - joeynmt.training - Example #3
2023-05-30 19:16:48,775 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 19:16:48,775 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 19:16:48,775 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'rei@@', 's', 'und', 'K@@', 'rei@@', 's', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'rei@@', 's', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'rei@@', 's', '</s>']
2023-05-30 19:16:48,775 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 19:16:48,775 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 19:16:48,775 - INFO - joeynmt.training - 	Hypothesis: Es ist in der Winter und Kreis und Kreis in den Sommer und Kreis in den Sommer und Kreis
2023-05-30 19:16:48,775 - INFO - joeynmt.training - Example #4
2023-05-30 19:16:48,776 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 19:16:48,776 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 19:16:48,776 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'der', 'näch@@', 'ste', 'Di@@', 'a', 'die', 'ich', 'zei@@', 'gt,', 'ist', 'eine', 'ver@@', 'n@@', 'etz@@', 'te', 'Ver@@', 'si@@', 'on', 'von', 'de@@', 'm,', 'was', 'die', 'letzten', '2@@', '5', 'Jahre', 'pass@@', 'iert.', '</s>']
2023-05-30 19:16:48,776 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 19:16:48,776 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 19:16:48,776 - INFO - joeynmt.training - 	Hypothesis: Und der nächste Dia die ich zeigt, ist eine vernetzte Version von dem, was die letzten 25 Jahre passiert.
2023-05-30 19:17:05,148 - INFO - joeynmt.training - Epoch   9, Step:    35600, Batch Loss:     1.652846, Batch Acc: 0.529310, Tokens per Sec:     4531, Lr: 0.000300
2023-05-30 19:17:22,128 - INFO - joeynmt.training - Epoch   9, Step:    35700, Batch Loss:     1.695526, Batch Acc: 0.532307, Tokens per Sec:     4531, Lr: 0.000300
2023-05-30 19:17:38,835 - INFO - joeynmt.training - Epoch   9, Step:    35800, Batch Loss:     1.525127, Batch Acc: 0.528273, Tokens per Sec:     4645, Lr: 0.000300
2023-05-30 19:17:56,473 - INFO - joeynmt.training - Epoch   9, Step:    35900, Batch Loss:     1.535675, Batch Acc: 0.529939, Tokens per Sec:     4261, Lr: 0.000300
2023-05-30 19:18:13,894 - INFO - joeynmt.training - Epoch   9, Step:    36000, Batch Loss:     1.607226, Batch Acc: 0.525853, Tokens per Sec:     4326, Lr: 0.000300
2023-05-30 19:18:13,895 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 19:18:13,896 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 19:19:15,455 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.85, ppl:   6.36, acc:   0.47, generation: 61.5511[sec], evaluation: 0.0000[sec]
2023-05-30 19:19:15,533 - INFO - joeynmt.helpers - delete models/transformer_model2/34500.ckpt
2023-05-30 19:19:15,535 - INFO - joeynmt.training - Example #0
2023-05-30 19:19:15,535 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 19:19:15,535 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 19:19:15,535 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'zei@@', 'ge', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'sehen,', 'um', 'die', 'P@@', 'ol@@', 'it@@', 'ik@@', 'en', 'zu', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'it@@', 'ik@@', '-@@', 'S@@', 'it@@', 'z@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'un@@', 'gefä@@', 'hr', 'die', 'U@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pf@@', 'en.', '</s>']
2023-05-30 19:19:15,535 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 19:19:15,535 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 19:19:15,535 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr zeige ich diese zwei Dias sehen, um die Politiken zu zeigen, dass die Politik-Sitz, die die letzten drei Millionen Jahre ungefähr die USA mit 40 Prozent der USA mit 40 Prozent gekrompfen.
2023-05-30 19:19:15,535 - INFO - joeynmt.training - Example #1
2023-05-30 19:19:15,535 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 19:19:15,535 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 19:19:15,535 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'dieses', 'Unter@@', 'sch@@', 'ä@@', 'tz@@', 'te', 'der', 'ern@@', 'ste', 'Proble@@', 'me', 'der', 'ern@@', 'ste', 'Proble@@', 'me', 'ist,', 'weil', 'es', 'nicht', 'die', 'T@@', 'u@@', 'ss@@', ',', 'die', 'ich', 'nicht', 'die', 'T@@', 'u@@', 'ss@@', '.', '</s>']
2023-05-30 19:19:15,535 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 19:19:15,535 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 19:19:15,535 - INFO - joeynmt.training - 	Hypothesis: Aber dieses Unterschätzte der ernste Probleme der ernste Probleme ist, weil es nicht die Tuss, die ich nicht die Tuss.
2023-05-30 19:19:15,535 - INFO - joeynmt.training - Example #2
2023-05-30 19:19:15,535 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 19:19:15,536 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 19:19:15,536 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'k@@', 'ut@@', 'ier@@', 'ung', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'is', 'in', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'S@@', 'in@@', 'n', 'des', 'H@@', 'ar@@', 'm@@', 's', 'von', 'unser@@', 'em', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 'y@@', 'ste@@', 'm.', '</s>']
2023-05-30 19:19:15,536 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 19:19:15,536 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 19:19:15,536 - INFO - joeynmt.training - 	Hypothesis: Die Eiskutierung auf der Nordpolis in ist in gewissem Sinn des Harms von unserem globalen Klimawandelystem.
2023-05-30 19:19:15,536 - INFO - joeynmt.training - Example #3
2023-05-30 19:19:15,536 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 19:19:15,536 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 19:19:15,536 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'rei@@', 'sl@@', 'auf@@', '.', '</s>']
2023-05-30 19:19:15,536 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 19:19:15,536 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 19:19:15,536 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Kreislauf.
2023-05-30 19:19:15,536 - INFO - joeynmt.training - Example #4
2023-05-30 19:19:15,536 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 19:19:15,536 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 19:19:15,536 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'der', 'näch@@', 'ste', 'Di@@', 'a', 'ist', 'eine', 'ver@@', 'le@@', 'ben@@', 's@@', 'an@@', 'f@@', 'än@@', 'ge', 'Ver@@', 'si@@', 'on', 'von', 'de@@', 'm,', 'was', 'die', 'letzten', '2@@', '5', 'Jahre', 'pass@@', 'iert', 'ist.', '</s>']
2023-05-30 19:19:15,536 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 19:19:15,536 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 19:19:15,536 - INFO - joeynmt.training - 	Hypothesis: Und der nächste Dia ist eine verlebensanfänge Version von dem, was die letzten 25 Jahre passiert ist.
2023-05-30 19:19:31,753 - INFO - joeynmt.training - Epoch   9, Step:    36100, Batch Loss:     1.640184, Batch Acc: 0.532227, Tokens per Sec:     4719, Lr: 0.000300
2023-05-30 19:19:47,763 - INFO - joeynmt.training - Epoch   9, Step:    36200, Batch Loss:     1.599357, Batch Acc: 0.527016, Tokens per Sec:     4797, Lr: 0.000300
2023-05-30 19:20:04,615 - INFO - joeynmt.training - Epoch   9, Step:    36300, Batch Loss:     1.570892, Batch Acc: 0.527816, Tokens per Sec:     4354, Lr: 0.000300
2023-05-30 19:20:21,273 - INFO - joeynmt.training - Epoch   9, Step:    36400, Batch Loss:     1.794848, Batch Acc: 0.529210, Tokens per Sec:     4490, Lr: 0.000300
2023-05-30 19:20:38,167 - INFO - joeynmt.training - Epoch   9, Step:    36500, Batch Loss:     1.548517, Batch Acc: 0.533612, Tokens per Sec:     4457, Lr: 0.000300
2023-05-30 19:20:38,168 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 19:20:38,168 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 19:21:48,581 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.85, ppl:   6.34, acc:   0.47, generation: 70.4056[sec], evaluation: 0.0000[sec]
2023-05-30 19:21:48,658 - INFO - joeynmt.helpers - delete models/transformer_model2/32000.ckpt
2023-05-30 19:21:48,661 - INFO - joeynmt.training - Example #0
2023-05-30 19:21:48,661 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 19:21:48,661 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 19:21:48,661 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'zei@@', 'g@@', 'te', 'ich', 'diese', 'bei@@', 'den', 'Di@@', 'a@@', 'st', 'zei@@', 'gen', 'um', 'zu', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'it@@', 'ik@@', '-@@', 'S@@', 'a@@', 'h@@', 'n', 'der', 'U@@', 'S@@', 'A', 'vor', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'die', 'die', 'Gr@@', 'ö@@', 'ß@@', 'e', 'der', 'U@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'ge@@', 'k@@', 'ru@@', 'p@@', 'pen', 'war.', '</s>']
2023-05-30 19:21:48,662 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 19:21:48,662 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 19:21:48,662 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr zeigte ich diese beiden Diast zeigen um zu zeigen, dass die Politik-Sahn der USA vor drei Millionen Jahre alt hatte, die die Größe der USA mit 40 Prozent gekruppen war.
2023-05-30 19:21:48,662 - INFO - joeynmt.training - Example #1
2023-05-30 19:21:48,662 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 19:21:48,662 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 19:21:48,662 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'Unter@@', 'sch@@', 'ä@@', 'tz@@', 'te', 'der', 'Er@@', 'n@@', 'st', 'dieses', 'spe@@', 'zi@@', 'f@@', 'ische', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'T@@', 'ik@@', 'te', 'zei@@', 'gt', 'zei@@', 'gt.', '</s>']
2023-05-30 19:21:48,662 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 19:21:48,662 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 19:21:48,662 - INFO - joeynmt.training - 	Hypothesis: Aber das Unterschätzte der Ernst dieses spezifische Problem ist, weil es nicht die Tikte zeigt zeigt.
2023-05-30 19:21:48,662 - INFO - joeynmt.training - Example #2
2023-05-30 19:21:48,662 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 19:21:48,662 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 19:21:48,662 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'k@@', 'ut@@', 'iert', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'is', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'des', 'H@@', 'ar@@', 'z', 'unserer', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 'y@@', 'ste@@', 'm.', '</s>']
2023-05-30 19:21:48,662 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 19:21:48,662 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 19:21:48,662 - INFO - joeynmt.training - 	Hypothesis: Die Eiskutiert auf der Nordpolis ist in gewissem Sinne des Harz unserer globalen Klimawandelystem.
2023-05-30 19:21:48,662 - INFO - joeynmt.training - Example #3
2023-05-30 19:21:48,662 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 19:21:48,662 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 19:21:48,662 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'der', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'ä@@', 'm@@', 'pf@@', 't.', '</s>']
2023-05-30 19:21:48,663 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 19:21:48,663 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 19:21:48,663 - INFO - joeynmt.training - 	Hypothesis: Es ist in der Winter und Krämpft.
2023-05-30 19:21:48,663 - INFO - joeynmt.training - Example #4
2023-05-30 19:21:48,663 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 19:21:48,663 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 19:21:48,663 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'der', 'näch@@', 'sten', 'Di@@', 'a', 'die', 'ich', 'zei@@', 'ge', 'Ihnen', 'eine', 'ver@@', 'n@@', 'etz@@', 'te', 'Ver@@', 'si@@', 'on', 'von', 'dem', 'letzten', '2@@', '5', 'Jahre', 'pass@@', 'iert', 'ist.', '</s>']
2023-05-30 19:21:48,663 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 19:21:48,663 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 19:21:48,663 - INFO - joeynmt.training - 	Hypothesis: Und der nächsten Dia die ich zeige Ihnen eine vernetzte Version von dem letzten 25 Jahre passiert ist.
2023-05-30 19:22:06,379 - INFO - joeynmt.training - Epoch   9, Step:    36600, Batch Loss:     1.677705, Batch Acc: 0.527512, Tokens per Sec:     4199, Lr: 0.000300
2023-05-30 19:22:23,025 - INFO - joeynmt.training - Epoch   9, Step:    36700, Batch Loss:     1.591070, Batch Acc: 0.527610, Tokens per Sec:     4592, Lr: 0.000300
2023-05-30 19:22:40,055 - INFO - joeynmt.training - Epoch   9, Step:    36800, Batch Loss:     1.839246, Batch Acc: 0.528597, Tokens per Sec:     4557, Lr: 0.000300
2023-05-30 19:22:56,754 - INFO - joeynmt.training - Epoch   9, Step:    36900, Batch Loss:     1.562942, Batch Acc: 0.531412, Tokens per Sec:     4414, Lr: 0.000300
2023-05-30 19:23:14,303 - INFO - joeynmt.training - Epoch   9, Step:    37000, Batch Loss:     1.456780, Batch Acc: 0.534262, Tokens per Sec:     4389, Lr: 0.000300
2023-05-30 19:23:14,304 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 19:23:14,304 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 19:24:14,517 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.84, ppl:   6.33, acc:   0.47, generation: 60.2041[sec], evaluation: 0.0000[sec]
2023-05-30 19:24:14,519 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 19:24:14,596 - INFO - joeynmt.helpers - delete models/transformer_model2/33500.ckpt
2023-05-30 19:24:14,598 - INFO - joeynmt.training - Example #0
2023-05-30 19:24:14,598 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 19:24:14,598 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 19:24:14,598 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'zei@@', 'g@@', 'te', 'ich', 'diese', 'bei@@', 'den', 'Di@@', 'as', 'zei@@', 'g@@', 'te', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'i@@', 'de@@', 'st@@', 'o', 'zei@@', 'g@@', 'te', 'etwa', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A', 'der', 'U@@', 'S@@', 'A', 'der', 'U@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A', 'ge@@', 'k@@', 'ü@@', 'm@@', 'pf@@', 't.', '</s>']
2023-05-30 19:24:14,598 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 19:24:14,598 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 19:24:14,598 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr zeigte ich diese beiden Dias zeigte zeigen, dass die Polidesto zeigte etwa 40 Prozent der USA der USA der USA mit 40 Prozent der USA gekümpft.
2023-05-30 19:24:14,598 - INFO - joeynmt.training - Example #1
2023-05-30 19:24:14,598 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 19:24:14,599 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 19:24:14,599 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'ein', 'Unter@@', 'sch@@', 'ä@@', 'tz@@', 'lich@@', 'es', 'Problem', 'der', 'ern@@', 'st', 'dieses', 'spe@@', 'zi@@', 'f@@', 'ischen', 'Proble@@', 'm,', 'weil', 'es', 'nicht', 'die', 'T@@', 'ik@@', 'te', 'des', 'E@@', 'is', 'zei@@', 'gt.', '</s>']
2023-05-30 19:24:14,599 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 19:24:14,599 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 19:24:14,599 - INFO - joeynmt.training - 	Hypothesis: Aber das ist ein Unterschätzliches Problem der ernst dieses spezifischen Problem, weil es nicht die Tikte des Eis zeigt.
2023-05-30 19:24:14,599 - INFO - joeynmt.training - Example #2
2023-05-30 19:24:14,599 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 19:24:14,599 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 19:24:14,599 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'k@@', 'ut@@', 'ier@@', 'ung', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'er', 'S@@', 'in@@', 'n', 'der', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 's@@', 'y@@', 'ste@@', 'm.', '</s>']
2023-05-30 19:24:14,599 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 19:24:14,599 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 19:24:14,599 - INFO - joeynmt.training - 	Hypothesis: Die Eiskutierung auf der Nordpol ist in gewisser Sinn der globalen Klimawandelsystem.
2023-05-30 19:24:14,599 - INFO - joeynmt.training - Example #3
2023-05-30 19:24:14,599 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 19:24:14,599 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 19:24:14,599 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'rei@@', 'sl@@', 'äu@@', 'f@@', 't.', '</s>']
2023-05-30 19:24:14,599 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 19:24:14,599 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 19:24:14,599 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Krimft in den Sommer und Kreisläuft.
2023-05-30 19:24:14,599 - INFO - joeynmt.training - Example #4
2023-05-30 19:24:14,599 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 19:24:14,599 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 19:24:14,600 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'der', 'näch@@', 'sten', 'Di@@', 'a', 'die', 'ich', 'zei@@', 'ge', 'Ihnen', 'zei@@', 'gt,', 'ist', 'eine', 'ver@@', 'n@@', 'un@@', 'gen@@', 'e', 'Ver@@', 'si@@', 'on', 'von', 'de@@', 'm,', 'was', 'die', 'letzten', '2@@', '5', 'Jahre', 'pass@@', 'iert', 'ist.', '</s>']
2023-05-30 19:24:14,600 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 19:24:14,600 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 19:24:14,600 - INFO - joeynmt.training - 	Hypothesis: Und der nächsten Dia die ich zeige Ihnen zeigt, ist eine vernungene Version von dem, was die letzten 25 Jahre passiert ist.
2023-05-30 19:24:30,409 - INFO - joeynmt.training - Epoch   9, Step:    37100, Batch Loss:     1.671123, Batch Acc: 0.527886, Tokens per Sec:     4796, Lr: 0.000300
2023-05-30 19:24:46,313 - INFO - joeynmt.training - Epoch   9, Step:    37200, Batch Loss:     1.551175, Batch Acc: 0.530114, Tokens per Sec:     4701, Lr: 0.000300
2023-05-30 19:25:02,488 - INFO - joeynmt.training - Epoch   9, Step:    37300, Batch Loss:     1.553285, Batch Acc: 0.525903, Tokens per Sec:     4709, Lr: 0.000300
2023-05-30 19:25:18,035 - INFO - joeynmt.training - Epoch   9, Step:    37400, Batch Loss:     1.770861, Batch Acc: 0.531517, Tokens per Sec:     4837, Lr: 0.000300
2023-05-30 19:25:23,500 - INFO - joeynmt.training - Epoch   9: total training loss 6640.62
2023-05-30 19:25:23,501 - INFO - joeynmt.training - EPOCH 10
2023-05-30 19:25:34,186 - INFO - joeynmt.training - Epoch  10, Step:    37500, Batch Loss:     1.679196, Batch Acc: 0.551272, Tokens per Sec:     4699, Lr: 0.000300
2023-05-30 19:25:34,187 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 19:25:34,187 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 19:26:49,339 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.84, ppl:   6.29, acc:   0.47, generation: 75.1435[sec], evaluation: 0.0000[sec]
2023-05-30 19:26:49,342 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 19:26:49,418 - INFO - joeynmt.helpers - delete models/transformer_model2/36000.ckpt
2023-05-30 19:26:49,420 - INFO - joeynmt.training - Example #0
2023-05-30 19:26:49,420 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 19:26:49,420 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 19:26:49,420 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'Di@@', 'as', 'ge@@', 'k@@', 'ä@@', 'mp@@', 'fen', 'um', 'zu', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'i@@', 'il@@', 'and', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te.', '</s>']
2023-05-30 19:26:49,420 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 19:26:49,420 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 19:26:49,420 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese beiden Dias gekämpfen um zu zeigen, dass die Poliiland die letzten drei Millionen Jahre alt hatte, die die letzten drei Millionen Jahre alt hatte.
2023-05-30 19:26:49,420 - INFO - joeynmt.training - Example #1
2023-05-30 19:26:49,420 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 19:26:49,420 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 19:26:49,420 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'E@@', 'is', 'der', 'Er@@', 'n@@', 'ähr@@', 'ung', 'dieses', 'spe@@', 'zi@@', 'f@@', 'ische', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'T@@', 'ik@@', 'te', 'des', 'E@@', 'is', 'zei@@', 't.', '</s>']
2023-05-30 19:26:49,421 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 19:26:49,421 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 19:26:49,421 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Eis der Ernährung dieses spezifische Problem ist, weil es nicht die Tikte des Eis zeit.
2023-05-30 19:26:49,421 - INFO - joeynmt.training - Example #2
2023-05-30 19:26:49,421 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 19:26:49,421 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 19:26:49,421 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'k@@', 'heit', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'e', 'ist', 'in', 'gew@@', 'iss@@', 'er', 'Wei@@', 'se', 'der', 'g@@', 'lob@@', 'alen', 'K@@', 'l@@', 'im@@', 'a', 'der', 'G@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', '-@@', 'Sy@@', 'ste@@', 'm.', '</s>']
2023-05-30 19:26:49,421 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 19:26:49,421 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 19:26:49,421 - INFO - joeynmt.training - 	Hypothesis: Die Eiskheit auf der Nordpole ist in gewisser Weise der globalen Klima der Globalen Klimawandel-System.
2023-05-30 19:26:49,421 - INFO - joeynmt.training - Example #3
2023-05-30 19:26:49,421 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 19:26:49,421 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 19:26:49,421 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'gibt', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'den', 'S@@', 'omm@@', 'er', 'ge@@', 'zei@@', 'gt.', '</s>']
2023-05-30 19:26:49,421 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 19:26:49,421 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 19:26:49,421 - INFO - joeynmt.training - 	Hypothesis: Es gibt in den Winter und Krimft in den Sommer und Krimft in den Sommer gezeigt.
2023-05-30 19:26:49,421 - INFO - joeynmt.training - Example #4
2023-05-30 19:26:49,421 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 19:26:49,421 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 19:26:49,421 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'der', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', 'ist', 'eine', 'ver@@', 'n@@', 'etz@@', 'te', 'Ver@@', 'si@@', 'on', 'von', 'de@@', 'm,', 'was', 'die', 'letzten', '2@@', '5', 'Jahre', 'pass@@', 'iert', 'ist.', '</s>']
2023-05-30 19:26:49,422 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 19:26:49,422 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 19:26:49,422 - INFO - joeynmt.training - 	Hypothesis: Und der nächste Folie ist eine vernetzte Version von dem, was die letzten 25 Jahre passiert ist.
2023-05-30 19:27:04,912 - INFO - joeynmt.training - Epoch  10, Step:    37600, Batch Loss:     1.481222, Batch Acc: 0.552043, Tokens per Sec:     4876, Lr: 0.000300
2023-05-30 19:27:21,472 - INFO - joeynmt.training - Epoch  10, Step:    37700, Batch Loss:     1.481419, Batch Acc: 0.545320, Tokens per Sec:     4573, Lr: 0.000300
2023-05-30 19:27:37,407 - INFO - joeynmt.training - Epoch  10, Step:    37800, Batch Loss:     1.544825, Batch Acc: 0.547619, Tokens per Sec:     4859, Lr: 0.000300
2023-05-30 19:27:53,450 - INFO - joeynmt.training - Epoch  10, Step:    37900, Batch Loss:     1.399118, Batch Acc: 0.546098, Tokens per Sec:     4606, Lr: 0.000300
2023-05-30 19:28:09,753 - INFO - joeynmt.training - Epoch  10, Step:    38000, Batch Loss:     1.597886, Batch Acc: 0.541056, Tokens per Sec:     4726, Lr: 0.000300
2023-05-30 19:28:09,754 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 19:28:09,754 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 19:29:23,206 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.85, ppl:   6.35, acc:   0.47, generation: 73.4441[sec], evaluation: 0.0000[sec]
2023-05-30 19:29:23,290 - INFO - joeynmt.helpers - delete models/transformer_model2/35000.ckpt
2023-05-30 19:29:23,292 - INFO - joeynmt.training - Example #0
2023-05-30 19:29:23,293 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 19:29:23,293 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 19:29:23,293 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'zei@@', 'g@@', 'te', 'ich', 'diese', 'bei@@', 'den', 'Di@@', 'as', 'zei@@', 'gen', 'dass', 'die', 'P@@', 'ol@@', 'i@@', 'de@@', 'st@@', 'o', 'zei@@', 'g@@', 'te', 'ich', 'un@@', 'gefä@@', 'hr', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'die', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 'ten', 'war.', '</s>']
2023-05-30 19:29:23,293 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 19:29:23,293 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 19:29:23,293 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr zeigte ich diese beiden Dias zeigen dass die Polidesto zeigte ich ungefähr die letzten drei Millionen Jahre alt hatte, die die letzten drei Millionen Jahre alt hatte, die die die letzten drei Millionen Jahre alten war.
2023-05-30 19:29:23,293 - INFO - joeynmt.training - Example #1
2023-05-30 19:29:23,293 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 19:29:23,293 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 19:29:23,293 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'wirklich', 'der', 'F@@', 'ern@@', 'ste', 'des', 'E@@', 'is', 'dieses', 'spe@@', 'zi@@', 'f@@', 'ische', 'Problem', 'der', 'E@@', 'is', 'zei@@', 't.', '</s>']
2023-05-30 19:29:23,293 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 19:29:23,293 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 19:29:23,293 - INFO - joeynmt.training - 	Hypothesis: Aber das ist wirklich der Fernste des Eis dieses spezifische Problem der Eis zeit.
2023-05-30 19:29:23,293 - INFO - joeynmt.training - Example #2
2023-05-30 19:29:23,293 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 19:29:23,293 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 19:29:23,293 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'k@@', 'ut@@', 'iert', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'er', 'Wei@@', 'se', 'die', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', '-@@', 'K@@', 'li@@', 'ma@@', '-@@', 'E@@', 'is@@', 'k@@', 'ut@@', 'ier@@', 'ung', 'des', 'g@@', 'lob@@', 'al', 'kl@@', 'i@@', 'ge@@', 'm', 'K@@', 'li@@', 'ma@@', '.', '</s>']
2023-05-30 19:29:23,294 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 19:29:23,294 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 19:29:23,294 - INFO - joeynmt.training - 	Hypothesis: Die Eiskutiert auf der Nordpol ist in gewisser Weise die Klimawandel-Klima-Eiskutierung des global kligem Klima.
2023-05-30 19:29:23,294 - INFO - joeynmt.training - Example #3
2023-05-30 19:29:23,294 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 19:29:23,294 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 19:29:23,294 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'rei@@', 's', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'rei@@', 'sl@@', 'äu@@', 'f@@', 't.', '</s>']
2023-05-30 19:29:23,294 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 19:29:23,294 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 19:29:23,294 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Kreis in den Sommer und Kreisläuft.
2023-05-30 19:29:23,294 - INFO - joeynmt.training - Example #4
2023-05-30 19:29:23,294 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 19:29:23,294 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 19:29:23,294 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', 'ist', 'eine', 'ver@@', 'n@@', 'etz@@', 'te', 'Ver@@', 'si@@', 'on', 'von', 'de@@', 'm,', 'was', 'die', 'letzten', '2@@', '5', 'Jahre', 'al@@', 't', 'ist.', '</s>']
2023-05-30 19:29:23,294 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 19:29:23,294 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 19:29:23,294 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie ist eine vernetzte Version von dem, was die letzten 25 Jahre alt ist.
2023-05-30 19:29:39,475 - INFO - joeynmt.training - Epoch  10, Step:    38100, Batch Loss:     1.556259, Batch Acc: 0.537993, Tokens per Sec:     4710, Lr: 0.000300
2023-05-30 19:29:56,060 - INFO - joeynmt.training - Epoch  10, Step:    38200, Batch Loss:     1.687994, Batch Acc: 0.547067, Tokens per Sec:     4654, Lr: 0.000300
2023-05-30 19:30:13,455 - INFO - joeynmt.training - Epoch  10, Step:    38300, Batch Loss:     1.587907, Batch Acc: 0.539355, Tokens per Sec:     4332, Lr: 0.000300
2023-05-30 19:30:29,313 - INFO - joeynmt.training - Epoch  10, Step:    38400, Batch Loss:     1.563493, Batch Acc: 0.544455, Tokens per Sec:     4709, Lr: 0.000300
2023-05-30 19:30:46,111 - INFO - joeynmt.training - Epoch  10, Step:    38500, Batch Loss:     1.661087, Batch Acc: 0.542260, Tokens per Sec:     4576, Lr: 0.000300
2023-05-30 19:30:46,111 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 19:30:46,111 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 19:32:02,258 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.84, ppl:   6.32, acc:   0.47, generation: 76.1387[sec], evaluation: 0.0000[sec]
2023-05-30 19:32:02,333 - INFO - joeynmt.helpers - delete models/transformer_model2/38000.ckpt
2023-05-30 19:32:02,333 - INFO - joeynmt.helpers - delete /Users/cyril/Desktop/krizzzzi/mt-exercise-5/models/transformer_model2/38000.ckpt
2023-05-30 19:32:02,333 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /Users/cyril/Desktop/krizzzzi/mt-exercise-5/models/transformer_model2/38000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/Users/cyril/Desktop/krizzzzi/mt-exercise-5/models/transformer_model2/38000.ckpt')
2023-05-30 19:32:02,335 - INFO - joeynmt.training - Example #0
2023-05-30 19:32:02,335 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 19:32:02,335 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 19:32:02,335 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'a@@', 's', 'ge@@', 'sehen,', 'um', 'zu', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'i@@', 'k@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahren', 'un@@', 'gefä@@', 'hr', 'die', 'Gr@@', 'ö@@', 'ß@@', 'e', 'der', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'war.', '</s>']
2023-05-30 19:32:02,335 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 19:32:02,335 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 19:32:02,335 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Dias gesehen, um zu zeigen, dass die Polikap, die die letzten drei Millionen Jahren ungefähr die Größe der USA, mit 40% gekrompen war.
2023-05-30 19:32:02,335 - INFO - joeynmt.training - Example #1
2023-05-30 19:32:02,336 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 19:32:02,336 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 19:32:02,336 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', 'F@@', 'ern@@', 'ste', 'des', 'Problem', 'der', 'ern@@', 'st', 'des', 'Problem', 'da@@', 'fü@@', 'r@@', ',', 'dass', 'es', 'nicht', 'die', 'T@@', 'au@@', 'sch@@', 'ung', 'der', 'E@@', 'is', 'zei@@', 'gt.', '</s>']
2023-05-30 19:32:02,336 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 19:32:02,336 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 19:32:02,336 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der Fernste des Problem der ernst des Problem dafür, dass es nicht die Tauschung der Eis zeigt.
2023-05-30 19:32:02,336 - INFO - joeynmt.training - Example #2
2023-05-30 19:32:02,336 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 19:32:02,336 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 19:32:02,336 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'k@@', 'heit', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'er', 'Wei@@', 'se', 'in', 'gew@@', 'iss@@', 'er', 'Wei@@', 'se', 'die', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 'y@@', 'ste@@', 'm@@', 's', 'Her@@', 'z', 'des', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', 's', 'ist.', '</s>']
2023-05-30 19:32:02,336 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 19:32:02,336 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 19:32:02,336 - INFO - joeynmt.training - 	Hypothesis: Die Eiskheit auf der Nordpol ist in gewisser Weise in gewisser Weise die Klimawandelystems Herz des Klimawandels ist.
2023-05-30 19:32:02,336 - INFO - joeynmt.training - Example #3
2023-05-30 19:32:02,336 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 19:32:02,336 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 19:32:02,336 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'sch@@', 'ließ@@', 'lich', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'rei@@', 's', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'rei@@', 's', 'in', 'den', 'S@@', 'omm@@', 'er', '</s>']
2023-05-30 19:32:02,336 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 19:32:02,336 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 19:32:02,336 - INFO - joeynmt.training - 	Hypothesis: Es schließlich in den Winter und Kreis in den Sommer in den Sommer und Kreis in den Sommer
2023-05-30 19:32:02,336 - INFO - joeynmt.training - Example #4
2023-05-30 19:32:02,336 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 19:32:02,337 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 19:32:02,337 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'der', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', 'ist', 'eine', 'ver@@', 'n@@', 'etz@@', 'te', 'Ver@@', 'si@@', 'on', 'von', 'de@@', 'm,', 'was', 'die', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.', '</s>']
2023-05-30 19:32:02,337 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 19:32:02,337 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 19:32:02,337 - INFO - joeynmt.training - 	Hypothesis: Und der nächste Folie ist eine vernetzte Version von dem, was die letzten 25 Jahren passiert ist.
2023-05-30 19:32:18,537 - INFO - joeynmt.training - Epoch  10, Step:    38600, Batch Loss:     1.381611, Batch Acc: 0.540443, Tokens per Sec:     4617, Lr: 0.000300
2023-05-30 19:32:36,068 - INFO - joeynmt.training - Epoch  10, Step:    38700, Batch Loss:     1.560508, Batch Acc: 0.540920, Tokens per Sec:     4351, Lr: 0.000300
2023-05-30 19:32:52,515 - INFO - joeynmt.training - Epoch  10, Step:    38800, Batch Loss:     1.607798, Batch Acc: 0.537782, Tokens per Sec:     4645, Lr: 0.000300
2023-05-30 19:33:09,265 - INFO - joeynmt.training - Epoch  10, Step:    38900, Batch Loss:     1.444888, Batch Acc: 0.541592, Tokens per Sec:     4585, Lr: 0.000300
2023-05-30 19:33:25,768 - INFO - joeynmt.training - Epoch  10, Step:    39000, Batch Loss:     1.660569, Batch Acc: 0.538689, Tokens per Sec:     4633, Lr: 0.000300
2023-05-30 19:33:25,768 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 19:33:25,768 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 19:34:40,887 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.85, ppl:   6.35, acc:   0.47, generation: 75.1100[sec], evaluation: 0.0000[sec]
2023-05-30 19:34:40,889 - INFO - joeynmt.training - Example #0
2023-05-30 19:34:40,890 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 19:34:40,890 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 19:34:40,890 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'Di@@', 'as', 'ge@@', 'zei@@', 'gt,', 'dass', 'die', 'P@@', 'ol@@', 'it@@', 'ik@@', '-@@', 'S@@', 'k@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'die', 'die', 'U@@', 'S@@', '-@@', 'St@@', 'ra@@', 'ß@@', 'e', 'ge@@', 'k@@', 'ü@@', 'm@@', 'mer@@', 'n', 'war.', '</s>']
2023-05-30 19:34:40,890 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 19:34:40,890 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 19:34:40,890 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese beiden Dias gezeigt, dass die Politik-Skap, die die letzten drei Millionen Jahre alt hatte, die die letzten drei Millionen Jahre alt hatte, die die US-Straße gekümmern war.
2023-05-30 19:34:40,890 - INFO - joeynmt.training - Example #1
2023-05-30 19:34:40,890 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 19:34:40,890 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 19:34:40,890 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'tatsächlich', 'ein', 'bis@@', 'schen', 'ern@@', 'st@@', 'h@@', 'af@@', 'ter', 'Proble@@', 'm,', 'weil', 'es', 'nicht', 'die', 'T@@', 'ik@@', 'el', 'des', 'E@@', 'is', 'zei@@', 't.', '</s>']
2023-05-30 19:34:40,890 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 19:34:40,890 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 19:34:40,890 - INFO - joeynmt.training - 	Hypothesis: Aber das ist tatsächlich ein bisschen ernsthafter Problem, weil es nicht die Tikel des Eis zeit.
2023-05-30 19:34:40,890 - INFO - joeynmt.training - Example #2
2023-05-30 19:34:40,890 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 19:34:40,890 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 19:34:40,891 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'k@@', 'ul@@', 'ar@@', 'e', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'er', 'Wei@@', 'se', 'die', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', '-@@', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', '-@@', 'St@@', 'em@@', '.', '</s>']
2023-05-30 19:34:40,891 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 19:34:40,891 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 19:34:40,891 - INFO - joeynmt.training - 	Hypothesis: Die Eiskulare auf der Nordpol ist in gewisser Weise die Klimawandel-Klimawandel Klimawandel-Stem.
2023-05-30 19:34:40,891 - INFO - joeynmt.training - Example #3
2023-05-30 19:34:40,891 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 19:34:40,891 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 19:34:40,891 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'den', 'S@@', 'omm@@', 'er', 'und', 'K@@', 'r@@', 'im@@', 'ft', 'in', 'den', 'S@@', 'omm@@', 'er', 'in', 'den', 'S@@', 'omm@@', 'en.', '</s>']
2023-05-30 19:34:40,891 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 19:34:40,891 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 19:34:40,891 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Krimft in den Sommer und Krimft in den Sommer und Krimft in den Sommer und Krimft in den Sommer und Krimft in den Sommer und Krimft in den Sommer in den Sommen.
2023-05-30 19:34:40,891 - INFO - joeynmt.training - Example #4
2023-05-30 19:34:40,891 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 19:34:40,891 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 19:34:40,891 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', 'ist', 'eine', 'ver@@', 'n@@', 'etz@@', 'te', 'Ver@@', 'si@@', 'on', 'von', 'de@@', 'm,', 'was', 'die', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.', '</s>']
2023-05-30 19:34:40,891 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 19:34:40,891 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 19:34:40,892 - INFO - joeynmt.training - 	Hypothesis: Der nächste Folie ist eine vernetzte Version von dem, was die letzten 25 Jahren passiert ist.
2023-05-30 19:34:58,343 - INFO - joeynmt.training - Epoch  10, Step:    39100, Batch Loss:     1.554218, Batch Acc: 0.533893, Tokens per Sec:     4333, Lr: 0.000300
2023-05-30 19:35:15,290 - INFO - joeynmt.training - Epoch  10, Step:    39200, Batch Loss:     1.457434, Batch Acc: 0.540434, Tokens per Sec:     4356, Lr: 0.000300
2023-05-30 19:35:32,141 - INFO - joeynmt.training - Epoch  10, Step:    39300, Batch Loss:     1.366966, Batch Acc: 0.536539, Tokens per Sec:     4576, Lr: 0.000300
2023-05-30 19:35:48,818 - INFO - joeynmt.training - Epoch  10, Step:    39400, Batch Loss:     1.500769, Batch Acc: 0.536290, Tokens per Sec:     4524, Lr: 0.000300
2023-05-30 19:36:06,413 - INFO - joeynmt.training - Epoch  10, Step:    39500, Batch Loss:     1.598445, Batch Acc: 0.540352, Tokens per Sec:     4291, Lr: 0.000300
2023-05-30 19:36:06,413 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 19:36:06,413 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 19:37:24,234 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.85, ppl:   6.33, acc:   0.47, generation: 77.8125[sec], evaluation: 0.0000[sec]
2023-05-30 19:37:24,315 - INFO - joeynmt.helpers - delete models/transformer_model2/36500.ckpt
2023-05-30 19:37:24,317 - INFO - joeynmt.training - Example #0
2023-05-30 19:37:24,317 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 19:37:24,318 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 19:37:24,318 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'Di@@', 'as', 'ge@@', 'zei@@', 'gt,', 'dass', 'die', 'P@@', 'ol@@', 'ar@@', 'i@@', 'um', 'die', 'P@@', 'ol@@', 'i@@', 'sk@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'die', 'Gr@@', 'ö@@', 'ß@@', 'e', 'der', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A@@', ',', 'mit', '4@@', '0', 'Prozent', 'ge@@', 'k@@', 'ro@@', 'll@@', 'en.', '</s>']
2023-05-30 19:37:24,318 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 19:37:24,318 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 19:37:24,318 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese beiden Dias gezeigt, dass die Polarium die Poliskap, die die letzten drei Millionen Jahre alt hatte, die Größe der USA, mit 40 Prozent der USA, mit 40 Prozent gekrollen.
2023-05-30 19:37:24,318 - INFO - joeynmt.training - Example #1
2023-05-30 19:37:24,318 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 19:37:24,318 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 19:37:24,318 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'ein', 'Unter@@', 'sch@@', 'ä@@', 'tz@@', 'lich', 'der', 'ern@@', 'st', 'des', 'Sp@@', 'e@@', 'zi@@', 'al@@', 'es', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'T@@', 'ik@@', 'el', 'des', 'E@@', 'is', 'zei@@', 't.', '</s>']
2023-05-30 19:37:24,318 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 19:37:24,318 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 19:37:24,318 - INFO - joeynmt.training - 	Hypothesis: Aber das ist ein Unterschätzlich der ernst des Speziales Problem ist, weil es nicht die Tikel des Eis zeit.
2023-05-30 19:37:24,318 - INFO - joeynmt.training - Example #2
2023-05-30 19:37:24,318 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 19:37:24,318 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 19:37:24,318 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'k@@', 'ut@@', 'ieren', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'er', 'S@@', 'in@@', 'n', 'des', 'G@@', 'lob@@', 'alen', 'K@@', 'l@@', 'im@@', 'a', 'des', 'G@@', 'lob@@', 'alen', 'K@@', 'l@@', 'im@@', 'a', 'des', 'G@@', 'lob@@', 'al@@', 'es', 'K@@', 'l@@', 'im@@', 'a', 'des', 'G@@', 'lob@@', 'al@@', 'es', 'K@@', 'l@@', 'im@@', 'a', 'in', 'gew@@', 'iss@@', 'er', 'Wei@@', 'se', 'zu', 'sein.', '</s>']
2023-05-30 19:37:24,318 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 19:37:24,318 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 19:37:24,318 - INFO - joeynmt.training - 	Hypothesis: Die Eiskutieren auf der Nordpol ist in gewisser Sinn des Globalen Klima des Globalen Klima des Globales Klima des Globales Klima in gewisser Weise zu sein.
2023-05-30 19:37:24,318 - INFO - joeynmt.training - Example #3
2023-05-30 19:37:24,319 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 19:37:24,319 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 19:37:24,319 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'ä@@', 'f@@', 't.', '</s>']
2023-05-30 19:37:24,319 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 19:37:24,319 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 19:37:24,319 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Kräft.
2023-05-30 19:37:24,319 - INFO - joeynmt.training - Example #4
2023-05-30 19:37:24,319 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 19:37:24,319 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 19:37:24,319 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'der', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', 'zei@@', 'gt', 'eine', 'ver@@', 'br@@', 'eit@@', 'ige', 'Ver@@', 'si@@', 'on', 'von', 'de@@', 'm,', 'was', 'die', 'letzten', '2@@', '5', 'Jahre', 'pass@@', 'iert.', '</s>']
2023-05-30 19:37:24,319 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 19:37:24,319 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 19:37:24,319 - INFO - joeynmt.training - 	Hypothesis: Und der nächste Folie zeigt eine verbreitige Version von dem, was die letzten 25 Jahre passiert.
2023-05-30 19:37:40,651 - INFO - joeynmt.training - Epoch  10, Step:    39600, Batch Loss:     1.616397, Batch Acc: 0.541768, Tokens per Sec:     4551, Lr: 0.000300
2023-05-30 19:37:56,895 - INFO - joeynmt.training - Epoch  10, Step:    39700, Batch Loss:     1.539041, Batch Acc: 0.540703, Tokens per Sec:     4633, Lr: 0.000300
2023-05-30 19:38:13,839 - INFO - joeynmt.training - Epoch  10, Step:    39800, Batch Loss:     1.320019, Batch Acc: 0.541600, Tokens per Sec:     4411, Lr: 0.000300
2023-05-30 19:38:29,526 - INFO - joeynmt.training - Epoch  10, Step:    39900, Batch Loss:     1.621321, Batch Acc: 0.537883, Tokens per Sec:     4718, Lr: 0.000300
2023-05-30 19:38:44,781 - INFO - joeynmt.training - Epoch  10, Step:    40000, Batch Loss:     1.718918, Batch Acc: 0.533078, Tokens per Sec:     4941, Lr: 0.000300
2023-05-30 19:38:44,781 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 19:38:44,781 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 19:40:01,648 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.84, ppl:   6.28, acc:   0.47, generation: 76.8587[sec], evaluation: 0.0000[sec]
2023-05-30 19:40:01,649 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 19:40:01,735 - INFO - joeynmt.helpers - delete models/transformer_model2/39500.ckpt
2023-05-30 19:40:01,738 - INFO - joeynmt.training - Example #0
2023-05-30 19:40:01,738 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 19:40:01,738 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 19:40:01,738 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'zwei', 'Di@@', 'as', 'ge@@', 'zei@@', 'gt,', 'um', 'die', 'P@@', 'ol@@', 'ar@@', 'k@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'etwa', 'die', 'Gr@@', 'ö@@', 'ß@@', 'e', 'der', 'U@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'der', 'Ver@@', 'ein@@', 'ig@@', 'ten', 'S@@', '-@@', 'St@@', 'r@@', 'ing@@', 'e', 'war.', '</s>']
2023-05-30 19:40:01,738 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 19:40:01,738 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 19:40:01,738 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr habe ich diese zwei Dias gezeigt, um die Polarkap, die die letzten drei Millionen Jahre etwa die Größe der USA mit 40 Prozent der USA mit 40 Prozent der USA mit 40 Prozent der Vereinigten S-Stringe war.
2023-05-30 19:40:01,738 - INFO - joeynmt.training - Example #1
2023-05-30 19:40:01,738 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 19:40:01,738 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 19:40:01,738 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'dieses', 'Unter@@', 'sch@@', 'ä@@', 'tz@@', 'te', 'der', 'Sch@@', 'ä@@', 'tz@@', 'ung', 'dieses', 'spe@@', 'zi@@', 'f@@', 'ischen', 'Problem', 'ist,', 'weil', 'es', 'nicht', 'die', 'T@@', 'r@@', 'ö@@', 'te', 'des', 'E@@', 'is', 'zei@@', 't.', '</s>']
2023-05-30 19:40:01,738 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 19:40:01,738 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 19:40:01,738 - INFO - joeynmt.training - 	Hypothesis: Aber dieses Unterschätzte der Schätzung dieses spezifischen Problem ist, weil es nicht die Tröte des Eis zeit.
2023-05-30 19:40:01,738 - INFO - joeynmt.training - Example #2
2023-05-30 19:40:01,738 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 19:40:01,738 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 19:40:01,738 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'k@@', 'ul@@', 'pt@@', 'ik', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'po@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'er', 'S@@', 'in@@', 'n', 'des', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'y@@', 'ste@@', 'm.', '</s>']
2023-05-30 19:40:01,739 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 19:40:01,739 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 19:40:01,739 - INFO - joeynmt.training - 	Hypothesis: Die Eiskulptik auf der Nordpol ist in gewisser Sinn des globalen Klimaystem.
2023-05-30 19:40:01,739 - INFO - joeynmt.training - Example #3
2023-05-30 19:40:01,739 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 19:40:01,739 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 19:40:01,739 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'ä@@', 'm@@', 'pf@@', 'e', 'in', 'den', 'S@@', 'om@@', 'mer@@', '.', '</s>']
2023-05-30 19:40:01,739 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 19:40:01,739 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 19:40:01,739 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Krämpfe in den Sommer.
2023-05-30 19:40:01,739 - INFO - joeynmt.training - Example #4
2023-05-30 19:40:01,739 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 19:40:01,739 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 19:40:01,739 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', 'zei@@', 'gt', 'die', 'ich', 'zei@@', 'ge', 'Ihnen', 'eine', 'ver@@', 'n@@', 'etz@@', 'te', 'Ver@@', 'si@@', 'on', 'von', 'de@@', 'm,', 'was', 'die', 'letzten', '2@@', '5', 'Jahre', 'pass@@', 'iert', 'ist.', '</s>']
2023-05-30 19:40:01,739 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 19:40:01,739 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 19:40:01,739 - INFO - joeynmt.training - 	Hypothesis: Die nächste Folie zeigt die ich zeige Ihnen eine vernetzte Version von dem, was die letzten 25 Jahre passiert ist.
2023-05-30 19:40:18,229 - INFO - joeynmt.training - Epoch  10, Step:    40100, Batch Loss:     1.415697, Batch Acc: 0.537106, Tokens per Sec:     4579, Lr: 0.000300
2023-05-30 19:40:34,505 - INFO - joeynmt.training - Epoch  10, Step:    40200, Batch Loss:     1.551257, Batch Acc: 0.537785, Tokens per Sec:     4674, Lr: 0.000300
2023-05-30 19:40:50,040 - INFO - joeynmt.training - Epoch  10, Step:    40300, Batch Loss:     1.587315, Batch Acc: 0.536054, Tokens per Sec:     4678, Lr: 0.000300
2023-05-30 19:41:05,805 - INFO - joeynmt.training - Epoch  10, Step:    40400, Batch Loss:     1.482201, Batch Acc: 0.535652, Tokens per Sec:     4930, Lr: 0.000300
2023-05-30 19:41:22,055 - INFO - joeynmt.training - Epoch  10, Step:    40500, Batch Loss:     1.777087, Batch Acc: 0.530331, Tokens per Sec:     4682, Lr: 0.000300
2023-05-30 19:41:22,059 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 19:41:22,059 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 19:42:33,130 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.83, ppl:   6.25, acc:   0.47, generation: 71.0626[sec], evaluation: 0.0000[sec]
2023-05-30 19:42:33,131 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 19:42:33,215 - INFO - joeynmt.helpers - delete models/transformer_model2/35500.ckpt
2023-05-30 19:42:33,217 - INFO - joeynmt.training - Example #0
2023-05-30 19:42:33,217 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 19:42:33,217 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 19:42:33,217 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'zei@@', 'g@@', 'te', 'ich', 'diese', 'bei@@', 'den', 'Di@@', 'a@@', 'st', 'zei@@', 'gen', 'und', 'zei@@', 'g@@', 'te', 'die', 'P@@', 'ol@@', 'i@@', 'sk@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'die', 'Gr@@', 'ö@@', 'ß@@', 'e', 'der', 'U@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'war.', '</s>']
2023-05-30 19:42:33,217 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 19:42:33,217 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 19:42:33,217 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr zeigte ich diese beiden Diast zeigen und zeigte die Poliskap, die die letzten drei Millionen Jahre alt hatte, die Größe der USA mit 40 Prozent der USA mit 40 Prozent gekrompen war.
2023-05-30 19:42:33,217 - INFO - joeynmt.training - Example #1
2023-05-30 19:42:33,218 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 19:42:33,218 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 19:42:33,218 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'dieses', 'Unter@@', 'sch@@', 'ä@@', 'tz@@', 'te', 'die', 'E@@', 'hr@@', 'e', 'dieses', 'Sp@@', 'e@@', 'zi@@', 'f@@', 'ik@@', 'er', 'ist,', 'weil', 'es', 'nicht', 'die', 'D@@', 'au@@', 'er', 'des', 'E@@', 'is', 'zei@@', 't.', '</s>']
2023-05-30 19:42:33,218 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 19:42:33,218 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 19:42:33,218 - INFO - joeynmt.training - 	Hypothesis: Aber dieses Unterschätzte die Ehre dieses Spezifiker ist, weil es nicht die Dauer des Eis zeit.
2023-05-30 19:42:33,218 - INFO - joeynmt.training - Example #2
2023-05-30 19:42:33,218 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 19:42:33,218 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 19:42:33,218 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'k@@', 'ul@@', 'ar@@', 'e', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'er', 'S@@', 'in@@', 'ne@@', ',', 'das', 'kl@@', 'op@@', 'p@@', 'elt', 'sich', 'von', 'uns', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'wan@@', 'del@@', '-@@', 'St@@', 'em@@', '.', '</s>']
2023-05-30 19:42:33,218 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 19:42:33,218 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 19:42:33,218 - INFO - joeynmt.training - 	Hypothesis: Die Eiskulare auf der Nordpoll ist in gewisser Sinne, das kloppelt sich von uns globalen Klimawandel-Stem.
2023-05-30 19:42:33,218 - INFO - joeynmt.training - Example #3
2023-05-30 19:42:33,218 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 19:42:33,218 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 19:42:33,218 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'rei@@', 's', 'in', 'den', 'S@@', 'om@@', 'mer@@', '.', '</s>']
2023-05-30 19:42:33,218 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 19:42:33,218 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 19:42:33,218 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Kreis in den Sommer.
2023-05-30 19:42:33,219 - INFO - joeynmt.training - Example #4
2023-05-30 19:42:33,219 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 19:42:33,219 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 19:42:33,219 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'näch@@', 'ste', 'Di@@', 'a', 'zei@@', 'gt', 'eine', 'ver@@', 'n@@', 'un@@', 'de,', 'ist', 'eine', 'ver@@', 'n@@', 'un@@', 'gen@@', 'e', 'Ver@@', 'si@@', 'on', 'von', 'de@@', 'm,', 'was', 'die', 'letzten', '2@@', '5', 'Jahre', 'pass@@', 'iert', 'ist.', '</s>']
2023-05-30 19:42:33,219 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 19:42:33,219 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 19:42:33,219 - INFO - joeynmt.training - 	Hypothesis: Und die nächste Dia zeigt eine vernunde, ist eine vernungene Version von dem, was die letzten 25 Jahre passiert ist.
2023-05-30 19:42:49,826 - INFO - joeynmt.training - Epoch  10, Step:    40600, Batch Loss:     1.565957, Batch Acc: 0.542691, Tokens per Sec:     4757, Lr: 0.000300
2023-05-30 19:43:05,869 - INFO - joeynmt.training - Epoch  10, Step:    40700, Batch Loss:     1.422048, Batch Acc: 0.538260, Tokens per Sec:     4529, Lr: 0.000300
2023-05-30 19:43:22,499 - INFO - joeynmt.training - Epoch  10, Step:    40800, Batch Loss:     1.620410, Batch Acc: 0.536016, Tokens per Sec:     4646, Lr: 0.000300
2023-05-30 19:43:38,762 - INFO - joeynmt.training - Epoch  10, Step:    40900, Batch Loss:     1.758262, Batch Acc: 0.536266, Tokens per Sec:     4622, Lr: 0.000300
2023-05-30 19:43:54,678 - INFO - joeynmt.training - Epoch  10, Step:    41000, Batch Loss:     1.532426, Batch Acc: 0.538870, Tokens per Sec:     4780, Lr: 0.000300
2023-05-30 19:43:54,679 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 19:43:54,679 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 19:45:03,450 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.83, ppl:   6.26, acc:   0.47, generation: 68.7635[sec], evaluation: 0.0000[sec]
2023-05-30 19:45:03,526 - INFO - joeynmt.helpers - delete models/transformer_model2/37000.ckpt
2023-05-30 19:45:03,532 - INFO - joeynmt.training - Example #0
2023-05-30 19:45:03,532 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 19:45:03,532 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 19:45:03,532 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I@@', 'm', 'letzten', 'Jahr', 'hat', 'ich', 'diese', 'zwei', 'Di@@', 'a@@', 'st', 'zei@@', 'gen', 'und', 'zei@@', 'gen,', 'dass', 'die', 'P@@', 'ol@@', 'i@@', 'sk@@', 'ap@@', ',', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'un@@', 'gefä@@', 'hr', 'die', 'Gr@@', 'ö@@', 'ß@@', 'e', 'des', 'U@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'der', 'U@@', 'S@@', 'A', 'mit', '4@@', '0', 'Prozent', 'ge@@', 'ck@@', 't', 'hat@@', 'te.', '</s>']
2023-05-30 19:45:03,532 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 19:45:03,532 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 19:45:03,532 - INFO - joeynmt.training - 	Hypothesis: Im letzten Jahr hat ich diese zwei Diast zeigen und zeigen, dass die Poliskap, die letzten drei Millionen Jahre ungefähr die Größe des USA mit 40 Prozent der USA mit 40 Prozent geckt hatte.
2023-05-30 19:45:03,532 - INFO - joeynmt.training - Example #1
2023-05-30 19:45:03,532 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 19:45:03,532 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 19:45:03,532 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'dieses', 'Unter@@', 'sch@@', 'ä@@', 'tz@@', 'te', 'der', 'E@@', 'is', 'dieses', 'spe@@', 'zi@@', 'f@@', 'ik', 'ist', 'es', 'nicht', 'die', 'D@@', 'au@@', 'er', 'des', 'E@@', 'is', 'zei@@', 'gt.', '</s>']
2023-05-30 19:45:03,533 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 19:45:03,533 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 19:45:03,533 - INFO - joeynmt.training - 	Hypothesis: Aber dieses Unterschätzte der Eis dieses spezifik ist es nicht die Dauer des Eis zeigt.
2023-05-30 19:45:03,533 - INFO - joeynmt.training - Example #2
2023-05-30 19:45:03,533 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 19:45:03,533 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 19:45:03,533 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sch@@', 'ir@@', 'men', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'l', 'ist', 'in', 'gew@@', 'iss@@', 'er', 'Wei@@', 'se', 'die', 'K@@', 'li@@', 'ma@@', 'ma@@', 'wan@@', 'del@@', 'y@@', 'ste@@', 'm@@', 's.', '</s>']
2023-05-30 19:45:03,533 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 19:45:03,533 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 19:45:03,533 - INFO - joeynmt.training - 	Hypothesis: Die Eisschirmen auf der Nordpoll ist in gewisser Weise die Klimamawandelystems.
2023-05-30 19:45:03,533 - INFO - joeynmt.training - Example #3
2023-05-30 19:45:03,533 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 19:45:03,533 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 19:45:03,533 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'r@@', 'im@@', 'p@@', 'pen', 'in', 'den', 'S@@', 'om@@', 'mer@@', '.', '</s>']
2023-05-30 19:45:03,533 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 19:45:03,533 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 19:45:03,533 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Krimppen in den Sommer.
2023-05-30 19:45:03,533 - INFO - joeynmt.training - Example #4
2023-05-30 19:45:03,533 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 19:45:03,533 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 19:45:03,533 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'näch@@', 'ste', 'Di@@', 'a', 'die', 'ich', 'Ihnen', 'zei@@', 'gen', 'ha@@', 'be,', 'ist', 'eine', 'ver@@', 'schn@@', 'ell@@', 'te', 'Ver@@', 'si@@', 'on', 'von', 'de@@', 'm,', 'was', 'die', 'letzten', '2@@', '5', 'Jahre', 'pass@@', 'iert', 'ist.', '</s>']
2023-05-30 19:45:03,534 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 19:45:03,534 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 19:45:03,534 - INFO - joeynmt.training - 	Hypothesis: Die nächste Dia die ich Ihnen zeigen habe, ist eine verschnellte Version von dem, was die letzten 25 Jahre passiert ist.
2023-05-30 19:45:20,286 - INFO - joeynmt.training - Epoch  10, Step:    41100, Batch Loss:     1.547142, Batch Acc: 0.534863, Tokens per Sec:     4598, Lr: 0.000300
2023-05-30 19:45:37,177 - INFO - joeynmt.training - Epoch  10, Step:    41200, Batch Loss:     1.382958, Batch Acc: 0.537648, Tokens per Sec:     4583, Lr: 0.000300
2023-05-30 19:45:53,919 - INFO - joeynmt.training - Epoch  10, Step:    41300, Batch Loss:     1.587070, Batch Acc: 0.534647, Tokens per Sec:     4556, Lr: 0.000300
2023-05-30 19:46:09,670 - INFO - joeynmt.training - Epoch  10, Step:    41400, Batch Loss:     1.571137, Batch Acc: 0.525744, Tokens per Sec:     4667, Lr: 0.000300
2023-05-30 19:46:25,897 - INFO - joeynmt.training - Epoch  10, Step:    41500, Batch Loss:     1.528466, Batch Acc: 0.531692, Tokens per Sec:     4822, Lr: 0.000300
2023-05-30 19:46:25,897 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 19:46:25,897 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 19:47:42,811 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.83, ppl:   6.24, acc:   0.48, generation: 76.9050[sec], evaluation: 0.0000[sec]
2023-05-30 19:47:42,812 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-30 19:47:42,888 - INFO - joeynmt.helpers - delete models/transformer_model2/38500.ckpt
2023-05-30 19:47:42,890 - INFO - joeynmt.training - Example #0
2023-05-30 19:47:42,890 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'onen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2023-05-30 19:47:42,890 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2023-05-30 19:47:42,890 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'etz@@', 'tes', 'Jahr', 'zei@@', 'ge', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'zei@@', 'g@@', 'te,', 'dass', 'die', 'P@@', 'ol@@', 'i@@', 'sk@@', 'ap@@', ',', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'al@@', 't', 'hat@@', 'te,', 'die', 'die', 'Gr@@', 'ö@@', 'ß@@', 'e', 'der', 'Ver@@', 'ein@@', 'ig@@', 'ten', 'St@@', 'aa@@', 'ten', 'der', 'Ver@@', 'ein@@', 'ig@@', 'ten', 'S@@', ',', 'mit', '4@@', '0', 'Prozent', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pf@@', 'en.', '</s>']
2023-05-30 19:47:42,890 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-30 19:47:42,890 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-30 19:47:42,890 - INFO - joeynmt.training - 	Hypothesis: Letztes Jahr zeige ich diese beiden Folien zeigte, dass die Poliskap, die die letzten drei Millionen Jahre alt hatte, die die Größe der Vereinigten Staaten der Vereinigten S, mit 40 Prozent gekrompfen.
2023-05-30 19:47:42,890 - INFO - joeynmt.training - Example #1
2023-05-30 19:47:42,890 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spec@@', 'if@@', 'ie@@', 'ke', 'probleem', 'omdat', 'het', 'niet', 'de', 'd@@', 'ik@@', 'te', 'van', 'het', 'ij@@', 's', 'laat', 'zien.']
2023-05-30 19:47:42,890 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt.']
2023-05-30 19:47:42,891 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'dieses', 'Unter@@', 'sch@@', 'ä@@', 'tz@@', 'ung', 'dieses', 'spe@@', 'zi@@', 'f@@', 'ische', 'Proble@@', 'me', 'ist,', 'weil', 'es', 'nicht', 'die', 'T@@', 'it@@', 'el', 'des', 'E@@', 'is', 'des', 'E@@', 'is', 'zei@@', 't.', '</s>']
2023-05-30 19:47:42,891 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-30 19:47:42,891 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-30 19:47:42,891 - INFO - joeynmt.training - 	Hypothesis: Aber dieses Unterschätzung dieses spezifische Probleme ist, weil es nicht die Titel des Eis des Eis zeit.
2023-05-30 19:47:42,891 - INFO - joeynmt.training - Example #2
2023-05-30 19:47:42,891 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lob@@', 'aal', 'kl@@', 'im@@', 'aa@@', 'ts@@', 'y@@', 'ste@@', 'em@@', '.']
2023-05-30 19:47:42,891 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2023-05-30 19:47:42,891 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'E@@', 'is@@', 'sk@@', 'ap@@', 'l', 'auf', 'der', 'N@@', 'or@@', 'd@@', 'p@@', 'ol@@', 'e', 'ist', 'in', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'des', 'G@@', 'lob@@', 'al@@', 'es', 'K@@', 'li@@', 'ma@@', 'sch@@', 'in@@', 'e,', '</s>']
2023-05-30 19:47:42,891 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-30 19:47:42,891 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-30 19:47:42,891 - INFO - joeynmt.training - 	Hypothesis: Die Eisskapl auf der Nordpole ist in gewissem Sinne des Globales Klimaschine,
2023-05-30 19:47:42,891 - INFO - joeynmt.training - Example #3
2023-05-30 19:47:42,891 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2023-05-30 19:47:42,891 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2023-05-30 19:47:42,891 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'in', 'den', 'W@@', 'in@@', 'ter', 'und', 'K@@', 'rei@@', 's', 'in', 'den', 'S@@', 'om@@', 'mer@@', '.', '</s>']
2023-05-30 19:47:42,891 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-30 19:47:42,891 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-30 19:47:42,891 - INFO - joeynmt.training - 	Hypothesis: Es ist in den Winter und Kreis in den Sommer.
2023-05-30 19:47:42,891 - INFO - joeynmt.training - Example #4
2023-05-30 19:47:42,891 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2023-05-30 19:47:42,891 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letzten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2023-05-30 19:47:42,891 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'der', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', 'ist', 'eine', 'ver@@', 'n@@', 'etz@@', 'te', 'Ver@@', 'si@@', 'on', 'von', 'de@@', 'm,', 'was', 'die', 'letzten', '2@@', '5', 'Jahre', 'lang', 'pass@@', 'iert.', '</s>']
2023-05-30 19:47:42,892 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-30 19:47:42,892 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-30 19:47:42,892 - INFO - joeynmt.training - 	Hypothesis: Und der nächste Folie ist eine vernetzte Version von dem, was die letzten 25 Jahre lang passiert.
2023-05-30 19:47:56,575 - INFO - joeynmt.training - Epoch  10: total training loss 6523.17
2023-05-30 19:47:56,575 - INFO - joeynmt.training - Training ended after  10 epochs.
2023-05-30 19:47:56,575 - INFO - joeynmt.training - Best validation result (greedy) at step    41500:   6.24 ppl.
2023-05-30 19:47:56,585 - INFO - joeynmt.model - Building an encoder-decoder model...
2023-05-30 19:47:56,616 - INFO - joeynmt.model - Enc-dec model built.
2023-05-30 19:47:56,630 - INFO - joeynmt.helpers - Load model from /Users/cyril/Desktop/krizzzzi/mt-exercise-5/models/transformer_model2/41500.ckpt.
2023-05-30 19:47:56,633 - INFO - joeynmt.prediction - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=2004),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=2004),
	loss_function=None)
2023-05-30 19:47:56,636 - INFO - joeynmt.prediction - Decoding on dev set...
2023-05-30 19:47:56,636 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 19:47:56,636 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 19:50:35,477 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 158.8338[sec], evaluation: 0.0000[sec]
2023-05-30 19:50:35,479 - INFO - joeynmt.prediction - Translations saved to: /Users/cyril/Desktop/krizzzzi/mt-exercise-5/models/transformer_model2/00041500.hyps.dev.
2023-05-30 19:50:35,479 - INFO - joeynmt.prediction - Decoding on test set...
2023-05-30 19:50:35,479 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-30 19:50:35,479 - INFO - joeynmt.prediction - Predicting 1779 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-30 19:54:04,857 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 209.3656[sec], evaluation: 0.0000[sec]
2023-05-30 19:54:04,860 - INFO - joeynmt.prediction - Translations saved to: /Users/cyril/Desktop/krizzzzi/mt-exercise-5/models/transformer_model2/00041500.hyps.test.
