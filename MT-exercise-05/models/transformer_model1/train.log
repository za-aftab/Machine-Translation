2023-05-25 19:50:24,828 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2023-05-25 19:50:24,828 - INFO - joeynmt.helpers -                           cfg.name : transformer_model1
2023-05-25 19:50:24,828 - INFO - joeynmt.helpers -                cfg.joeynmt_version : 2.0.0
2023-05-25 19:50:24,828 - INFO - joeynmt.helpers -                     cfg.data.train : data/train
2023-05-25 19:50:24,828 - INFO - joeynmt.helpers -                       cfg.data.dev : data/dev
2023-05-25 19:50:24,828 - INFO - joeynmt.helpers -                      cfg.data.test : data/test
2023-05-25 19:50:24,828 - INFO - joeynmt.helpers -              cfg.data.dataset_type : plain
2023-05-25 19:50:24,828 - INFO - joeynmt.helpers -                  cfg.data.src.lang : nl
2023-05-25 19:50:24,828 - INFO - joeynmt.helpers -                 cfg.data.src.level : word
2023-05-25 19:50:24,828 - INFO - joeynmt.helpers -             cfg.data.src.lowercase : False
2023-05-25 19:50:24,828 - INFO - joeynmt.helpers -       cfg.data.src.max_sent_length : 100
2023-05-25 19:50:24,828 - INFO - joeynmt.helpers -             cfg.data.src.voc_limit : 2000
2023-05-25 19:50:24,828 - INFO - joeynmt.helpers -                  cfg.data.trg.lang : de
2023-05-25 19:50:24,828 - INFO - joeynmt.helpers -                 cfg.data.trg.level : word
2023-05-25 19:50:24,828 - INFO - joeynmt.helpers -             cfg.data.trg.lowercase : False
2023-05-25 19:50:24,828 - INFO - joeynmt.helpers -       cfg.data.trg.max_sent_length : 100
2023-05-25 19:50:24,828 - INFO - joeynmt.helpers -             cfg.data.trg.voc_limit : 2000
2023-05-25 19:50:24,828 - INFO - joeynmt.helpers -              cfg.testing.beam_size : 5
2023-05-25 19:50:24,828 - INFO - joeynmt.helpers -                  cfg.testing.alpha : 1.0
2023-05-25 19:50:24,828 - INFO - joeynmt.helpers -           cfg.training.random_seed : 42
2023-05-25 19:50:24,828 - INFO - joeynmt.helpers -             cfg.training.optimizer : adam
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -         cfg.training.normalization : tokens
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -         cfg.training.learning_rate : 0.0003
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -            cfg.training.batch_size : 2048
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -            cfg.training.batch_type : token
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -       cfg.training.eval_batch_size : 1024
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -       cfg.training.eval_batch_type : token
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -            cfg.training.scheduling : plateau
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -              cfg.training.patience : 8
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -          cfg.training.weight_decay : 0.0
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -       cfg.training.decrease_factor : 0.7
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -                cfg.training.epochs : 10
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -       cfg.training.validation_freq : 500
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -          cfg.training.logging_freq : 100
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -           cfg.training.eval_metric : bleu
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -             cfg.training.model_dir : models/transformer_model1
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -             cfg.training.overwrite : False
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -               cfg.training.shuffle : True
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -              cfg.training.use_cuda : False
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -     cfg.training.max_output_length : 100
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -     cfg.training.print_valid_sents : [0, 1, 2, 3, 4]
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -       cfg.training.label_smoothing : 0.3
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -              cfg.model.initializer : xavier_uniform
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -         cfg.model.bias_initializer : zeros
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -                cfg.model.init_gain : 1.0
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -        cfg.model.embed_initializer : xavier_uniform
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -          cfg.model.embed_init_gain : 1.0
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -          cfg.model.tied_embeddings : False
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -             cfg.model.tied_softmax : True
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -             cfg.model.encoder.type : transformer
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -       cfg.model.encoder.num_layers : 4
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -        cfg.model.encoder.num_heads : 2
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -      cfg.model.encoder.hidden_size : 256
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -          cfg.model.encoder.ff_size : 512
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -          cfg.model.encoder.dropout : 0
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -             cfg.model.decoder.type : transformer
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -       cfg.model.decoder.num_layers : 1
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -        cfg.model.decoder.num_heads : 2
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -      cfg.model.decoder.hidden_size : 256
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -          cfg.model.decoder.ff_size : 512
2023-05-25 19:50:24,829 - INFO - joeynmt.helpers -          cfg.model.decoder.dropout : 0
2023-05-25 19:50:24,832 - INFO - joeynmt.data - Building tokenizer...
2023-05-25 19:50:24,832 - INFO - joeynmt.tokenizers - nl tokenizer: BasicTokenizer(level=word, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none)
2023-05-25 19:50:24,832 - INFO - joeynmt.tokenizers - de tokenizer: BasicTokenizer(level=word, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none)
2023-05-25 19:50:24,832 - INFO - joeynmt.data - Loading train set...
2023-05-25 19:50:24,931 - INFO - joeynmt.data - Building vocabulary...
2023-05-25 19:50:25,883 - INFO - joeynmt.data - Loading dev set...
2023-05-25 19:50:25,886 - INFO - joeynmt.data - Loading test set...
2023-05-25 19:50:25,889 - INFO - joeynmt.data - Data loaded.
2023-05-25 19:50:25,889 - INFO - joeynmt.data - Train dataset: PlaintextDataset(split=train, len=100000, src_lang=nl, trg_lang=de, has_trg=True, random_subset=-1)
2023-05-25 19:50:25,889 - INFO - joeynmt.data - Valid dataset: PlaintextDataset(split=dev, len=1001, src_lang=nl, trg_lang=de, has_trg=True, random_subset=-1)
2023-05-25 19:50:25,889 - INFO - joeynmt.data -  Test dataset: PlaintextDataset(split=test, len=1779, src_lang=nl, trg_lang=de, has_trg=True, random_subset=-1)
2023-05-25 19:50:25,889 - INFO - joeynmt.data - First training example:
	[SRC] Al Gore over het afwenden van de klimaatcrisis
	[TRG] Al Gore: Die Abwendung der Klimakatastrophe
2023-05-25 19:50:25,889 - INFO - joeynmt.data - First 10 Src tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) de (5) een (6) het (7) van (8) en (9) dat
2023-05-25 19:50:25,889 - INFO - joeynmt.data - First 10 Trg tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) die (5) und (6) der (7) in (8) das (9) zu
2023-05-25 19:50:25,889 - INFO - joeynmt.data - Number of unique Src tokens (vocab_size): 2004
2023-05-25 19:50:25,889 - INFO - joeynmt.data - Number of unique Trg tokens (vocab_size): 2004
2023-05-25 19:50:25,890 - INFO - joeynmt.model - Building an encoder-decoder model...
2023-05-25 19:50:25,942 - INFO - joeynmt.model - Enc-dec model built.
2023-05-25 19:50:25,944 - INFO - joeynmt.model - Total params: 3925248
2023-05-25 19:50:25,944 - DEBUG - joeynmt.model - Trainable parameters: ['decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2023-05-25 19:50:25,944 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=2004),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=2004),
	loss_function=XentLoss(criterion=KLDivLoss(), smoothing=0.3))
2023-05-25 19:50:25,944 - INFO - joeynmt.builders - Adam(lr=0.0003, weight_decay=0.0, betas=(0.9, 0.999))
2023-05-25 19:50:25,944 - INFO - joeynmt.builders - ReduceLROnPlateau(mode=min, verbose=False, threshold_mode=abs, eps=0.0, factor=0.7, patience=8)
2023-05-25 19:50:25,945 - INFO - joeynmt.training - Train stats:
	device: cpu
	n_gpu: 0
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 2048
	effective batch size (w. parallel & accumulation): 2048
2023-05-25 19:50:25,945 - INFO - joeynmt.training - EPOCH 1
2023-05-25 19:50:39,556 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     2.983600, Batch Acc: 0.259805, Tokens per Sec:     4859, Lr: 0.000300
2023-05-25 19:50:53,227 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     2.887002, Batch Acc: 0.291778, Tokens per Sec:     4776, Lr: 0.000300
2023-05-25 19:51:06,738 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     2.782387, Batch Acc: 0.311419, Tokens per Sec:     4951, Lr: 0.000300
2023-05-25 19:51:20,525 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     2.624839, Batch Acc: 0.325932, Tokens per Sec:     4816, Lr: 0.000300
2023-05-25 19:51:34,221 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     2.476795, Batch Acc: 0.338656, Tokens per Sec:     4719, Lr: 0.000300
2023-05-25 19:51:34,222 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 19:51:34,223 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 19:52:07,343 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.57, ppl:  13.13, acc:   0.33, generation: 33.1163[sec], evaluation: 0.0000[sec]
2023-05-25 19:52:07,344 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-25 19:52:07,432 - INFO - joeynmt.training - Example #0
2023-05-25 19:52:07,432 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 19:52:07,432 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 19:52:07,432 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', '<unk>', 'ich', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 19:52:07,433 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 19:52:07,433 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 19:52:07,433 - INFO - joeynmt.training - 	Hypothesis: <unk> <unk> ich <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>
2023-05-25 19:52:07,433 - INFO - joeynmt.training - Example #1
2023-05-25 19:52:07,433 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 19:52:07,433 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 19:52:07,433 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 19:52:07,433 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 19:52:07,433 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 19:52:07,433 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>
2023-05-25 19:52:07,433 - INFO - joeynmt.training - Example #2
2023-05-25 19:52:07,433 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 19:52:07,433 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 19:52:07,433 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 19:52:07,433 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 19:52:07,433 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 19:52:07,433 - INFO - joeynmt.training - 	Hypothesis: Die <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>
2023-05-25 19:52:07,433 - INFO - joeynmt.training - Example #3
2023-05-25 19:52:07,433 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 19:52:07,433 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 19:52:07,433 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'die', '<unk>', '<unk>', 'und', '<unk>', '<unk>', '</s>']
2023-05-25 19:52:07,433 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 19:52:07,433 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 19:52:07,433 - INFO - joeynmt.training - 	Hypothesis: Es ist die <unk> <unk> und <unk> <unk>
2023-05-25 19:52:07,433 - INFO - joeynmt.training - Example #4
2023-05-25 19:52:07,433 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 19:52:07,433 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 19:52:07,433 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', '<unk>', 'die', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'was', 'es', 'ist', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 19:52:07,434 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 19:52:07,434 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 19:52:07,434 - INFO - joeynmt.training - 	Hypothesis: Die <unk> <unk> die <unk> <unk> <unk> <unk> <unk> <unk> was es ist <unk> <unk> <unk> <unk>
2023-05-25 19:52:20,963 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     2.456144, Batch Acc: 0.347297, Tokens per Sec:     4747, Lr: 0.000300
2023-05-25 19:52:34,463 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     2.462013, Batch Acc: 0.352809, Tokens per Sec:     4762, Lr: 0.000300
2023-05-25 19:52:48,081 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:     2.364388, Batch Acc: 0.358534, Tokens per Sec:     4809, Lr: 0.000300
2023-05-25 19:53:01,738 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:     2.361957, Batch Acc: 0.366762, Tokens per Sec:     4812, Lr: 0.000300
2023-05-25 19:53:15,661 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     2.304681, Batch Acc: 0.372563, Tokens per Sec:     4709, Lr: 0.000300
2023-05-25 19:53:15,662 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 19:53:15,662 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 19:53:44,200 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.40, ppl:  10.99, acc:   0.35, generation: 28.5331[sec], evaluation: 0.0000[sec]
2023-05-25 19:53:44,201 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-25 19:53:44,310 - INFO - joeynmt.training - Example #0
2023-05-25 19:53:44,310 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 19:53:44,310 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 19:53:44,310 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', '<unk>', 'ich', 'diese', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 19:53:44,311 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 19:53:44,311 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 19:53:44,311 - INFO - joeynmt.training - 	Hypothesis: <unk> <unk> ich diese <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>
2023-05-25 19:53:44,311 - INFO - joeynmt.training - Example #1
2023-05-25 19:53:44,311 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 19:53:44,311 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 19:53:44,311 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', '<unk>', '<unk>', 'das', '<unk>', '<unk>', '<unk>', 'weil', 'es', 'nicht', 'der', '<unk>', '<unk>', '</s>']
2023-05-25 19:53:44,311 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 19:53:44,311 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 19:53:44,311 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> <unk> <unk> das <unk> <unk> <unk> weil es nicht der <unk> <unk>
2023-05-25 19:53:44,311 - INFO - joeynmt.training - Example #2
2023-05-25 19:53:44,311 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 19:53:44,311 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 19:53:44,311 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', '<unk>', 'ist', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 19:53:44,311 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 19:53:44,311 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 19:53:44,311 - INFO - joeynmt.training - 	Hypothesis: Die <unk> <unk> ist <unk> in <unk> <unk> <unk> <unk> <unk> <unk>
2023-05-25 19:53:44,311 - INFO - joeynmt.training - Example #3
2023-05-25 19:53:44,311 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 19:53:44,311 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 19:53:44,311 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', '<unk>', '<unk>', 'und', '<unk>', '<unk>', 'und', '<unk>', '</s>']
2023-05-25 19:53:44,312 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 19:53:44,312 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 19:53:44,312 - INFO - joeynmt.training - 	Hypothesis: <unk> <unk> <unk> und <unk> <unk> und <unk>
2023-05-25 19:53:44,312 - INFO - joeynmt.training - Example #4
2023-05-25 19:53:44,312 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 19:53:44,312 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 19:53:44,312 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', '<unk>', 'ich', '<unk>', 'die', 'ich', '<unk>', '<unk>', 'ist', 'ein', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 19:53:44,312 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 19:53:44,312 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 19:53:44,312 - INFO - joeynmt.training - 	Hypothesis: Die <unk> <unk> ich <unk> die ich <unk> <unk> ist ein <unk> <unk> <unk>
2023-05-25 19:53:58,000 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:     2.258507, Batch Acc: 0.380646, Tokens per Sec:     4807, Lr: 0.000300
2023-05-25 19:54:11,813 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:     2.122504, Batch Acc: 0.382513, Tokens per Sec:     4843, Lr: 0.000300
2023-05-25 19:54:26,013 - INFO - joeynmt.training - Epoch   1, Step:     1300, Batch Loss:     2.166152, Batch Acc: 0.389477, Tokens per Sec:     4629, Lr: 0.000300
2023-05-25 19:54:39,692 - INFO - joeynmt.training - Epoch   1, Step:     1400, Batch Loss:     2.199739, Batch Acc: 0.391489, Tokens per Sec:     4781, Lr: 0.000300
2023-05-25 19:54:53,103 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:     2.019515, Batch Acc: 0.397341, Tokens per Sec:     4958, Lr: 0.000300
2023-05-25 19:54:53,104 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 19:54:53,104 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 19:55:23,339 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.28, ppl:   9.78, acc:   0.37, generation: 30.2315[sec], evaluation: 0.0000[sec]
2023-05-25 19:55:23,341 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-25 19:55:23,428 - INFO - joeynmt.training - Example #0
2023-05-25 19:55:23,429 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 19:55:23,429 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 19:55:23,429 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahre', '<unk>', '<unk>', 'ich', 'diese', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'dass', 'die', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 19:55:23,429 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 19:55:23,429 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 19:55:23,429 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahre <unk> <unk> ich diese <unk> <unk> <unk> <unk> <unk> <unk> dass die <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>
2023-05-25 19:55:23,429 - INFO - joeynmt.training - Example #1
2023-05-25 19:55:23,429 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 19:55:23,429 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 19:55:23,429 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'weil', 'es', 'das', '<unk>', '<unk>', '<unk>', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '</s>']
2023-05-25 19:55:23,429 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 19:55:23,429 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 19:55:23,429 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> <unk> <unk> <unk> <unk> weil es das <unk> <unk> <unk> weil es nicht die <unk> des <unk>
2023-05-25 19:55:23,429 - INFO - joeynmt.training - Example #2
2023-05-25 19:55:23,429 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 19:55:23,429 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 19:55:23,429 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', 'der', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 19:55:23,429 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 19:55:23,429 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 19:55:23,429 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in der <unk> <unk> <unk> <unk> <unk>
2023-05-25 19:55:23,429 - INFO - joeynmt.training - Example #3
2023-05-25 19:55:23,429 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 19:55:23,429 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 19:55:23,429 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'aus', '<unk>', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2023-05-25 19:55:23,430 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 19:55:23,430 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 19:55:23,430 - INFO - joeynmt.training - 	Hypothesis: Es ist aus <unk> <unk> und <unk> in der <unk>
2023-05-25 19:55:23,430 - INFO - joeynmt.training - Example #4
2023-05-25 19:55:23,430 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 19:55:23,430 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 19:55:23,430 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', '<unk>', '<unk>', '<unk>', '<unk>', 'ist', 'eine', '<unk>', '<unk>', 'der', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten', 'letzten']
2023-05-25 19:55:23,430 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 19:55:23,430 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 19:55:23,430 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich <unk> <unk> <unk> <unk> ist eine <unk> <unk> der letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten letzten
2023-05-25 19:55:37,405 - INFO - joeynmt.training - Epoch   1, Step:     1600, Batch Loss:     2.144475, Batch Acc: 0.401030, Tokens per Sec:     4764, Lr: 0.000300
2023-05-25 19:55:51,137 - INFO - joeynmt.training - Epoch   1, Step:     1700, Batch Loss:     2.202127, Batch Acc: 0.405381, Tokens per Sec:     4680, Lr: 0.000300
2023-05-25 19:56:04,876 - INFO - joeynmt.training - Epoch   1, Step:     1800, Batch Loss:     2.053602, Batch Acc: 0.415730, Tokens per Sec:     4901, Lr: 0.000300
2023-05-25 19:56:18,027 - INFO - joeynmt.training - Epoch   1, Step:     1900, Batch Loss:     2.007424, Batch Acc: 0.415630, Tokens per Sec:     5101, Lr: 0.000300
2023-05-25 19:56:31,424 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:     1.875782, Batch Acc: 0.415371, Tokens per Sec:     4959, Lr: 0.000300
2023-05-25 19:56:31,425 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 19:56:31,425 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 19:56:42,887 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.19, ppl:   8.96, acc:   0.39, generation: 11.4590[sec], evaluation: 0.0000[sec]
2023-05-25 19:56:42,888 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-25 19:56:42,980 - INFO - joeynmt.training - Example #0
2023-05-25 19:56:42,980 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 19:56:42,980 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 19:56:42,980 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahre', '<unk>', 'ich', 'diese', 'beiden', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 19:56:42,981 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 19:56:42,981 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 19:56:42,981 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahre <unk> ich diese beiden <unk> <unk> <unk>
2023-05-25 19:56:42,981 - INFO - joeynmt.training - Example #1
2023-05-25 19:56:42,981 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 19:56:42,981 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 19:56:42,981 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'denn', 'es', 'ist', 'nicht', 'die', '<unk>', 'der', '<unk>', '</s>']
2023-05-25 19:56:42,981 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 19:56:42,981 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 19:56:42,981 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> <unk> <unk> <unk> denn es ist nicht die <unk> der <unk>
2023-05-25 19:56:42,981 - INFO - joeynmt.training - Example #2
2023-05-25 19:56:42,981 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 19:56:42,981 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 19:56:42,981 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 19:56:42,981 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 19:56:42,981 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 19:56:42,981 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk>
2023-05-25 19:56:42,981 - INFO - joeynmt.training - Example #3
2023-05-25 19:56:42,981 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 19:56:42,981 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 19:56:42,981 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'aus', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2023-05-25 19:56:42,981 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 19:56:42,981 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 19:56:42,981 - INFO - joeynmt.training - 	Hypothesis: Es ist aus der <unk> und <unk> in der <unk>
2023-05-25 19:56:42,981 - INFO - joeynmt.training - Example #4
2023-05-25 19:56:42,982 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 19:56:42,982 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 19:56:42,982 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'nächsten', '<unk>', 'die', 'ich', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 19:56:42,982 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 19:56:42,982 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 19:56:42,982 - INFO - joeynmt.training - 	Hypothesis: Und die nächsten <unk> die ich <unk> <unk> <unk>
2023-05-25 19:56:56,815 - INFO - joeynmt.training - Epoch   1, Step:     2100, Batch Loss:     1.970810, Batch Acc: 0.418465, Tokens per Sec:     4802, Lr: 0.000300
2023-05-25 19:57:10,652 - INFO - joeynmt.training - Epoch   1, Step:     2200, Batch Loss:     2.076899, Batch Acc: 0.426454, Tokens per Sec:     4755, Lr: 0.000300
2023-05-25 19:57:25,195 - INFO - joeynmt.training - Epoch   1, Step:     2300, Batch Loss:     1.906292, Batch Acc: 0.426474, Tokens per Sec:     4450, Lr: 0.000300
2023-05-25 19:57:39,152 - INFO - joeynmt.training - Epoch   1, Step:     2400, Batch Loss:     2.014539, Batch Acc: 0.425974, Tokens per Sec:     4717, Lr: 0.000300
2023-05-25 19:57:47,076 - INFO - joeynmt.training - Epoch   1: total training loss 5681.12
2023-05-25 19:57:47,078 - INFO - joeynmt.training - EPOCH 2
2023-05-25 19:57:52,824 - INFO - joeynmt.training - Epoch   2, Step:     2500, Batch Loss:     1.889616, Batch Acc: 0.435790, Tokens per Sec:     5056, Lr: 0.000300
2023-05-25 19:57:52,824 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 19:57:52,824 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 19:58:05,665 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.15, ppl:   8.57, acc:   0.39, generation: 12.8369[sec], evaluation: 0.0000[sec]
2023-05-25 19:58:05,667 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-25 19:58:05,759 - INFO - joeynmt.training - Example #0
2023-05-25 19:58:05,759 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 19:58:05,759 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 19:58:05,759 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahre', '<unk>', 'ich', 'diese', 'zwei', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 19:58:05,759 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 19:58:05,759 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 19:58:05,759 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahre <unk> ich diese zwei <unk> <unk> um zu zeigen, dass die <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>
2023-05-25 19:58:05,759 - INFO - joeynmt.training - Example #1
2023-05-25 19:58:05,759 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 19:58:05,759 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 19:58:05,759 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 19:58:05,759 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 19:58:05,759 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 19:58:05,759 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> <unk> <unk> <unk>
2023-05-25 19:58:05,759 - INFO - joeynmt.training - Example #2
2023-05-25 19:58:05,759 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 19:58:05,759 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 19:58:05,759 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', '<unk>', '<unk>', '</s>']
2023-05-25 19:58:05,760 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 19:58:05,760 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 19:58:05,760 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk>  <unk> <unk>
2023-05-25 19:58:05,760 - INFO - joeynmt.training - Example #3
2023-05-25 19:58:05,760 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 19:58:05,760 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 19:58:05,760 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'aus', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2023-05-25 19:58:05,760 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 19:58:05,760 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 19:58:05,760 - INFO - joeynmt.training - 	Hypothesis: Es <unk> aus <unk> und <unk> in der <unk>
2023-05-25 19:58:05,760 - INFO - joeynmt.training - Example #4
2023-05-25 19:58:05,760 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 19:58:05,760 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 19:58:05,760 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', '<unk>', '<unk>', '', 'ist', 'ein', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 19:58:05,760 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 19:58:05,760 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 19:58:05,760 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich <unk> <unk>  ist ein <unk> <unk> <unk>
2023-05-25 19:58:19,804 - INFO - joeynmt.training - Epoch   2, Step:     2600, Batch Loss:     1.903917, Batch Acc: 0.440415, Tokens per Sec:     4681, Lr: 0.000300
2023-05-25 19:58:33,682 - INFO - joeynmt.training - Epoch   2, Step:     2700, Batch Loss:     1.838050, Batch Acc: 0.441069, Tokens per Sec:     4839, Lr: 0.000300
2023-05-25 19:58:47,501 - INFO - joeynmt.training - Epoch   2, Step:     2800, Batch Loss:     1.930318, Batch Acc: 0.442852, Tokens per Sec:     4823, Lr: 0.000300
2023-05-25 19:59:01,434 - INFO - joeynmt.training - Epoch   2, Step:     2900, Batch Loss:     2.085412, Batch Acc: 0.441261, Tokens per Sec:     4705, Lr: 0.000300
2023-05-25 19:59:14,699 - INFO - joeynmt.training - Epoch   2, Step:     3000, Batch Loss:     1.931507, Batch Acc: 0.443954, Tokens per Sec:     4918, Lr: 0.000300
2023-05-25 19:59:14,700 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 19:59:14,700 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 19:59:27,540 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.11, ppl:   8.29, acc:   0.40, generation: 12.8357[sec], evaluation: 0.0000[sec]
2023-05-25 19:59:27,542 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-25 19:59:27,630 - INFO - joeynmt.helpers - delete models/transformer_model1/500.ckpt
2023-05-25 19:59:27,635 - INFO - joeynmt.training - Example #0
2023-05-25 19:59:27,635 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 19:59:27,635 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 19:59:27,635 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', '<unk>', 'ich', 'diese', 'zwei', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 19:59:27,635 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 19:59:27,635 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 19:59:27,635 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr <unk> ich diese zwei <unk> <unk> um zu zeigen, dass die <unk> <unk> <unk> <unk> <unk> <unk> <unk>
2023-05-25 19:59:27,635 - INFO - joeynmt.training - Example #1
2023-05-25 19:59:27,635 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 19:59:27,635 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 19:59:27,635 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '</s>']
2023-05-25 19:59:27,635 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 19:59:27,635 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 19:59:27,635 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> weil es nicht die <unk> des <unk>
2023-05-25 19:59:27,635 - INFO - joeynmt.training - Example #2
2023-05-25 19:59:27,635 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 19:59:27,635 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 19:59:27,635 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', 'das', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 19:59:27,635 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 19:59:27,635 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 19:59:27,635 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk>  das <unk> <unk> <unk>
2023-05-25 19:59:27,636 - INFO - joeynmt.training - Example #3
2023-05-25 19:59:27,636 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 19:59:27,636 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 19:59:27,636 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2023-05-25 19:59:27,636 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 19:59:27,636 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 19:59:27,636 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in der <unk> und <unk> in der <unk>
2023-05-25 19:59:27,636 - INFO - joeynmt.training - Example #4
2023-05-25 19:59:27,636 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 19:59:27,636 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 19:59:27,636 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', '<unk>', '<unk>', '<unk>', 'ist', 'eine', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 19:59:27,636 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 19:59:27,636 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 19:59:27,636 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich <unk> <unk> <unk> ist eine <unk> <unk> <unk> <unk>
2023-05-25 19:59:40,987 - INFO - joeynmt.training - Epoch   2, Step:     3100, Batch Loss:     1.833393, Batch Acc: 0.448851, Tokens per Sec:     4788, Lr: 0.000300
2023-05-25 19:59:55,045 - INFO - joeynmt.training - Epoch   2, Step:     3200, Batch Loss:     1.991134, Batch Acc: 0.441022, Tokens per Sec:     4612, Lr: 0.000300
2023-05-25 20:00:08,899 - INFO - joeynmt.training - Epoch   2, Step:     3300, Batch Loss:     1.920053, Batch Acc: 0.448985, Tokens per Sec:     4824, Lr: 0.000300
2023-05-25 20:00:22,719 - INFO - joeynmt.training - Epoch   2, Step:     3400, Batch Loss:     1.804814, Batch Acc: 0.451287, Tokens per Sec:     4723, Lr: 0.000300
2023-05-25 20:00:36,391 - INFO - joeynmt.training - Epoch   2, Step:     3500, Batch Loss:     1.763224, Batch Acc: 0.449524, Tokens per Sec:     4717, Lr: 0.000300
2023-05-25 20:00:36,392 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:00:36,392 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:00:58,315 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.07, ppl:   7.93, acc:   0.40, generation: 21.9193[sec], evaluation: 0.0000[sec]
2023-05-25 20:00:58,316 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-25 20:00:58,401 - INFO - joeynmt.helpers - delete models/transformer_model1/1000.ckpt
2023-05-25 20:00:58,405 - INFO - joeynmt.training - Example #0
2023-05-25 20:00:58,405 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:00:58,405 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:00:58,405 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahre', '<unk>', 'habe', 'ich', 'diese', 'zwei', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '<unk>', '', '<unk>', 'die', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:00:58,405 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:00:58,405 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:00:58,405 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahre <unk> habe ich diese zwei <unk> <unk> um zu zeigen, dass die <unk> <unk>  <unk> die <unk> <unk> <unk> <unk>
2023-05-25 20:00:58,405 - INFO - joeynmt.training - Example #1
2023-05-25 20:00:58,405 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:00:58,405 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:00:58,405 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', '<unk>', 'dieses', '<unk>', '<unk>', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2023-05-25 20:00:58,405 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:00:58,405 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:00:58,405 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> <unk> dieses <unk> <unk>  weil es nicht die <unk> des <unk> <unk>
2023-05-25 20:00:58,405 - INFO - joeynmt.training - Example #2
2023-05-25 20:00:58,405 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:00:58,405 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:00:58,405 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', '<unk>', '<unk>', '</s>']
2023-05-25 20:00:58,405 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:00:58,405 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:00:58,405 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk>  <unk> <unk>
2023-05-25 20:00:58,406 - INFO - joeynmt.training - Example #3
2023-05-25 20:00:58,406 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:00:58,406 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:00:58,406 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'aus', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2023-05-25 20:00:58,406 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:00:58,406 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:00:58,406 - INFO - joeynmt.training - 	Hypothesis: Es <unk> aus der <unk> und <unk> in der <unk>
2023-05-25 20:00:58,406 - INFO - joeynmt.training - Example #4
2023-05-25 20:00:58,406 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:00:58,406 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:00:58,406 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', '<unk>', '<unk>', '', 'ist', 'ein', '<unk>', 'Version', 'von', '<unk>', '<unk>', '</s>']
2023-05-25 20:00:58,406 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:00:58,406 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:00:58,406 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich <unk> <unk>  ist ein <unk> Version von <unk> <unk>
2023-05-25 20:01:12,210 - INFO - joeynmt.training - Epoch   2, Step:     3600, Batch Loss:     1.840596, Batch Acc: 0.451079, Tokens per Sec:     4766, Lr: 0.000300
2023-05-25 20:01:26,385 - INFO - joeynmt.training - Epoch   2, Step:     3700, Batch Loss:     1.951370, Batch Acc: 0.456250, Tokens per Sec:     4690, Lr: 0.000300
2023-05-25 20:01:39,993 - INFO - joeynmt.training - Epoch   2, Step:     3800, Batch Loss:     1.826797, Batch Acc: 0.457891, Tokens per Sec:     4701, Lr: 0.000300
2023-05-25 20:01:53,735 - INFO - joeynmt.training - Epoch   2, Step:     3900, Batch Loss:     1.769205, Batch Acc: 0.456924, Tokens per Sec:     4962, Lr: 0.000300
2023-05-25 20:02:07,447 - INFO - joeynmt.training - Epoch   2, Step:     4000, Batch Loss:     1.968807, Batch Acc: 0.455433, Tokens per Sec:     4853, Lr: 0.000300
2023-05-25 20:02:07,448 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:02:07,448 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:02:22,671 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.04, ppl:   7.66, acc:   0.41, generation: 15.2192[sec], evaluation: 0.0000[sec]
2023-05-25 20:02:22,671 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-25 20:02:22,764 - INFO - joeynmt.helpers - delete models/transformer_model1/1500.ckpt
2023-05-25 20:02:22,776 - INFO - joeynmt.training - Example #0
2023-05-25 20:02:22,776 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:02:22,776 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:02:22,776 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahre', 'habe', 'ich', 'diese', 'zwei', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '<unk>', '', 'ungefähr', 'die', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:02:22,776 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:02:22,776 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:02:22,776 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahre habe ich diese zwei <unk> <unk> um zu zeigen, dass die <unk> <unk>  ungefähr die <unk> <unk> <unk> <unk> <unk>
2023-05-25 20:02:22,776 - INFO - joeynmt.training - Example #1
2023-05-25 20:02:22,776 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:02:22,776 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:02:22,776 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:02:22,777 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:02:22,777 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:02:22,777 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> <unk> <unk> <unk>
2023-05-25 20:02:22,777 - INFO - joeynmt.training - Example #2
2023-05-25 20:02:22,777 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:02:22,777 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:02:22,777 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:02:22,777 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:02:22,777 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:02:22,777 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk>
2023-05-25 20:02:22,777 - INFO - joeynmt.training - Example #3
2023-05-25 20:02:22,777 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:02:22,777 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:02:22,777 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'aus', 'der', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2023-05-25 20:02:22,777 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:02:22,777 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:02:22,777 - INFO - joeynmt.training - 	Hypothesis: Es <unk> aus der <unk> und <unk> in den <unk>
2023-05-25 20:02:22,777 - INFO - joeynmt.training - Example #4
2023-05-25 20:02:22,777 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:02:22,777 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:02:22,777 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächsten', '<unk>', 'die', 'ich', '<unk>', '<unk>', '', 'ist', 'eine', '<unk>', 'Version', 'von', '<unk>', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'ist', '<unk>', '</s>']
2023-05-25 20:02:22,777 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:02:22,777 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:02:22,777 - INFO - joeynmt.training - 	Hypothesis: Die nächsten <unk> die ich <unk> <unk>  ist eine <unk> Version von <unk> was in den letzten 25 Jahren ist <unk>
2023-05-25 20:02:36,939 - INFO - joeynmt.training - Epoch   2, Step:     4100, Batch Loss:     1.870103, Batch Acc: 0.458985, Tokens per Sec:     4482, Lr: 0.000300
2023-05-25 20:02:51,195 - INFO - joeynmt.training - Epoch   2, Step:     4200, Batch Loss:     1.809113, Batch Acc: 0.453910, Tokens per Sec:     4544, Lr: 0.000300
2023-05-25 20:03:05,504 - INFO - joeynmt.training - Epoch   2, Step:     4300, Batch Loss:     1.725789, Batch Acc: 0.463084, Tokens per Sec:     4393, Lr: 0.000300
2023-05-25 20:03:19,049 - INFO - joeynmt.training - Epoch   2, Step:     4400, Batch Loss:     1.759029, Batch Acc: 0.460175, Tokens per Sec:     4959, Lr: 0.000300
2023-05-25 20:03:32,597 - INFO - joeynmt.training - Epoch   2, Step:     4500, Batch Loss:     1.878069, Batch Acc: 0.458797, Tokens per Sec:     4887, Lr: 0.000300
2023-05-25 20:03:32,598 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:03:32,598 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:03:54,949 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.01, ppl:   7.47, acc:   0.42, generation: 22.3468[sec], evaluation: 0.0000[sec]
2023-05-25 20:03:54,950 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-25 20:03:55,065 - INFO - joeynmt.helpers - delete models/transformer_model1/2000.ckpt
2023-05-25 20:03:55,067 - INFO - joeynmt.training - Example #0
2023-05-25 20:03:55,067 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:03:55,067 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:03:55,067 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahre', '<unk>', 'ich', 'diese', 'zwei', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', '<unk>', '<unk>', 'die', 'die', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:03:55,068 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:03:55,068 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:03:55,068 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahre <unk> ich diese zwei <unk> <unk> um zu zeigen, dass die <unk>  die <unk> <unk> die die <unk> <unk> <unk> <unk> <unk> <unk>
2023-05-25 20:03:55,068 - INFO - joeynmt.training - Example #1
2023-05-25 20:03:55,068 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:03:55,068 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:03:55,068 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '</s>']
2023-05-25 20:03:55,068 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:03:55,068 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:03:55,068 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> <unk> <unk> <unk> <unk> <unk> weil es nicht die <unk> des <unk>
2023-05-25 20:03:55,068 - INFO - joeynmt.training - Example #2
2023-05-25 20:03:55,068 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:03:55,068 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:03:55,068 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:03:55,068 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:03:55,068 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:03:55,068 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk> <unk>
2023-05-25 20:03:55,068 - INFO - joeynmt.training - Example #3
2023-05-25 20:03:55,068 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:03:55,068 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:03:55,068 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2023-05-25 20:03:55,069 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:03:55,069 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:03:55,069 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2023-05-25 20:03:55,069 - INFO - joeynmt.training - Example #4
2023-05-25 20:03:55,069 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:03:55,069 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:03:55,069 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'sehen,', '', 'ist', 'ein', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:03:55,069 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:03:55,069 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:03:55,069 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen sehen,  ist ein <unk> <unk> <unk>
2023-05-25 20:04:09,007 - INFO - joeynmt.training - Epoch   2, Step:     4600, Batch Loss:     1.740876, Batch Acc: 0.468890, Tokens per Sec:     4626, Lr: 0.000300
2023-05-25 20:04:22,418 - INFO - joeynmt.training - Epoch   2, Step:     4700, Batch Loss:     1.851996, Batch Acc: 0.460694, Tokens per Sec:     4927, Lr: 0.000300
2023-05-25 20:04:35,889 - INFO - joeynmt.training - Epoch   2, Step:     4800, Batch Loss:     1.790164, Batch Acc: 0.465191, Tokens per Sec:     4768, Lr: 0.000300
2023-05-25 20:04:49,192 - INFO - joeynmt.training - Epoch   2, Step:     4900, Batch Loss:     1.883428, Batch Acc: 0.462268, Tokens per Sec:     5010, Lr: 0.000300
2023-05-25 20:04:52,063 - INFO - joeynmt.training - Epoch   2: total training loss 4589.66
2023-05-25 20:04:52,063 - INFO - joeynmt.training - EPOCH 3
2023-05-25 20:05:02,462 - INFO - joeynmt.training - Epoch   3, Step:     5000, Batch Loss:     1.681625, Batch Acc: 0.479173, Tokens per Sec:     4922, Lr: 0.000300
2023-05-25 20:05:02,464 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:05:02,464 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:05:22,306 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.00, ppl:   7.41, acc:   0.42, generation: 19.8374[sec], evaluation: 0.0000[sec]
2023-05-25 20:05:22,306 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-25 20:05:22,400 - INFO - joeynmt.helpers - delete models/transformer_model1/2500.ckpt
2023-05-25 20:05:22,406 - INFO - joeynmt.training - Example #0
2023-05-25 20:05:22,406 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:05:22,406 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:05:22,406 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahre', '<unk>', 'ich', 'diese', 'zwei', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', '', 'die', '<unk>', '', 'der', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:05:22,406 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:05:22,406 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:05:22,406 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahre <unk> ich diese zwei <unk> <unk> um zu zeigen, dass die <unk>   die <unk>  der letzten drei Millionen Jahre <unk> <unk> <unk>
2023-05-25 20:05:22,406 - INFO - joeynmt.training - Example #1
2023-05-25 20:05:22,406 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:05:22,406 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:05:22,406 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'das', '<unk>', 'Problem', '<unk>', '', 'denn', 'es', 'ist', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2023-05-25 20:05:22,406 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:05:22,406 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:05:22,406 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> das <unk> Problem <unk>  denn es ist nicht die <unk> des <unk> <unk>
2023-05-25 20:05:22,406 - INFO - joeynmt.training - Example #2
2023-05-25 20:05:22,406 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:05:22,406 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:05:22,406 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:05:22,407 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:05:22,407 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:05:22,407 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk> <unk>
2023-05-25 20:05:22,407 - INFO - joeynmt.training - Example #3
2023-05-25 20:05:22,407 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:05:22,407 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:05:22,407 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'aus', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2023-05-25 20:05:22,407 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:05:22,407 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:05:22,407 - INFO - joeynmt.training - 	Hypothesis: Es <unk> aus der <unk> und <unk> in der <unk>
2023-05-25 20:05:22,407 - INFO - joeynmt.training - Example #4
2023-05-25 20:05:22,407 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:05:22,407 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:05:22,407 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', '<unk>', '<unk>', '', 'ist', 'ein', '<unk>', '<unk>', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2023-05-25 20:05:22,407 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:05:22,407 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:05:22,407 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich <unk> <unk>  ist ein <unk> <unk> was in den letzten 25 Jahren <unk>
2023-05-25 20:05:36,292 - INFO - joeynmt.training - Epoch   3, Step:     5100, Batch Loss:     1.627764, Batch Acc: 0.479934, Tokens per Sec:     4584, Lr: 0.000300
2023-05-25 20:05:50,202 - INFO - joeynmt.training - Epoch   3, Step:     5200, Batch Loss:     1.852760, Batch Acc: 0.481750, Tokens per Sec:     4726, Lr: 0.000300
2023-05-25 20:06:03,918 - INFO - joeynmt.training - Epoch   3, Step:     5300, Batch Loss:     1.578066, Batch Acc: 0.479578, Tokens per Sec:     4863, Lr: 0.000300
2023-05-25 20:06:17,464 - INFO - joeynmt.training - Epoch   3, Step:     5400, Batch Loss:     1.629763, Batch Acc: 0.476302, Tokens per Sec:     4910, Lr: 0.000300
2023-05-25 20:06:31,267 - INFO - joeynmt.training - Epoch   3, Step:     5500, Batch Loss:     1.853794, Batch Acc: 0.478099, Tokens per Sec:     4766, Lr: 0.000300
2023-05-25 20:06:31,268 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:06:31,268 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:06:54,484 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.98, ppl:   7.27, acc:   0.42, generation: 23.2109[sec], evaluation: 0.0000[sec]
2023-05-25 20:06:54,484 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-25 20:06:54,575 - INFO - joeynmt.helpers - delete models/transformer_model1/3000.ckpt
2023-05-25 20:06:54,578 - INFO - joeynmt.training - Example #0
2023-05-25 20:06:54,578 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:06:54,578 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:06:54,578 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahre', '<unk>', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', '<unk>', '', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', '<unk>', '<unk>', 'die', '<unk>', '', 'mit', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:06:54,578 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:06:54,578 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:06:54,579 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahre <unk> ich diese beiden <unk> <unk> um <unk>  zu zeigen, dass die <unk>  <unk> <unk> die <unk>  mit <unk> <unk> <unk>
2023-05-25 20:06:54,579 - INFO - joeynmt.training - Example #1
2023-05-25 20:06:54,579 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:06:54,579 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:06:54,579 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'dieses', '<unk>', 'Problem', '<unk>', '<unk>', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2023-05-25 20:06:54,579 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:06:54,579 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:06:54,579 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> dieses <unk> Problem <unk> <unk> weil es nicht die <unk> des <unk> <unk>
2023-05-25 20:06:54,579 - INFO - joeynmt.training - Example #2
2023-05-25 20:06:54,579 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:06:54,579 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:06:54,579 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:06:54,579 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:06:54,579 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:06:54,579 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk> <unk>
2023-05-25 20:06:54,579 - INFO - joeynmt.training - Example #3
2023-05-25 20:06:54,579 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:06:54,579 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:06:54,579 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2023-05-25 20:06:54,579 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:06:54,579 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:06:54,579 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in der <unk>
2023-05-25 20:06:54,579 - INFO - joeynmt.training - Example #4
2023-05-25 20:06:54,579 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:06:54,580 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:06:54,580 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', '<unk>', '<unk>', '', 'ist', 'ein', '<unk>', '<unk>', '<unk>', '<unk>', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'ist', '<unk>', '</s>']
2023-05-25 20:06:54,580 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:06:54,580 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:06:54,580 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich <unk> <unk>  ist ein <unk> <unk> <unk> <unk> was in den letzten 25 Jahren ist <unk>
2023-05-25 20:07:08,761 - INFO - joeynmt.training - Epoch   3, Step:     5600, Batch Loss:     1.781148, Batch Acc: 0.479922, Tokens per Sec:     4648, Lr: 0.000300
2023-05-25 20:07:22,581 - INFO - joeynmt.training - Epoch   3, Step:     5700, Batch Loss:     1.738679, Batch Acc: 0.476135, Tokens per Sec:     4785, Lr: 0.000300
2023-05-25 20:07:36,037 - INFO - joeynmt.training - Epoch   3, Step:     5800, Batch Loss:     1.652171, Batch Acc: 0.477936, Tokens per Sec:     4940, Lr: 0.000300
2023-05-25 20:07:49,660 - INFO - joeynmt.training - Epoch   3, Step:     5900, Batch Loss:     1.908834, Batch Acc: 0.480976, Tokens per Sec:     4872, Lr: 0.000300
2023-05-25 20:08:03,285 - INFO - joeynmt.training - Epoch   3, Step:     6000, Batch Loss:     1.688703, Batch Acc: 0.479036, Tokens per Sec:     4737, Lr: 0.000300
2023-05-25 20:08:03,286 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:08:03,286 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:08:20,882 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.00, ppl:   7.38, acc:   0.42, generation: 17.5914[sec], evaluation: 0.0000[sec]
2023-05-25 20:08:20,971 - INFO - joeynmt.helpers - delete models/transformer_model1/3500.ckpt
2023-05-25 20:08:20,974 - INFO - joeynmt.training - Example #0
2023-05-25 20:08:20,974 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:08:20,974 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:08:20,974 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahre', '<unk>', 'ich', 'diese', 'beiden', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', '<unk>', '', 'die', '<unk>', '', 'mit', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:08:20,974 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:08:20,974 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:08:20,974 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahre <unk> ich diese beiden <unk> um zu zeigen, dass die <unk>  die <unk>  die <unk>  mit <unk> <unk> <unk>
2023-05-25 20:08:20,974 - INFO - joeynmt.training - Example #1
2023-05-25 20:08:20,974 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:08:20,974 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:08:20,974 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', '<unk>', '<unk>', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:08:20,975 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:08:20,975 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:08:20,975 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> <unk> <unk>  weil es nicht die <unk> des <unk> <unk> <unk>
2023-05-25 20:08:20,975 - INFO - joeynmt.training - Example #2
2023-05-25 20:08:20,975 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:08:20,975 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:08:20,975 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:08:20,975 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:08:20,975 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:08:20,975 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk>
2023-05-25 20:08:20,975 - INFO - joeynmt.training - Example #3
2023-05-25 20:08:20,975 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:08:20,975 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:08:20,975 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'aus', 'der', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2023-05-25 20:08:20,975 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:08:20,975 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:08:20,975 - INFO - joeynmt.training - 	Hypothesis: Es <unk> aus der <unk> und <unk> in den <unk>
2023-05-25 20:08:20,975 - INFO - joeynmt.training - Example #4
2023-05-25 20:08:20,975 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:08:20,975 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:08:20,975 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'Ihnen', 'zeigen', '', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'der', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2023-05-25 20:08:20,975 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:08:20,975 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:08:20,976 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen Ihnen zeigen   ist eine <unk> Version von dem, was in der letzten 25 Jahren <unk>
2023-05-25 20:08:35,216 - INFO - joeynmt.training - Epoch   3, Step:     6100, Batch Loss:     1.595361, Batch Acc: 0.483211, Tokens per Sec:     4531, Lr: 0.000300
2023-05-25 20:08:48,731 - INFO - joeynmt.training - Epoch   3, Step:     6200, Batch Loss:     1.816540, Batch Acc: 0.479385, Tokens per Sec:     4834, Lr: 0.000300
2023-05-25 20:09:02,261 - INFO - joeynmt.training - Epoch   3, Step:     6300, Batch Loss:     1.739081, Batch Acc: 0.477775, Tokens per Sec:     4836, Lr: 0.000300
2023-05-25 20:09:15,325 - INFO - joeynmt.training - Epoch   3, Step:     6400, Batch Loss:     1.635602, Batch Acc: 0.479883, Tokens per Sec:     5030, Lr: 0.000300
2023-05-25 20:09:28,449 - INFO - joeynmt.training - Epoch   3, Step:     6500, Batch Loss:     1.727624, Batch Acc: 0.480865, Tokens per Sec:     5054, Lr: 0.000300
2023-05-25 20:09:28,450 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:09:28,450 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:09:46,479 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.99, ppl:   7.30, acc:   0.41, generation: 18.0246[sec], evaluation: 0.0000[sec]
2023-05-25 20:09:46,572 - INFO - joeynmt.helpers - delete models/transformer_model1/4000.ckpt
2023-05-25 20:09:46,577 - INFO - joeynmt.training - Example #0
2023-05-25 20:09:46,577 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:09:46,577 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:09:46,577 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahre', '<unk>', 'ich', 'diese', 'zwei', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', 'letzten', 'drei', 'Millionen', 'Jahren', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:09:46,578 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:09:46,578 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:09:46,578 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahre <unk> ich diese zwei <unk> <unk> um zu zeigen, dass die <unk>  die letzten drei Millionen Jahren <unk> <unk> <unk> <unk> <unk> <unk> <unk>
2023-05-25 20:09:46,578 - INFO - joeynmt.training - Example #1
2023-05-25 20:09:46,578 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:09:46,578 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:09:46,578 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'dieses', '<unk>', 'Problem', '<unk>', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2023-05-25 20:09:46,578 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:09:46,578 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:09:46,578 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> dieses <unk> Problem <unk>  weil es nicht die <unk> des <unk> <unk>
2023-05-25 20:09:46,578 - INFO - joeynmt.training - Example #2
2023-05-25 20:09:46,578 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:09:46,578 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:09:46,578 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', 'das', '<unk>', 'Herz', 'unserer', '<unk>', '<unk>', '</s>']
2023-05-25 20:09:46,578 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:09:46,578 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:09:46,578 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk>  das <unk> Herz unserer <unk> <unk>
2023-05-25 20:09:46,578 - INFO - joeynmt.training - Example #3
2023-05-25 20:09:46,578 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:09:46,578 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:09:46,578 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'aus', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2023-05-25 20:09:46,578 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:09:46,578 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:09:46,578 - INFO - joeynmt.training - 	Hypothesis: Es <unk> aus <unk> und <unk> in den <unk>
2023-05-25 20:09:46,578 - INFO - joeynmt.training - Example #4
2023-05-25 20:09:46,579 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:09:46,579 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:09:46,579 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'nächste', '<unk>', 'die', 'ich', 'sehen,', '', 'ist', 'ein', '<unk>', 'Version', 'von', '<unk>', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2023-05-25 20:09:46,579 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:09:46,579 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:09:46,579 - INFO - joeynmt.training - 	Hypothesis: Und die nächste <unk> die ich sehen,  ist ein <unk> Version von <unk> in den letzten 25 Jahren <unk>
2023-05-25 20:09:59,771 - INFO - joeynmt.training - Epoch   3, Step:     6600, Batch Loss:     1.841782, Batch Acc: 0.481182, Tokens per Sec:     4816, Lr: 0.000300
2023-05-25 20:10:13,050 - INFO - joeynmt.training - Epoch   3, Step:     6700, Batch Loss:     1.736020, Batch Acc: 0.479852, Tokens per Sec:     5046, Lr: 0.000300
2023-05-25 20:10:26,104 - INFO - joeynmt.training - Epoch   3, Step:     6800, Batch Loss:     1.734702, Batch Acc: 0.480890, Tokens per Sec:     4949, Lr: 0.000300
2023-05-25 20:10:39,796 - INFO - joeynmt.training - Epoch   3, Step:     6900, Batch Loss:     1.741174, Batch Acc: 0.479985, Tokens per Sec:     4770, Lr: 0.000300
2023-05-25 20:10:53,403 - INFO - joeynmt.training - Epoch   3, Step:     7000, Batch Loss:     1.554515, Batch Acc: 0.478810, Tokens per Sec:     4721, Lr: 0.000300
2023-05-25 20:10:53,404 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:10:53,404 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:11:12,258 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.93, ppl:   6.92, acc:   0.43, generation: 18.8493[sec], evaluation: 0.0000[sec]
2023-05-25 20:11:12,260 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-25 20:11:12,346 - INFO - joeynmt.helpers - delete models/transformer_model1/4500.ckpt
2023-05-25 20:11:12,350 - INFO - joeynmt.training - Example #0
2023-05-25 20:11:12,351 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:11:12,351 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:11:12,351 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahre', '<unk>', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', '<unk>', '<unk>', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:11:12,351 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:11:12,351 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:11:12,351 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahre <unk> ich diese beiden <unk> <unk> um zu zeigen, dass die <unk>  die <unk> <unk> die die letzten drei Millionen Jahre <unk> <unk> <unk>
2023-05-25 20:11:12,351 - INFO - joeynmt.training - Example #1
2023-05-25 20:11:12,351 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:11:12,351 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:11:12,351 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'dieses', '<unk>', 'Problem', '<unk>', '', 'denn', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2023-05-25 20:11:12,351 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:11:12,351 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:11:12,351 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> dieses <unk> Problem <unk>  denn es nicht die <unk> des <unk> <unk>
2023-05-25 20:11:12,351 - INFO - joeynmt.training - Example #2
2023-05-25 20:11:12,351 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:11:12,351 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:11:12,351 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '', 'der', '<unk>', '<unk>', '</s>']
2023-05-25 20:11:12,351 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:11:12,351 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:11:12,351 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk>  der <unk> <unk>
2023-05-25 20:11:12,351 - INFO - joeynmt.training - Example #3
2023-05-25 20:11:12,351 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:11:12,351 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:11:12,351 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'aus', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2023-05-25 20:11:12,352 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:11:12,352 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:11:12,352 - INFO - joeynmt.training - 	Hypothesis: Es <unk> aus <unk> und <unk> in der <unk>
2023-05-25 20:11:12,352 - INFO - joeynmt.training - Example #4
2023-05-25 20:11:12,352 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:11:12,352 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:11:12,352 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', '<unk>', 'sehen,', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'der', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2023-05-25 20:11:12,352 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:11:12,352 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:11:12,352 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich <unk> sehen,  ist eine <unk> Version von der letzten 25 Jahren <unk>
2023-05-25 20:11:26,282 - INFO - joeynmt.training - Epoch   3, Step:     7100, Batch Loss:     1.641015, Batch Acc: 0.481216, Tokens per Sec:     4704, Lr: 0.000300
2023-05-25 20:11:40,241 - INFO - joeynmt.training - Epoch   3, Step:     7200, Batch Loss:     1.630291, Batch Acc: 0.478039, Tokens per Sec:     4700, Lr: 0.000300
2023-05-25 20:11:54,043 - INFO - joeynmt.training - Epoch   3, Step:     7300, Batch Loss:     1.731262, Batch Acc: 0.482393, Tokens per Sec:     4848, Lr: 0.000300
2023-05-25 20:12:06,004 - INFO - joeynmt.training - Epoch   3: total training loss 4261.91
2023-05-25 20:12:06,006 - INFO - joeynmt.training - EPOCH 4
2023-05-25 20:12:08,169 - INFO - joeynmt.training - Epoch   4, Step:     7400, Batch Loss:     1.749542, Batch Acc: 0.508493, Tokens per Sec:     4628, Lr: 0.000300
2023-05-25 20:12:22,204 - INFO - joeynmt.training - Epoch   4, Step:     7500, Batch Loss:     1.513822, Batch Acc: 0.503887, Tokens per Sec:     4729, Lr: 0.000300
2023-05-25 20:12:22,204 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:12:22,204 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:12:48,965 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.94, ppl:   6.98, acc:   0.43, generation: 26.7543[sec], evaluation: 0.0000[sec]
2023-05-25 20:12:49,056 - INFO - joeynmt.helpers - delete models/transformer_model1/5000.ckpt
2023-05-25 20:12:49,061 - INFO - joeynmt.training - Example #0
2023-05-25 20:12:49,061 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:12:49,061 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:12:49,061 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahre', '<unk>', 'habe', 'ich', 'diese', 'zwei', '<unk>', '<unk>', 'um', '<unk>', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:12:49,061 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:12:49,061 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:12:49,061 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahre <unk> habe ich diese zwei <unk> <unk> um <unk> zu zeigen, dass die <unk>  die <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>
2023-05-25 20:12:49,061 - INFO - joeynmt.training - Example #1
2023-05-25 20:12:49,061 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:12:49,061 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:12:49,061 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'dieses', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2023-05-25 20:12:49,061 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:12:49,061 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:12:49,061 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> dieses <unk> <unk> <unk> <unk> <unk> weil es nicht die <unk> des <unk> <unk>
2023-05-25 20:12:49,061 - INFO - joeynmt.training - Example #2
2023-05-25 20:12:49,061 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:12:49,062 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:12:49,062 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:12:49,062 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:12:49,062 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:12:49,062 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk>
2023-05-25 20:12:49,062 - INFO - joeynmt.training - Example #3
2023-05-25 20:12:49,062 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:12:49,062 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:12:49,062 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'aus', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2023-05-25 20:12:49,062 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:12:49,062 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:12:49,062 - INFO - joeynmt.training - 	Hypothesis: Es <unk> aus der <unk> und <unk> in der <unk>
2023-05-25 20:12:49,062 - INFO - joeynmt.training - Example #4
2023-05-25 20:12:49,062 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:12:49,062 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:12:49,062 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', '<unk>', 'die', 'ich', '<unk>', '<unk>', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', 'ich', '<unk>', '<unk>', '</s>']
2023-05-25 20:12:49,062 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:12:49,062 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:12:49,062 - INFO - joeynmt.training - 	Hypothesis: <unk> <unk> die ich <unk> <unk> ist eine <unk> Version von dem ich <unk> <unk>
2023-05-25 20:13:02,124 - INFO - joeynmt.training - Epoch   4, Step:     7600, Batch Loss:     1.721455, Batch Acc: 0.500194, Tokens per Sec:     5090, Lr: 0.000300
2023-05-25 20:13:15,660 - INFO - joeynmt.training - Epoch   4, Step:     7700, Batch Loss:     1.534380, Batch Acc: 0.499609, Tokens per Sec:     4823, Lr: 0.000300
2023-05-25 20:13:29,525 - INFO - joeynmt.training - Epoch   4, Step:     7800, Batch Loss:     1.364600, Batch Acc: 0.499688, Tokens per Sec:     4741, Lr: 0.000300
2023-05-25 20:13:43,258 - INFO - joeynmt.training - Epoch   4, Step:     7900, Batch Loss:     1.616365, Batch Acc: 0.498330, Tokens per Sec:     4884, Lr: 0.000300
2023-05-25 20:13:57,420 - INFO - joeynmt.training - Epoch   4, Step:     8000, Batch Loss:     1.691230, Batch Acc: 0.494534, Tokens per Sec:     4664, Lr: 0.000300
2023-05-25 20:13:57,420 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:13:57,420 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:14:15,080 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.97, ppl:   7.14, acc:   0.42, generation: 17.6556[sec], evaluation: 0.0000[sec]
2023-05-25 20:14:15,165 - INFO - joeynmt.helpers - delete models/transformer_model1/6000.ckpt
2023-05-25 20:14:15,171 - INFO - joeynmt.training - Example #0
2023-05-25 20:14:15,171 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:14:15,171 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:14:15,171 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahre', '<unk>', 'habe', 'ich', 'diese', 'zwei', '<unk>', '<unk>', 'um', '', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:14:15,171 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:14:15,171 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:14:15,171 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahre <unk> habe ich diese zwei <unk> <unk> um  zu zeigen, dass die <unk>  die letzten drei Millionen Jahre <unk> <unk> <unk> <unk> <unk> <unk> <unk>
2023-05-25 20:14:15,171 - INFO - joeynmt.training - Example #1
2023-05-25 20:14:15,171 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:14:15,171 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:14:15,171 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '', 'denn', 'es', 'ist', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2023-05-25 20:14:15,171 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:14:15,171 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:14:15,171 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> <unk> <unk> <unk>  denn es ist nicht die <unk> des <unk> <unk>
2023-05-25 20:14:15,171 - INFO - joeynmt.training - Example #2
2023-05-25 20:14:15,171 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:14:15,171 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:14:15,171 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', 'das', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:14:15,172 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:14:15,172 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:14:15,172 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk>  das <unk> <unk> <unk>
2023-05-25 20:14:15,172 - INFO - joeynmt.training - Example #3
2023-05-25 20:14:15,172 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:14:15,172 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:14:15,172 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'aus', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2023-05-25 20:14:15,172 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:14:15,172 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:14:15,172 - INFO - joeynmt.training - 	Hypothesis: Es <unk> aus den <unk> und <unk> in den <unk>
2023-05-25 20:14:15,172 - INFO - joeynmt.training - Example #4
2023-05-25 20:14:15,172 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:14:15,172 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:14:15,172 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', '', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'vor', '25', 'Jahren', '<unk>', 'ist.', '</s>']
2023-05-25 20:14:15,172 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:14:15,172 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:14:15,172 - INFO - joeynmt.training - 	Hypothesis: Und die nächste <unk> die ich Ihnen zeigen   ist eine <unk> Version von dem, was vor 25 Jahren <unk> ist.
2023-05-25 20:14:30,516 - INFO - joeynmt.training - Epoch   4, Step:     8100, Batch Loss:     1.672853, Batch Acc: 0.489960, Tokens per Sec:     4133, Lr: 0.000300
2023-05-25 20:14:45,078 - INFO - joeynmt.training - Epoch   4, Step:     8200, Batch Loss:     1.648430, Batch Acc: 0.495201, Tokens per Sec:     4601, Lr: 0.000300
2023-05-25 20:14:58,857 - INFO - joeynmt.training - Epoch   4, Step:     8300, Batch Loss:     1.602237, Batch Acc: 0.494928, Tokens per Sec:     4750, Lr: 0.000300
2023-05-25 20:15:12,408 - INFO - joeynmt.training - Epoch   4, Step:     8400, Batch Loss:     1.662076, Batch Acc: 0.493998, Tokens per Sec:     4783, Lr: 0.000300
2023-05-25 20:15:26,176 - INFO - joeynmt.training - Epoch   4, Step:     8500, Batch Loss:     1.701622, Batch Acc: 0.498657, Tokens per Sec:     4815, Lr: 0.000300
2023-05-25 20:15:26,178 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:15:26,178 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:15:46,115 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.96, ppl:   7.07, acc:   0.43, generation: 19.9321[sec], evaluation: 0.0000[sec]
2023-05-25 20:15:46,204 - INFO - joeynmt.helpers - delete models/transformer_model1/6500.ckpt
2023-05-25 20:15:46,207 - INFO - joeynmt.training - Example #0
2023-05-25 20:15:46,207 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:15:46,207 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:15:46,207 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahre', '<unk>', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:15:46,207 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:15:46,208 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:15:46,208 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahre <unk> ich diese beiden <unk> <unk> um zu zeigen, dass die <unk>  die letzten drei Millionen Jahre <unk> <unk> <unk>
2023-05-25 20:15:46,208 - INFO - joeynmt.training - Example #1
2023-05-25 20:15:46,208 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:15:46,208 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:15:46,208 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'dieses', '<unk>', 'Problem', 'der', '<unk>', '<unk>', '', 'denn', 'es', 'ist', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2023-05-25 20:15:46,208 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:15:46,208 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:15:46,208 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> dieses <unk> Problem der <unk> <unk>  denn es ist nicht die <unk> des <unk> <unk>
2023-05-25 20:15:46,208 - INFO - joeynmt.training - Example #2
2023-05-25 20:15:46,208 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:15:46,208 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:15:46,208 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '', 'das', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:15:46,208 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:15:46,208 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:15:46,208 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk>  das <unk> <unk> <unk>
2023-05-25 20:15:46,208 - INFO - joeynmt.training - Example #3
2023-05-25 20:15:46,208 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:15:46,208 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:15:46,208 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'aus', 'dem', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2023-05-25 20:15:46,208 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:15:46,208 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:15:46,208 - INFO - joeynmt.training - 	Hypothesis: Es <unk> aus dem <unk> und <unk> in der <unk>
2023-05-25 20:15:46,208 - INFO - joeynmt.training - Example #4
2023-05-25 20:15:46,208 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:15:46,208 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:15:46,208 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', '<unk>', '', 'ist', 'eine', '<unk>', 'Version', 'von', '<unk>', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2023-05-25 20:15:46,209 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:15:46,209 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:15:46,209 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen <unk>  ist eine <unk> Version von <unk> was in den letzten 25 Jahren <unk>
2023-05-25 20:16:00,232 - INFO - joeynmt.training - Epoch   4, Step:     8600, Batch Loss:     1.642370, Batch Acc: 0.491167, Tokens per Sec:     4704, Lr: 0.000300
2023-05-25 20:16:14,601 - INFO - joeynmt.training - Epoch   4, Step:     8700, Batch Loss:     1.707874, Batch Acc: 0.492347, Tokens per Sec:     4507, Lr: 0.000300
2023-05-25 20:16:28,521 - INFO - joeynmt.training - Epoch   4, Step:     8800, Batch Loss:     1.637857, Batch Acc: 0.491379, Tokens per Sec:     4850, Lr: 0.000300
2023-05-25 20:16:43,007 - INFO - joeynmt.training - Epoch   4, Step:     8900, Batch Loss:     1.694156, Batch Acc: 0.495231, Tokens per Sec:     4560, Lr: 0.000300
2023-05-25 20:16:56,826 - INFO - joeynmt.training - Epoch   4, Step:     9000, Batch Loss:     1.533741, Batch Acc: 0.498680, Tokens per Sec:     4660, Lr: 0.000300
2023-05-25 20:16:56,827 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:16:56,827 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:17:16,502 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.92, ppl:   6.80, acc:   0.43, generation: 19.6707[sec], evaluation: 0.0000[sec]
2023-05-25 20:17:16,503 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-25 20:17:16,588 - INFO - joeynmt.helpers - delete models/transformer_model1/5500.ckpt
2023-05-25 20:17:16,591 - INFO - joeynmt.training - Example #0
2023-05-25 20:17:16,591 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:17:16,591 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:17:16,591 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahre', '<unk>', 'habe', 'ich', 'diese', 'zwei', '<unk>', '<unk>', 'um', '<unk>', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:17:16,591 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:17:16,591 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:17:16,591 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahre <unk> habe ich diese zwei <unk> <unk> um <unk> zu zeigen, dass die <unk>  die letzten drei Millionen Jahre <unk> <unk> <unk>
2023-05-25 20:17:16,591 - INFO - joeynmt.training - Example #1
2023-05-25 20:17:16,591 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:17:16,591 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:17:16,591 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'dieses', '<unk>', 'Problem', 'der', '<unk>', '<unk>', '<unk>', '<unk>', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2023-05-25 20:17:16,592 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:17:16,592 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:17:16,592 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> dieses <unk> Problem der <unk> <unk> <unk> <unk> weil es nicht die <unk> des <unk> <unk>
2023-05-25 20:17:16,592 - INFO - joeynmt.training - Example #2
2023-05-25 20:17:16,592 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:17:16,592 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:17:16,592 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:17:16,592 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:17:16,592 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:17:16,592 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk> <unk>
2023-05-25 20:17:16,592 - INFO - joeynmt.training - Example #3
2023-05-25 20:17:16,592 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:17:16,592 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:17:16,592 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2023-05-25 20:17:16,592 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:17:16,592 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:17:16,592 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2023-05-25 20:17:16,592 - INFO - joeynmt.training - Example #4
2023-05-25 20:17:16,592 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:17:16,592 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:17:16,592 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', '<unk>', '<unk>', '<unk>', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2023-05-25 20:17:16,592 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:17:16,592 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:17:16,592 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich <unk> <unk> <unk> ist eine <unk> Version von dem, was in den letzten 25 Jahren <unk>
2023-05-25 20:17:30,665 - INFO - joeynmt.training - Epoch   4, Step:     9100, Batch Loss:     1.688223, Batch Acc: 0.491753, Tokens per Sec:     4624, Lr: 0.000300
2023-05-25 20:17:44,820 - INFO - joeynmt.training - Epoch   4, Step:     9200, Batch Loss:     1.612306, Batch Acc: 0.493306, Tokens per Sec:     4597, Lr: 0.000300
2023-05-25 20:17:58,572 - INFO - joeynmt.training - Epoch   4, Step:     9300, Batch Loss:     1.621184, Batch Acc: 0.498676, Tokens per Sec:     4696, Lr: 0.000300
2023-05-25 20:18:12,378 - INFO - joeynmt.training - Epoch   4, Step:     9400, Batch Loss:     1.787174, Batch Acc: 0.491855, Tokens per Sec:     4651, Lr: 0.000300
2023-05-25 20:18:26,104 - INFO - joeynmt.training - Epoch   4, Step:     9500, Batch Loss:     1.569453, Batch Acc: 0.490358, Tokens per Sec:     4719, Lr: 0.000300
2023-05-25 20:18:26,104 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:18:26,104 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:18:53,086 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.93, ppl:   6.90, acc:   0.43, generation: 26.9767[sec], evaluation: 0.0000[sec]
2023-05-25 20:18:53,180 - INFO - joeynmt.helpers - delete models/transformer_model1/8000.ckpt
2023-05-25 20:18:53,187 - INFO - joeynmt.training - Example #0
2023-05-25 20:18:53,187 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:18:53,187 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:18:53,187 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahre', '<unk>', 'habe', 'ich', 'diese', 'zwei', '<unk>', 'um', '<unk>', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', 'die', 'letzten', 'drei', 'Millionen', 'Jahren', '<unk>', '', 'ungefähr', 'die', 'Größe', 'des', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:18:53,187 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:18:53,187 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:18:53,187 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahre <unk> habe ich diese zwei <unk> um <unk> zu zeigen, dass die <unk>  die die letzten drei Millionen Jahren <unk>  ungefähr die Größe des <unk> <unk> <unk> <unk>
2023-05-25 20:18:53,187 - INFO - joeynmt.training - Example #1
2023-05-25 20:18:53,187 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:18:53,187 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:18:53,187 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'tatsächlich', 'die', '<unk>', 'dieses', '<unk>', 'Problem', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2023-05-25 20:18:53,187 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:18:53,187 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:18:53,187 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> tatsächlich die <unk> dieses <unk> Problem  weil es nicht die <unk> des <unk> <unk>
2023-05-25 20:18:53,187 - INFO - joeynmt.training - Example #2
2023-05-25 20:18:53,187 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:18:53,187 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:18:53,187 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', 'das', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:18:53,188 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:18:53,188 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:18:53,188 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk>  das <unk> <unk> <unk>
2023-05-25 20:18:53,188 - INFO - joeynmt.training - Example #3
2023-05-25 20:18:53,188 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:18:53,188 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:18:53,188 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2023-05-25 20:18:53,188 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:18:53,188 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:18:53,188 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2023-05-25 20:18:53,188 - INFO - joeynmt.training - Example #4
2023-05-25 20:18:53,188 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:18:53,188 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:18:53,188 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', '', '', 'ist', 'ein', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', 'ist.', '</s>']
2023-05-25 20:18:53,188 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:18:53,188 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:18:53,188 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen zeigen   ist ein <unk> Version von dem, was in den letzten 25 Jahren <unk> ist.
2023-05-25 20:19:07,351 - INFO - joeynmt.training - Epoch   4, Step:     9600, Batch Loss:     1.609563, Batch Acc: 0.496509, Tokens per Sec:     4689, Lr: 0.000300
2023-05-25 20:19:21,249 - INFO - joeynmt.training - Epoch   4, Step:     9700, Batch Loss:     1.680610, Batch Acc: 0.496717, Tokens per Sec:     4855, Lr: 0.000300
2023-05-25 20:19:34,969 - INFO - joeynmt.training - Epoch   4, Step:     9800, Batch Loss:     1.695712, Batch Acc: 0.494167, Tokens per Sec:     4812, Lr: 0.000300
2023-05-25 20:19:40,968 - INFO - joeynmt.training - Epoch   4: total training loss 4082.05
2023-05-25 20:19:40,968 - INFO - joeynmt.training - EPOCH 5
2023-05-25 20:19:48,445 - INFO - joeynmt.training - Epoch   5, Step:     9900, Batch Loss:     1.596003, Batch Acc: 0.512378, Tokens per Sec:     4793, Lr: 0.000300
2023-05-25 20:20:01,982 - INFO - joeynmt.training - Epoch   5, Step:    10000, Batch Loss:     1.682286, Batch Acc: 0.512555, Tokens per Sec:     4866, Lr: 0.000300
2023-05-25 20:20:01,982 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:20:01,983 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:20:24,508 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.94, ppl:   6.96, acc:   0.42, generation: 22.5204[sec], evaluation: 0.0000[sec]
2023-05-25 20:20:24,597 - INFO - joeynmt.helpers - delete models/transformer_model1/8500.ckpt
2023-05-25 20:20:24,601 - INFO - joeynmt.training - Example #0
2023-05-25 20:20:24,601 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:20:24,601 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:20:24,601 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahre', '<unk>', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', '<unk>', 'die', 'die', '<unk>', 'drei', 'Millionen', 'Jahre', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:20:24,601 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:20:24,601 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:20:24,601 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahre <unk> ich diese beiden <unk> <unk> um zu zeigen, dass die <unk>  die <unk> die die <unk> drei Millionen Jahre <unk> <unk> <unk> <unk>
2023-05-25 20:20:24,601 - INFO - joeynmt.training - Example #1
2023-05-25 20:20:24,601 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:20:24,601 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:20:24,601 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'die', '<unk>', 'dieses', '<unk>', '<unk>', '', 'Denn', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '</s>']
2023-05-25 20:20:24,602 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:20:24,602 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:20:24,602 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> die <unk> dieses <unk> <unk>  Denn es nicht die <unk> des <unk>
2023-05-25 20:20:24,602 - INFO - joeynmt.training - Example #2
2023-05-25 20:20:24,602 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:20:24,602 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:20:24,602 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', 'das', '<unk>', 'Herz', 'unserer', '<unk>', '</s>']
2023-05-25 20:20:24,602 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:20:24,602 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:20:24,602 - INFO - joeynmt.training - 	Hypothesis: Der <unk> auf der <unk> ist in <unk> <unk>  das <unk> Herz unserer <unk>
2023-05-25 20:20:24,602 - INFO - joeynmt.training - Example #3
2023-05-25 20:20:24,602 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:20:24,602 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:20:24,602 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2023-05-25 20:20:24,602 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:20:24,602 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:20:24,602 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2023-05-25 20:20:24,602 - INFO - joeynmt.training - Example #4
2023-05-25 20:20:24,602 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:20:24,602 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:20:24,602 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', '<unk>', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', 'wir', 'in', 'den', 'letzten', '25', 'Jahre', '<unk>', '</s>']
2023-05-25 20:20:24,602 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:20:24,602 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:20:24,603 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen <unk>  ist eine <unk> Version von dem wir in den letzten 25 Jahre <unk>
2023-05-25 20:20:38,545 - INFO - joeynmt.training - Epoch   5, Step:    10100, Batch Loss:     1.541087, Batch Acc: 0.512459, Tokens per Sec:     4681, Lr: 0.000300
2023-05-25 20:20:52,553 - INFO - joeynmt.training - Epoch   5, Step:    10200, Batch Loss:     1.543097, Batch Acc: 0.514068, Tokens per Sec:     4679, Lr: 0.000300
2023-05-25 20:21:06,638 - INFO - joeynmt.training - Epoch   5, Step:    10300, Batch Loss:     1.537784, Batch Acc: 0.513766, Tokens per Sec:     4691, Lr: 0.000300
2023-05-25 20:21:20,508 - INFO - joeynmt.training - Epoch   5, Step:    10400, Batch Loss:     1.569343, Batch Acc: 0.509017, Tokens per Sec:     4834, Lr: 0.000300
2023-05-25 20:21:34,544 - INFO - joeynmt.training - Epoch   5, Step:    10500, Batch Loss:     1.557938, Batch Acc: 0.511856, Tokens per Sec:     4826, Lr: 0.000300
2023-05-25 20:21:34,545 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:21:34,545 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:21:52,224 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.92, ppl:   6.84, acc:   0.43, generation: 17.6745[sec], evaluation: 0.0000[sec]
2023-05-25 20:21:52,306 - INFO - joeynmt.helpers - delete models/transformer_model1/7500.ckpt
2023-05-25 20:21:52,313 - INFO - joeynmt.training - Example #0
2023-05-25 20:21:52,313 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:21:52,313 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:21:52,313 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahre', '<unk>', 'ich', 'diese', 'beiden', '<unk>', 'um', '', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:21:52,313 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:21:52,313 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:21:52,314 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahre <unk> ich diese beiden <unk> um  zu zeigen, dass die <unk>  die letzten drei Millionen Jahre <unk> <unk> <unk>
2023-05-25 20:21:52,314 - INFO - joeynmt.training - Example #1
2023-05-25 20:21:52,314 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:21:52,314 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:21:52,314 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'die', '<unk>', 'dieses', '<unk>', 'Problem', '', 'denn', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '</s>']
2023-05-25 20:21:52,314 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:21:52,314 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:21:52,314 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> die <unk> dieses <unk> Problem  denn es nicht die <unk> des <unk>
2023-05-25 20:21:52,314 - INFO - joeynmt.training - Example #2
2023-05-25 20:21:52,314 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:21:52,314 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:21:52,314 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:21:52,314 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:21:52,314 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:21:52,314 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk> <unk>
2023-05-25 20:21:52,314 - INFO - joeynmt.training - Example #3
2023-05-25 20:21:52,314 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:21:52,314 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:21:52,314 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2023-05-25 20:21:52,314 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:21:52,314 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:21:52,314 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2023-05-25 20:21:52,314 - INFO - joeynmt.training - Example #4
2023-05-25 20:21:52,314 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:21:52,314 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:21:52,314 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', '<unk>', '', 'ist', 'eine', '<unk>', 'Version', 'von', '<unk>', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2023-05-25 20:21:52,315 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:21:52,315 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:21:52,315 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen <unk>  ist eine <unk> Version von <unk> was in den letzten 25 Jahren <unk>
2023-05-25 20:22:06,519 - INFO - joeynmt.training - Epoch   5, Step:    10600, Batch Loss:     1.625235, Batch Acc: 0.508716, Tokens per Sec:     4511, Lr: 0.000300
2023-05-25 20:22:20,544 - INFO - joeynmt.training - Epoch   5, Step:    10700, Batch Loss:     1.608538, Batch Acc: 0.503737, Tokens per Sec:     4704, Lr: 0.000300
2023-05-25 20:22:34,916 - INFO - joeynmt.training - Epoch   5, Step:    10800, Batch Loss:     1.570930, Batch Acc: 0.506943, Tokens per Sec:     4565, Lr: 0.000300
2023-05-25 20:22:49,376 - INFO - joeynmt.training - Epoch   5, Step:    10900, Batch Loss:     1.699772, Batch Acc: 0.507554, Tokens per Sec:     4568, Lr: 0.000300
2023-05-25 20:23:03,536 - INFO - joeynmt.training - Epoch   5, Step:    11000, Batch Loss:     1.420163, Batch Acc: 0.512296, Tokens per Sec:     4787, Lr: 0.000300
2023-05-25 20:23:03,536 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:23:03,536 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:23:24,129 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.95, ppl:   7.04, acc:   0.42, generation: 20.5886[sec], evaluation: 0.0000[sec]
2023-05-25 20:23:24,131 - INFO - joeynmt.training - Example #0
2023-05-25 20:23:24,131 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:23:24,131 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:23:24,131 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahre', '<unk>', 'habe', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', '<unk>', '', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', '<unk>', '<unk>', '<unk>', '<unk>', '', 'mit', '<unk>', '<unk>', '</s>']
2023-05-25 20:23:24,131 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:23:24,131 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:23:24,131 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahre <unk> habe ich diese beiden <unk> <unk> um <unk>  zu zeigen, dass die <unk>  die in den letzten drei Millionen Jahren <unk> <unk> <unk> <unk>  mit <unk> <unk>
2023-05-25 20:23:24,131 - INFO - joeynmt.training - Example #1
2023-05-25 20:23:24,132 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:23:24,132 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:23:24,132 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'dieses', '<unk>', 'Problem', '', 'denn', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2023-05-25 20:23:24,132 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:23:24,132 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:23:24,132 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> dieses <unk> Problem  denn es nicht die <unk> des <unk> <unk>
2023-05-25 20:23:24,132 - INFO - joeynmt.training - Example #2
2023-05-25 20:23:24,132 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:23:24,132 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:23:24,132 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:23:24,132 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:23:24,132 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:23:24,132 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk> <unk>
2023-05-25 20:23:24,132 - INFO - joeynmt.training - Example #3
2023-05-25 20:23:24,132 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:23:24,132 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:23:24,132 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2023-05-25 20:23:24,132 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:23:24,132 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:23:24,132 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2023-05-25 20:23:24,133 - INFO - joeynmt.training - Example #4
2023-05-25 20:23:24,133 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:23:24,133 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:23:24,133 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', '<unk>', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', 'ist.', '</s>']
2023-05-25 20:23:24,133 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:23:24,133 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:23:24,133 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich <unk>  ist eine <unk> Version von dem, was in den letzten 25 Jahren <unk> ist.
2023-05-25 20:23:38,147 - INFO - joeynmt.training - Epoch   5, Step:    11100, Batch Loss:     1.693509, Batch Acc: 0.504110, Tokens per Sec:     4800, Lr: 0.000300
2023-05-25 20:23:52,161 - INFO - joeynmt.training - Epoch   5, Step:    11200, Batch Loss:     1.590925, Batch Acc: 0.508000, Tokens per Sec:     4706, Lr: 0.000300
2023-05-25 20:24:06,050 - INFO - joeynmt.training - Epoch   5, Step:    11300, Batch Loss:     1.746717, Batch Acc: 0.508761, Tokens per Sec:     4718, Lr: 0.000300
2023-05-25 20:24:20,303 - INFO - joeynmt.training - Epoch   5, Step:    11400, Batch Loss:     1.578772, Batch Acc: 0.507416, Tokens per Sec:     4551, Lr: 0.000300
2023-05-25 20:24:34,470 - INFO - joeynmt.training - Epoch   5, Step:    11500, Batch Loss:     1.639118, Batch Acc: 0.500578, Tokens per Sec:     4705, Lr: 0.000300
2023-05-25 20:24:34,471 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:24:34,471 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:24:54,261 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.90, ppl:   6.67, acc:   0.43, generation: 19.7855[sec], evaluation: 0.0000[sec]
2023-05-25 20:24:54,262 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-25 20:24:54,354 - INFO - joeynmt.helpers - delete models/transformer_model1/10000.ckpt
2023-05-25 20:24:54,361 - INFO - joeynmt.training - Example #0
2023-05-25 20:24:54,361 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:24:54,362 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:24:54,362 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'der', '<unk>', '', 'die', 'in', 'drei', 'Millionen', 'Jahren', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:24:54,362 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:24:54,362 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:24:54,362 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese beiden <unk> <unk> um zu zeigen, dass der <unk>  die in drei Millionen Jahren <unk> <unk> <unk> <unk> <unk>
2023-05-25 20:24:54,362 - INFO - joeynmt.training - Example #1
2023-05-25 20:24:54,362 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:24:54,362 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:24:54,362 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'tatsächlich', 'die', '<unk>', 'dieses', '<unk>', 'Problem', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2023-05-25 20:24:54,362 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:24:54,362 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:24:54,362 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> tatsächlich die <unk> dieses <unk> Problem  weil es nicht die <unk> des <unk> <unk>
2023-05-25 20:24:54,362 - INFO - joeynmt.training - Example #2
2023-05-25 20:24:54,362 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:24:54,362 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:24:54,362 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:24:54,362 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:24:54,362 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:24:54,362 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk> <unk> <unk>
2023-05-25 20:24:54,362 - INFO - joeynmt.training - Example #3
2023-05-25 20:24:54,362 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:24:54,362 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:24:54,362 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2023-05-25 20:24:54,363 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:24:54,363 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:24:54,363 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2023-05-25 20:24:54,363 - INFO - joeynmt.training - Example #4
2023-05-25 20:24:54,363 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:24:54,363 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:24:54,363 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', '', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'denen', 'es', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2023-05-25 20:24:54,363 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:24:54,363 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:24:54,363 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen zeigen   ist eine <unk> Version von denen es in den letzten 25 Jahren <unk>
2023-05-25 20:25:09,320 - INFO - joeynmt.training - Epoch   5, Step:    11600, Batch Loss:     1.622270, Batch Acc: 0.503083, Tokens per Sec:     4395, Lr: 0.000300
2023-05-25 20:25:23,491 - INFO - joeynmt.training - Epoch   5, Step:    11700, Batch Loss:     1.769922, Batch Acc: 0.507288, Tokens per Sec:     4624, Lr: 0.000300
2023-05-25 20:25:37,519 - INFO - joeynmt.training - Epoch   5, Step:    11800, Batch Loss:     1.756005, Batch Acc: 0.503612, Tokens per Sec:     4579, Lr: 0.000300
2023-05-25 20:25:51,659 - INFO - joeynmt.training - Epoch   5, Step:    11900, Batch Loss:     1.583657, Batch Acc: 0.505917, Tokens per Sec:     4745, Lr: 0.000300
2023-05-25 20:26:05,620 - INFO - joeynmt.training - Epoch   5, Step:    12000, Batch Loss:     1.656373, Batch Acc: 0.501858, Tokens per Sec:     4569, Lr: 0.000300
2023-05-25 20:26:05,621 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:26:05,621 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:26:26,434 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.92, ppl:   6.85, acc:   0.43, generation: 20.8080[sec], evaluation: 0.0000[sec]
2023-05-25 20:26:26,528 - INFO - joeynmt.helpers - delete models/transformer_model1/7000.ckpt
2023-05-25 20:26:26,533 - INFO - joeynmt.training - Example #0
2023-05-25 20:26:26,533 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:26:26,533 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:26:26,533 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'zwei', '<unk>', '<unk>', 'um', '<unk>', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', '', '<unk>', '<unk>', '</s>']
2023-05-25 20:26:26,533 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:26:26,533 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:26:26,533 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese zwei <unk> <unk> um <unk> zu zeigen, dass die <unk>  die letzten drei Millionen Jahre <unk>  <unk> <unk>
2023-05-25 20:26:26,533 - INFO - joeynmt.training - Example #1
2023-05-25 20:26:26,533 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:26:26,533 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:26:26,533 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'dieses', '<unk>', 'Problem', '', 'denn', 'es', 'ist', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2023-05-25 20:26:26,534 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:26:26,534 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:26:26,534 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> dieses <unk> Problem  denn es ist nicht die <unk> des <unk> <unk>
2023-05-25 20:26:26,534 - INFO - joeynmt.training - Example #2
2023-05-25 20:26:26,534 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:26:26,534 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:26:26,534 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:26:26,534 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:26:26,534 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:26:26,534 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk>
2023-05-25 20:26:26,534 - INFO - joeynmt.training - Example #3
2023-05-25 20:26:26,534 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:26:26,534 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:26:26,534 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2023-05-25 20:26:26,534 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:26:26,534 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:26:26,534 - INFO - joeynmt.training - 	Hypothesis: Es <unk> <unk> in den <unk> und <unk> in der <unk>
2023-05-25 20:26:26,534 - INFO - joeynmt.training - Example #4
2023-05-25 20:26:26,534 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:26:26,534 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:26:26,534 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'nächsten', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2023-05-25 20:26:26,534 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:26:26,535 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:26:26,535 - INFO - joeynmt.training - 	Hypothesis: Der nächsten <unk> die ich Ihnen zeigen  ist eine <unk> Version von dem, was in den letzten 25 Jahren <unk>
2023-05-25 20:26:41,385 - INFO - joeynmt.training - Epoch   5, Step:    12100, Batch Loss:     1.653746, Batch Acc: 0.508099, Tokens per Sec:     4476, Lr: 0.000300
2023-05-25 20:26:55,450 - INFO - joeynmt.training - Epoch   5, Step:    12200, Batch Loss:     1.632155, Batch Acc: 0.499180, Tokens per Sec:     4597, Lr: 0.000300
2023-05-25 20:27:09,918 - INFO - joeynmt.training - Epoch   5, Step:    12300, Batch Loss:     1.708466, Batch Acc: 0.502799, Tokens per Sec:     4507, Lr: 0.000300
2023-05-25 20:27:09,918 - INFO - joeynmt.training - Epoch   5: total training loss 3944.44
2023-05-25 20:27:09,919 - INFO - joeynmt.training - EPOCH 6
2023-05-25 20:27:24,341 - INFO - joeynmt.training - Epoch   6, Step:    12400, Batch Loss:     1.641426, Batch Acc: 0.523509, Tokens per Sec:     4520, Lr: 0.000300
2023-05-25 20:27:38,780 - INFO - joeynmt.training - Epoch   6, Step:    12500, Batch Loss:     1.541710, Batch Acc: 0.522515, Tokens per Sec:     4439, Lr: 0.000300
2023-05-25 20:27:38,781 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:27:38,781 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:28:02,790 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.93, ppl:   6.90, acc:   0.43, generation: 24.0035[sec], evaluation: 0.0000[sec]
2023-05-25 20:28:02,877 - INFO - joeynmt.helpers - delete models/transformer_model1/9500.ckpt
2023-05-25 20:28:02,883 - INFO - joeynmt.training - Example #0
2023-05-25 20:28:02,883 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:28:02,883 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:28:02,883 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', '<unk>', 'die', '<unk>', '<unk>', '<unk>', '<unk>', '', '<unk>', '</s>']
2023-05-25 20:28:02,883 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:28:02,883 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:28:02,883 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese beiden <unk> <unk> um zu zeigen, dass die <unk>  die <unk> die <unk> <unk> <unk> <unk>  <unk>
2023-05-25 20:28:02,883 - INFO - joeynmt.training - Example #1
2023-05-25 20:28:02,883 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:28:02,883 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:28:02,883 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'dieses', '<unk>', '<unk>', 'dieses', '<unk>', 'Problem', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2023-05-25 20:28:02,883 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:28:02,883 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:28:02,883 - INFO - joeynmt.training - 	Hypothesis: Aber dieses <unk> <unk> dieses <unk> Problem  weil es nicht die <unk> des <unk> <unk>
2023-05-25 20:28:02,883 - INFO - joeynmt.training - Example #2
2023-05-25 20:28:02,883 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:28:02,883 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:28:02,883 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', 'das', '<unk>', '<unk>', '</s>']
2023-05-25 20:28:02,884 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:28:02,884 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:28:02,884 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk>  das <unk> <unk>
2023-05-25 20:28:02,884 - INFO - joeynmt.training - Example #3
2023-05-25 20:28:02,884 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:28:02,884 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:28:02,884 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2023-05-25 20:28:02,884 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:28:02,884 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:28:02,884 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in der <unk> und <unk> in der <unk>
2023-05-25 20:28:02,884 - INFO - joeynmt.training - Example #4
2023-05-25 20:28:02,884 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:28:02,884 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:28:02,884 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', 'ist.', '</s>']
2023-05-25 20:28:02,884 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:28:02,884 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:28:02,884 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen zeigen  ist eine <unk> Version von dem, was in den letzten 25 Jahren <unk> ist.
2023-05-25 20:28:17,338 - INFO - joeynmt.training - Epoch   6, Step:    12600, Batch Loss:     1.497777, Batch Acc: 0.517754, Tokens per Sec:     4599, Lr: 0.000300
2023-05-25 20:28:31,830 - INFO - joeynmt.training - Epoch   6, Step:    12700, Batch Loss:     1.636791, Batch Acc: 0.522873, Tokens per Sec:     4603, Lr: 0.000300
2023-05-25 20:28:45,745 - INFO - joeynmt.training - Epoch   6, Step:    12800, Batch Loss:     1.521533, Batch Acc: 0.524889, Tokens per Sec:     4644, Lr: 0.000300
2023-05-25 20:28:59,385 - INFO - joeynmt.training - Epoch   6, Step:    12900, Batch Loss:     1.614856, Batch Acc: 0.520239, Tokens per Sec:     4680, Lr: 0.000300
2023-05-25 20:29:13,244 - INFO - joeynmt.training - Epoch   6, Step:    13000, Batch Loss:     1.487694, Batch Acc: 0.523558, Tokens per Sec:     4740, Lr: 0.000300
2023-05-25 20:29:13,245 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:29:13,245 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:29:31,642 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.91, ppl:   6.74, acc:   0.43, generation: 18.3921[sec], evaluation: 0.0000[sec]
2023-05-25 20:29:31,735 - INFO - joeynmt.helpers - delete models/transformer_model1/12500.ckpt
2023-05-25 20:29:31,739 - INFO - joeynmt.helpers - delete /Users/cyril/Desktop/krizzzzi/mt-exercise-5/models/transformer_model1/12500.ckpt
2023-05-25 20:29:31,739 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /Users/cyril/Desktop/krizzzzi/mt-exercise-5/models/transformer_model1/12500.ckpt but file does not exist. ([Errno 2] No such file or directory: '/Users/cyril/Desktop/krizzzzi/mt-exercise-5/models/transformer_model1/12500.ckpt')
2023-05-25 20:29:31,740 - INFO - joeynmt.training - Example #0
2023-05-25 20:29:31,740 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:29:31,740 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:29:31,740 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahre', '<unk>', 'ich', 'diese', 'beiden', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:29:31,740 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:29:31,740 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:29:31,740 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahre <unk> ich diese beiden <unk> <unk> <unk> <unk>
2023-05-25 20:29:31,740 - INFO - joeynmt.training - Example #1
2023-05-25 20:29:31,740 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:29:31,740 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:29:31,740 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'tatsächlich', 'die', '<unk>', 'dieses', '<unk>', 'Problem', '<unk>', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2023-05-25 20:29:31,740 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:29:31,740 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:29:31,740 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> tatsächlich die <unk> dieses <unk> Problem <unk>  weil es nicht die <unk> des <unk> <unk>
2023-05-25 20:29:31,740 - INFO - joeynmt.training - Example #2
2023-05-25 20:29:31,740 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:29:31,740 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:29:31,740 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:29:31,740 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:29:31,740 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:29:31,740 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk> <unk> <unk>
2023-05-25 20:29:31,741 - INFO - joeynmt.training - Example #3
2023-05-25 20:29:31,741 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:29:31,741 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:29:31,741 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2023-05-25 20:29:31,741 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:29:31,741 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:29:31,741 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in der <unk> und <unk> in der <unk>
2023-05-25 20:29:31,741 - INFO - joeynmt.training - Example #4
2023-05-25 20:29:31,741 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:29:31,741 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:29:31,741 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2023-05-25 20:29:31,741 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:29:31,741 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:29:31,741 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen zeigen  ist eine <unk> Version von dem, was in den letzten 25 Jahren <unk>
2023-05-25 20:29:45,485 - INFO - joeynmt.training - Epoch   6, Step:    13100, Batch Loss:     1.530649, Batch Acc: 0.520196, Tokens per Sec:     4707, Lr: 0.000300
2023-05-25 20:29:59,312 - INFO - joeynmt.training - Epoch   6, Step:    13200, Batch Loss:     1.533152, Batch Acc: 0.516975, Tokens per Sec:     4764, Lr: 0.000300
2023-05-25 20:30:13,918 - INFO - joeynmt.training - Epoch   6, Step:    13300, Batch Loss:     1.656287, Batch Acc: 0.521657, Tokens per Sec:     4657, Lr: 0.000300
2023-05-25 20:30:28,094 - INFO - joeynmt.training - Epoch   6, Step:    13400, Batch Loss:     1.725030, Batch Acc: 0.515247, Tokens per Sec:     4447, Lr: 0.000300
2023-05-25 20:30:42,061 - INFO - joeynmt.training - Epoch   6, Step:    13500, Batch Loss:     1.580255, Batch Acc: 0.515902, Tokens per Sec:     4908, Lr: 0.000300
2023-05-25 20:30:42,061 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:30:42,061 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:31:03,004 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.91, ppl:   6.73, acc:   0.43, generation: 20.9377[sec], evaluation: 0.0000[sec]
2023-05-25 20:31:03,088 - INFO - joeynmt.helpers - delete models/transformer_model1/12000.ckpt
2023-05-25 20:31:03,091 - INFO - joeynmt.training - Example #0
2023-05-25 20:31:03,091 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:31:03,092 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:31:03,092 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'zwei', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', '<unk>', '', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', '<unk>', '<unk>', '</s>']
2023-05-25 20:31:03,092 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:31:03,092 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:31:03,092 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese zwei <unk> <unk> um zu zeigen, dass die <unk>  die <unk>  die in den letzten drei Millionen Jahren <unk> <unk>
2023-05-25 20:31:03,092 - INFO - joeynmt.training - Example #1
2023-05-25 20:31:03,092 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:31:03,092 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:31:03,092 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'der', '<unk>', 'dieses', '<unk>', 'Problem', '', 'denn', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '</s>']
2023-05-25 20:31:03,092 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:31:03,092 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:31:03,092 - INFO - joeynmt.training - 	Hypothesis: Aber das ist der <unk> dieses <unk> Problem  denn es nicht die <unk> des <unk>
2023-05-25 20:31:03,092 - INFO - joeynmt.training - Example #2
2023-05-25 20:31:03,092 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:31:03,092 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:31:03,092 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:31:03,092 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:31:03,092 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:31:03,092 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk> <unk>
2023-05-25 20:31:03,092 - INFO - joeynmt.training - Example #3
2023-05-25 20:31:03,092 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:31:03,092 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:31:03,092 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2023-05-25 20:31:03,093 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:31:03,093 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:31:03,093 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2023-05-25 20:31:03,093 - INFO - joeynmt.training - Example #4
2023-05-25 20:31:03,093 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:31:03,093 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:31:03,093 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', 'werde,', 'ist', 'ein', '<unk>', '<unk>', '<unk>', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', 'ist.', '</s>']
2023-05-25 20:31:03,093 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:31:03,093 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:31:03,093 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen zeigen werde, ist ein <unk> <unk> <unk> was in den letzten 25 Jahren <unk> ist.
2023-05-25 20:31:17,050 - INFO - joeynmt.training - Epoch   6, Step:    13600, Batch Loss:     1.610539, Batch Acc: 0.517460, Tokens per Sec:     4541, Lr: 0.000300
2023-05-25 20:31:30,769 - INFO - joeynmt.training - Epoch   6, Step:    13700, Batch Loss:     1.708971, Batch Acc: 0.517773, Tokens per Sec:     4854, Lr: 0.000300
2023-05-25 20:31:44,622 - INFO - joeynmt.training - Epoch   6, Step:    13800, Batch Loss:     1.695074, Batch Acc: 0.514447, Tokens per Sec:     4797, Lr: 0.000300
2023-05-25 20:31:58,600 - INFO - joeynmt.training - Epoch   6, Step:    13900, Batch Loss:     1.587048, Batch Acc: 0.515346, Tokens per Sec:     4830, Lr: 0.000300
2023-05-25 20:32:12,788 - INFO - joeynmt.training - Epoch   6, Step:    14000, Batch Loss:     1.527356, Batch Acc: 0.514329, Tokens per Sec:     4727, Lr: 0.000300
2023-05-25 20:32:12,789 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:32:12,789 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:32:35,485 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.89, ppl:   6.61, acc:   0.44, generation: 22.6917[sec], evaluation: 0.0000[sec]
2023-05-25 20:32:35,487 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-25 20:32:35,576 - INFO - joeynmt.helpers - delete models/transformer_model1/10500.ckpt
2023-05-25 20:32:35,582 - INFO - joeynmt.training - Example #0
2023-05-25 20:32:35,582 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:32:35,582 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:32:35,582 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahre', '<unk>', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', 'die', 'in', 'drei', 'Millionen', 'Jahren', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:32:35,582 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:32:35,582 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:32:35,582 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahre <unk> ich diese beiden <unk> <unk> um zu zeigen, dass die <unk> die in drei Millionen Jahren <unk> <unk> <unk> <unk> <unk> <unk>
2023-05-25 20:32:35,582 - INFO - joeynmt.training - Example #1
2023-05-25 20:32:35,582 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:32:35,582 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:32:35,582 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'dieses', '<unk>', 'Problem', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2023-05-25 20:32:35,582 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:32:35,582 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:32:35,582 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> dieses <unk> Problem  weil es nicht die <unk> des <unk> <unk>
2023-05-25 20:32:35,582 - INFO - joeynmt.training - Example #2
2023-05-25 20:32:35,582 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:32:35,582 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:32:35,582 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:32:35,582 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:32:35,582 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:32:35,583 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk> <unk> <unk>
2023-05-25 20:32:35,583 - INFO - joeynmt.training - Example #3
2023-05-25 20:32:35,583 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:32:35,583 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:32:35,583 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'der', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2023-05-25 20:32:35,583 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:32:35,583 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:32:35,583 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in der <unk> und <unk> in den <unk>
2023-05-25 20:32:35,583 - INFO - joeynmt.training - Example #4
2023-05-25 20:32:35,583 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:32:35,583 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:32:35,583 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', '<unk>', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2023-05-25 20:32:35,583 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:32:35,583 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:32:35,583 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen <unk>  ist eine <unk> Version von dem, was in den letzten 25 Jahren <unk>
2023-05-25 20:32:49,664 - INFO - joeynmt.training - Epoch   6, Step:    14100, Batch Loss:     1.590556, Batch Acc: 0.512913, Tokens per Sec:     4624, Lr: 0.000300
2023-05-25 20:33:04,203 - INFO - joeynmt.training - Epoch   6, Step:    14200, Batch Loss:     1.535346, Batch Acc: 0.516068, Tokens per Sec:     4366, Lr: 0.000300
2023-05-25 20:33:18,529 - INFO - joeynmt.training - Epoch   6, Step:    14300, Batch Loss:     1.586881, Batch Acc: 0.515486, Tokens per Sec:     4605, Lr: 0.000300
2023-05-25 20:33:32,244 - INFO - joeynmt.training - Epoch   6, Step:    14400, Batch Loss:     1.533321, Batch Acc: 0.517135, Tokens per Sec:     4745, Lr: 0.000300
2023-05-25 20:33:45,308 - INFO - joeynmt.training - Epoch   6, Step:    14500, Batch Loss:     1.697376, Batch Acc: 0.508673, Tokens per Sec:     5045, Lr: 0.000300
2023-05-25 20:33:45,309 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:33:45,309 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:34:02,385 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.91, ppl:   6.78, acc:   0.43, generation: 17.0721[sec], evaluation: 0.0000[sec]
2023-05-25 20:34:02,475 - INFO - joeynmt.helpers - delete models/transformer_model1/9000.ckpt
2023-05-25 20:34:02,482 - INFO - joeynmt.training - Example #0
2023-05-25 20:34:02,482 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:34:02,482 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:34:02,482 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'beiden', '<unk>', '<unk>', '<unk>', 'um', '<unk>', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', 'in', 'drei', 'Millionen', 'Jahren', '<unk>', '</s>']
2023-05-25 20:34:02,482 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:34:02,482 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:34:02,482 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese beiden <unk> <unk> <unk> um <unk> zu zeigen, dass die <unk>  die in drei Millionen Jahren <unk>
2023-05-25 20:34:02,482 - INFO - joeynmt.training - Example #1
2023-05-25 20:34:02,482 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:34:02,482 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:34:02,482 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'wirklich', 'die', '<unk>', 'dieses', '<unk>', 'Problem', '', 'denn', 'es', 'ist', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2023-05-25 20:34:02,482 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:34:02,482 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:34:02,482 - INFO - joeynmt.training - 	Hypothesis: Aber das ist wirklich die <unk> dieses <unk> Problem  denn es ist nicht die <unk> des <unk> <unk>
2023-05-25 20:34:02,483 - INFO - joeynmt.training - Example #2
2023-05-25 20:34:02,483 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:34:02,483 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:34:02,483 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', 'das', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:34:02,483 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:34:02,483 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:34:02,483 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk>  das <unk> <unk> <unk>
2023-05-25 20:34:02,483 - INFO - joeynmt.training - Example #3
2023-05-25 20:34:02,483 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:34:02,483 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:34:02,483 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2023-05-25 20:34:02,483 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:34:02,483 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:34:02,483 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in der <unk> und <unk> in der <unk>
2023-05-25 20:34:02,483 - INFO - joeynmt.training - Example #4
2023-05-25 20:34:02,483 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:34:02,483 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:34:02,483 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', 'werde,', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2023-05-25 20:34:02,483 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:34:02,483 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:34:02,483 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen zeigen werde, ist eine <unk> Version von dem was in den letzten 25 Jahren <unk>
2023-05-25 20:34:16,549 - INFO - joeynmt.training - Epoch   6, Step:    14600, Batch Loss:     1.522985, Batch Acc: 0.513538, Tokens per Sec:     4600, Lr: 0.000300
2023-05-25 20:34:30,758 - INFO - joeynmt.training - Epoch   6, Step:    14700, Batch Loss:     1.685299, Batch Acc: 0.515902, Tokens per Sec:     4661, Lr: 0.000300
2023-05-25 20:34:39,660 - INFO - joeynmt.training - Epoch   6: total training loss 3854.09
2023-05-25 20:34:39,662 - INFO - joeynmt.training - EPOCH 7
2023-05-25 20:34:44,914 - INFO - joeynmt.training - Epoch   7, Step:    14800, Batch Loss:     1.457142, Batch Acc: 0.544105, Tokens per Sec:     4783, Lr: 0.000300
2023-05-25 20:34:58,954 - INFO - joeynmt.training - Epoch   7, Step:    14900, Batch Loss:     1.423760, Batch Acc: 0.538070, Tokens per Sec:     4658, Lr: 0.000300
2023-05-25 20:35:13,042 - INFO - joeynmt.training - Epoch   7, Step:    15000, Batch Loss:     1.458193, Batch Acc: 0.536697, Tokens per Sec:     4656, Lr: 0.000300
2023-05-25 20:35:13,044 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:35:13,044 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:35:31,629 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.91, ppl:   6.72, acc:   0.44, generation: 18.5811[sec], evaluation: 0.0000[sec]
2023-05-25 20:35:31,725 - INFO - joeynmt.helpers - delete models/transformer_model1/14500.ckpt
2023-05-25 20:35:31,725 - INFO - joeynmt.helpers - delete /Users/cyril/Desktop/krizzzzi/mt-exercise-5/models/transformer_model1/14500.ckpt
2023-05-25 20:35:31,725 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /Users/cyril/Desktop/krizzzzi/mt-exercise-5/models/transformer_model1/14500.ckpt but file does not exist. ([Errno 2] No such file or directory: '/Users/cyril/Desktop/krizzzzi/mt-exercise-5/models/transformer_model1/14500.ckpt')
2023-05-25 20:35:31,728 - INFO - joeynmt.training - Example #0
2023-05-25 20:35:31,728 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:35:31,728 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:35:31,728 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', '<unk>', 'ich', '<unk>', 'diese', 'zwei', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', '<unk>', '', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', '<unk>', '</s>']
2023-05-25 20:35:31,728 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:35:31,728 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:35:31,728 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr <unk> ich <unk> diese zwei <unk> <unk> um zu zeigen, dass die <unk>  die <unk>  die in den letzten drei Millionen Jahre <unk> <unk>
2023-05-25 20:35:31,728 - INFO - joeynmt.training - Example #1
2023-05-25 20:35:31,728 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:35:31,728 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:35:31,728 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'es', 'ist', 'tatsächlich', 'die', '<unk>', 'dieses', '<unk>', 'Problem', '<unk>', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2023-05-25 20:35:31,728 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:35:31,728 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:35:31,728 - INFO - joeynmt.training - 	Hypothesis: Aber es ist tatsächlich die <unk> dieses <unk> Problem <unk>  weil es nicht die <unk> des <unk> <unk>
2023-05-25 20:35:31,728 - INFO - joeynmt.training - Example #2
2023-05-25 20:35:31,728 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:35:31,728 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:35:31,728 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:35:31,729 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:35:31,729 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:35:31,729 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk>
2023-05-25 20:35:31,729 - INFO - joeynmt.training - Example #3
2023-05-25 20:35:31,729 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:35:31,729 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:35:31,729 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2023-05-25 20:35:31,729 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:35:31,729 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:35:31,729 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in der <unk> und <unk> in der <unk>
2023-05-25 20:35:31,729 - INFO - joeynmt.training - Example #4
2023-05-25 20:35:31,729 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:35:31,729 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:35:31,729 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2023-05-25 20:35:31,729 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:35:31,729 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:35:31,729 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen zeigen  ist eine <unk> Version von dem, was in den letzten 25 Jahren <unk>
2023-05-25 20:35:47,069 - INFO - joeynmt.training - Epoch   7, Step:    15100, Batch Loss:     1.479529, Batch Acc: 0.534995, Tokens per Sec:     4299, Lr: 0.000300
2023-05-25 20:36:00,898 - INFO - joeynmt.training - Epoch   7, Step:    15200, Batch Loss:     1.419854, Batch Acc: 0.532209, Tokens per Sec:     4727, Lr: 0.000300
2023-05-25 20:36:14,836 - INFO - joeynmt.training - Epoch   7, Step:    15300, Batch Loss:     1.522621, Batch Acc: 0.527315, Tokens per Sec:     4797, Lr: 0.000300
2023-05-25 20:36:28,751 - INFO - joeynmt.training - Epoch   7, Step:    15400, Batch Loss:     1.421532, Batch Acc: 0.530486, Tokens per Sec:     4745, Lr: 0.000300
2023-05-25 20:36:42,490 - INFO - joeynmt.training - Epoch   7, Step:    15500, Batch Loss:     1.504682, Batch Acc: 0.533529, Tokens per Sec:     4674, Lr: 0.000300
2023-05-25 20:36:42,490 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:36:42,490 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:37:04,284 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.93, ppl:   6.89, acc:   0.43, generation: 21.7891[sec], evaluation: 0.0000[sec]
2023-05-25 20:37:04,286 - INFO - joeynmt.training - Example #0
2023-05-25 20:37:04,286 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:37:04,286 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:37:04,286 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', '<unk>', '', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:37:04,286 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:37:04,286 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:37:04,286 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese beiden <unk> <unk> um <unk>  zu zeigen, dass die <unk>  die letzten drei Millionen Jahre <unk> <unk> <unk> <unk>
2023-05-25 20:37:04,286 - INFO - joeynmt.training - Example #1
2023-05-25 20:37:04,286 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:37:04,286 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:37:04,286 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'tatsächlich', 'die', '<unk>', 'dieses', '<unk>', 'Problem', '', 'denn', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '</s>']
2023-05-25 20:37:04,286 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:37:04,286 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:37:04,286 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> tatsächlich die <unk> dieses <unk> Problem  denn es nicht die <unk> des <unk>
2023-05-25 20:37:04,286 - INFO - joeynmt.training - Example #2
2023-05-25 20:37:04,286 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:37:04,286 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:37:04,286 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '', 'das', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:37:04,287 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:37:04,287 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:37:04,287 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk>  das <unk> <unk> <unk>
2023-05-25 20:37:04,287 - INFO - joeynmt.training - Example #3
2023-05-25 20:37:04,287 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:37:04,287 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:37:04,287 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2023-05-25 20:37:04,287 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:37:04,287 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:37:04,287 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2023-05-25 20:37:04,287 - INFO - joeynmt.training - Example #4
2023-05-25 20:37:04,287 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:37:04,287 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:37:04,287 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', 'zeige', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '<unk>', '</s>']
2023-05-25 20:37:04,287 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:37:04,287 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:37:04,287 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen zeigen zeige  ist eine <unk> Version von dem, was in den letzten 25 Jahren <unk> <unk>
2023-05-25 20:37:18,304 - INFO - joeynmt.training - Epoch   7, Step:    15600, Batch Loss:     1.599687, Batch Acc: 0.523365, Tokens per Sec:     4627, Lr: 0.000300
2023-05-25 20:37:32,037 - INFO - joeynmt.training - Epoch   7, Step:    15700, Batch Loss:     1.378478, Batch Acc: 0.524341, Tokens per Sec:     4792, Lr: 0.000300
2023-05-25 20:37:46,096 - INFO - joeynmt.training - Epoch   7, Step:    15800, Batch Loss:     1.558805, Batch Acc: 0.527245, Tokens per Sec:     4684, Lr: 0.000300
2023-05-25 20:37:59,826 - INFO - joeynmt.training - Epoch   7, Step:    15900, Batch Loss:     1.566831, Batch Acc: 0.520173, Tokens per Sec:     4710, Lr: 0.000300
2023-05-25 20:38:14,090 - INFO - joeynmt.training - Epoch   7, Step:    16000, Batch Loss:     1.559144, Batch Acc: 0.522621, Tokens per Sec:     4720, Lr: 0.000300
2023-05-25 20:38:14,091 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:38:14,091 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:38:31,680 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.90, ppl:   6.66, acc:   0.44, generation: 17.5838[sec], evaluation: 0.0000[sec]
2023-05-25 20:38:31,778 - INFO - joeynmt.helpers - delete models/transformer_model1/13000.ckpt
2023-05-25 20:38:31,781 - INFO - joeynmt.training - Example #0
2023-05-25 20:38:31,781 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:38:31,781 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:38:31,781 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'beiden', '<unk>', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', 'Jahren', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:38:31,781 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:38:31,781 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:38:31,781 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese beiden <unk> <unk> <unk> um zu zeigen, dass die <unk>  die in den letzten drei Millionen Jahren Jahren <unk> <unk> <unk>
2023-05-25 20:38:31,781 - INFO - joeynmt.training - Example #1
2023-05-25 20:38:31,781 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:38:31,781 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:38:31,781 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'diese', '<unk>', 'tatsächlich', 'die', '<unk>', 'dieses', '<unk>', 'Problem', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2023-05-25 20:38:31,782 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:38:31,782 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:38:31,782 - INFO - joeynmt.training - 	Hypothesis: Aber diese <unk> tatsächlich die <unk> dieses <unk> Problem  weil es nicht die <unk> des <unk> <unk>
2023-05-25 20:38:31,782 - INFO - joeynmt.training - Example #2
2023-05-25 20:38:31,782 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:38:31,782 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:38:31,782 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:38:31,782 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:38:31,782 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:38:31,782 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk> <unk>
2023-05-25 20:38:31,782 - INFO - joeynmt.training - Example #3
2023-05-25 20:38:31,782 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:38:31,782 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:38:31,782 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2023-05-25 20:38:31,782 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:38:31,782 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:38:31,782 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2023-05-25 20:38:31,782 - INFO - joeynmt.training - Example #4
2023-05-25 20:38:31,782 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:38:31,782 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:38:31,782 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', 'werde,', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', 'Jahren', 'in', 'den', 'letzten', 'Jahren', '<unk>', '</s>']
2023-05-25 20:38:31,782 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:38:31,782 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:38:31,783 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen zeigen werde, ist eine <unk> Version von dem, was in den letzten Jahren in den letzten Jahren <unk>
2023-05-25 20:38:45,317 - INFO - joeynmt.training - Epoch   7, Step:    16100, Batch Loss:     1.384422, Batch Acc: 0.523535, Tokens per Sec:     4862, Lr: 0.000300
2023-05-25 20:38:58,906 - INFO - joeynmt.training - Epoch   7, Step:    16200, Batch Loss:     1.531711, Batch Acc: 0.525584, Tokens per Sec:     4814, Lr: 0.000300
2023-05-25 20:39:12,521 - INFO - joeynmt.training - Epoch   7, Step:    16300, Batch Loss:     1.449139, Batch Acc: 0.524401, Tokens per Sec:     4767, Lr: 0.000300
2023-05-25 20:39:25,998 - INFO - joeynmt.training - Epoch   7, Step:    16400, Batch Loss:     1.574332, Batch Acc: 0.521840, Tokens per Sec:     4940, Lr: 0.000300
2023-05-25 20:39:39,869 - INFO - joeynmt.training - Epoch   7, Step:    16500, Batch Loss:     1.557123, Batch Acc: 0.523767, Tokens per Sec:     4707, Lr: 0.000300
2023-05-25 20:39:39,870 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:39:39,870 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:39:59,743 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.91, ppl:   6.77, acc:   0.43, generation: 19.8688[sec], evaluation: 0.0000[sec]
2023-05-25 20:39:59,745 - INFO - joeynmt.training - Example #0
2023-05-25 20:39:59,745 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:39:59,745 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:39:59,745 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', '<unk>', 'ich', 'diese', 'beiden', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:39:59,745 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:39:59,745 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:39:59,745 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr <unk> ich diese beiden <unk> <unk> <unk> <unk> <unk>
2023-05-25 20:39:59,746 - INFO - joeynmt.training - Example #1
2023-05-25 20:39:59,746 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:39:59,746 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:39:59,746 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'dieses', '<unk>', '<unk>', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2023-05-25 20:39:59,746 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:39:59,746 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:39:59,746 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> dieses <unk> <unk>  weil es nicht die <unk> des <unk> <unk>
2023-05-25 20:39:59,746 - INFO - joeynmt.training - Example #2
2023-05-25 20:39:59,746 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:39:59,746 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:39:59,746 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:39:59,746 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:39:59,746 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:39:59,746 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk> <unk>
2023-05-25 20:39:59,746 - INFO - joeynmt.training - Example #3
2023-05-25 20:39:59,746 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:39:59,746 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:39:59,746 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2023-05-25 20:39:59,746 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:39:59,746 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:39:59,746 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in der <unk> und <unk> in der <unk>
2023-05-25 20:39:59,746 - INFO - joeynmt.training - Example #4
2023-05-25 20:39:59,747 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:39:59,747 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:39:59,747 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', '<unk>', '<unk>', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2023-05-25 20:39:59,747 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:39:59,747 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:39:59,747 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich <unk> <unk> ist eine <unk> Version von dem, was in den letzten 25 Jahren <unk>
2023-05-25 20:40:13,997 - INFO - joeynmt.training - Epoch   7, Step:    16600, Batch Loss:     1.478350, Batch Acc: 0.522039, Tokens per Sec:     4702, Lr: 0.000300
2023-05-25 20:40:27,882 - INFO - joeynmt.training - Epoch   7, Step:    16700, Batch Loss:     1.532200, Batch Acc: 0.526113, Tokens per Sec:     4663, Lr: 0.000300
2023-05-25 20:40:42,085 - INFO - joeynmt.training - Epoch   7, Step:    16800, Batch Loss:     1.548832, Batch Acc: 0.519931, Tokens per Sec:     4796, Lr: 0.000300
2023-05-25 20:40:56,024 - INFO - joeynmt.training - Epoch   7, Step:    16900, Batch Loss:     1.477774, Batch Acc: 0.524575, Tokens per Sec:     4660, Lr: 0.000300
2023-05-25 20:41:10,050 - INFO - joeynmt.training - Epoch   7, Step:    17000, Batch Loss:     1.562181, Batch Acc: 0.521870, Tokens per Sec:     4711, Lr: 0.000300
2023-05-25 20:41:10,051 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:41:10,051 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:41:29,504 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.90, ppl:   6.71, acc:   0.43, generation: 19.4489[sec], evaluation: 0.0000[sec]
2023-05-25 20:41:29,594 - INFO - joeynmt.helpers - delete models/transformer_model1/13500.ckpt
2023-05-25 20:41:29,600 - INFO - joeynmt.training - Example #0
2023-05-25 20:41:29,600 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:41:29,600 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:41:29,600 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', '<unk>', '', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', '<unk>', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:41:29,600 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:41:29,600 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:41:29,601 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese beiden <unk> <unk> um <unk>  zu zeigen, dass die <unk>  die <unk> die in den letzten drei Millionen Jahren <unk> <unk> <unk>
2023-05-25 20:41:29,601 - INFO - joeynmt.training - Example #1
2023-05-25 20:41:29,601 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:41:29,601 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:41:29,601 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'tatsächlich', 'die', '<unk>', 'dieses', '<unk>', 'Problem', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2023-05-25 20:41:29,601 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:41:29,601 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:41:29,601 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> tatsächlich die <unk> dieses <unk> Problem  weil es nicht die <unk> des <unk> <unk>
2023-05-25 20:41:29,601 - INFO - joeynmt.training - Example #2
2023-05-25 20:41:29,601 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:41:29,601 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:41:29,601 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '', 'das', '<unk>', 'Herz', 'unseres', '<unk>', '<unk>', '</s>']
2023-05-25 20:41:29,601 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:41:29,601 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:41:29,601 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk>  das <unk> Herz unseres <unk> <unk>
2023-05-25 20:41:29,601 - INFO - joeynmt.training - Example #3
2023-05-25 20:41:29,601 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:41:29,601 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:41:29,601 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'der', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2023-05-25 20:41:29,601 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:41:29,601 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:41:29,601 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in der <unk> und <unk> in den <unk>
2023-05-25 20:41:29,601 - INFO - joeynmt.training - Example #4
2023-05-25 20:41:29,601 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:41:29,601 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:41:29,601 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', '<unk>', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2023-05-25 20:41:29,602 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:41:29,602 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:41:29,602 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen <unk>  ist eine <unk> Version von dem was in den letzten 25 Jahren <unk>
2023-05-25 20:41:44,223 - INFO - joeynmt.training - Epoch   7, Step:    17100, Batch Loss:     1.531374, Batch Acc: 0.520762, Tokens per Sec:     4406, Lr: 0.000300
2023-05-25 20:41:57,659 - INFO - joeynmt.training - Epoch   7, Step:    17200, Batch Loss:     1.349308, Batch Acc: 0.522634, Tokens per Sec:     4902, Lr: 0.000300
2023-05-25 20:42:00,590 - INFO - joeynmt.training - Epoch   7: total training loss 3756.89
2023-05-25 20:42:00,590 - INFO - joeynmt.training - EPOCH 8
2023-05-25 20:42:11,251 - INFO - joeynmt.training - Epoch   8, Step:    17300, Batch Loss:     1.566500, Batch Acc: 0.542690, Tokens per Sec:     4929, Lr: 0.000300
2023-05-25 20:42:24,894 - INFO - joeynmt.training - Epoch   8, Step:    17400, Batch Loss:     1.451738, Batch Acc: 0.544344, Tokens per Sec:     4795, Lr: 0.000300
2023-05-25 20:42:38,840 - INFO - joeynmt.training - Epoch   8, Step:    17500, Batch Loss:     1.509336, Batch Acc: 0.540512, Tokens per Sec:     4731, Lr: 0.000300
2023-05-25 20:42:38,842 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:42:38,842 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:42:57,762 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.90, ppl:   6.72, acc:   0.44, generation: 18.9154[sec], evaluation: 0.0000[sec]
2023-05-25 20:42:57,857 - INFO - joeynmt.helpers - delete models/transformer_model1/15000.ckpt
2023-05-25 20:42:57,862 - INFO - joeynmt.training - Example #0
2023-05-25 20:42:57,862 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:42:57,862 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:42:57,862 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', '<unk>', '', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', 'hatte,', '', 'mit', '<unk>', '<unk>', '</s>']
2023-05-25 20:42:57,862 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:42:57,862 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:42:57,862 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese beiden <unk> <unk> um zu zeigen, dass die <unk>  die <unk>  die letzten drei Millionen Jahre <unk> hatte,  mit <unk> <unk>
2023-05-25 20:42:57,862 - INFO - joeynmt.training - Example #1
2023-05-25 20:42:57,862 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:42:57,862 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:42:57,862 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'dieses', '<unk>', 'Problem', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2023-05-25 20:42:57,862 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:42:57,862 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:42:57,862 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> dieses <unk> Problem  weil es nicht die <unk> des <unk> <unk>
2023-05-25 20:42:57,862 - INFO - joeynmt.training - Example #2
2023-05-25 20:42:57,862 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:42:57,862 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:42:57,862 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:42:57,863 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:42:57,863 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:42:57,863 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk> <unk>
2023-05-25 20:42:57,863 - INFO - joeynmt.training - Example #3
2023-05-25 20:42:57,863 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:42:57,863 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:42:57,863 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2023-05-25 20:42:57,863 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:42:57,863 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:42:57,863 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2023-05-25 20:42:57,863 - INFO - joeynmt.training - Example #4
2023-05-25 20:42:57,863 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:42:57,863 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:42:57,863 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächsten', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', 'werde,', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2023-05-25 20:42:57,863 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:42:57,863 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:42:57,863 - INFO - joeynmt.training - 	Hypothesis: Die nächsten <unk> die ich Ihnen zeigen werde, ist eine <unk> Version von dem, was in den letzten 25 Jahren <unk>
2023-05-25 20:43:12,412 - INFO - joeynmt.training - Epoch   8, Step:    17600, Batch Loss:     1.455408, Batch Acc: 0.539030, Tokens per Sec:     4426, Lr: 0.000300
2023-05-25 20:43:26,208 - INFO - joeynmt.training - Epoch   8, Step:    17700, Batch Loss:     1.432311, Batch Acc: 0.539737, Tokens per Sec:     4709, Lr: 0.000300
2023-05-25 20:43:39,728 - INFO - joeynmt.training - Epoch   8, Step:    17800, Batch Loss:     1.439165, Batch Acc: 0.537872, Tokens per Sec:     4849, Lr: 0.000300
2023-05-25 20:43:53,177 - INFO - joeynmt.training - Epoch   8, Step:    17900, Batch Loss:     1.428900, Batch Acc: 0.536899, Tokens per Sec:     4922, Lr: 0.000300
2023-05-25 20:44:07,239 - INFO - joeynmt.training - Epoch   8, Step:    18000, Batch Loss:     1.391184, Batch Acc: 0.542471, Tokens per Sec:     4689, Lr: 0.000300
2023-05-25 20:44:07,240 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:44:07,240 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:44:29,008 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.93, ppl:   6.87, acc:   0.43, generation: 21.7628[sec], evaluation: 0.0000[sec]
2023-05-25 20:44:29,010 - INFO - joeynmt.training - Example #0
2023-05-25 20:44:29,010 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:44:29,010 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:44:29,010 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', '<unk>', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', '<unk>', '', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', '<unk>', 'hatte,', 'die', 'Größe', 'der', '<unk>', '', 'mit', '<unk>', '<unk>', '</s>']
2023-05-25 20:44:29,010 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:44:29,010 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:44:29,010 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr <unk> ich diese beiden <unk> <unk> um zu zeigen, dass die <unk>  die <unk>  die in den letzten drei Millionen Jahren <unk> hatte, die Größe der <unk>  mit <unk> <unk>
2023-05-25 20:44:29,010 - INFO - joeynmt.training - Example #1
2023-05-25 20:44:29,010 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:44:29,010 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:44:29,010 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'dieses', '<unk>', 'Problem', '', 'denn', 'es', 'ist', 'nicht', 'die', '<unk>', 'des', '<unk>', 'sehen.', '</s>']
2023-05-25 20:44:29,011 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:44:29,011 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:44:29,011 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> dieses <unk> Problem  denn es ist nicht die <unk> des <unk> sehen.
2023-05-25 20:44:29,011 - INFO - joeynmt.training - Example #2
2023-05-25 20:44:29,011 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:44:29,011 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:44:29,011 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '', 'das', '<unk>', 'Herz', 'unserer', '<unk>', '<unk>', '</s>']
2023-05-25 20:44:29,011 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:44:29,011 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:44:29,011 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk>  das <unk> Herz unserer <unk> <unk>
2023-05-25 20:44:29,011 - INFO - joeynmt.training - Example #3
2023-05-25 20:44:29,011 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:44:29,011 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:44:29,011 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2023-05-25 20:44:29,011 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:44:29,011 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:44:29,011 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in der <unk> und <unk> in der <unk>
2023-05-25 20:44:29,011 - INFO - joeynmt.training - Example #4
2023-05-25 20:44:29,011 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:44:29,011 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:44:29,011 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', '<unk>', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', 'ist.', '</s>']
2023-05-25 20:44:29,011 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:44:29,011 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:44:29,011 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen <unk>  ist eine <unk> Version von dem, was in den letzten 25 Jahren <unk> ist.
2023-05-25 20:44:42,962 - INFO - joeynmt.training - Epoch   8, Step:    18100, Batch Loss:     1.543540, Batch Acc: 0.538129, Tokens per Sec:     4821, Lr: 0.000300
2023-05-25 20:44:56,936 - INFO - joeynmt.training - Epoch   8, Step:    18200, Batch Loss:     1.453461, Batch Acc: 0.539799, Tokens per Sec:     4712, Lr: 0.000300
2023-05-25 20:45:10,798 - INFO - joeynmt.training - Epoch   8, Step:    18300, Batch Loss:     1.422731, Batch Acc: 0.529440, Tokens per Sec:     4791, Lr: 0.000300
2023-05-25 20:45:24,735 - INFO - joeynmt.training - Epoch   8, Step:    18400, Batch Loss:     1.509737, Batch Acc: 0.534450, Tokens per Sec:     4664, Lr: 0.000300
2023-05-25 20:45:38,645 - INFO - joeynmt.training - Epoch   8, Step:    18500, Batch Loss:     1.529382, Batch Acc: 0.529933, Tokens per Sec:     4798, Lr: 0.000300
2023-05-25 20:45:38,646 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:45:38,646 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:45:57,983 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.92, ppl:   6.84, acc:   0.43, generation: 19.3332[sec], evaluation: 0.0000[sec]
2023-05-25 20:45:57,985 - INFO - joeynmt.training - Example #0
2023-05-25 20:45:57,985 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:45:57,985 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:45:57,985 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', '<unk>', '', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', '<unk>', 'die', '<unk>', 'die', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:45:57,985 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:45:57,985 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:45:57,985 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese beiden <unk> <unk> um <unk>  zu zeigen, dass die <unk>  die <unk> die <unk> die <unk> <unk> <unk> <unk>
2023-05-25 20:45:57,985 - INFO - joeynmt.training - Example #1
2023-05-25 20:45:57,985 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:45:57,985 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:45:57,985 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'die', '<unk>', 'dieses', '<unk>', 'Problem', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', 'sehen.', '</s>']
2023-05-25 20:45:57,986 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:45:57,986 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:45:57,986 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> die <unk> dieses <unk> Problem  weil es nicht die <unk> des <unk> sehen.
2023-05-25 20:45:57,986 - INFO - joeynmt.training - Example #2
2023-05-25 20:45:57,986 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:45:57,986 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:45:57,986 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', 'Weise', '<unk>', '', 'das', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:45:57,986 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:45:57,986 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:45:57,986 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> Weise <unk>  das <unk> <unk> <unk>
2023-05-25 20:45:57,986 - INFO - joeynmt.training - Example #3
2023-05-25 20:45:57,986 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:45:57,986 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:45:57,986 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2023-05-25 20:45:57,986 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:45:57,986 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:45:57,986 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2023-05-25 20:45:57,986 - INFO - joeynmt.training - Example #4
2023-05-25 20:45:57,986 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:45:57,986 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:45:57,986 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', '<unk>', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2023-05-25 20:45:57,986 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:45:57,986 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:45:57,987 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen zeigen  ist eine <unk> Version von dem <unk> was in den letzten 25 Jahren <unk>
2023-05-25 20:46:12,105 - INFO - joeynmt.training - Epoch   8, Step:    18600, Batch Loss:     1.568666, Batch Acc: 0.539587, Tokens per Sec:     4551, Lr: 0.000210
2023-05-25 20:46:26,490 - INFO - joeynmt.training - Epoch   8, Step:    18700, Batch Loss:     1.599811, Batch Acc: 0.538156, Tokens per Sec:     4563, Lr: 0.000210
2023-05-25 20:46:40,828 - INFO - joeynmt.training - Epoch   8, Step:    18800, Batch Loss:     1.576800, Batch Acc: 0.541580, Tokens per Sec:     4709, Lr: 0.000210
2023-05-25 20:46:54,938 - INFO - joeynmt.training - Epoch   8, Step:    18900, Batch Loss:     1.551878, Batch Acc: 0.541498, Tokens per Sec:     4634, Lr: 0.000210
2023-05-25 20:47:09,593 - INFO - joeynmt.training - Epoch   8, Step:    19000, Batch Loss:     1.508121, Batch Acc: 0.540619, Tokens per Sec:     4434, Lr: 0.000210
2023-05-25 20:47:09,594 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:47:09,594 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:47:30,679 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.89, ppl:   6.63, acc:   0.44, generation: 21.0805[sec], evaluation: 0.0000[sec]
2023-05-25 20:47:30,767 - INFO - joeynmt.helpers - delete models/transformer_model1/17500.ckpt
2023-05-25 20:47:30,767 - INFO - joeynmt.helpers - delete /Users/cyril/Desktop/krizzzzi/mt-exercise-5/models/transformer_model1/17500.ckpt
2023-05-25 20:47:30,767 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /Users/cyril/Desktop/krizzzzi/mt-exercise-5/models/transformer_model1/17500.ckpt but file does not exist. ([Errno 2] No such file or directory: '/Users/cyril/Desktop/krizzzzi/mt-exercise-5/models/transformer_model1/17500.ckpt')
2023-05-25 20:47:30,769 - INFO - joeynmt.training - Example #0
2023-05-25 20:47:30,769 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:47:30,769 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:47:30,769 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'beiden', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:47:30,770 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:47:30,770 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:47:30,770 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese beiden <unk> <unk> <unk> <unk> <unk>
2023-05-25 20:47:30,770 - INFO - joeynmt.training - Example #1
2023-05-25 20:47:30,770 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:47:30,770 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:47:30,770 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'der', '<unk>', 'dieses', '<unk>', 'Problem', '', 'denn', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', 'sehen.', '</s>']
2023-05-25 20:47:30,770 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:47:30,770 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:47:30,770 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> der <unk> dieses <unk> Problem  denn es nicht die <unk> des <unk> sehen.
2023-05-25 20:47:30,770 - INFO - joeynmt.training - Example #2
2023-05-25 20:47:30,770 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:47:30,770 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:47:30,770 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', 'das', '<unk>', 'unserer', '<unk>', '<unk>', '</s>']
2023-05-25 20:47:30,770 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:47:30,770 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:47:30,770 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk>  das <unk> unserer <unk> <unk>
2023-05-25 20:47:30,770 - INFO - joeynmt.training - Example #3
2023-05-25 20:47:30,770 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:47:30,770 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:47:30,770 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2023-05-25 20:47:30,770 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:47:30,770 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:47:30,771 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in der <unk> und <unk> in der <unk>
2023-05-25 20:47:30,771 - INFO - joeynmt.training - Example #4
2023-05-25 20:47:30,771 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:47:30,771 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:47:30,771 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', '<unk>', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2023-05-25 20:47:30,771 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:47:30,771 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:47:30,771 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen zeigen  ist eine <unk> Version von dem <unk> was in den letzten 25 Jahren <unk>
2023-05-25 20:47:45,550 - INFO - joeynmt.training - Epoch   8, Step:    19100, Batch Loss:     1.473333, Batch Acc: 0.536414, Tokens per Sec:     4343, Lr: 0.000210
2023-05-25 20:47:59,934 - INFO - joeynmt.training - Epoch   8, Step:    19200, Batch Loss:     1.486743, Batch Acc: 0.539302, Tokens per Sec:     4571, Lr: 0.000210
2023-05-25 20:48:14,748 - INFO - joeynmt.training - Epoch   8, Step:    19300, Batch Loss:     1.547939, Batch Acc: 0.537479, Tokens per Sec:     4324, Lr: 0.000210
2023-05-25 20:48:29,180 - INFO - joeynmt.training - Epoch   8, Step:    19400, Batch Loss:     1.440980, Batch Acc: 0.537861, Tokens per Sec:     4592, Lr: 0.000210
2023-05-25 20:48:43,808 - INFO - joeynmt.training - Epoch   8, Step:    19500, Batch Loss:     1.494748, Batch Acc: 0.539315, Tokens per Sec:     4478, Lr: 0.000210
2023-05-25 20:48:43,809 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:48:43,809 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:49:03,951 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.88, ppl:   6.58, acc:   0.44, generation: 20.1363[sec], evaluation: 0.0000[sec]
2023-05-25 20:49:03,952 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-25 20:49:04,043 - INFO - joeynmt.helpers - delete models/transformer_model1/17000.ckpt
2023-05-25 20:49:04,047 - INFO - joeynmt.training - Example #0
2023-05-25 20:49:04,047 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:49:04,047 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:49:04,047 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', '<unk>', '', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:49:04,048 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:49:04,048 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:49:04,048 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese beiden <unk> <unk> um <unk>  zu zeigen, dass die <unk>  die in den letzten drei Millionen Jahren <unk> <unk> <unk> <unk> <unk>
2023-05-25 20:49:04,048 - INFO - joeynmt.training - Example #1
2023-05-25 20:49:04,048 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:49:04,048 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:49:04,048 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'eigentlich', 'die', '<unk>', 'dieses', '<unk>', 'Problem', '', 'denn', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', 'sehen.', '</s>']
2023-05-25 20:49:04,048 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:49:04,048 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:49:04,048 - INFO - joeynmt.training - 	Hypothesis: Aber das ist eigentlich die <unk> dieses <unk> Problem  denn es nicht die <unk> des <unk> sehen.
2023-05-25 20:49:04,048 - INFO - joeynmt.training - Example #2
2023-05-25 20:49:04,048 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:49:04,048 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:49:04,048 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', 'das', '<unk>', 'Herz', 'unserer', '<unk>', '</s>']
2023-05-25 20:49:04,048 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:49:04,048 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:49:04,048 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk>  das <unk> Herz unserer <unk>
2023-05-25 20:49:04,048 - INFO - joeynmt.training - Example #3
2023-05-25 20:49:04,048 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:49:04,048 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:49:04,048 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2023-05-25 20:49:04,048 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:49:04,048 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:49:04,048 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2023-05-25 20:49:04,048 - INFO - joeynmt.training - Example #4
2023-05-25 20:49:04,048 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:49:04,048 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:49:04,048 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', 'werde,', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', 'Jahren', 'in', 'der', '<unk>', '<unk>', '</s>']
2023-05-25 20:49:04,049 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:49:04,049 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:49:04,049 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen zeigen werde, ist eine <unk> Version von dem, was in den letzten Jahren in der <unk> <unk>
2023-05-25 20:49:18,720 - INFO - joeynmt.training - Epoch   8, Step:    19600, Batch Loss:     1.531896, Batch Acc: 0.534737, Tokens per Sec:     4397, Lr: 0.000210
2023-05-25 20:49:30,619 - INFO - joeynmt.training - Epoch   8: total training loss 3652.20
2023-05-25 20:49:30,620 - INFO - joeynmt.training - EPOCH 9
2023-05-25 20:49:32,758 - INFO - joeynmt.training - Epoch   9, Step:    19700, Batch Loss:     1.346375, Batch Acc: 0.562744, Tokens per Sec:     4802, Lr: 0.000210
2023-05-25 20:49:46,801 - INFO - joeynmt.training - Epoch   9, Step:    19800, Batch Loss:     1.301894, Batch Acc: 0.564015, Tokens per Sec:     4714, Lr: 0.000210
2023-05-25 20:50:00,809 - INFO - joeynmt.training - Epoch   9, Step:    19900, Batch Loss:     1.491823, Batch Acc: 0.561676, Tokens per Sec:     4721, Lr: 0.000210
2023-05-25 20:50:14,940 - INFO - joeynmt.training - Epoch   9, Step:    20000, Batch Loss:     1.518317, Batch Acc: 0.564662, Tokens per Sec:     4596, Lr: 0.000210
2023-05-25 20:50:14,942 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:50:14,942 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:50:33,960 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.91, ppl:   6.78, acc:   0.44, generation: 19.0134[sec], evaluation: 0.0000[sec]
2023-05-25 20:50:33,962 - INFO - joeynmt.training - Example #0
2023-05-25 20:50:33,962 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:50:33,962 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:50:33,962 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', '<unk>', '<unk>', 'hatte,', 'die', '<unk>', 'der', '<unk>', '', 'mit', '<unk>', '<unk>', 'war.', '</s>']
2023-05-25 20:50:33,962 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:50:33,962 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:50:33,962 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese beiden <unk> <unk> um zu zeigen, dass die <unk>  die in den letzten drei Millionen Jahren <unk> <unk> hatte, die <unk> der <unk>  mit <unk> <unk> war.
2023-05-25 20:50:33,962 - INFO - joeynmt.training - Example #1
2023-05-25 20:50:33,962 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:50:33,962 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:50:33,962 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'tatsächlich', 'die', '<unk>', 'dieses', '<unk>', 'Problem', '', 'denn', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', 'sehen.', '</s>']
2023-05-25 20:50:33,962 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:50:33,962 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:50:33,962 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> tatsächlich die <unk> dieses <unk> Problem  denn es nicht die <unk> des <unk> sehen.
2023-05-25 20:50:33,962 - INFO - joeynmt.training - Example #2
2023-05-25 20:50:33,962 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:50:33,962 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:50:33,962 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '', 'das', '<unk>', 'Herz', 'unseres', '<unk>', '<unk>', '</s>']
2023-05-25 20:50:33,963 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:50:33,963 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:50:33,963 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk>  das <unk> Herz unseres <unk> <unk>
2023-05-25 20:50:33,963 - INFO - joeynmt.training - Example #3
2023-05-25 20:50:33,963 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:50:33,963 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:50:33,963 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2023-05-25 20:50:33,963 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:50:33,963 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:50:33,963 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2023-05-25 20:50:33,963 - INFO - joeynmt.training - Example #4
2023-05-25 20:50:33,963 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:50:33,963 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:50:33,963 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', 'werde,', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2023-05-25 20:50:33,963 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:50:33,963 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:50:33,963 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen zeigen werde, ist eine <unk> Version von dem, was in den letzten 25 Jahren <unk>
2023-05-25 20:50:48,216 - INFO - joeynmt.training - Epoch   9, Step:    20100, Batch Loss:     1.464977, Batch Acc: 0.565737, Tokens per Sec:     4527, Lr: 0.000210
2023-05-25 20:51:02,020 - INFO - joeynmt.training - Epoch   9, Step:    20200, Batch Loss:     1.388547, Batch Acc: 0.560149, Tokens per Sec:     4811, Lr: 0.000210
2023-05-25 20:51:15,796 - INFO - joeynmt.training - Epoch   9, Step:    20300, Batch Loss:     1.375550, Batch Acc: 0.560358, Tokens per Sec:     4709, Lr: 0.000210
2023-05-25 20:51:29,703 - INFO - joeynmt.training - Epoch   9, Step:    20400, Batch Loss:     1.442325, Batch Acc: 0.563978, Tokens per Sec:     4790, Lr: 0.000210
2023-05-25 20:51:43,385 - INFO - joeynmt.training - Epoch   9, Step:    20500, Batch Loss:     1.366094, Batch Acc: 0.556868, Tokens per Sec:     4727, Lr: 0.000210
2023-05-25 20:51:43,386 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:51:43,386 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:52:02,480 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.90, ppl:   6.66, acc:   0.44, generation: 19.0898[sec], evaluation: 0.0000[sec]
2023-05-25 20:52:02,570 - INFO - joeynmt.helpers - delete models/transformer_model1/11500.ckpt
2023-05-25 20:52:02,575 - INFO - joeynmt.training - Example #0
2023-05-25 20:52:02,575 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:52:02,575 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:52:02,575 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', '<unk>', '', 'zu', 'zeigen,', 'dass', 'die', '<unk>', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:52:02,576 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:52:02,576 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:52:02,576 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese beiden <unk> <unk> um <unk>  zu zeigen, dass die <unk> die in den letzten drei Millionen Jahren <unk> <unk> <unk>
2023-05-25 20:52:02,576 - INFO - joeynmt.training - Example #1
2023-05-25 20:52:02,576 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:52:02,576 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:52:02,576 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'tatsächlich', 'die', '<unk>', 'dieses', '<unk>', 'Problem', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', 'sehen.', '</s>']
2023-05-25 20:52:02,576 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:52:02,576 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:52:02,576 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> tatsächlich die <unk> dieses <unk> Problem  weil es nicht die <unk> des <unk> sehen.
2023-05-25 20:52:02,576 - INFO - joeynmt.training - Example #2
2023-05-25 20:52:02,576 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:52:02,576 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:52:02,576 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '', 'das', '<unk>', 'Herz', 'unserer', '<unk>', '</s>']
2023-05-25 20:52:02,576 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:52:02,576 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:52:02,576 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk>  das <unk> Herz unserer <unk>
2023-05-25 20:52:02,576 - INFO - joeynmt.training - Example #3
2023-05-25 20:52:02,576 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:52:02,576 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:52:02,576 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2023-05-25 20:52:02,576 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:52:02,577 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:52:02,577 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2023-05-25 20:52:02,577 - INFO - joeynmt.training - Example #4
2023-05-25 20:52:02,577 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:52:02,577 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:52:02,577 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', '<unk>', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2023-05-25 20:52:02,577 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:52:02,577 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:52:02,577 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen <unk>  ist eine <unk> Version von dem, was in den letzten 25 Jahren <unk>
2023-05-25 20:52:17,779 - INFO - joeynmt.training - Epoch   9, Step:    20600, Batch Loss:     1.319330, Batch Acc: 0.555875, Tokens per Sec:     4302, Lr: 0.000210
2023-05-25 20:52:32,125 - INFO - joeynmt.training - Epoch   9, Step:    20700, Batch Loss:     1.589564, Batch Acc: 0.557691, Tokens per Sec:     4611, Lr: 0.000210
2023-05-25 20:52:46,397 - INFO - joeynmt.training - Epoch   9, Step:    20800, Batch Loss:     1.527567, Batch Acc: 0.553723, Tokens per Sec:     4648, Lr: 0.000210
2023-05-25 20:53:00,587 - INFO - joeynmt.training - Epoch   9, Step:    20900, Batch Loss:     1.517051, Batch Acc: 0.554344, Tokens per Sec:     4685, Lr: 0.000210
2023-05-25 20:53:14,950 - INFO - joeynmt.training - Epoch   9, Step:    21000, Batch Loss:     1.571391, Batch Acc: 0.552862, Tokens per Sec:     4703, Lr: 0.000210
2023-05-25 20:53:14,950 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:53:14,950 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:53:35,863 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.91, ppl:   6.73, acc:   0.44, generation: 20.9086[sec], evaluation: 0.0000[sec]
2023-05-25 20:53:35,864 - INFO - joeynmt.training - Example #0
2023-05-25 20:53:35,864 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:53:35,864 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:53:35,864 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', '<unk>', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', '', 'etwa', 'die', 'Größe', 'des', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:53:35,864 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:53:35,864 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:53:35,864 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese beiden <unk> <unk> um zu zeigen, dass die <unk>  die <unk> die letzten drei Millionen Jahre <unk>  etwa die Größe des <unk> <unk> <unk>
2023-05-25 20:53:35,864 - INFO - joeynmt.training - Example #1
2023-05-25 20:53:35,864 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:53:35,864 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:53:35,864 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'tatsächlich', 'die', '<unk>', 'dieses', '<unk>', 'Problem', '', 'denn', 'es', 'ist', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2023-05-25 20:53:35,864 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:53:35,864 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:53:35,864 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> tatsächlich die <unk> dieses <unk> Problem  denn es ist nicht die <unk> des <unk> <unk>
2023-05-25 20:53:35,864 - INFO - joeynmt.training - Example #2
2023-05-25 20:53:35,864 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:53:35,864 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:53:35,864 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', 'das', '<unk>', 'Herz', 'unserer', '<unk>', '</s>']
2023-05-25 20:53:35,864 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:53:35,864 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:53:35,864 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk>  das <unk> Herz unserer <unk>
2023-05-25 20:53:35,864 - INFO - joeynmt.training - Example #3
2023-05-25 20:53:35,865 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:53:35,865 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:53:35,865 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'der', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2023-05-25 20:53:35,865 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:53:35,865 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:53:35,865 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in der <unk> und <unk> in den <unk>
2023-05-25 20:53:35,865 - INFO - joeynmt.training - Example #4
2023-05-25 20:53:35,865 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:53:35,865 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:53:35,865 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', 'werde,', 'ist', 'eine', '<unk>', 'Version', 'von', 'den', 'letzten', '25', 'Jahren', '<unk>', '<unk>', '</s>']
2023-05-25 20:53:35,865 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:53:35,865 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:53:35,865 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen zeigen werde, ist eine <unk> Version von den letzten 25 Jahren <unk> <unk>
2023-05-25 20:53:50,735 - INFO - joeynmt.training - Epoch   9, Step:    21100, Batch Loss:     1.439885, Batch Acc: 0.551832, Tokens per Sec:     4380, Lr: 0.000210
2023-05-25 20:54:04,773 - INFO - joeynmt.training - Epoch   9, Step:    21200, Batch Loss:     1.372753, Batch Acc: 0.553486, Tokens per Sec:     4753, Lr: 0.000210
2023-05-25 20:54:18,422 - INFO - joeynmt.training - Epoch   9, Step:    21300, Batch Loss:     1.521987, Batch Acc: 0.553435, Tokens per Sec:     4864, Lr: 0.000210
2023-05-25 20:54:32,231 - INFO - joeynmt.training - Epoch   9, Step:    21400, Batch Loss:     1.421372, Batch Acc: 0.550304, Tokens per Sec:     4964, Lr: 0.000210
2023-05-25 20:54:45,911 - INFO - joeynmt.training - Epoch   9, Step:    21500, Batch Loss:     1.404543, Batch Acc: 0.550564, Tokens per Sec:     4827, Lr: 0.000210
2023-05-25 20:54:45,913 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:54:45,913 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:55:09,023 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.92, ppl:   6.85, acc:   0.43, generation: 23.1058[sec], evaluation: 0.0000[sec]
2023-05-25 20:55:09,026 - INFO - joeynmt.training - Example #0
2023-05-25 20:55:09,026 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:55:09,026 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:55:09,026 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', '<unk>', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', '', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:55:09,026 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:55:09,026 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:55:09,026 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr <unk> ich diese beiden <unk> <unk> um  zu zeigen, dass die <unk>  die in den letzten drei Millionen Jahren <unk> <unk> <unk> <unk> <unk>
2023-05-25 20:55:09,026 - INFO - joeynmt.training - Example #1
2023-05-25 20:55:09,026 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:55:09,026 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:55:09,026 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'dieses', '<unk>', 'Problem', '', 'denn', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2023-05-25 20:55:09,027 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:55:09,027 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:55:09,027 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> dieses <unk> Problem  denn es nicht die <unk> des <unk> <unk>
2023-05-25 20:55:09,027 - INFO - joeynmt.training - Example #2
2023-05-25 20:55:09,027 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:55:09,027 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:55:09,027 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', 'das', '<unk>', 'Herz', 'unseres', '<unk>', '<unk>', '</s>']
2023-05-25 20:55:09,027 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:55:09,027 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:55:09,027 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk>  das <unk> Herz unseres <unk> <unk>
2023-05-25 20:55:09,027 - INFO - joeynmt.training - Example #3
2023-05-25 20:55:09,027 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:55:09,027 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:55:09,027 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'aus', 'dem', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2023-05-25 20:55:09,027 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:55:09,027 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:55:09,027 - INFO - joeynmt.training - 	Hypothesis: Es <unk> aus dem <unk> und <unk> in der <unk>
2023-05-25 20:55:09,027 - INFO - joeynmt.training - Example #4
2023-05-25 20:55:09,027 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:55:09,027 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:55:09,027 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', '<unk>', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2023-05-25 20:55:09,028 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:55:09,028 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:55:09,028 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen <unk>  ist eine <unk> Version von den letzten 25 Jahren <unk>
2023-05-25 20:55:22,766 - INFO - joeynmt.training - Epoch   9, Step:    21600, Batch Loss:     1.470809, Batch Acc: 0.551848, Tokens per Sec:     4751, Lr: 0.000210
2023-05-25 20:55:36,313 - INFO - joeynmt.training - Epoch   9, Step:    21700, Batch Loss:     1.446373, Batch Acc: 0.551086, Tokens per Sec:     4822, Lr: 0.000210
2023-05-25 20:55:50,276 - INFO - joeynmt.training - Epoch   9, Step:    21800, Batch Loss:     1.375310, Batch Acc: 0.551042, Tokens per Sec:     4666, Lr: 0.000210
2023-05-25 20:56:04,427 - INFO - joeynmt.training - Epoch   9, Step:    21900, Batch Loss:     1.501380, Batch Acc: 0.552734, Tokens per Sec:     4592, Lr: 0.000210
2023-05-25 20:56:18,346 - INFO - joeynmt.training - Epoch   9, Step:    22000, Batch Loss:     1.385099, Batch Acc: 0.551009, Tokens per Sec:     4644, Lr: 0.000210
2023-05-25 20:56:18,346 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:56:18,346 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:56:37,797 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.89, ppl:   6.59, acc:   0.44, generation: 19.4469[sec], evaluation: 0.0000[sec]
2023-05-25 20:56:37,884 - INFO - joeynmt.helpers - delete models/transformer_model1/20500.ckpt
2023-05-25 20:56:37,888 - INFO - joeynmt.helpers - delete /Users/cyril/Desktop/krizzzzi/mt-exercise-5/models/transformer_model1/20500.ckpt
2023-05-25 20:56:37,888 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /Users/cyril/Desktop/krizzzzi/mt-exercise-5/models/transformer_model1/20500.ckpt but file does not exist. ([Errno 2] No such file or directory: '/Users/cyril/Desktop/krizzzzi/mt-exercise-5/models/transformer_model1/20500.ckpt')
2023-05-25 20:56:37,889 - INFO - joeynmt.training - Example #0
2023-05-25 20:56:37,889 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:56:37,889 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:56:37,889 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', '<unk>', '', 'zu', 'zeigen,', 'dass', 'die', '<unk>', 'die', '<unk>', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', '', '<unk>', 'hatte', 'die', '<unk>', 'der', '<unk>', '', 'mit', '<unk>', '<unk>', '</s>']
2023-05-25 20:56:37,889 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:56:37,889 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:56:37,889 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese beiden <unk> <unk> um <unk>  zu zeigen, dass die <unk> die <unk> die letzten drei Millionen Jahre <unk>  <unk> hatte die <unk> der <unk>  mit <unk> <unk>
2023-05-25 20:56:37,889 - INFO - joeynmt.training - Example #1
2023-05-25 20:56:37,889 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:56:37,889 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:56:37,889 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'dieses', '<unk>', 'ist', 'die', '<unk>', 'dieses', '<unk>', 'Problem', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2023-05-25 20:56:37,889 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:56:37,889 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:56:37,889 - INFO - joeynmt.training - 	Hypothesis: Aber dieses <unk> ist die <unk> dieses <unk> Problem  weil es nicht die <unk> des <unk> <unk>
2023-05-25 20:56:37,889 - INFO - joeynmt.training - Example #2
2023-05-25 20:56:37,889 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:56:37,889 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:56:37,889 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '', 'das', '<unk>', 'Herz', 'unserer', '<unk>', '<unk>', '</s>']
2023-05-25 20:56:37,890 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:56:37,890 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:56:37,890 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk>  das <unk> Herz unserer <unk> <unk>
2023-05-25 20:56:37,890 - INFO - joeynmt.training - Example #3
2023-05-25 20:56:37,890 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:56:37,890 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:56:37,890 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2023-05-25 20:56:37,890 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:56:37,890 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:56:37,890 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in der <unk>
2023-05-25 20:56:37,890 - INFO - joeynmt.training - Example #4
2023-05-25 20:56:37,890 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:56:37,890 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:56:37,890 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'Ihnen', '<unk>', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2023-05-25 20:56:37,890 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:56:37,890 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:56:37,890 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen Ihnen <unk>  ist eine <unk> Version von dem, was in den letzten 25 Jahren <unk>
2023-05-25 20:56:51,711 - INFO - joeynmt.training - Epoch   9, Step:    22100, Batch Loss:     1.472209, Batch Acc: 0.543839, Tokens per Sec:     4608, Lr: 0.000210
2023-05-25 20:56:57,720 - INFO - joeynmt.training - Epoch   9: total training loss 3500.79
2023-05-25 20:56:57,721 - INFO - joeynmt.training - EPOCH 10
2023-05-25 20:57:05,425 - INFO - joeynmt.training - Epoch  10, Step:    22200, Batch Loss:     1.284218, Batch Acc: 0.582462, Tokens per Sec:     4792, Lr: 0.000210
2023-05-25 20:57:19,161 - INFO - joeynmt.training - Epoch  10, Step:    22300, Batch Loss:     1.354611, Batch Acc: 0.571642, Tokens per Sec:     4737, Lr: 0.000210
2023-05-25 20:57:33,328 - INFO - joeynmt.training - Epoch  10, Step:    22400, Batch Loss:     1.327215, Batch Acc: 0.572442, Tokens per Sec:     4726, Lr: 0.000210
2023-05-25 20:57:47,204 - INFO - joeynmt.training - Epoch  10, Step:    22500, Batch Loss:     1.415132, Batch Acc: 0.571333, Tokens per Sec:     4745, Lr: 0.000210
2023-05-25 20:57:47,204 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:57:47,204 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:58:09,188 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.92, ppl:   6.82, acc:   0.43, generation: 21.9789[sec], evaluation: 0.0000[sec]
2023-05-25 20:58:09,190 - INFO - joeynmt.training - Example #0
2023-05-25 20:58:09,190 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:58:09,190 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:58:09,190 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', '', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', '<unk>', '', 'mit', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:58:09,190 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:58:09,190 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:58:09,190 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese beiden <unk> <unk> um  zu zeigen, dass die <unk>  die in den letzten drei Millionen Jahren <unk>  mit <unk> <unk> <unk>
2023-05-25 20:58:09,190 - INFO - joeynmt.training - Example #1
2023-05-25 20:58:09,190 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:58:09,190 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:58:09,190 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'tatsächlich', 'die', '<unk>', 'dieses', '<unk>', 'Problem', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', 'sehen.', '</s>']
2023-05-25 20:58:09,190 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:58:09,190 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:58:09,190 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> tatsächlich die <unk> dieses <unk> Problem  weil es nicht die <unk> des <unk> sehen.
2023-05-25 20:58:09,190 - INFO - joeynmt.training - Example #2
2023-05-25 20:58:09,190 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:58:09,190 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:58:09,190 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '', 'das', '<unk>', 'Herz', 'unseres', '<unk>', '</s>']
2023-05-25 20:58:09,191 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:58:09,191 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:58:09,191 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk>  das <unk> Herz unseres <unk>
2023-05-25 20:58:09,191 - INFO - joeynmt.training - Example #3
2023-05-25 20:58:09,191 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:58:09,191 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:58:09,191 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2023-05-25 20:58:09,191 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:58:09,191 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:58:09,191 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2023-05-25 20:58:09,191 - INFO - joeynmt.training - Example #4
2023-05-25 20:58:09,191 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:58:09,191 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:58:09,191 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', '<unk>', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2023-05-25 20:58:09,191 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:58:09,191 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:58:09,191 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen <unk>  ist eine <unk> Version von dem, was in den letzten 25 Jahren <unk>
2023-05-25 20:58:23,925 - INFO - joeynmt.training - Epoch  10, Step:    22600, Batch Loss:     1.423946, Batch Acc: 0.569469, Tokens per Sec:     4502, Lr: 0.000210
2023-05-25 20:58:37,887 - INFO - joeynmt.training - Epoch  10, Step:    22700, Batch Loss:     1.420264, Batch Acc: 0.570297, Tokens per Sec:     4747, Lr: 0.000210
2023-05-25 20:58:51,854 - INFO - joeynmt.training - Epoch  10, Step:    22800, Batch Loss:     1.439122, Batch Acc: 0.567661, Tokens per Sec:     4681, Lr: 0.000210
2023-05-25 20:59:05,754 - INFO - joeynmt.training - Epoch  10, Step:    22900, Batch Loss:     1.357281, Batch Acc: 0.569473, Tokens per Sec:     4703, Lr: 0.000210
2023-05-25 20:59:19,944 - INFO - joeynmt.training - Epoch  10, Step:    23000, Batch Loss:     1.353347, Batch Acc: 0.568565, Tokens per Sec:     4761, Lr: 0.000210
2023-05-25 20:59:19,946 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 20:59:19,946 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 20:59:39,307 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.94, ppl:   6.96, acc:   0.43, generation: 19.3558[sec], evaluation: 0.0000[sec]
2023-05-25 20:59:39,309 - INFO - joeynmt.training - Example #0
2023-05-25 20:59:39,309 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 20:59:39,309 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 20:59:39,309 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', '<unk>', '', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 20:59:39,309 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 20:59:39,309 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 20:59:39,309 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese beiden <unk> <unk> um <unk>  zu zeigen, dass die <unk>  die in den letzten drei Millionen Jahren <unk> <unk> <unk> <unk>
2023-05-25 20:59:39,309 - INFO - joeynmt.training - Example #1
2023-05-25 20:59:39,309 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 20:59:39,309 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 20:59:39,309 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'eigentlich', 'die', '<unk>', 'dieses', '<unk>', 'Problem', '', 'denn', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', 'sehen.', '</s>']
2023-05-25 20:59:39,310 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 20:59:39,310 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 20:59:39,310 - INFO - joeynmt.training - 	Hypothesis: Aber das ist eigentlich die <unk> dieses <unk> Problem  denn es nicht die <unk> des <unk> sehen.
2023-05-25 20:59:39,310 - INFO - joeynmt.training - Example #2
2023-05-25 20:59:39,310 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 20:59:39,310 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 20:59:39,310 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', 'das', '<unk>', 'Herz', 'unseres', '<unk>', '<unk>', '</s>']
2023-05-25 20:59:39,310 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 20:59:39,310 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 20:59:39,310 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk>  das <unk> Herz unseres <unk> <unk>
2023-05-25 20:59:39,310 - INFO - joeynmt.training - Example #3
2023-05-25 20:59:39,310 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 20:59:39,310 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 20:59:39,310 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2023-05-25 20:59:39,310 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 20:59:39,310 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 20:59:39,310 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2023-05-25 20:59:39,310 - INFO - joeynmt.training - Example #4
2023-05-25 20:59:39,310 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 20:59:39,310 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 20:59:39,310 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', 'werde,', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2023-05-25 20:59:39,310 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 20:59:39,310 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 20:59:39,311 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen zeigen werde, ist eine <unk> Version von dem, was in den letzten 25 Jahren <unk>
2023-05-25 20:59:53,161 - INFO - joeynmt.training - Epoch  10, Step:    23100, Batch Loss:     1.417198, Batch Acc: 0.566027, Tokens per Sec:     4682, Lr: 0.000210
2023-05-25 21:00:06,972 - INFO - joeynmt.training - Epoch  10, Step:    23200, Batch Loss:     1.320288, Batch Acc: 0.563550, Tokens per Sec:     4661, Lr: 0.000210
2023-05-25 21:00:20,571 - INFO - joeynmt.training - Epoch  10, Step:    23300, Batch Loss:     1.435375, Batch Acc: 0.561843, Tokens per Sec:     4796, Lr: 0.000210
2023-05-25 21:00:34,399 - INFO - joeynmt.training - Epoch  10, Step:    23400, Batch Loss:     1.339030, Batch Acc: 0.566542, Tokens per Sec:     4841, Lr: 0.000210
2023-05-25 21:00:48,360 - INFO - joeynmt.training - Epoch  10, Step:    23500, Batch Loss:     1.251310, Batch Acc: 0.559969, Tokens per Sec:     4709, Lr: 0.000210
2023-05-25 21:00:48,361 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 21:00:48,361 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 21:01:08,525 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.93, ppl:   6.92, acc:   0.43, generation: 20.1600[sec], evaluation: 0.0000[sec]
2023-05-25 21:01:08,526 - INFO - joeynmt.training - Example #0
2023-05-25 21:01:08,526 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 21:01:08,526 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 21:01:08,526 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', '<unk>', '', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', '<unk>', '<unk>', 'hatte,', '<unk>', '<unk>', '<unk>', '<unk>', '', 'mit', '<unk>', '<unk>', '</s>']
2023-05-25 21:01:08,526 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 21:01:08,526 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 21:01:08,526 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese beiden <unk> <unk> um <unk>  zu zeigen, dass die <unk>  die in den letzten drei Millionen Jahren <unk> <unk> hatte, <unk> <unk> <unk> <unk>  mit <unk> <unk>
2023-05-25 21:01:08,526 - INFO - joeynmt.training - Example #1
2023-05-25 21:01:08,527 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 21:01:08,527 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 21:01:08,527 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', 'ist', 'eigentlich', 'die', '<unk>', 'dieses', '<unk>', '<unk>', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2023-05-25 21:01:08,527 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 21:01:08,527 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 21:01:08,527 - INFO - joeynmt.training - 	Hypothesis: Aber das ist eigentlich die <unk> dieses <unk> <unk>  weil es nicht die <unk> des <unk> <unk>
2023-05-25 21:01:08,527 - INFO - joeynmt.training - Example #2
2023-05-25 21:01:08,527 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 21:01:08,527 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 21:01:08,527 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '', 'das', '<unk>', 'Herz', 'unserer', '<unk>', '<unk>', '</s>']
2023-05-25 21:01:08,527 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 21:01:08,527 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 21:01:08,527 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk>  das <unk> Herz unserer <unk> <unk>
2023-05-25 21:01:08,527 - INFO - joeynmt.training - Example #3
2023-05-25 21:01:08,527 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 21:01:08,527 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 21:01:08,527 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2023-05-25 21:01:08,527 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 21:01:08,527 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 21:01:08,527 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2023-05-25 21:01:08,527 - INFO - joeynmt.training - Example #4
2023-05-25 21:01:08,527 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 21:01:08,527 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 21:01:08,527 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Als', 'nächstes', '<unk>', 'ich', 'Ihnen', '<unk>', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '<unk>', '</s>']
2023-05-25 21:01:08,528 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 21:01:08,528 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 21:01:08,528 - INFO - joeynmt.training - 	Hypothesis: Als nächstes <unk> ich Ihnen <unk>  ist eine <unk> Version von dem, was in den letzten 25 Jahren <unk> <unk>
2023-05-25 21:01:21,788 - INFO - joeynmt.training - Epoch  10, Step:    23600, Batch Loss:     1.385419, Batch Acc: 0.562380, Tokens per Sec:     4962, Lr: 0.000210
2023-05-25 21:01:35,518 - INFO - joeynmt.training - Epoch  10, Step:    23700, Batch Loss:     1.375553, Batch Acc: 0.559132, Tokens per Sec:     4866, Lr: 0.000210
2023-05-25 21:01:49,417 - INFO - joeynmt.training - Epoch  10, Step:    23800, Batch Loss:     1.520701, Batch Acc: 0.563784, Tokens per Sec:     4781, Lr: 0.000210
2023-05-25 21:02:03,418 - INFO - joeynmt.training - Epoch  10, Step:    23900, Batch Loss:     1.464054, Batch Acc: 0.561842, Tokens per Sec:     4759, Lr: 0.000210
2023-05-25 21:02:17,402 - INFO - joeynmt.training - Epoch  10, Step:    24000, Batch Loss:     1.642792, Batch Acc: 0.560097, Tokens per Sec:     4698, Lr: 0.000210
2023-05-25 21:02:17,402 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 21:02:17,402 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 21:02:36,829 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.91, ppl:   6.75, acc:   0.43, generation: 19.4229[sec], evaluation: 0.0000[sec]
2023-05-25 21:02:36,832 - INFO - joeynmt.training - Example #0
2023-05-25 21:02:36,832 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 21:02:36,832 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 21:02:36,832 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', '<unk>', 'ich', '<unk>', 'diese', 'beiden', '<unk>', 'um', '<unk>', '', 'zu', 'zeigen,', 'dass', 'die', '<unk>', 'die', '<unk>', 'die', '<unk>', '<unk>', '', 'die', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 21:02:36,832 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 21:02:36,832 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 21:02:36,832 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr <unk> ich <unk> diese beiden <unk> um <unk>  zu zeigen, dass die <unk> die <unk> die <unk> <unk>  die <unk> <unk> <unk>
2023-05-25 21:02:36,832 - INFO - joeynmt.training - Example #1
2023-05-25 21:02:36,832 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 21:02:36,832 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 21:02:36,832 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'dieses', '<unk>', 'Problem', '', 'denn', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2023-05-25 21:02:36,832 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 21:02:36,832 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 21:02:36,832 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> dieses <unk> Problem  denn es nicht die <unk> des <unk> <unk>
2023-05-25 21:02:36,832 - INFO - joeynmt.training - Example #2
2023-05-25 21:02:36,832 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 21:02:36,832 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 21:02:36,832 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 21:02:36,833 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 21:02:36,833 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 21:02:36,833 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk> <unk>
2023-05-25 21:02:36,833 - INFO - joeynmt.training - Example #3
2023-05-25 21:02:36,833 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 21:02:36,833 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 21:02:36,833 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2023-05-25 21:02:36,833 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 21:02:36,833 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 21:02:36,833 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in der <unk> und <unk> in der <unk>
2023-05-25 21:02:36,833 - INFO - joeynmt.training - Example #4
2023-05-25 21:02:36,833 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 21:02:36,833 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 21:02:36,833 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', '<unk>', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2023-05-25 21:02:36,833 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 21:02:36,833 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 21:02:36,833 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen <unk>  ist eine <unk> Version von dem, was in den letzten 25 Jahren <unk>
2023-05-25 21:02:51,351 - INFO - joeynmt.training - Epoch  10, Step:    24100, Batch Loss:     1.437913, Batch Acc: 0.563342, Tokens per Sec:     4467, Lr: 0.000147
2023-05-25 21:03:05,420 - INFO - joeynmt.training - Epoch  10, Step:    24200, Batch Loss:     1.422930, Batch Acc: 0.562092, Tokens per Sec:     4602, Lr: 0.000147
2023-05-25 21:03:19,367 - INFO - joeynmt.training - Epoch  10, Step:    24300, Batch Loss:     1.371240, Batch Acc: 0.559179, Tokens per Sec:     4723, Lr: 0.000147
2023-05-25 21:03:33,730 - INFO - joeynmt.training - Epoch  10, Step:    24400, Batch Loss:     1.422970, Batch Acc: 0.567143, Tokens per Sec:     4589, Lr: 0.000147
2023-05-25 21:03:48,271 - INFO - joeynmt.training - Epoch  10, Step:    24500, Batch Loss:     1.434189, Batch Acc: 0.560684, Tokens per Sec:     4476, Lr: 0.000147
2023-05-25 21:03:48,272 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 21:03:48,272 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 21:04:04,960 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.90, ppl:   6.69, acc:   0.44, generation: 16.6835[sec], evaluation: 0.0000[sec]
2023-05-25 21:04:04,962 - INFO - joeynmt.training - Example #0
2023-05-25 21:04:04,962 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2023-05-25 21:04:04,962 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2023-05-25 21:04:04,962 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', '<unk>', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', '<unk>', 'hatte,', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 21:04:04,962 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2023-05-25 21:04:04,963 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-25 21:04:04,963 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese beiden <unk> <unk> um zu zeigen, dass die <unk>  die <unk> die in den letzten drei Millionen Jahren <unk> hatte, <unk> <unk> <unk>
2023-05-25 21:04:04,963 - INFO - joeynmt.training - Example #1
2023-05-25 21:04:04,963 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2023-05-25 21:04:04,963 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2023-05-25 21:04:04,963 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'dieses', '<unk>', 'Problem', '', 'denn', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2023-05-25 21:04:04,963 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2023-05-25 21:04:04,963 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-25 21:04:04,963 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> dieses <unk> Problem  denn es nicht die <unk> des <unk> <unk>
2023-05-25 21:04:04,963 - INFO - joeynmt.training - Example #2
2023-05-25 21:04:04,963 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2023-05-25 21:04:04,963 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2023-05-25 21:04:04,963 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2023-05-25 21:04:04,963 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2023-05-25 21:04:04,963 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-25 21:04:04,963 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk> <unk>
2023-05-25 21:04:04,963 - INFO - joeynmt.training - Example #3
2023-05-25 21:04:04,963 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2023-05-25 21:04:04,963 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2023-05-25 21:04:04,963 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2023-05-25 21:04:04,963 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2023-05-25 21:04:04,964 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2023-05-25 21:04:04,964 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2023-05-25 21:04:04,964 - INFO - joeynmt.training - Example #4
2023-05-25 21:04:04,964 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2023-05-25 21:04:04,964 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2023-05-25 21:04:04,964 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', '<unk>', '', 'ist', 'eine', '<unk>', 'Version', 'davon', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2023-05-25 21:04:04,964 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-25 21:04:04,964 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-25 21:04:04,964 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen <unk>  ist eine <unk> Version davon was in den letzten 25 Jahren <unk>
2023-05-25 21:04:18,136 - INFO - joeynmt.training - Epoch  10, Step:    24600, Batch Loss:     1.469106, Batch Acc: 0.563853, Tokens per Sec:     5077, Lr: 0.000147
2023-05-25 21:04:18,137 - INFO - joeynmt.training - Epoch  10: total training loss 3414.90
2023-05-25 21:04:18,137 - INFO - joeynmt.training - Training ended after  10 epochs.
2023-05-25 21:04:18,137 - INFO - joeynmt.training - Best validation result (greedy) at step    19500:   6.58 ppl.
2023-05-25 21:04:18,147 - INFO - joeynmt.model - Building an encoder-decoder model...
2023-05-25 21:04:18,185 - INFO - joeynmt.model - Enc-dec model built.
2023-05-25 21:04:18,223 - INFO - joeynmt.helpers - Load model from /Users/cyril/Desktop/krizzzzi/mt-exercise-5/models/transformer_model1/19500.ckpt.
2023-05-25 21:04:18,227 - INFO - joeynmt.prediction - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=2004),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=2004),
	loss_function=None)
2023-05-25 21:04:18,230 - INFO - joeynmt.prediction - Decoding on dev set...
2023-05-25 21:04:18,230 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 21:04:18,230 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 21:04:34,935 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 16.7009[sec], evaluation: 0.0000[sec]
2023-05-25 21:04:34,938 - INFO - joeynmt.prediction - Translations saved to: /Users/cyril/Desktop/krizzzzi/mt-exercise-5/models/transformer_model1/00019500.hyps.dev.
2023-05-25 21:04:34,938 - INFO - joeynmt.prediction - Decoding on test set...
2023-05-25 21:04:34,938 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-25 21:04:34,938 - INFO - joeynmt.prediction - Predicting 1779 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-25 21:05:01,800 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 26.8549[sec], evaluation: 0.0000[sec]
2023-05-25 21:05:01,802 - INFO - joeynmt.prediction - Translations saved to: /Users/cyril/Desktop/krizzzzi/mt-exercise-5/models/transformer_model1/00019500.hyps.test.
